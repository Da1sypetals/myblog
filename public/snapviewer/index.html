<!DOCTYPE html>
<html lang="zh-CN" dir="ltr">

<head>
  {{ if .Param "math" }}
  {{ partialCached "math.html" . }}
  {{ end }}
  <script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <title>SnapViewer: Faster PyTorch Memory Allocation Viewer | Da1sypetals</title>
  <link rel="icon" href="/favicon.svg" sizes="any" type="image/svg+xml" />
  <meta property="og:url" content="http://localhost:1313/snapviewer/">
  <meta property="og:site_name" content="Da1sypetals">
  <meta property="og:title" content="SnapViewer: Faster PyTorch Memory Allocation Viewer">
  <meta property="og:description"
    content="Background When training models with PyTorch, out-of-memory (OOM) errors are common, necessitating GPU memory optimization. When simple methods (like reducing batch size) no longer work, analyzing the memory footprint of the model itself may be required.
At this point, you might come across this documentation, which teaches you how to record a memory snapshot and visualize it on this website.
However, there’s a major issue: the website is extremely laggy. If your model is small, with snapshots of just a few MB, the performance is somewhat tolerable. But if your model is large, with snapshots reaching tens or even hundreds of MB, the website becomes unbearably slow, with frame rates dropping as low as 2–3 frames per minute (this is not a typo).">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
  <meta property="article:published_time" content="2025-10-01T16:09:53+08:00">
  <meta property="article:modified_time" content="2025-10-01T16:09:53+08:00">
  <meta property="article:tag" content="Torch">
  <meta property="article:tag" content="Deep-Learning">
  <meta property="article:tag" content="Rust">
  <meta property="article:tag" content="Gui">

  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="SnapViewer: Faster PyTorch Memory Allocation Viewer">
  <meta name="twitter:description"
    content="Background When training models with PyTorch, out-of-memory (OOM) errors are common, necessitating GPU memory optimization. When simple methods (like reducing batch size) no longer work, analyzing the memory footprint of the model itself may be required.
At this point, you might come across this documentation, which teaches you how to record a memory snapshot and visualize it on this website.
However, there’s a major issue: the website is extremely laggy. If your model is small, with snapshots of just a few MB, the performance is somewhat tolerable. But if your model is large, with snapshots reaching tens or even hundreds of MB, the website becomes unbearably slow, with frame rates dropping as low as 2–3 frames per minute (this is not a typo).">

  <link rel="stylesheet" href="/css/root.css">
  <link rel="stylesheet" href="/css/bundle.css">

  <script src="/js/bundle.js"></script>
  <script defer src="/js/search/flexsearch.compact.5e0de3b335e5c523c7cf45473dc43fccb6c75f64a9d59cc04a6eccbb7c25eb49.js"
    integrity="sha256-Xg3jszXlxSPHz0VHPcQ/zLbHX2Sp1ZzASm7Mu3wl60k="></script>
  <script defer src="/js/search/search.1d980f84df11f3eb7c8c5f17f541d49a0611608df179dd74fa7f06225eb56ace.js"
    integrity="sha256-HZgPhN8R8&#43;t8jF8X9UHUmgYRYI3xed10&#43;n8GIl61as4="></script>

  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link
    href="https://fonts.googleapis.com/css2?family=Spectral:ital,wght@0,200;0,300;0,400;0,500;0,600;0,700;0,800;1,200;1,300;1,400;1,500;1,600;1,700;1,800&display=swap"
    rel="stylesheet">
  <link
    href="https://fonts.googleapis.com/css2?family=Bricolage+Grotesque:opsz,wght@12..96,200..800&family=Spectral:ital,wght@0,200;0,300;0,400;0,500;0,600;0,700;0,800;1,200;1,300;1,400;1,500;1,600;1,700;1,800&display=swap"
    rel="stylesheet">

</head>

<body class="notransition">
  <div id="container">
    <header id="main-header">
      <div role="navigation" aria-label="Main">
        <div class="nav-left">
          <a href="http://localhost:1313/" style="color: inherit;">Da1sypetals</a>
        </div>
        <div class="nav-right">
          <div style="position:absolute;width:0px;height:0px;">
            <div id="nav-dropdown-menu" class="hidden" href="#">
              <div class="nav-item">
                <a>Posts</a>
              </div>
              <div class="nav-item">
                <a>Features</a>
              </div>
              <div class="nav-item">
                <a>About</a>
              </div>
            </div>
          </div>
          <a id="nav-dropdown-button" href="#"><svg width="20px" height="20px" viewBox="0 0 24 24" fill="none"
              xmlns="http://www.w3.org/2000/svg">
              <path d="M4 6H20M4 12H20M4 18H20" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                stroke-linejoin="round" />
            </svg>
          </a>
          <div id="nav-menu">
            <div class="nav-item">
              <a>Posts</a>
            </div>
            <div class="nav-item">
              <a>Features</a>
            </div>
            <div class="nav-item">
              <a>About</a>
            </div>
          </div>
          <a id="theme-switcher" href="#">
            <svg class="light-icon" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg">
              <path
                d="M12 3V4M12 20V21M4 12H3M6.31412 6.31412L5.5 5.5M17.6859 6.31412L18.5 5.5M6.31412 17.69L5.5 18.5001M17.6859 17.69L18.5 18.5001M21 12H20M16 12C16 14.2091 14.2091 16 12 16C9.79086 16 8 14.2091 8 12C8 9.79086 9.79086 8 12 8C14.2091 8 16 9.79086 16 12Z"
                stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" />
            </svg>

            <svg class="dark-icon" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg">
              <path
                d="M3.32031 11.6835C3.32031 16.6541 7.34975 20.6835 12.3203 20.6835C16.1075 20.6835 19.3483 18.3443 20.6768 15.032C19.6402 15.4486 18.5059 15.6834 17.3203 15.6834C12.3497 15.6834 8.32031 11.654 8.32031 6.68342C8.32031 5.50338 8.55165 4.36259 8.96453 3.32996C5.65605 4.66028 3.32031 7.89912 3.32031 11.6835Z"
                stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" />
            </svg>
          </a>
        </div>
      </div>
    </header>
    <div class="flex grow">
      <div id="main-pane">
        <main id="main-content">
          <div class="single-header">
            <ol class="breadcrumbs" itemscope itemtype="https://schema.org/BreadcrumbList">
              <li itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
                <a itemprop="item" href="http://localhost:1313/">
                  <span itemprop="name">Home</span>
                </a>
                <meta itemprop="position" content='1' />
              </li>
              <span>&nbsp»&nbsp</span>
            </ol>
            <h1>SnapViewer: Faster PyTorch Memory Allocation Viewer</h1><time class="dim"
              datetime="2025-10-01T16:09:53&#43;08:00">October 1, 2025</time>
            <div class="term-container">
              <div class="tag">
                <a href="http://localhost:1313/tags/torch/">#torch</a>
              </div>
              <div class="tag">
                <a href="http://localhost:1313/tags/deep-learning/">#deep-learning</a>
              </div>
              <div class="tag">
                <a href="http://localhost:1313/tags/rust/">#rust</a>
              </div>
              <div class="tag">
                <a href="http://localhost:1313/tags/gui/">#gui</a>
              </div>
              </ol>
            </div>
            <section class="page-section">
              <h1 id="background">Background</h1>
              <p>When training models with PyTorch, out-of-memory (OOM) errors are common, necessitating GPU memory
                optimization. When simple methods (like reducing batch size) no longer work, analyzing the memory
                footprint of the model itself may be required.</p>
              <p>At this point, you might come across this <a
                  href="https://docs.pytorch.org/docs/stable/torch_cuda_memory.html">documentation</a>, which teaches
                you how to record a memory snapshot and visualize it on this website.</p>
              <p>However, there’s a major issue: the website is extremely laggy. If your model is small, with snapshots
                of just a few MB, the performance is somewhat tolerable. But if your model is large, with snapshots
                reaching tens or even hundreds of MB, the website becomes unbearably slow, with frame rates dropping as
                low as 2–3 frames per minute (this is not a typo).</p>
              <p>I looked into the website’s JavaScript code, and here’s what it primarily does:</p>
              <ol>
                <li>Manually loads Python pickle files;</li>
                <li>Re-parses the raw data into graphical representations time the viewport changes, then renders it to
                  the screen.</li>
              </ol>
              <p>This parsing logic is written in JavaScript. You can imagine the performance when it is executed each
                frame, operating on hundred-MB data.</p>
              <h1 id="inspiration">Inspiration</h1>
              <p>My current work includes optimizing a deep learning model whose optimization is under-explored compared
                to LLM. I encountered this issue while working with a snapshot of a model with several billion
                parameters.</p>
              <p>Why not just use existing LLM infrastructure instead of optimizing manually? Long story short, this
                model was custom-designed by a researcher and contains many modules completely different from standard
                LLMs. It seems like nowadays, everyone assumes deep learning is all about LLMs — so much so that even
                some tech leads believe LLM infrastructure can be easily adapted to other models… but I digress.
                I originally wrote a simple script to parse the snapshot’s contents, hoping to identify memory
                allocation issues in the model. But after working with this model for a month, I finally had enough.
                That’s how this project — SnapViewer — came to be.</p>
              <p>TL;DR​​: The graphical data from the memory snapshot is parsed and represented as a massive triangle
                mesh, leveraging existing rendering libraries to handle mesh rendering efficiently.</p>
              <p>Here’s a snapshot of over 100 MB running smoothly on my integrated GPU:</p>
              <p><img src="../images/snapviewer.gif" alt="snapviewer"></p>
              <h1 id="implementation">Implementation</h1>
              <h2 id="the-reference-implementation">The reference implementation</h2>
              <p>The snapshot format is <em>partially</em> documented in the record_memory_history function&rsquo;s <a
                  href="https://github.com/pytorch/pytorch/blob/main/torch/cuda/memory.py">docstring</a>. However, this
                documentation is incomplete — likely because later updates weren’t reflected in the docstring.</p>
              <p>The actual parsing of the snapshot into a dictionary happens <a
                  href="https://github.com/pytorch/pytorch/blob/main/torch/cuda/_memory_viz.py">here</a>.</p>
              <ol>
                <li>This script converts the allocator trace into a memory timeline, which is then passed to the web
                  viewer’s JS code.</li>
                <li>The JS code further transforms this into polygons (representing allocations) for visualization. Each
                  polygon corresponds to an allocation, storing details like size and callstack.</li>
              </ol>
              <h2 id="implementation-snapshot-deserialize">Implementation: Snapshot (De)serialize</h2>
              <h3 id="initial-implementation">Initial implementation</h3>
              <p>This part is impelmented in Python since I need to deal with Python-native data structures. I simply
                convert the dict to a json file.</p>
              <h3 id="optimizations">Optimizations</h3>
              <ol>
                <li>Raw JSON is too large on disk → compress it in-memory (Python zipfile) before writing.</li>
                <li>During visualization, read the ZIP from disk (Rust zip crate) and decompress in-memory.</li>
              </ol>
              <h4 id="tradeoffs">Tradeoffs</h4>
              <ul>
                <li>This approach causes a temporary memory spike during JSON parsing but avoids persistent high memory
                  usage.</li>
                <li>Also leverages Rust’s serde-json (since Rust’s serde-pickle is incomplete and can’t handle recursive
                  structures).</li>
              </ul>
              <h2 id="implementation-rendering--interaction">Implementation: Rendering &amp; Interaction​​</h2>
              <p>This part is implemented in Rust.</p>
              <h3 id="rendering">Rendering</h3>
              <ul>
                <li>
                  <p>Since allocation data remains static during visualization, all allocations are combined into a
                    single large mesh and sent to the GPU once.</p>
                </li>
                <li>
                  <p>​Library Used​​: three-d</p>
                  <ul>
                    <li>Provides good mesh abstraction.</li>
                    <li>Supports one-time GPU upload (no per-frame CPU→GPU transfers).</li>
                    <li>Handles mouse/keyboard events.</li>
                  </ul>
                </li>
              </ul>
              <h3 id="world-to-window-coordinate-conversion">​World-to-Window Coordinate Conversion​​</h3>
              <ol>
                <li>​Step 1​​: Convert window coordinates to world coordinates (scale + window center offset).</li>
                <li>​​Step 2​​: Convert world coordinates to memory positions (predefined scaling).</li>
              </ol>
              <h3 id="ui--interaction-features">UI &amp; Interaction Features​</h3>
              <h4 id="memory-scale-markers">Memory Scale Markers​​</h4>
              <ul>
                <li>Dynamically adjust the number and precision of markers based on screen visibility.</li>
                <li>Keep markers at consistent screen positions while moving/zooming.</li>
              </ul>
              <h4 id="pan--zoom">Pan &amp; Zoom​​</h4>
              <ol>
                <li>Track the original scale (1/zoom).</li>
                <li>Update to the new zoom level and compute the ratio between old and new scales.</li>
                <li>Adjust the screen center position based on the mouse’s invariant world position.</li>
              </ol>
              <h2 id="implementation-query">Implementation: Query</h2>
              <p>After using this tool at work for around a week, I find myself frequently needing to search in the
                memory snapshot, especially:</p>
              <ul>
                <li>Find all allocations which is alive at a specific timestamp</li>
                <li>Find all allocations whose call stack has a specific substring</li>
                <li>Preferablly the allocations should be sorted by allocation size in descending order</li>
              </ul>
              <p>My first thought was to build a simple REPL and a simple command parser, and map each command to a
                specific query function.</p>
              <p>However, after having listed out all the functionalities I want, I found it to be a subset of database
                query, especially SQL.</p>
              <p>So I decided not to reinvent wheels: I just connect to a in-memory SQLite database. Interfacing user is
                simple: read user input, let SQLite execute it and format the output to human-readable format.</p>
              <hr>
              <p>If you’ve struggled with PyTorch memory snapshots, <a
                  href="https://github.com/Da1sypetals/SnapViewer">check it out</a>! Contributions &amp; feedback
                welcome. ⭐</p>
            </section>
        </main>
        <footer id="main-footer">
          <div class="footer">
            <a href="#">Scroll to Top</a>
            <div class="footer-copyright">
              <div class="dim">© 2025 Da1sypetals</div>
              <div>Made with ❤️ and powered by <a href="https://github.com/math-queiroz/rusty-typewriter"
                  target="_blank">Rusty Typewriter</a> theme for <a href="https://gohugo.io/" target="_blank">Hugo</a>
              </div>
            </div>
          </div>
        </footer>
      </div>
      <aside id="side-pane" class="side-sticky">
        <div class="side-details">
          <span>821 words</span>
          <span>5 - 6 minutes read</span>
        </div>
        <h3>Table Of Contents</h3>
        <nav id="TableOfContents">
          <ul>
            <li><a href="#the-reference-implementation">The reference implementation</a></li>
            <li><a href="#implementation-snapshot-deserialize">Implementation: Snapshot (De)serialize</a>
              <ul>
                <li><a href="#initial-implementation">Initial implementation</a></li>
                <li><a href="#optimizations">Optimizations</a></li>
              </ul>
            </li>
            <li><a href="#implementation-rendering--interaction">Implementation: Rendering &amp; Interaction​​</a>
              <ul>
                <li><a href="#rendering">Rendering</a></li>
                <li><a href="#world-to-window-coordinate-conversion">​World-to-Window Coordinate Conversion​​</a></li>
                <li><a href="#ui--interaction-features">UI &amp; Interaction Features​</a></li>
              </ul>
            </li>
            <li><a href="#implementation-query">Implementation: Query</a></li>
          </ul>
        </nav>
      </aside>
    </div>
  </div>
</body>

</html>