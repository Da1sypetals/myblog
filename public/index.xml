<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Da1sypetals</title>
    <link>https://da1sy-petals.vercel.app/</link>
    <description>Recent content on Da1sypetals</description>
    <generator>Hugo</generator>
    <language>zh-CN</language>
    <lastBuildDate>Thu, 16 Oct 2025 14:57:00 +0800</lastBuildDate>
    <atom:link href="https://da1sy-petals.vercel.app/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>PyG Batching</title>
      <link>https://da1sy-petals.vercel.app/documents/pyg-batching/</link>
      <pubDate>Thu, 16 Oct 2025 14:57:00 +0800</pubDate>
      <guid>https://da1sy-petals.vercel.app/documents/pyg-batching/</guid>
      <description>&lt;p&gt;内容来自&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/advanced/batching.html&#34;&gt;这里&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;p&gt;高级 Mini-Batching（Mini-Batching）&lt;/p&gt;&#xA;&lt;p&gt;创建 mini-batching 对于让深度学习模型的训练扩展到海量数据至关重要。mini-batch 不会一个接一个地处理样本，而是将一组样本分组到一个统一的表示中，从而可以高效地并行处理。在图像或语言领域，这个过程通常是通过将每个样本重新缩放或 padding 到一组等大小的形状来实现的，然后将样本分组到一个额外的维度中。这个维度的长度等于分组在一个 mini-batch 中的样本数量，通常称为 batch_size。&lt;/p&gt;&#xA;&lt;p&gt;由于图是一种最通用的数据结构，可以包含任意数量的节点（nodes）或边（edges），因此上述两种方法要么不可行，要么可能导致大量不必要的内存消耗。在 PyG 中，我们采用另一种方法来实现对大量样本的并行化。在这里，adjacency matrices 以对角线方式堆叠（创建一个包含多个孤立子图的巨大图），并且节点和目标特征（features）简单地沿节点维度进行拼接，即：&lt;/p&gt;&#xA;$$&#xA;A = \begin{bmatrix} A_1 &amp; &amp; \\ &amp; \ddots &amp; \\ &amp; &amp; A_n \end{bmatrix}, \quad&#xA;X = \begin{bmatrix} X_1 \\ \vdots \\ X_n \end{bmatrix}, \quad&#xA;Y = \begin{bmatrix} Y_1 \\ \vdots \\ Y_n \end{bmatrix}.&#xA;$$&lt;p&gt;与其他 batching 过程相比，此过程具有一些关键优势：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;依赖于 message passing scheme 的 GNN operators 不需要修改，因为属于不同图的两个节点之间仍然不能交换消息。&lt;/li&gt;&#xA;&lt;li&gt;没有计算或内存开销。例如，此 batching 过程完全不需要对节点或边的特征进行任何 padding。请注意，adjacency matrices 没有额外的内存开销，因为它们以稀疏（sparse）方式保存，只包含非零项，即边。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;PyG 借助 &lt;code&gt;torch_geometric.loader.DataLoader&lt;/code&gt; 类自动将多个图 batch 成一个巨大的图。在内部，&lt;code&gt;DataLoader&lt;/code&gt; 只是一个常规的 PyTorch torch.utils.data.DataLoader，它重写了其 &lt;code&gt;collate()&lt;/code&gt; 功能，即定义如何将样本列表分组在一起。因此，所有可以传递给 PyTorch DataLoader 的参数也可以传递给 PyG &lt;code&gt;DataLoader&lt;/code&gt;，例如 worker 数量 &lt;code&gt;num_workers&lt;/code&gt;。&lt;/p&gt;</description>
    </item>
    <item>
      <title>我的萝卜头像</title>
      <link>https://da1sy-petals.vercel.app/documents/carrot/</link>
      <pubDate>Sun, 12 Oct 2025 15:29:58 +0800</pubDate>
      <guid>https://da1sy-petals.vercel.app/documents/carrot/</guid>
      <description>&lt;h2 id=&#34;矢量图&#34;&gt;矢量图&lt;/h2&gt;&#xA;&lt;p&gt;&lt;img src=&#34;../images/carrot.svg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;位图hires&#34;&gt;位图，hires&lt;/h2&gt;&#xA;&lt;p&gt;&lt;img src=&#34;../images/carrot_padded.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;位图lowres&#34;&gt;位图，lowres&lt;/h2&gt;&#xA;&lt;p&gt;&lt;img src=&#34;../images/carrot_540.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>全民K歌如何下载歌曲</title>
      <link>https://da1sy-petals.vercel.app/documents/quanmin-download/</link>
      <pubDate>Sun, 05 Oct 2025 21:07:06 +0800</pubDate>
      <guid>https://da1sy-petals.vercel.app/documents/quanmin-download/</guid>
      <description>&lt;h2 id=&#34;1-用默认浏览器打开&#34;&gt;1. 用默认浏览器打开&lt;/h2&gt;&#xA;&lt;p&gt;&lt;img src=&#34;../images/2025-10-05-21-08-03.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;2-按f12然后把focus放在html&#34;&gt;2. 按F12，然后把Focus放在html&lt;/h2&gt;&#xA;&lt;p&gt;先按F12，然后按下面的步骤操作&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;../images/2025-10-05-21-10-32.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;3-搜索音频扩展名&#34;&gt;3. 搜索音频扩展名&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;先随便点一下里面的代码，然后 Ctrl-F&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;搜索&lt;code&gt;.m4a&lt;/code&gt;&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;&lt;img src=&#34;../images/2025-10-05-21-13-53.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;ol start=&#34;3&#34;&gt;&#xA;&lt;li&gt;找到一个含有&lt;code&gt;.m4a&lt;/code&gt; 的链接，&lt;strong&gt;然后双击，复制到新的标签页打开&lt;/strong&gt;。很长一串&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;4-下载&#34;&gt;4. 下载&lt;/h2&gt;&#xA;&lt;p&gt;&lt;img src=&#34;../2025-10-05-21-15-16.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>一个关于GNN在Tensor Core上的实现的数学问题</title>
      <link>https://da1sy-petals.vercel.app/posts/interesting-math-gnn-tensor-core/</link>
      <pubDate>Sat, 04 Oct 2025 16:07:12 +0800</pubDate>
      <guid>https://da1sy-petals.vercel.app/posts/interesting-math-gnn-tensor-core/</guid>
      <description>&lt;h2 id=&#34;完整的问题&#34;&gt;完整的问题&lt;/h2&gt;&#xA;&lt;p&gt;可以看&lt;a href=&#34;https://g.co/gemini/share/ad1bd7ed4a63&#34;&gt;我和Gemini的对话&lt;/a&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;抽象出的问题&#34;&gt;抽象出的问题&lt;/h2&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;假设在mxn的矩阵中全为0，现在进行两个操作：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;以avgdeg/n的概率将矩阵中的值变为1；&lt;/li&gt;&#xA;&lt;li&gt;如果矩阵中有一列有一个1，那就把这一列都变成1。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;现在计算avgdeg&amp;rsquo;为矩阵中1的个数/(mn)，记avgdeg=d, avgdeg&amp;rsquo;=d&#39;&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;h2 id=&#34;kimi的回答&#34;&gt;Kimi的回答&lt;/h2&gt;&#xA;&lt;p&gt;我们来逐步分析这个问题，并给出数学推导。&lt;/p&gt;&#xA;&lt;h3 id=&#34;问题设定&#34;&gt;问题设定&lt;/h3&gt;&#xA;&lt;p&gt;我们有一个 $ m \times n $ 的矩阵，初始时所有元素为 0。&lt;/p&gt;&#xA;&lt;p&gt;进行两个操作：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;随机置 1&lt;/strong&gt;：以概率 $ \frac{\text{avgdeg}}{n} $ 将每个元素独立地变为 1（否则保持 0）。&lt;br&gt;&#xA;记 $ d = \text{avgdeg} $，所以每个元素变为 1 的概率是 $ p = \frac{d}{n} $。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;列传播&lt;/strong&gt;：如果某一列中&lt;strong&gt;至少有一个 1&lt;/strong&gt;，则将该列&lt;strong&gt;所有元素都变为 1&lt;/strong&gt;。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;最终，我们计算新的平均度：&lt;/p&gt;&#xA;\[&#xA;d&#39; = \frac{\text{矩阵中 1 的总数}}{mn}&#xA;\]&lt;p&gt;我们的目标是求 $ d&#39; $ 关于 $ d $ 的表达式，即 $ d&#39; = f(d) $。&lt;/p&gt;&#xA;&lt;h3 id=&#34;步骤-1计算某一列在操作-1-后至少有一个-1的概率&#34;&gt;步骤 1：计算某一列在操作 1 后&lt;strong&gt;至少有一个 1&lt;/strong&gt;的概率&lt;/h3&gt;&#xA;&lt;p&gt;在操作 1 后，每个元素独立地以概率 $ p = \frac{d}{n} $ 变为 1。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Pedalboard 文档</title>
      <link>https://da1sy-petals.vercel.app/documents/pedalboard/</link>
      <pubDate>Sat, 04 Oct 2025 14:20:22 +0800</pubDate>
      <guid>https://da1sy-petals.vercel.app/documents/pedalboard/</guid>
      <description>&lt;p&gt;Github: &lt;a href=&#34;https://github.com/spotify/pedalboard&#34;&gt;https://github.com/spotify/pedalboard&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;Docs: &lt;a href=&#34;https://spotify.github.io/pedalboard/reference/pedalboard.html#pedalboard.LowShelfFilter&#34;&gt;https://spotify.github.io/pedalboard/reference/pedalboard.html#pedalboard.LowShelfFilter&lt;/a&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;pedalboard-api-documentation&#34;&gt;Pedalboard API Documentation&lt;/h1&gt;&#xA;&lt;p&gt;The &lt;code&gt;pedalboard&lt;/code&gt; module provides classes and functions for adding effects to audio. Most classes in this module are subclasses of &lt;code&gt;Plugin&lt;/code&gt;, each of which allows applying effects to an audio buffer or stream.&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; For audio I/O functionality (i.e.: reading and writing audio files), see the &lt;code&gt;pedalboard.io&lt;/code&gt; module.&lt;/p&gt;&lt;/blockquote&gt;&#xA;&lt;p&gt;The &lt;code&gt;pedalboard&lt;/code&gt; module is named after the concept of a guitar pedalboard, in which musicians will chain various effects pedals together to give them complete control over their sound. The &lt;code&gt;pedalboard&lt;/code&gt; module implements this concept with its main &lt;code&gt;Pedalboard&lt;/code&gt; class:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Raddy devlog: forward autodiff system</title>
      <link>https://da1sy-petals.vercel.app/english-post/raddy/</link>
      <pubDate>Thu, 02 Oct 2025 15:15:21 +0800</pubDate>
      <guid>https://da1sy-petals.vercel.app/english-post/raddy/</guid>
      <description>&lt;p&gt;&lt;strong&gt;TL;DR:&lt;/strong&gt; I created &lt;a href=&#34;https://github.com/Da1sypetals/Raddy&#34;&gt;Raddy&lt;/a&gt;, a forward autodiff library, and &lt;a href=&#34;https://github.com/Da1sypetals/Symars&#34;&gt;Symars&lt;/a&gt;, a symbolic codegen library.&lt;/p&gt;&#xA;&lt;p&gt;If you&amp;rsquo;re interested, please give them a star and try them out! ❤️&lt;/p&gt;&#xA;&lt;h2 id=&#34;the-origin-of-the-story&#34;&gt;The Origin of the Story&lt;/h2&gt;&#xA;&lt;p&gt;I recently read papers on physical simulation and wanted to reproduce them. I started with &lt;a href=&#34;https://graphics.pixar.com/library/StableElasticity/paper.pdf&#34;&gt;Stable Neo-Hookean Flesh Simulation&lt;/a&gt;, though the choice isn&amp;rsquo;t critical. Many modern physical simulations are implicit, requiring Newton&amp;rsquo;s method to solve optimization problems.&lt;/p&gt;&#xA;&lt;p&gt;This involves:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Computing derivatives of the constitutive energy model (first-order gradient, second-order Hessian).&lt;/li&gt;&#xA;&lt;li&gt;Assembling a large, sparse Hessian from small, dense Hessian submatrices — a delicate task prone to hard-to-debug bugs.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;From &lt;a href=&#34;https://www.tkim.graphics/DYNAMIC_DEFORMABLES/&#34;&gt;Dynamic Deformables&lt;/a&gt;, I learned deriving these formulas is labor-intensive (even understanding the notation takes time). Searching for alternatives to avoid meticulous debugging, I found two solutions:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Triton Common Pitfalls</title>
      <link>https://da1sy-petals.vercel.app/english-post/triton-pitfalls/</link>
      <pubDate>Thu, 02 Oct 2025 15:12:24 +0800</pubDate>
      <guid>https://da1sy-petals.vercel.app/english-post/triton-pitfalls/</guid>
      <description>&lt;p&gt;From the perspective of a newbie user&lt;/p&gt;&#xA;&lt;h2 id=&#34;the-documentation-is-a-disaster&#34;&gt;The Documentation is a Disaster&lt;/h2&gt;&#xA;&lt;p&gt;Recently, I had to optimize a custom operator and decided to use OpenAI&amp;rsquo;s Triton. After digging into the documentation, I was shocked at how poorly written it is — like an academic paper full of equations but lacking practical code examples.&lt;/p&gt;&#xA;&lt;p&gt;If the library operates on tensors, the docs should clearly specify input/output shapes and provide concrete examples (like PyTorch does). Instead, everything is vaguely described in plain text, leaving users to guess the details.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Try To Implement IPC</title>
      <link>https://da1sy-petals.vercel.app/english-post/try-impl-ipc/</link>
      <pubDate>Thu, 02 Oct 2025 15:03:07 +0800</pubDate>
      <guid>https://da1sy-petals.vercel.app/english-post/try-impl-ipc/</guid>
      <description>&lt;p&gt;&lt;strong&gt;Intro: A taste of the Rust programming language&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;Recently, I tried to get started with Rust and wanted to write some code.&lt;/p&gt;&#xA;&lt;p&gt;Most people&amp;rsquo;s first application is probably some kind of backend service (converting HTTP requests from the frontend into CRUD operations on a database and returning the results to the frontend).&lt;/p&gt;&#xA;&lt;p&gt;However, I&amp;rsquo;ve never learned how to write backend services (I&amp;rsquo;ve been wanting to learn recently — if anyone has good zero-to-hero beginner resources, feel free to recommend them). So, I ended up picking up the two papers I&amp;rsquo;ve been studying lately (@Li2020IPC, @abd) to try reproducing them.&lt;/p&gt;</description>
    </item>
    <item>
      <title>SnapViewer Devlog #3: Optimizations</title>
      <link>https://da1sy-petals.vercel.app/english-post/snapviewer-3-optim/</link>
      <pubDate>Thu, 02 Oct 2025 15:01:14 +0800</pubDate>
      <guid>https://da1sy-petals.vercel.app/english-post/snapviewer-3-optim/</guid>
      <description>&lt;p&gt;&lt;strong&gt;Intro: Troubleshooting Memory and Speed Performance&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Disclaimer:&lt;/strong&gt; I develop and test primarily on Windows using the latest stable Rust toolchain and CPython 3.13.&lt;/p&gt;&#xA;&lt;h2 id=&#34;1-background-and-motivation&#34;&gt;1. Background and Motivation&lt;/h2&gt;&#xA;&lt;p&gt;SnapViewer handles large memory snapshots effectively — for example, pickle files up to 1 GB and compressed snapshots up to 500 MB. However, when processing extremely large dumps (e.g., a 1.3 GB snapshot), we encountered serious memory and speed bottlenecks:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Format conversion (pickle → compressed JSON) triggered memory peaks around 30 GB.&lt;/li&gt;&#xA;&lt;li&gt;Data loading of the compressed JSON into Rust structures caused another ~30 GB spike.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Frequent page faults and intense disk I/O (observed in Task Manager) made the application sluggish and prone to stalls. To address this, we applied a Profile-Guided Optimization (PGO) approach.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Snapviewer Devlog #2: UI</title>
      <link>https://da1sy-petals.vercel.app/english-post/snapviewer-2-ui/</link>
      <pubDate>Thu, 02 Oct 2025 14:56:13 +0800</pubDate>
      <guid>https://da1sy-petals.vercel.app/english-post/snapviewer-2-ui/</guid>
      <description>&lt;p&gt;&lt;strong&gt;Intro: Building the UI as a Hybrid Rust &amp;amp; Python Application&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;Building a UI can often be the trickiest part of a development project, especially when you&amp;rsquo;re trying to integrate different languages and paradigms.&lt;/p&gt;&#xA;&lt;p&gt;For SnapViewer, my memory allocation viewer, I needed an integrated UI that could display allocation details on click and feature a REPL for SQL queries against a SQLite database. This post details my journey, the hurdles I faced, and the solutions I found, primarily focusing on a Rust backend and Python UI.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Notes on Writing PyTorch CUDA Extensions</title>
      <link>https://da1sy-petals.vercel.app/english-post/torch-cuda-ext/</link>
      <pubDate>Thu, 02 Oct 2025 14:48:02 +0800</pubDate>
      <guid>https://da1sy-petals.vercel.app/english-post/torch-cuda-ext/</guid>
      <description>&lt;p&gt;&lt;strong&gt;Intro: PyTorch is a Deep Learning Operating System.&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;check-tensor-storage&#34;&gt;Check tensor storage&lt;/h2&gt;&#xA;&lt;h3 id=&#34;device-check&#34;&gt;Device check&lt;/h3&gt;&#xA;&lt;p&gt;You should ALWAYS check EXPLICITLY whether input tensors are on desired devices. In most cases you want them on the same GPU, or in rare cases you want some tensors on CPU to perform some operations that are not efficient on GPU.&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;API:&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;code&gt;tensor.is_cuda()&lt;/code&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;tensor.device()&lt;/code&gt; (Use &lt;code&gt;operator==&lt;/code&gt; for equality comparison).&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Sometimes the not on correct device problem causes strange error messages like &lt;code&gt;Cusparse context initialization failure&lt;/code&gt; or things even more weird, which first seem unrelated to a device problem. This is why I suggest you always start your debug journey here.&lt;/p&gt;</description>
    </item>
    <item>
      <title>近期GNN Attention算子优化工作速览</title>
      <link>https://da1sy-petals.vercel.app/posts/gnn-optim/</link>
      <pubDate>Thu, 02 Oct 2025 00:00:00 +0000</pubDate>
      <guid>https://da1sy-petals.vercel.app/posts/gnn-optim/</guid>
      <description>&lt;p&gt;注：本文用LLM辅助写作的地方主要在：&lt;em&gt;&lt;strong&gt;我认为LLM比我理解的更好的地方，会用LLM的表述代替。&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;问题设定&#34;&gt;问题设定&lt;/h2&gt;&#xA;&lt;p&gt;需要计算Graph Transformer中的Attention。在此我们忽略multihead-attention，考虑基本的single-head attention.&lt;/p&gt;&#xA;&lt;p&gt;此外，我们的attention mask(邻接矩阵A)是非结构化稀疏的。如果你的attention mask是结构化稀疏的，比如blockwise等可以被代码表示的稀疏pattern，你应该使用flash attention的varlen变体, 或者flex attention等attention编译器。&lt;/p&gt;&#xA;&lt;h3 id=&#34;notation&#34;&gt;Notation&lt;/h3&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;n: 图节点数，规模为 1k~1M&#xD;&#xA;nnz: 图边数（稀疏矩阵非零元素数，Num NonZero）&#xD;&#xA;&#x9;  规模为10n~1000n&#xD;&#xA;q, k, v: (n, d)&#xD;&#xA;A: (n, n), binary, 高度稀疏&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;计算公式&#34;&gt;计算公式&lt;/h3&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;softmax((q @ k.transpose()) * A) @ V&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;其中，&lt;code&gt;@&lt;/code&gt; 表示矩阵乘法，&lt;code&gt;*&lt;/code&gt;表示element-wise乘法。&lt;/p&gt;&#xA;&lt;h2 id=&#34;实现naive-version&#34;&gt;实现：naive version&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;最简单的就是把A给materialize出来，然后用作attention_mask。问题是A是$n^2$的，显存不够用。&lt;/li&gt;&#xA;&lt;li&gt;A用COO方式存储，大小(2,nnz)，然后先把每条边的qk-pair取出来得到(nnz,d)，然后再做reduce和scatter, 和V相乘。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;reformulate&#34;&gt;Reformulate&lt;/h2&gt;&#xA;&lt;p&gt;我们引入三个算子:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;SDDMM (Sampled Dense-Dense MatMul)&lt;/strong&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;A (m, k), B (k, n), 稠密&lt;/li&gt;&#xA;&lt;li&gt;M (n, n)， 稀疏&#xA;SDDMM(A, B, M) 定义为：&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;for i, j in product(range(n), range(n)):&#xD;&#xA;&#x9;if M[i, j] != 0:&#xD;&#xA;&#x9;&#x9;out[i, j] = dot(A[i,:], B[:,j])&#xD;&#xA;&#x9;else:&#xD;&#xA;&#x9;&#x9;out[i, j] = 0&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;&#xA;&lt;li&gt;Sparse Softmax: 在稀疏矩阵上按行softmax&lt;/li&gt;&#xA;&lt;li&gt;SpMM：sparse A @ dense B&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;此时我们的计算公式就可以重新写成:&lt;/p&gt;</description>
    </item>
    <item>
      <title>SnapViewer: Faster PyTorch Memory Allocation Viewer</title>
      <link>https://da1sy-petals.vercel.app/english-post/snapviewer/</link>
      <pubDate>Wed, 01 Oct 2025 16:09:53 +0800</pubDate>
      <guid>https://da1sy-petals.vercel.app/english-post/snapviewer/</guid>
      <description>&lt;h1 id=&#34;background&#34;&gt;Background&lt;/h1&gt;&#xA;&lt;p&gt;When training models with PyTorch, out-of-memory (OOM) errors are common, necessitating GPU memory optimization. When simple methods (like reducing batch size) no longer work, analyzing the memory footprint of the model itself may be required.&lt;/p&gt;&#xA;&lt;p&gt;At this point, you might come across this &lt;a href=&#34;https://docs.pytorch.org/docs/stable/torch_cuda_memory.html&#34;&gt;documentation&lt;/a&gt;, which teaches you how to record a memory snapshot and visualize it on this website.&lt;/p&gt;&#xA;&lt;p&gt;However, there’s a major issue: the website is extremely laggy. If your model is small, with snapshots of just a few MB, the performance is somewhat tolerable. But if your model is large, with snapshots reaching tens or even hundreds of MB, the website becomes unbearably slow, with frame rates dropping as low as 2–3 frames per minute (this is not a typo).&lt;/p&gt;</description>
    </item>
    <item>
      <title>AI怎么解读《牵丝戏》的背景故事？</title>
      <link>https://da1sy-petals.vercel.app/posts/story-qiansixi/</link>
      <pubDate>Tue, 22 Jul 2025 00:00:00 +0000</pubDate>
      <guid>https://da1sy-petals.vercel.app/posts/story-qiansixi/</guid>
      <description>&lt;p&gt;实验设定放在最后。&lt;/p&gt;&#xA;&lt;h2 id=&#34;个人评论&#34;&gt;个人评论&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;不少模型背出了书名《牵丝戏》(未联网), 说明这首歌的知名度确实挺高的.&lt;/li&gt;&#xA;&lt;li&gt;Kimi 继续稳定发挥, 可以说是本土化做的最好的模型之一.&#xA;&lt;ul&gt;&#xA;&lt;li&gt;是苏老师魔改的MuonClip发力了, 还是Kimi的数据团队洗的中文数据最好? 这个我就不得而知了.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;GLM 总是倾向于 &lt;em&gt;详细解释&lt;/em&gt; , 而Kimi更愿意 &lt;em&gt;带着情感和理解重述&lt;/em&gt;.&lt;/li&gt;&#xA;&lt;li&gt;Grok的中文理解能力疑似烂得有点离谱，后续使用Grok可能需要尽量用英文沟通.&lt;/li&gt;&#xA;&lt;li&gt;LongCat和Qwen的的哲学含量比较高, 然而我不懂哲学不好评价. 有意思的事他们还一同主动附上了&amp;quot;现代解读&amp;quot;.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;claude-sonnet-45&#34;&gt;Claude Sonnet 4.5&lt;/h2&gt;&#xA;&lt;p&gt;这是一个凄美动人的志怪故事，蕴含着深刻的人生哲思。让我为你解析其中的层次：&lt;/p&gt;&#xA;&lt;h3 id=&#34;故事梗概&#34;&gt;故事梗概&lt;/h3&gt;&#xA;&lt;p&gt;雪夜荒寺中，&amp;ldquo;我&amp;quot;遇见一位白发苍苍的傀儡艺人。老翁毕生痴迷傀儡技艺，终身漂泊，唯有一具精美木偶相伴。应邀表演后，老翁却迁怒于木偶，认为是它导致自己穷困潦倒，愤而将其投入火中。火光中，木偶如活人般起身作揖告别，含泪一笑化为灰烬。老翁顿悟，哭喊&amp;quot;暖矣，孤矣&amp;rdquo;。&lt;/p&gt;&#xA;&lt;h3 id=&#34;深层寓意&#34;&gt;深层寓意&lt;/h3&gt;&#xA;&lt;p&gt;&lt;strong&gt;1. 艺术与生存的悖论&lt;/strong&gt;&#xA;老翁将一生献给傀儡艺术，却落得贫寒孤苦。这是许多艺术追求者的宿命——精神富足与物质匮乏的尖锐矛盾。他责怪木偶&amp;quot;误&amp;quot;了自己，实际是对命运的质问。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;2. 陪伴与执念的双重性&lt;/strong&gt;&#xA;木偶既是老翁的精神寄托，也是他孤独的见证。&amp;ldquo;居无所行无侣，所伴唯一傀儡木偶&amp;rdquo;——这具木偶填补了他生命的空白，却也映照出他的孤绝。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;3. 木偶显灵的象征&lt;/strong&gt;&#xA;火中木偶&amp;quot;如生人&amp;quot;般作揖告别，这个超自然场景有多重解读：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;艺术赋予的灵性：匠心独运的造物通了人性&lt;/li&gt;&#xA;&lt;li&gt;情感投射的具现：老翁数十年的情感终于得到回应&lt;/li&gt;&#xA;&lt;li&gt;诀别的仪式感：一生羁绊在此刻完成了最后的对话&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;strong&gt;4. &amp;ldquo;暖矣，孤矣&amp;quot;的双关&lt;/strong&gt;&#xA;这四个字是全文的精髓：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;暖矣&lt;/strong&gt;：身体得到了温暖（火焰），冬衣之忧暂解&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;孤矣&lt;/strong&gt;：唯一的伴侣已灭，从此真正形单影只&lt;/li&gt;&#xA;&lt;li&gt;物质与精神、温度与温情的对立统一&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;悲剧内核&#34;&gt;悲剧内核&lt;/h3&gt;&#xA;&lt;p&gt;故事的悲剧性在于：老翁为了眼前的&amp;quot;暖&amp;rdquo;（生存），毁掉了一生的&amp;quot;伴&amp;quot;（意义）。当木偶含泪一笑消失时，他才明白自己失去了什么——不是累赘，而是生命中唯一懂他的&amp;quot;人&amp;quot;。&lt;/p&gt;&#xA;&lt;p&gt;这个故事借志怪之笔，写尽了艺术家的执着与困顿，写尽了人在贫寒与孤独中的挣扎，更写出了那种&amp;quot;清醒得太晚&amp;quot;的追悔莫及。&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;grok&#34;&gt;Grok&lt;/h2&gt;&#xA;&lt;p&gt;Grok 三次把 &amp;ldquo;余少&amp;rdquo; 认成了一个人名🤣, 后续内容不堪入目, 这里跳过.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;kimi-k2&#34;&gt;Kimi K2&lt;/h2&gt;&#xA;&lt;p&gt;这是一个&lt;strong&gt;寓言式的志怪故事&lt;/strong&gt;，表面讲“遇鬼”，实则讲&lt;strong&gt;人一生的执念、孤独与顿悟&lt;/strong&gt;。它用极冷的雪夜、极暖的火焰，演了一出“人焚傀儡，傀儡成人”的反向悲剧——&lt;strong&gt;不是人抛弃了傀儡，而是傀儡终于挣脱了人&lt;/strong&gt;。&lt;/p&gt;&#xA;&lt;h3 id=&#34;逐句拆解&#34;&gt;逐句拆解&lt;/h3&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;&lt;strong&gt;“余少能视鬼，尝于雪夜野寺逢一提傀儡翁……”&lt;/strong&gt;&lt;/p&gt;&lt;/blockquote&gt;&#xA;&lt;p&gt;“我”从小能见鬼，雪夜荒寺，撞见一个&lt;strong&gt;白发破烂的老木偶师&lt;/strong&gt;，手里提着一只&lt;strong&gt;制作极精、宛如少女、眼角绘泪&lt;/strong&gt;的木偶。&lt;br&gt;&#xA;——&lt;strong&gt;鬼不一定是亡魂，也可能是执念的化身&lt;/strong&gt;。老翁本身就是“活鬼”，被技艺与孤独啃噬得只剩空壳。&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;&lt;strong&gt;“翁自述：少时好观牵丝戏……所伴唯一傀儡木偶。”&lt;/strong&gt;&lt;/p&gt;&lt;/blockquote&gt;&#xA;&lt;p&gt;老翁一生只做一件事：演傀儡戏。&lt;br&gt;&#xA;&lt;strong&gt;“以物象人，自得其乐”&lt;/strong&gt;——他把人形寄托在木偶里，反而把真人世界过成了空壳。&lt;br&gt;&#xA;&lt;strong&gt;“漂泊终生，居无所行无侣”&lt;/strong&gt;——技艺成了诅咒：越专注，越被常人世界驱逐。&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;&lt;strong&gt;“演剧于三尺红绵之上……虽妆绘悲容而婉媚绝伦。”&lt;/strong&gt;&lt;/p&gt;&lt;/blockquote&gt;&#xA;&lt;p&gt;这是全篇最暖也最幻灭的一幕：&lt;/p&gt;</description>
    </item>
    <item>
      <title>Snapviewer Devlog #3: 性能优化</title>
      <link>https://da1sy-petals.vercel.app/posts/snapviewer-3-zh/</link>
      <pubDate>Sat, 07 Jun 2025 00:00:00 +0000</pubDate>
      <guid>https://da1sy-petals.vercel.app/posts/snapviewer-3-zh/</guid>
      <description>&lt;h1 id=&#34;内存与速度性能问题排查&#34;&gt;内存与速度性能问题排查&lt;/h1&gt;&#xA;&lt;p&gt;&lt;strong&gt;免责声明&lt;/strong&gt;：我主要在 Windows 上使用最新的稳定版 Rust 工具链和 CPython 3.13 进行开发和测试。&lt;/p&gt;&#xA;&lt;h2 id=&#34;1-背景与动机&#34;&gt;1. 背景与动机&lt;/h2&gt;&#xA;&lt;p&gt;SnapViewer 能够高效处理大型内存快照——例如，支持高达 500 MB 的压缩快照。然而，在处理 1.3 GB的snapshot的时，我发现了严重的内存和速度瓶颈：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;格式转换（pickle → 压缩 JSON）引发了约 30 GB 的内存峰值。&lt;/li&gt;&#xA;&lt;li&gt;将压缩 JSON 加载到 Rust 数据结构中又引发了另一次约 30 GB 的内存激增。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;频繁的 page fault 和强烈的磁盘 I/O（在任务管理器中观察到）导致应用程序响应迟缓，甚至频繁卡顿。为了解决这一问题，我们采用了 Profile-Guided Optimization（PGO，基于性能分析的优化）方法。&lt;/p&gt;&#xA;&lt;h2 id=&#34;2-profile-guided-optimizationpgo&#34;&gt;2. Profile-Guided Optimization（PGO）&lt;/h2&gt;&#xA;&lt;p&gt;PGO 需要通过实证分析来识别真正的热点。我首先使用 &lt;a href=&#34;https://crates.io/crates/memory-stats&#34;&gt;memory-stats&lt;/a&gt; crate 进行内存分析，在早期优化阶段进行轻量级检查。随后，我将数据加载流水线拆解为若干离散步骤：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;读取压缩文件（重度磁盘 I/O）&lt;/li&gt;&#xA;&lt;li&gt;从压缩流中提取 JSON 字符串&lt;/li&gt;&#xA;&lt;li&gt;将 JSON 反序列化为原生 Rust 数据结构&lt;/li&gt;&#xA;&lt;li&gt;填充内存中的 SQLite 数据库以支持即席 SQL 查询&lt;/li&gt;&#xA;&lt;li&gt;在 CPU 上构建三角网格（triangle mesh）&lt;/li&gt;&#xA;&lt;li&gt;初始化渲染窗口（CPU-GPU 数据传输）&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;性能分析揭示了两个主要的内存问题：过度使用 &lt;code&gt;clone&lt;/code&gt; 和多个中间数据结构。以下是我实施的优化措施。&lt;/p&gt;</description>
    </item>
    <item>
      <title>SnapViewer: 更快的PyTorch显存分配可视化</title>
      <link>https://da1sy-petals.vercel.app/posts/snapviewer-zh/</link>
      <pubDate>Fri, 06 Jun 2025 00:00:00 +0000</pubDate>
      <guid>https://da1sy-petals.vercel.app/posts/snapviewer-zh/</guid>
      <description>&lt;h2 id=&#34;背景&#34;&gt;背景&lt;/h2&gt;&#xA;&lt;p&gt;在使用 PyTorch 训练模型时，内存不足（OOM）错误是很常见的，因此需要对 GPU 内存进行优化。当简单的方法（如减少batch size）不再有效时，就需要分析模型本身的内存占用情况。&lt;/p&gt;&#xA;&lt;p&gt;此时，你可能会看到这份&lt;a href=&#34;https://docs.pytorch.org/docs/stable/torch_cuda_memory.html&#34;&gt;文档&lt;/a&gt;，它教你如何记录内存快照并在网站上进行可视化。&lt;/p&gt;&#xA;&lt;p&gt;但是这里存在一个严重的问题：这个网站性能比较差。&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;如果你的模型较小，快照只有几 MB，性能还可以接受。&lt;/li&gt;&#xA;&lt;li&gt;但是如果你的模型很大，快照达到几十甚至上百 MB，网站就会变得极慢，帧率可能低至每分钟 2-3 帧（非笔误）。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;我研究了网站的 JavaScript 代码，其主要功能是：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;手动加载 Python 的 pickle 文件；&lt;/li&gt;&#xA;&lt;li&gt;每次视口发生变化时重新解析原始数据为图形表示，然后将其渲染到屏幕上。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;这些解析逻辑用 JavaScript 编写，你可以想象一下每帧执行这些操作，处理上百 MB 数据要多久.&lt;/p&gt;&#xA;&lt;h2 id=&#34;灵感&#34;&gt;灵感&lt;/h2&gt;&#xA;&lt;p&gt;我当前的工作包括优化一个非LLM的深度学习模型。在处理数十亿参数的模型所导出的显存snapshot时，我遇到了这个问题。&lt;/p&gt;&#xA;&lt;p&gt;为什么不用现有的 LLM 基础设施而选择手动优化？简单地说，这个模型是研究人员自定义设计的，其中包含许多与标准 LLM 完全不同的模块。现在似乎每个人都认为深度学习就只是关于 LLM——以至于一些技术负责人也认为 LLM 的基础设施可以很容易地适配到其他模型上……不过我有点跑题了。&lt;/p&gt;&#xA;&lt;p&gt;最初，我写了一个简单的脚本来解析快照内容，希望能发现模型中的内存分配问题。但是在一个月的工作中，我发现我还是需要一个带有GUI的可视化器, 于是我开发了 SnapViewer.&lt;/p&gt;&#xA;&lt;p&gt;简而言之：内存快照的图形数据被解析并呈现为一个巨大的三角形mesh，利用现有的渲染库来高效处理网格渲染。&lt;/p&gt;&#xA;&lt;p&gt;下面是一个 100 MB 以上的快照在我的集成显卡上流畅运行的截图：&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;../images/snapviewer.gif&#34; alt=&#34;snapviewer&#34;&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;实现&#34;&gt;实现&lt;/h2&gt;&#xA;&lt;h3 id=&#34;参考实现&#34;&gt;参考实现&lt;/h3&gt;&#xA;&lt;p&gt;快照格式在 &lt;code&gt;record_memory_history&lt;/code&gt; 函数的&lt;a href=&#34;https://github.com/pytorch/pytorch/blob/main/torch/cuda/memory.py&#34;&gt;docstring&lt;/a&gt;中有部分记录。但这份文档并不完整, 可能是后续commit的人懒得更新docstring了.&lt;/p&gt;&#xA;&lt;p&gt;实际将快照解析为字典的过程发生在&lt;a href=&#34;https://github.com/pytorch/pytorch/blob/main/torch/cuda/_memory_viz.py&#34;&gt;这里&lt;/a&gt;：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;该脚本将分配器跟踪转换为内存时间线，然后传递给网页查看器的 JS 代码。&lt;/li&gt;&#xA;&lt;li&gt;JS 代码进一步将其转换为多边形（表示分配），用于可视化。每个多边形对应一个分配，存储大小和调用栈等细节。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h3 id=&#34;实现快照-反序列化&#34;&gt;实现：快照 (反)序列化&lt;/h3&gt;&#xA;&lt;h4 id=&#34;初始实现&#34;&gt;初始实现&lt;/h4&gt;&#xA;&lt;p&gt;我用 Python 实现这一部分，因为我需要处理 Python 原生数据结构。我只是简单地将字典转换为 JSON 文件。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Search</title>
      <link>https://da1sy-petals.vercel.app/search/</link>
      <pubDate>Mon, 24 Mar 2025 23:00:00 -0300</pubDate>
      <guid>https://da1sy-petals.vercel.app/search/</guid>
      <description>&lt;h1 id=&#34;search&#34;&gt;Search&lt;/h1&gt;&#xA;&lt;p&gt;What would you like to read today?&lt;/p&gt;&#xA;&lt;p class=&#34;hidden&#34;&gt;It&amp;#39;s necessary to enable Javascript&lt;/p&gt;&#xD;&#xA;&lt;p class=&#34;search-loading hidden&#34;&gt;Loading...&lt;/p&gt;&#xD;&#xA;&#xD;&#xA;&lt;form id=&#34;search-form&#34; class=&#34;search-form&#34; action=&#34;#&#34; method=&#34;post&#34; accept-charset=&#34;UTF-8&#34; role=&#34;search&#34;&gt;&#xD;&#xA;  &lt;div class=&#34;search-bar&#34;&gt;&#xD;&#xA;    &lt;label for=&#34;query&#34; class=&#34;hidden&#34;&gt;&lt;/label&gt;&#xD;&#xA;    &lt;input id=&#34;query&#34; class=&#34;search-text&#34; type=&#34;text&#34; placeholder=&#34;Search...&#34;/&gt;&#xD;&#xA;  &lt;/div&gt;&#xD;&#xA;&lt;/form&gt;&#xD;&#xA;&#xD;&#xA;&lt;div class=&#34;search-results&#34;&gt;&lt;/div&gt;&#xD;&#xA;&#xD;&#xA;&lt;template&gt;&#xD;&#xA;  &lt;article class=&#34;search-result list-view&#34;&gt;&#xD;&#xA;    &lt;header&gt;&#xD;&#xA;      &lt;h2 class=&#34;title&#34;&gt;&lt;a href=&#34;#&#34;&gt;&lt;/a&gt;&lt;/h2&gt;&#xD;&#xA;      &lt;div class=&#34;submitted&#34;&gt;&#xD;&#xA;        &lt;time class=&#34;created-date&#34;&gt;&lt;/time&gt;&#xD;&#xA;      &lt;/div&gt;&#xD;&#xA;    &lt;/header&gt;&#xD;&#xA;    &lt;p class=&#34;content&#34;&gt;&lt;/p&gt;&#xD;&#xA;  &lt;/article&gt;&#xD;&#xA;&lt;/template&gt;</description>
    </item>
    <item>
      <title>Lsm Tree 实现备注</title>
      <link>https://da1sy-petals.vercel.app/posts/lsm/</link>
      <pubDate>Sat, 01 Mar 2025 00:00:00 +0000</pubDate>
      <guid>https://da1sy-petals.vercel.app/posts/lsm/</guid>
      <description>&lt;p&gt;Lsm Tree 是一种内存-磁盘的层级式数据结构，常用于实现写多读少的存储引擎。&lt;/p&gt;&#xA;&lt;p&gt;这是我实现 &lt;a href=&#34;https://github.com/Da1sypetals/Lsmkv&#34;&gt;Lsmkv&lt;/a&gt; 的时候记录的备注.&lt;/p&gt;&#xA;&lt;h2 id=&#34;组件&#34;&gt;组件&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;内存部分&lt;/li&gt;&#xA;&lt;li&gt;磁盘部分&lt;/li&gt;&#xA;&lt;li&gt;WAL&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;总体&#34;&gt;总体&lt;/h2&gt;&#xA;&lt;h2 id=&#34;初始化&#34;&gt;初始化&lt;/h2&gt;&#xA;&lt;p&gt;需要 init flush thread。flush thread 的工作流程:&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;等待 flush 信号量被 notify,获取一个 compact 信号量资源&lt;/li&gt;&#xA;&lt;li&gt;启动一个 sstwriter,写入这个 memtable&#xA;&lt;ul&gt;&#xA;&lt;li&gt;一个 memtable 对一个 sst&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;等到写入 sst 写完之后,才进行:&#xA;&lt;ul&gt;&#xA;&lt;li&gt;从 frozen memtables、frozen memtable sizes 里面删除这个 memtable&lt;/li&gt;&#xA;&lt;li&gt;从 wal 里面删除这个 memtable 对应的 wal&lt;/li&gt;&#xA;&lt;li&gt;update manifest&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;try-freeze&#34;&gt;Try Freeze&lt;/h2&gt;&#xA;&lt;p&gt;如果当前大小 &amp;gt; freeze size 那么就 freeze;进一步如果所有 frozen memtable 大小之和 &amp;gt; flush threshold,那么就 set flush signal。&lt;/p&gt;&#xA;&lt;h2 id=&#34;写操作&#34;&gt;写操作&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;写 memtable&lt;/li&gt;&#xA;&lt;li&gt;写 WAL&lt;/li&gt;&#xA;&lt;li&gt;try freeze&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;内存部分&#34;&gt;内存部分&lt;/h2&gt;&#xA;&lt;h3 id=&#34;put&#34;&gt;Put&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;添加到 memtable;&lt;/li&gt;&#xA;&lt;li&gt;更新 size。&#xA;&lt;ul&gt;&#xA;&lt;li&gt;size 不需要特别精确,只需要是一个大致的值即可。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h3 id=&#34;delete&#34;&gt;Delete&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;添加一个 tomb 标记到 memtable&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h3 id=&#34;get&#34;&gt;Get&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;从 active memtable 中获取&lt;/li&gt;&#xA;&lt;li&gt;从 new 到 old 遍历所有的 inactive memtable,获取。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;磁盘部分&#34;&gt;磁盘部分&lt;/h2&gt;&#xA;&lt;h3 id=&#34;compact-信号量&#34;&gt;compact 信号量&lt;/h3&gt;&#xA;&lt;p&gt;二元信号量。&lt;/p&gt;</description>
    </item>
    <item>
      <title>AI怎么解读银临《迟迟》的背景故事？</title>
      <link>https://da1sy-petals.vercel.app/posts/story-chichi/</link>
      <pubDate>Mon, 13 Jan 2025 00:00:00 +0000</pubDate>
      <guid>https://da1sy-petals.vercel.app/posts/story-chichi/</guid>
      <description>&lt;p&gt;实验设定放在最后。&lt;/p&gt;&#xA;&lt;h2 id=&#34;kimi-k2&#34;&gt;Kimi K2&lt;/h2&gt;&#xA;&lt;p&gt;这个故事是一个关于记忆、爱情与执念的幽怨传说，表面讲的是沈慕云与容娘的“负约”，实则讲的是 &lt;strong&gt;“如何不让一段真情被时间吞没”&lt;/strong&gt; ——哪怕要用谎言、用鬼魂、用一座城三十年不散的闲言碎语，也要把那个人留在人间。&lt;/p&gt;&#xA;&lt;p&gt;容娘（化作“谢娘”）自编自演了一出“赌约”，把负心、等待、重逢这些最戏剧化的扣子全缝进传闻里，让一代又一代外乡人替她“记得”。&lt;strong&gt;真正的负约者不是沈慕云，而是时间&lt;/strong&gt;；真正的守约者也不是容娘，而是“故事”本身——故事替他们完成了“三十年后故地重见”的誓言。&lt;/p&gt;&#xA;&lt;h3 id=&#34;一逐句解词&#34;&gt;一、逐句解词&lt;/h3&gt;&#xA;&lt;p&gt;&lt;strong&gt;小院深静，欲问卿卿，何处月笼明。&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;“小院深静”——当年二人初会的场景：河桥对岸的小院，春月微湿，一切尚未发生。&lt;/li&gt;&#xA;&lt;li&gt;“欲问卿卿”——想开口，却终究没问；一声“卿卿”把未出口的千言万语都压在舌尖。&lt;/li&gt;&#xA;&lt;li&gt;“何处月笼明”——月亮仍在，却照不到当年并肩看月的人；也暗指“容娘”自己已成幽魂，&lt;strong&gt;“月”是人间与冥界的唯一通道&lt;/strong&gt;，她再也回不去了。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;&lt;strong&gt;千秋岁好，休负兰因。&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;“千秋岁好”——字面是祝颂：愿你长享百岁千秋，岁岁安好。&lt;/li&gt;&#xA;&lt;li&gt;“休负兰因”——&lt;strong&gt;“兰因”出自《左传》“兰因絮果”&lt;/strong&gt;，兰因＝美好的开端，絮果＝离散的结局。&lt;br&gt;&#xA;容娘把典故截半，只留“兰因”，是&lt;strong&gt;把结局生生改写成“花开未谢”&lt;/strong&gt;——她不要“絮果”，只要“兰因”永存；换言之，&lt;strong&gt;“你若安好，便不算负我”&lt;/strong&gt;。&lt;/li&gt;&#xA;&lt;li&gt;合在一起，是&lt;strong&gt;鬼魂对活人最温柔的赦令&lt;/strong&gt;：你不必自责，不必回头，甚至不必记得我；只要你在人间岁岁平安，我们那一段“兰因”就从未被辜负。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h3 id=&#34;二整首小词在故事里的功能&#34;&gt;二、整首小词在故事里的功能&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;strong&gt;替沈慕云“平反”&lt;/strong&gt;&lt;br&gt;&#xA;城里传说他“高中负心”，而容娘最后一句“休负兰因”等于亲口否认了“负”字——&lt;strong&gt;“负”是世人附会，“兰因”才是她私藏的真相&lt;/strong&gt;。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;替自己“松绑”&lt;/strong&gt;&lt;br&gt;&#xA;她等了三十年，其实等的不是沈慕云，而是一个&lt;strong&gt;可以自我释怀的叙事版本&lt;/strong&gt;——“千秋岁好”四个字出口，执念才终于落地，鬼魂才能消散。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;把“故事”升华为“公共记忆”&lt;/strong&gt;&lt;br&gt;&#xA;词里“月笼明”是开放画面，任何后来者（包括“我”）只要站在河桥细雨里，就自动成为新的“卿卿”。&lt;strong&gt;故事不死，兰因就不死&lt;/strong&gt;；人间继续流传，她就能继续借他人的心头一点月光，与沈慕云并肩。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h3 id=&#34;三总结&#34;&gt;三、总结&lt;/h3&gt;&#xA;&lt;p&gt;“小院深静……”二十一字，是容娘亲手写给自己的“反向墓志铭”：&lt;br&gt;&#xA;——不写“我曾恨你”，写“愿你安好”；&lt;br&gt;&#xA;——不写“我等你”，写“休负兰因”；&lt;br&gt;&#xA;——不写“故事结束”，写“月笼明”留给下一位行人。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;她用最轻的语调，把最重的执念吹散在雨里：&lt;/strong&gt;&lt;br&gt;&#xA;&lt;strong&gt;“只要世上还有人替我传诵这一句，你就从未真正离开我。”&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;claude-sonnet-45&#34;&gt;Claude Sonnet 4.5&lt;/h2&gt;&#xA;&lt;p&gt;这是一个凄美动人的志怪爱情故事，充满了中国古典文学的浪漫与哀愁。让我为你解读：&lt;/p&gt;&#xA;&lt;h3 id=&#34;故事解读&#34;&gt;故事解读&lt;/h3&gt;&#xA;&lt;p&gt;&lt;strong&gt;真相的反转&lt;/strong&gt;&#xA;故事最精妙之处在于层层剥开的真相:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;表面上是沈慕云负心悔婚的俗套故事&lt;/li&gt;&#xA;&lt;li&gt;实际上容娘早已溺水身亡，她自己编造了所有传言&lt;/li&gt;&#xA;&lt;li&gt;她化身&amp;quot;谢娘&amp;quot;引导&amp;quot;我&amp;quot;，只为让世人记住他们的故事&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;strong&gt;深藏的深情&lt;/strong&gt;&#xA;容娘的所作所为揭示了她至深的爱:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;编造负面传言&lt;/strong&gt;：让沈慕云背负薄情之名，实则是她对这段感情念念不忘的证明&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;&amp;ldquo;三十年之约&amp;rdquo;&lt;/strong&gt;：明知他不会来（因为她已是鬼魂），仍要给自己一个等待的理由&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;最后的谎言&lt;/strong&gt;：当得知沈慕云27岁早逝，她选择相信&amp;quot;我&amp;quot;善意的谎言，带着他幸福的假象消散&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;strong&gt;悲剧的本质&lt;/strong&gt;&#xA;两人都是命运的牺牲品——一个溺水早逝，一个27岁早卒。他们的爱情从未因背叛而破碎，而是被死亡生生拆散。容娘那句&amp;quot;因缘注定，捞一捞终不能得&amp;quot;正是这无奈的注脚。&lt;/p&gt;&#xA;&lt;h3 id=&#34;词句深意解读&#34;&gt;词句深意解读&lt;/h3&gt;&#xA;&lt;p&gt;&lt;strong&gt;&amp;ldquo;小院深静，欲问卿卿，何处月笼明&amp;rdquo;&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;字面含义&lt;/strong&gt;：深深的庭院静悄悄，想要问我的爱人，哪里的月光最明亮？&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;故事中的含义&lt;/strong&gt;：&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&amp;ldquo;小院深静&amp;quot;是她独自等待的孤寂处境&lt;/li&gt;&#xA;&lt;li&gt;&amp;ldquo;欲问卿卿&amp;quot;是她想问沈慕云，却永远无法相见的遗憾&lt;/li&gt;&#xA;&lt;li&gt;&amp;ldquo;何处月笼明&amp;quot;是在问：你在人间何处？那里的月色可好？我们还能否在同一轮明月下相望？&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;strong&gt;&amp;ldquo;千秋岁好，休负兰因&amp;rdquo;&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;字面含义&lt;/strong&gt;：愿你千秋万世安好，不要辜负我们美好的缘分&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;故事中的含义&lt;/strong&gt;：&#xA;&lt;ul&gt;&#xA;&lt;li&gt;这是容娘最后的祝福与释怀&lt;/li&gt;&#xA;&lt;li&gt;&amp;ldquo;千秋岁好&amp;rdquo;：既是祝福沈慕云（虽然他已逝），也是对这段感情的纪念&lt;/li&gt;&#xA;&lt;li&gt;&amp;ldquo;休负兰因&amp;rdquo;：不是责怪他辜负，而是说&amp;quot;我们的缘分虽短暂如兰花，但请你记得它的芬芳，不要忘记我们曾经相爱&amp;rdquo;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;最动人之处&#34;&gt;最动人之处&lt;/h3&gt;&#xA;&lt;p&gt;容娘明知沈慕云已死，却仍要编织&amp;quot;他白头偕老&amp;quot;的幻象来安慰自己；她&amp;quot;任性使坏编排他一回&amp;rdquo;，实则是用全部的爱为他守护名声——宁可世人说她痴情被负，也不愿他在冥冥中孤独。&lt;/p&gt;&#xA;&lt;p&gt;那句&amp;quot;捞一捞终不能得，但宁可难平，也不愿放手&amp;rdquo;，是对所有求而不得之爱最诗意的诠释：&lt;strong&gt;即使知道不可能，也要在记忆里、在传说里，让这份爱永远鲜活&lt;/strong&gt;。&lt;/p&gt;&#xA;&lt;p&gt;这正是中国古典爱情故事的极致浪漫——生死相隔，却以魂灵相守；真相残酷，却以谎言温柔。&lt;/p&gt;&#xA;&lt;h2 id=&#34;gemini-3-flash&#34;&gt;Gemini 3 Flash&lt;/h2&gt;&#xA;&lt;p&gt;这是一个&lt;strong&gt;凄美而富有诗意的爱情故事&lt;/strong&gt;，它通过“我”的视角，揭示了一个被时间、流言和自我幻想所包裹的悲剧真相。故事的魅力在于其层层剥开的悬念，以及对&lt;strong&gt;爱、遗憾、和记忆&lt;/strong&gt;的深刻探讨。&lt;/p&gt;&#xA;&lt;h3 id=&#34;故事解读-1&#34;&gt;故事解读&lt;/h3&gt;&#xA;&lt;h4 id=&#34;1-传说的建构与真相的揭示&#34;&gt;1. 传说的建构与真相的揭示&lt;/h4&gt;&#xA;&lt;p&gt;故事首先提出了关于&lt;strong&gt;沈慕云&lt;/strong&gt;悔婚的三个不同版本，其中城里老人讲述的“赌约”版本最有戏剧性，也吸引了“我”的探访。&lt;/p&gt;</description>
    </item>
    <item>
      <title>自动求导, 道阻且长</title>
      <link>https://da1sy-petals.vercel.app/posts/road-to-diff/</link>
      <pubDate>Sun, 29 Dec 2024 00:00:00 +0000</pubDate>
      <guid>https://da1sy-petals.vercel.app/posts/road-to-diff/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://github.com/Da1sypetals/Symars&#34;&gt;Symars &lt;/a&gt; Rust代码生成库和 &lt;a href=&#34;https://github.com/Da1sypetals/Raddy&#34;&gt;Raddy&lt;/a&gt; 自动求导库的来龙去脉&lt;/p&gt;&#xA;&lt;h2 id=&#34;故事的起因&#34;&gt;故事的起因：&lt;/h2&gt;&#xA;&lt;p&gt;前段时间读了一些物理模拟的论文，想尝试复现一下。下手点先选了 &lt;a href=&#34;https://graphics.pixar.com/library/StableElasticity/paper.pdf&#34;&gt;stable neo hookean flesh simulation&lt;/a&gt;，但是选了什么并不重要。重要的是，所谓“现代”的物理模拟很多是隐式模拟，需要用牛顿法解一个优化问题。&lt;/p&gt;&#xA;&lt;p&gt;这之中就涉及到了：对能量的本构模型求导数（一阶梯度，二阶 hessian 矩阵）。这之中还涉及到从 &lt;em&gt;小而稠密&lt;/em&gt;  的 hessian 子矩阵组装成 &lt;em&gt;大而稀疏&lt;/em&gt; 的完整 hessian。这是一个精细活，一不小心就会出现极其难以排查的 bug。&lt;/p&gt;&#xA;&lt;p&gt;从 &lt;a href=&#34;https://www.tkim.graphics/DYNAMIC_DEFORMABLES/&#34;&gt;&lt;em&gt;Dynamic Deformables&lt;/em&gt;&lt;/a&gt; 这篇文章中可以看出推导这个公式就要花不少功夫（就算是看懂论文里的 notation 也要好一会儿），于是我搜了搜更多东西，尝试寻找一些其他的解决方法：我不是很想在精细的 debug 上花很多时间。最终找到的解决方法有两种：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;求符号导数，然后进行代码生成；&lt;/li&gt;&#xA;&lt;li&gt;自动求导。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;找到的资料中，前者有 MATLAB 或者 SymPy，后者有 PyTorch 等深度学习库，和更适合的 &lt;a href=&#34;https://github.com/patr-schm/TinyAD&#34;&gt;TinyAD&lt;/a&gt;。&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;为什么说更适合？因为深度学习库的求导是以tensor为单位的，但是我这里的求导需要以单个标量为单位，粒度不同，深度学习库可能会跑出完全没法看的帧率。&lt;/p&gt;&lt;/blockquote&gt;&#xA;&lt;p&gt;但是一个致命的问题来了：上述工具都在 C++ 的工具链上，而我不会 C++（或者，我可能会一点点 C++，但是我不会 CMake，因此不会调包。）&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;我曾经花了三天尝试在项目里用上 Eigen，然后失败告终，还是技术水平太菜了。&lt;/p&gt;&lt;/blockquote&gt;&#xA;&lt;p&gt;我只好换一门我比较熟悉的语言：Rust。这是一切罪恶的开始&amp;hellip;&lt;/p&gt;&#xA;&lt;h2 id=&#34;一条看起来简单的路&#34;&gt;一条看起来简单的路&lt;/h2&gt;&#xA;&lt;p&gt;目前 Rust 还没有一个可以求二阶 hessian 的自动求导库（至少我在 crates.io 没搜到）。&lt;br&gt;&#xA;SymPy 目前还不能生成 Rust 代码（可以，但是有 bug）。&lt;br&gt;&#xA;考虑实现难度我先选了后者：从 SymPy 表达式生成 Rust 代码。于是有了 &lt;a href=&#34;https://github.com/Da1sypetals/Symars&#34;&gt;Symars&lt;/a&gt;。&lt;/p&gt;&#xA;&lt;p&gt;SymPy 提供的访问符号表达式的数据结构是树的形式，节点类型是运算符类型（&lt;code&gt;Add&lt;/code&gt;, &lt;code&gt;Mul&lt;/code&gt;, &lt;code&gt;Div&lt;/code&gt;, &lt;code&gt;Sin&lt;/code&gt;, 等等）或者常数/符号，节点的孩子是 operand 操作数。实现代码生成的思路就是按深度优先遍历树，得到孩子的表达式，然后再根据节点类型得到当前节点的表达式。边界条件是当前节点是常数，或者符号。&lt;/p&gt;</description>
    </item>
    <item>
      <title>共轭梯度：一种高中解析几何的视角</title>
      <link>https://da1sy-petals.vercel.app/posts/conj-grad/</link>
      <pubDate>Sat, 07 Dec 2024 00:00:00 +0000</pubDate>
      <guid>https://da1sy-petals.vercel.app/posts/conj-grad/</guid>
      <description>&lt;p&gt;本文没有任何数学推导。我们从直观上理解这个算法，然后直接介绍算法的流程。希望了解数学推导的读者可以查看 &lt;a href=&#34;https://www.cs.cmu.edu/~quake-papers/painless-conjugate-gradient.pdf&#34;&gt;CMU 的教案&lt;/a&gt;及其&lt;a href=&#34;https://flat2010.github.io/2018/10/26/%E5%85%B1%E8%BD%AD%E6%A2%AF%E5%BA%A6%E6%B3%95%E9%80%9A%E4%BF%97%E8%AE%B2%E4%B9%89/#8-%E5%85%B1%E8%BD%AD%E6%A2%AF%E5%BA%A6%E6%B3%95&#34;&gt;翻译&lt;/a&gt;。&lt;/p&gt;&#xA;&lt;h2 id=&#34;1-问题&#34;&gt;1. 问题&lt;/h2&gt;&#xA;&lt;p&gt;对于实对称矩阵 $A \in \mathbb{R}^{n \times n}$ 和向量 $b \in \mathbb{R}^n$，求解&lt;/p&gt;&#xA;$$Ax = b$$&lt;p&gt;或者，等价的，&lt;/p&gt;&#xA;$$\text{argmin}_x f(x)$$&lt;p&gt;其中&lt;/p&gt;&#xA;$$f(x) = \frac{1}{2}x^T A x - b^T x$$&lt;h2 id=&#34;2-预备知识&#34;&gt;2. 预备知识&lt;/h2&gt;&#xA;&lt;h3 id=&#34;21-从高中学的二级结论说起&#34;&gt;2.1. 从高中学的二级结论说起&lt;/h3&gt;&#xA;&lt;p&gt;高中的时候我们学过椭圆：&lt;/p&gt;&#xA;$$a^{-2}x^2 + b^{-2}y^2 = 1$$&lt;p&gt;如果你记性好的话，你应该记得这个二级结论：&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;../images/2025-10-03-00-44-15.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;这是一个从圆里面推广而来的结论：如果 $a = b$，椭圆退化为圆，$k_{OM}k_l = -1$，即 $OM, l$ 两条直线垂直。&lt;/p&gt;&#xA;&lt;h3 id=&#34;22-最速下降法&#34;&gt;2.2. 最速下降法&lt;/h3&gt;&#xA;&lt;p&gt;首先，你应该知道梯度下降法：&lt;/p&gt;&#xA;$$x_{i+1} = x_i - \alpha\nabla f(x_i)$$&lt;p&gt;最速下降法就是在梯度下降法的基础上，选择 $\alpha$ 使得 $x_{i+1}$ 达到最小（在搜索方向上的最小值）：&lt;/p&gt;&#xA;$$\alpha^* = \text{argmin}_\alpha f(x_i - \alpha\nabla f(x_i))$$&lt;h2 id=&#34;3-共轭梯度法&#34;&gt;3. 共轭梯度法&lt;/h2&gt;&#xA;&lt;h3 id=&#34;31-记号&#34;&gt;3.1. 记号&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;$x_i$：第 $i$ 次循环之后的 $x$ 向量&lt;/p&gt;</description>
    </item>
    <item>
      <title>关于我</title>
      <link>https://da1sy-petals.vercel.app/about/</link>
      <pubDate>Tue, 01 Jun 2004 00:00:00 +0000</pubDate>
      <guid>https://da1sy-petals.vercel.app/about/</guid>
      <description>&lt;h2 id=&#34;个人信息&#34;&gt;个人信息&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;名称：黛西&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;Nickname: Da1sypetals&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;Email: &lt;code&gt;da1sypetals.iota@gmail.com&lt;/code&gt;&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;爱好&#34;&gt;爱好&lt;/h2&gt;&#xA;&lt;p&gt;唱&lt;strong&gt;古风歌&lt;/strong&gt;。&lt;/p&gt;&#xA;&lt;p&gt;比如, 我会唱这些：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;《人间不值得》《楚歌起》 黄诗扶&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;《迟迟》《腐草为萤》 银临&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;《故事外的人》 慕寒&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;《惊鹊》《心上秋》 忘川风华录&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;《泼墨漓江》 泠鸢yousa&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;《敢归云间宿》 三无Marblue&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;《忘川》《霁夜茶》 小曲儿&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;《松烟入墨》《如是我闻》 Winky诗&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;《悦神》 KBShinya&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;《第三十八年夏至》《永定四十年》 河图&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;《东风志》 Aki阿杰&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://singings.netlify.app&#34;&gt;这里&lt;/a&gt;还有很多&amp;hellip;&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
  </channel>
</rss>
