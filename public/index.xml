<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Da1sypetals</title>
    <link>http://localhost:1313/</link>
    <description>Recent content on Da1sypetals</description>
    <generator>Hugo</generator>
    <language>zh-CN</language>
    <lastBuildDate>Fri, 03 Oct 2025 01:02:21 +0800</lastBuildDate>
    <atom:link href="http://localhost:1313/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>AI怎么解读银临《迟迟》的背景故事？</title>
      <link>http://localhost:1313/chinese-post/chichi-story/</link>
      <pubDate>Fri, 03 Oct 2025 01:02:21 +0800</pubDate>
      <guid>http://localhost:1313/chinese-post/chichi-story/</guid>
      <description>&lt;p&gt;实验设定放在最后。&lt;/p&gt;&#xA;&lt;h2 id=&#34;kimi-k2&#34;&gt;Kimi K2&lt;/h2&gt;&#xA;&lt;p&gt;这个故事是一个关于记忆、爱情与执念的幽怨传说，表面讲的是沈慕云与容娘的“负约”，实则讲的是 &lt;strong&gt;“如何不让一段真情被时间吞没”&lt;/strong&gt; ——哪怕要用谎言、用鬼魂、用一座城三十年不散的闲言碎语，也要把那个人留在人间。&lt;/p&gt;&#xA;&lt;p&gt;容娘（化作“谢娘”）自编自演了一出“赌约”，把负心、等待、重逢这些最戏剧化的扣子全缝进传闻里，让一代又一代外乡人替她“记得”。&lt;strong&gt;真正的负约者不是沈慕云，而是时间&lt;/strong&gt;；真正的守约者也不是容娘，而是“故事”本身——故事替他们完成了“三十年后故地重见”的誓言。&lt;/p&gt;&#xA;&lt;h3 id=&#34;一逐句解词&#34;&gt;一、逐句解词&lt;/h3&gt;&#xA;&lt;p&gt;&lt;strong&gt;小院深静，欲问卿卿，何处月笼明。&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;“小院深静”——当年二人初会的场景：河桥对岸的小院，春月微湿，一切尚未发生。&lt;/li&gt;&#xA;&lt;li&gt;“欲问卿卿”——想开口，却终究没问；一声“卿卿”把未出口的千言万语都压在舌尖。&lt;/li&gt;&#xA;&lt;li&gt;“何处月笼明”——月亮仍在，却照不到当年并肩看月的人；也暗指“容娘”自己已成幽魂，&lt;strong&gt;“月”是人间与冥界的唯一通道&lt;/strong&gt;，她再也回不去了。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;&lt;strong&gt;千秋岁好，休负兰因。&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;“千秋岁好”——字面是祝颂：愿你长享百岁千秋，岁岁安好。&lt;/li&gt;&#xA;&lt;li&gt;“休负兰因”——&lt;strong&gt;“兰因”出自《左传》“兰因絮果”&lt;/strong&gt;，兰因＝美好的开端，絮果＝离散的结局。&lt;br&gt;&#xA;容娘把典故截半，只留“兰因”，是&lt;strong&gt;把结局生生改写成“花开未谢”&lt;/strong&gt;——她不要“絮果”，只要“兰因”永存；换言之，&lt;strong&gt;“你若安好，便不算负我”&lt;/strong&gt;。&lt;/li&gt;&#xA;&lt;li&gt;合在一起，是&lt;strong&gt;鬼魂对活人最温柔的赦令&lt;/strong&gt;：你不必自责，不必回头，甚至不必记得我；只要你在人间岁岁平安，我们那一段“兰因”就从未被辜负。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h3 id=&#34;二整首小词在故事里的功能&#34;&gt;二、整首小词在故事里的功能&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;strong&gt;替沈慕云“平反”&lt;/strong&gt;&lt;br&gt;&#xA;城里传说他“高中负心”，而容娘最后一句“休负兰因”等于亲口否认了“负”字——&lt;strong&gt;“负”是世人附会，“兰因”才是她私藏的真相&lt;/strong&gt;。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;替自己“松绑”&lt;/strong&gt;&lt;br&gt;&#xA;她等了三十年，其实等的不是沈慕云，而是一个&lt;strong&gt;可以自我释怀的叙事版本&lt;/strong&gt;——“千秋岁好”四个字出口，执念才终于落地，鬼魂才能消散。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;把“故事”升华为“公共记忆”&lt;/strong&gt;&lt;br&gt;&#xA;词里“月笼明”是开放画面，任何后来者（包括“我”）只要站在河桥细雨里，就自动成为新的“卿卿”。&lt;strong&gt;故事不死，兰因就不死&lt;/strong&gt;；人间继续流传，她就能继续借他人的心头一点月光，与沈慕云并肩。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h3 id=&#34;三总结&#34;&gt;三、总结&lt;/h3&gt;&#xA;&lt;p&gt;“小院深静……”二十一字，是容娘亲手写给自己的“反向墓志铭”：&lt;br&gt;&#xA;——不写“我曾恨你”，写“愿你安好”；&lt;br&gt;&#xA;——不写“我等你”，写“休负兰因”；&lt;br&gt;&#xA;——不写“故事结束”，写“月笼明”留给下一位行人。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;她用最轻的语调，把最重的执念吹散在雨里：&lt;/strong&gt;&lt;br&gt;&#xA;&lt;strong&gt;“只要世上还有人替我传诵这一句，你就从未真正离开我。”&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;claude-sonnet-45&#34;&gt;Claude Sonnet 4.5&lt;/h2&gt;&#xA;&lt;p&gt;这是一个凄美动人的志怪爱情故事，充满了中国古典文学的浪漫与哀愁。让我为你解读：&lt;/p&gt;&#xA;&lt;h3 id=&#34;故事解读&#34;&gt;故事解读&lt;/h3&gt;&#xA;&lt;p&gt;&lt;strong&gt;真相的反转&lt;/strong&gt;&#xA;故事最精妙之处在于层层剥开的真相:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;表面上是沈慕云负心悔婚的俗套故事&lt;/li&gt;&#xA;&lt;li&gt;实际上容娘早已溺水身亡，她自己编造了所有传言&lt;/li&gt;&#xA;&lt;li&gt;她化身&amp;quot;谢娘&amp;quot;引导&amp;quot;我&amp;quot;，只为让世人记住他们的故事&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;strong&gt;深藏的深情&lt;/strong&gt;&#xA;容娘的所作所为揭示了她至深的爱:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;编造负面传言&lt;/strong&gt;：让沈慕云背负薄情之名，实则是她对这段感情念念不忘的证明&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;&amp;ldquo;三十年之约&amp;rdquo;&lt;/strong&gt;：明知他不会来（因为她已是鬼魂），仍要给自己一个等待的理由&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;最后的谎言&lt;/strong&gt;：当得知沈慕云27岁早逝，她选择相信&amp;quot;我&amp;quot;善意的谎言，带着他幸福的假象消散&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;strong&gt;悲剧的本质&lt;/strong&gt;&#xA;两人都是命运的牺牲品——一个溺水早逝，一个27岁早卒。他们的爱情从未因背叛而破碎，而是被死亡生生拆散。容娘那句&amp;quot;因缘注定，捞一捞终不能得&amp;quot;正是这无奈的注脚。&lt;/p&gt;&#xA;&lt;h3 id=&#34;词句深意解读&#34;&gt;词句深意解读&lt;/h3&gt;&#xA;&lt;p&gt;&lt;strong&gt;&amp;ldquo;小院深静，欲问卿卿，何处月笼明&amp;rdquo;&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;字面含义&lt;/strong&gt;：深深的庭院静悄悄，想要问我的爱人，哪里的月光最明亮？&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;故事中的含义&lt;/strong&gt;：&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&amp;ldquo;小院深静&amp;quot;是她独自等待的孤寂处境&lt;/li&gt;&#xA;&lt;li&gt;&amp;ldquo;欲问卿卿&amp;quot;是她想问沈慕云，却永远无法相见的遗憾&lt;/li&gt;&#xA;&lt;li&gt;&amp;ldquo;何处月笼明&amp;quot;是在问：你在人间何处？那里的月色可好？我们还能否在同一轮明月下相望？&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;strong&gt;&amp;ldquo;千秋岁好，休负兰因&amp;rdquo;&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;字面含义&lt;/strong&gt;：愿你千秋万世安好，不要辜负我们美好的缘分&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;故事中的含义&lt;/strong&gt;：&#xA;&lt;ul&gt;&#xA;&lt;li&gt;这是容娘最后的祝福与释怀&lt;/li&gt;&#xA;&lt;li&gt;&amp;ldquo;千秋岁好&amp;rdquo;：既是祝福沈慕云（虽然他已逝），也是对这段感情的纪念&lt;/li&gt;&#xA;&lt;li&gt;&amp;ldquo;休负兰因&amp;rdquo;：不是责怪他辜负，而是说&amp;quot;我们的缘分虽短暂如兰花，但请你记得它的芬芳，不要忘记我们曾经相爱&amp;rdquo;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;最动人之处&#34;&gt;最动人之处&lt;/h3&gt;&#xA;&lt;p&gt;容娘明知沈慕云已死，却仍要编织&amp;quot;他白头偕老&amp;quot;的幻象来安慰自己；她&amp;quot;任性使坏编排他一回&amp;rdquo;，实则是用全部的爱为他守护名声——宁可世人说她痴情被负，也不愿他在冥冥中孤独。&lt;/p&gt;&#xA;&lt;p&gt;那句&amp;quot;捞一捞终不能得，但宁可难平，也不愿放手&amp;rdquo;，是对所有求而不得之爱最诗意的诠释：&lt;strong&gt;即使知道不可能，也要在记忆里、在传说里，让这份爱永远鲜活&lt;/strong&gt;。&lt;/p&gt;&#xA;&lt;p&gt;这正是中国古典爱情故事的极致浪漫——生死相隔，却以魂灵相守；真相残酷，却以谎言温柔。&lt;/p&gt;&#xA;&lt;h2 id=&#34;gemini-3-flash&#34;&gt;Gemini 3 Flash&lt;/h2&gt;&#xA;&lt;p&gt;这是一个&lt;strong&gt;凄美而富有诗意的爱情故事&lt;/strong&gt;，它通过“我”的视角，揭示了一个被时间、流言和自我幻想所包裹的悲剧真相。故事的魅力在于其层层剥开的悬念，以及对&lt;strong&gt;爱、遗憾、和记忆&lt;/strong&gt;的深刻探讨。&lt;/p&gt;&#xA;&lt;h3 id=&#34;故事解读-1&#34;&gt;故事解读&lt;/h3&gt;&#xA;&lt;h4 id=&#34;1-传说的建构与真相的揭示&#34;&gt;1. 传说的建构与真相的揭示&lt;/h4&gt;&#xA;&lt;p&gt;故事首先提出了关于&lt;strong&gt;沈慕云&lt;/strong&gt;悔婚的三个不同版本，其中城里老人讲述的“赌约”版本最有戏剧性，也吸引了“我”的探访。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Raddy devlog: forward autodiff system</title>
      <link>http://localhost:1313/english-post/raddy/</link>
      <pubDate>Thu, 02 Oct 2025 15:15:21 +0800</pubDate>
      <guid>http://localhost:1313/english-post/raddy/</guid>
      <description>&lt;p&gt;&lt;strong&gt;TL;DR:&lt;/strong&gt; I created &lt;a href=&#34;https://github.com/Da1sypetals/Raddy&#34;&gt;Raddy&lt;/a&gt;, a forward autodiff library, and &lt;a href=&#34;https://github.com/Da1sypetals/Symars&#34;&gt;Symars&lt;/a&gt;, a symbolic codegen library.&lt;/p&gt;&#xA;&lt;p&gt;If you&amp;rsquo;re interested, please give them a star and try them out! ❤️&lt;/p&gt;&#xA;&lt;h2 id=&#34;the-origin-of-the-story&#34;&gt;The Origin of the Story&lt;/h2&gt;&#xA;&lt;p&gt;I recently read papers on physical simulation and wanted to reproduce them. I started with &lt;a href=&#34;https://graphics.pixar.com/library/StableElasticity/paper.pdf&#34;&gt;Stable Neo-Hookean Flesh Simulation&lt;/a&gt;, though the choice isn&amp;rsquo;t critical. Many modern physical simulations are implicit, requiring Newton&amp;rsquo;s method to solve optimization problems.&lt;/p&gt;&#xA;&lt;p&gt;This involves:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Computing derivatives of the constitutive energy model (first-order gradient, second-order Hessian).&lt;/li&gt;&#xA;&lt;li&gt;Assembling a large, sparse Hessian from small, dense Hessian submatrices — a delicate task prone to hard-to-debug bugs.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;From &lt;a href=&#34;https://www.tkim.graphics/DYNAMIC_DEFORMABLES/&#34;&gt;Dynamic Deformables&lt;/a&gt;, I learned deriving these formulas is labor-intensive (even understanding the notation takes time). Searching for alternatives to avoid meticulous debugging, I found two solutions:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Triton Common Pitfalls</title>
      <link>http://localhost:1313/english-post/triton-pitfalls/</link>
      <pubDate>Thu, 02 Oct 2025 15:12:24 +0800</pubDate>
      <guid>http://localhost:1313/english-post/triton-pitfalls/</guid>
      <description>&lt;p&gt;From the perspective of a newbie user&lt;/p&gt;&#xA;&lt;h2 id=&#34;the-documentation-is-a-disaster&#34;&gt;The Documentation is a Disaster&lt;/h2&gt;&#xA;&lt;p&gt;Recently, I had to optimize a custom operator and decided to use OpenAI&amp;rsquo;s Triton. After digging into the documentation, I was shocked at how poorly written it is — like an academic paper full of equations but lacking practical code examples.&lt;/p&gt;&#xA;&lt;p&gt;If the library operates on tensors, the docs should clearly specify input/output shapes and provide concrete examples (like PyTorch does). Instead, everything is vaguely described in plain text, leaving users to guess the details.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Try To Implement IPC</title>
      <link>http://localhost:1313/english-post/try-impl-ipc/</link>
      <pubDate>Thu, 02 Oct 2025 15:03:07 +0800</pubDate>
      <guid>http://localhost:1313/english-post/try-impl-ipc/</guid>
      <description>&lt;p&gt;&lt;strong&gt;Intro: A taste of the Rust programming language&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;Recently, I tried to get started with Rust and wanted to write some code.&lt;/p&gt;&#xA;&lt;p&gt;Most people&amp;rsquo;s first application is probably some kind of backend service (converting HTTP requests from the frontend into CRUD operations on a database and returning the results to the frontend).&lt;/p&gt;&#xA;&lt;p&gt;However, I&amp;rsquo;ve never learned how to write backend services (I&amp;rsquo;ve been wanting to learn recently — if anyone has good zero-to-hero beginner resources, feel free to recommend them). So, I ended up picking up the two papers I&amp;rsquo;ve been studying lately (@Li2020IPC, @abd) to try reproducing them.&lt;/p&gt;</description>
    </item>
    <item>
      <title>SnapViewer Devlog #3: Optimizations</title>
      <link>http://localhost:1313/english-post/snapviewer-3-optim/</link>
      <pubDate>Thu, 02 Oct 2025 15:01:14 +0800</pubDate>
      <guid>http://localhost:1313/english-post/snapviewer-3-optim/</guid>
      <description>&lt;p&gt;&lt;strong&gt;Intro: Troubleshooting Memory and Speed Performance&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Disclaimer:&lt;/strong&gt; I develop and test primarily on Windows using the latest stable Rust toolchain and CPython 3.13.&lt;/p&gt;&#xA;&lt;h2 id=&#34;1-background-and-motivation&#34;&gt;1. Background and Motivation&lt;/h2&gt;&#xA;&lt;p&gt;SnapViewer handles large memory snapshots effectively — for example, pickle files up to 1 GB and compressed snapshots up to 500 MB. However, when processing extremely large dumps (e.g., a 1.3 GB snapshot), we encountered serious memory and speed bottlenecks:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Format conversion (pickle → compressed JSON) triggered memory peaks around 30 GB.&lt;/li&gt;&#xA;&lt;li&gt;Data loading of the compressed JSON into Rust structures caused another ~30 GB spike.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Frequent page faults and intense disk I/O (observed in Task Manager) made the application sluggish and prone to stalls. To address this, we applied a Profile-Guided Optimization (PGO) approach.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Snapviewer Devlog #2: UI</title>
      <link>http://localhost:1313/english-post/snapviewer-2-ui/</link>
      <pubDate>Thu, 02 Oct 2025 14:56:13 +0800</pubDate>
      <guid>http://localhost:1313/english-post/snapviewer-2-ui/</guid>
      <description>&lt;p&gt;&lt;strong&gt;Intro: Building the UI as a Hybrid Rust &amp;amp; Python Application&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;Building a UI can often be the trickiest part of a development project, especially when you&amp;rsquo;re trying to integrate different languages and paradigms.&lt;/p&gt;&#xA;&lt;p&gt;For SnapViewer, my memory allocation viewer, I needed an integrated UI that could display allocation details on click and feature a REPL for SQL queries against a SQLite database. This post details my journey, the hurdles I faced, and the solutions I found, primarily focusing on a Rust backend and Python UI.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Notes on Writing PyTorch CUDA Extensions</title>
      <link>http://localhost:1313/english-post/torch-cuda-ext/</link>
      <pubDate>Thu, 02 Oct 2025 14:48:02 +0800</pubDate>
      <guid>http://localhost:1313/english-post/torch-cuda-ext/</guid>
      <description>&lt;p&gt;&lt;strong&gt;Intro: PyTorch is a Deep Learning Operating System.&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;check-tensor-storage&#34;&gt;Check tensor storage&lt;/h2&gt;&#xA;&lt;h3 id=&#34;device-check&#34;&gt;Device check&lt;/h3&gt;&#xA;&lt;p&gt;You should ALWAYS check EXPLICITLY whether input tensors are on desired devices. In most cases you want them on the same GPU, or in rare cases you want some tensors on CPU to perform some operations that are not efficient on GPU.&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;API:&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;code&gt;tensor.is_cuda()&lt;/code&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;tensor.device()&lt;/code&gt; (Use &lt;code&gt;operator==&lt;/code&gt; for equality comparison).&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Sometimes the not on correct device problem causes strange error messages like &lt;code&gt;Cusparse context initialization failure&lt;/code&gt; or things even more weird, which first seem unrelated to a device problem. This is why I suggest you always start your debug journey here.&lt;/p&gt;</description>
    </item>
    <item>
      <title>近期GNN Attention算子优化工作速览</title>
      <link>http://localhost:1313/chinese-post/gnn-optim/</link>
      <pubDate>Thu, 02 Oct 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/chinese-post/gnn-optim/</guid>
      <description>&lt;p&gt;注：本文用LLM辅助写作的地方主要在：&lt;em&gt;&lt;strong&gt;我认为LLM比我理解的更好的地方，会用LLM的表述代替。&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;问题设定&#34;&gt;问题设定&lt;/h2&gt;&#xA;&lt;p&gt;需要计算Graph Transformer中的Attention。在此我们忽略multihead-attention，考虑基本的single-head attention.&lt;/p&gt;&#xA;&lt;p&gt;此外，我们的attention mask(邻接矩阵A)是非结构化稀疏的。如果你的attention mask是结构化稀疏的，比如blockwise等可以被代码表示的稀疏pattern，你应该使用flash attention的varlen变体, 或者flex attention等attention编译器。&lt;/p&gt;&#xA;&lt;h3 id=&#34;notation&#34;&gt;Notation&lt;/h3&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;n: 图节点数，规模为 1k~1M&#xD;&#xA;nnz: 图边数（稀疏矩阵非零元素数，Num NonZero）&#xD;&#xA;&#x9;  规模为10n~1000n&#xD;&#xA;q, k, v: (n, d)&#xD;&#xA;A: (n, n), binary, 高度稀疏&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;计算公式&#34;&gt;计算公式&lt;/h3&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;softmax((q @ k.transpose()) * A) @ V&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;其中，&lt;code&gt;@&lt;/code&gt; 表示矩阵乘法，&lt;code&gt;*&lt;/code&gt;表示element-wise乘法。&lt;/p&gt;&#xA;&lt;h2 id=&#34;实现naive-version&#34;&gt;实现：naive version&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;最简单的就是把A给materialize出来，然后用作attention_mask。问题是A是$n^2$的，显存不够用。&lt;/li&gt;&#xA;&lt;li&gt;A用COO方式存储，大小(2,nnz)，然后先把每条边的qk-pair取出来得到(nnz,d)，然后再做reduce和scatter, 和V相乘。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;reformulate&#34;&gt;Reformulate&lt;/h2&gt;&#xA;&lt;p&gt;我们引入三个算子:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;SDDMM (Sampled Dense-Dense MatMul)&lt;/strong&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;A (m, k), B (k, n), 稠密&lt;/li&gt;&#xA;&lt;li&gt;M (n, n)， 稀疏&#xA;SDDMM(A, B, M) 定义为：&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;for i, j in product(range(n), range(n)):&#xD;&#xA;&#x9;if M[i, j] != 0:&#xD;&#xA;&#x9;&#x9;out[i, j] = dot(A[i,:], B[:,j])&#xD;&#xA;&#x9;else:&#xD;&#xA;&#x9;&#x9;out[i, j] = 0&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;&#xA;&lt;li&gt;Sparse Softmax: 在稀疏矩阵上按行softmax&lt;/li&gt;&#xA;&lt;li&gt;SpMM：sparse A @ dense B&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;此时我们的计算公式就可以重新写成:&lt;/p&gt;</description>
    </item>
    <item>
      <title>SnapViewer: Faster PyTorch Memory Allocation Viewer</title>
      <link>http://localhost:1313/english-post/snapviewer/</link>
      <pubDate>Wed, 01 Oct 2025 16:09:53 +0800</pubDate>
      <guid>http://localhost:1313/english-post/snapviewer/</guid>
      <description>&lt;h1 id=&#34;background&#34;&gt;Background&lt;/h1&gt;&#xA;&lt;p&gt;When training models with PyTorch, out-of-memory (OOM) errors are common, necessitating GPU memory optimization. When simple methods (like reducing batch size) no longer work, analyzing the memory footprint of the model itself may be required.&lt;/p&gt;&#xA;&lt;p&gt;At this point, you might come across this &lt;a href=&#34;https://docs.pytorch.org/docs/stable/torch_cuda_memory.html&#34;&gt;documentation&lt;/a&gt;, which teaches you how to record a memory snapshot and visualize it on this website.&lt;/p&gt;&#xA;&lt;p&gt;However, there’s a major issue: the website is extremely laggy. If your model is small, with snapshots of just a few MB, the performance is somewhat tolerable. But if your model is large, with snapshots reaching tens or even hundreds of MB, the website becomes unbearably slow, with frame rates dropping as low as 2–3 frames per minute (this is not a typo).&lt;/p&gt;</description>
    </item>
    <item>
      <title>Snapviewer Devlog #3: 性能优化</title>
      <link>http://localhost:1313/chinese-post/snapviewer-3-zh/</link>
      <pubDate>Sat, 07 Jun 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/chinese-post/snapviewer-3-zh/</guid>
      <description>&lt;h1 id=&#34;内存与速度性能问题排查&#34;&gt;内存与速度性能问题排查&lt;/h1&gt;&#xA;&lt;p&gt;&lt;strong&gt;免责声明&lt;/strong&gt;：我主要在 Windows 上使用最新的稳定版 Rust 工具链和 CPython 3.13 进行开发和测试。&lt;/p&gt;&#xA;&lt;h2 id=&#34;1-背景与动机&#34;&gt;1. 背景与动机&lt;/h2&gt;&#xA;&lt;p&gt;SnapViewer 能够高效处理大型内存快照——例如，支持高达 500 MB 的压缩快照。然而，在处理 1.3 GB的snapshot的时，我发现了严重的内存和速度瓶颈：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;格式转换（pickle → 压缩 JSON）引发了约 30 GB 的内存峰值。&lt;/li&gt;&#xA;&lt;li&gt;将压缩 JSON 加载到 Rust 数据结构中又引发了另一次约 30 GB 的内存激增。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;频繁的 page fault 和强烈的磁盘 I/O（在任务管理器中观察到）导致应用程序响应迟缓，甚至频繁卡顿。为了解决这一问题，我们采用了 Profile-Guided Optimization（PGO，基于性能分析的优化）方法。&lt;/p&gt;&#xA;&lt;h2 id=&#34;2-profile-guided-optimizationpgo&#34;&gt;2. Profile-Guided Optimization（PGO）&lt;/h2&gt;&#xA;&lt;p&gt;PGO 需要通过实证分析来识别真正的热点。我首先使用 &lt;a href=&#34;https://crates.io/crates/memory-stats&#34;&gt;memory-stats&lt;/a&gt; crate 进行内存分析，在早期优化阶段进行轻量级检查。随后，我将数据加载流水线拆解为若干离散步骤：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;读取压缩文件（重度磁盘 I/O）&lt;/li&gt;&#xA;&lt;li&gt;从压缩流中提取 JSON 字符串&lt;/li&gt;&#xA;&lt;li&gt;将 JSON 反序列化为原生 Rust 数据结构&lt;/li&gt;&#xA;&lt;li&gt;填充内存中的 SQLite 数据库以支持即席 SQL 查询&lt;/li&gt;&#xA;&lt;li&gt;在 CPU 上构建三角网格（triangle mesh）&lt;/li&gt;&#xA;&lt;li&gt;初始化渲染窗口（CPU-GPU 数据传输）&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;性能分析揭示了两个主要的内存问题：过度使用 &lt;code&gt;clone&lt;/code&gt; 和多个中间数据结构。以下是我实施的优化措施。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Search</title>
      <link>http://localhost:1313/search/</link>
      <pubDate>Mon, 24 Mar 2025 23:00:00 -0300</pubDate>
      <guid>http://localhost:1313/search/</guid>
      <description>&lt;h1 id=&#34;search&#34;&gt;Search&lt;/h1&gt;&#xA;&lt;p&gt;What would you like to read today?&lt;/p&gt;&#xA;&lt;p class=&#34;hidden&#34;&gt;It&amp;#39;s necessary to enable Javascript&lt;/p&gt;&#xD;&#xA;&lt;p class=&#34;search-loading hidden&#34;&gt;Loading...&lt;/p&gt;&#xD;&#xA;&#xD;&#xA;&lt;form id=&#34;search-form&#34; class=&#34;search-form&#34; action=&#34;#&#34; method=&#34;post&#34; accept-charset=&#34;UTF-8&#34; role=&#34;search&#34;&gt;&#xD;&#xA;  &lt;div class=&#34;search-bar&#34;&gt;&#xD;&#xA;    &lt;label for=&#34;query&#34; class=&#34;hidden&#34;&gt;&lt;/label&gt;&#xD;&#xA;    &lt;input id=&#34;query&#34; class=&#34;search-text&#34; type=&#34;text&#34; placeholder=&#34;Search...&#34;/&gt;&#xD;&#xA;  &lt;/div&gt;&#xD;&#xA;&lt;/form&gt;&#xD;&#xA;&#xD;&#xA;&lt;div class=&#34;search-results&#34;&gt;&lt;/div&gt;&#xD;&#xA;&#xD;&#xA;&lt;template&gt;&#xD;&#xA;  &lt;article class=&#34;search-result list-view&#34;&gt;&#xD;&#xA;    &lt;header&gt;&#xD;&#xA;      &lt;h2 class=&#34;title&#34;&gt;&lt;a href=&#34;#&#34;&gt;&lt;/a&gt;&lt;/h2&gt;&#xD;&#xA;      &lt;div class=&#34;submitted&#34;&gt;&#xD;&#xA;        &lt;time class=&#34;created-date&#34;&gt;&lt;/time&gt;&#xD;&#xA;      &lt;/div&gt;&#xD;&#xA;    &lt;/header&gt;&#xD;&#xA;    &lt;p class=&#34;content&#34;&gt;&lt;/p&gt;&#xD;&#xA;  &lt;/article&gt;&#xD;&#xA;&lt;/template&gt;</description>
    </item>
    <item>
      <title>Lsm Tree 实现备注</title>
      <link>http://localhost:1313/chinese-post/lsm/</link>
      <pubDate>Sat, 01 Mar 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/chinese-post/lsm/</guid>
      <description>&lt;p&gt;Lsm Tree 是一种内存-磁盘的层级式数据结构，常用于实现写多读少的存储引擎。&lt;/p&gt;&#xA;&lt;p&gt;这是我实现 &lt;a href=&#34;https://github.com/Da1sypetals/Lsmkv&#34;&gt;Lsmkv&lt;/a&gt; 的时候记录的备注.&lt;/p&gt;&#xA;&lt;h2 id=&#34;组件&#34;&gt;组件&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;内存部分&lt;/li&gt;&#xA;&lt;li&gt;磁盘部分&lt;/li&gt;&#xA;&lt;li&gt;WAL&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;总体&#34;&gt;总体&lt;/h2&gt;&#xA;&lt;h2 id=&#34;初始化&#34;&gt;初始化&lt;/h2&gt;&#xA;&lt;p&gt;需要 init flush thread。flush thread 的工作流程:&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;等待 flush 信号量被 notify,获取一个 compact 信号量资源&lt;/li&gt;&#xA;&lt;li&gt;启动一个 sstwriter,写入这个 memtable&#xA;&lt;ul&gt;&#xA;&lt;li&gt;一个 memtable 对一个 sst&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;等到写入 sst 写完之后,才进行:&#xA;&lt;ul&gt;&#xA;&lt;li&gt;从 frozen memtables、frozen memtable sizes 里面删除这个 memtable&lt;/li&gt;&#xA;&lt;li&gt;从 wal 里面删除这个 memtable 对应的 wal&lt;/li&gt;&#xA;&lt;li&gt;update manifest&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;try-freeze&#34;&gt;Try Freeze&lt;/h2&gt;&#xA;&lt;p&gt;如果当前大小 &amp;gt; freeze size 那么就 freeze;进一步如果所有 frozen memtable 大小之和 &amp;gt; flush threshold,那么就 set flush signal。&lt;/p&gt;&#xA;&lt;h2 id=&#34;写操作&#34;&gt;写操作&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;写 memtable&lt;/li&gt;&#xA;&lt;li&gt;写 WAL&lt;/li&gt;&#xA;&lt;li&gt;try freeze&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;内存部分&#34;&gt;内存部分&lt;/h2&gt;&#xA;&lt;h3 id=&#34;put&#34;&gt;Put&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;添加到 memtable;&lt;/li&gt;&#xA;&lt;li&gt;更新 size。&#xA;&lt;ul&gt;&#xA;&lt;li&gt;size 不需要特别精确,只需要是一个大致的值即可。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h3 id=&#34;delete&#34;&gt;Delete&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;添加一个 tomb 标记到 memtable&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h3 id=&#34;get&#34;&gt;Get&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;从 active memtable 中获取&lt;/li&gt;&#xA;&lt;li&gt;从 new 到 old 遍历所有的 inactive memtable,获取。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;磁盘部分&#34;&gt;磁盘部分&lt;/h2&gt;&#xA;&lt;h3 id=&#34;compact-信号量&#34;&gt;compact 信号量&lt;/h3&gt;&#xA;&lt;p&gt;二元信号量。&lt;/p&gt;</description>
    </item>
    <item>
      <title>共轭梯度：高中解析几何的拓展</title>
      <link>http://localhost:1313/chinese-post/conj-grad/</link>
      <pubDate>Sat, 07 Dec 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/chinese-post/conj-grad/</guid>
      <description>&lt;p&gt;本文没有任何数学推导。我们从直观上理解这个算法，然后直接介绍算法的流程。希望了解数学推导的读者可以查看 &lt;a href=&#34;https://www.cs.cmu.edu/~quake-papers/painless-conjugate-gradient.pdf&#34;&gt;CMU 的教案&lt;/a&gt;及其&lt;a href=&#34;https://flat2010.github.io/2018/10/26/%E5%85%B1%E8%BD%AD%E6%A2%AF%E5%BA%A6%E6%B3%95%E9%80%9A%E4%BF%97%E8%AE%B2%E4%B9%89/#8-%E5%85%B1%E8%BD%AD%E6%A2%AF%E5%BA%A6%E6%B3%95&#34;&gt;翻译&lt;/a&gt;。&lt;/p&gt;&#xA;&lt;h2 id=&#34;1-问题&#34;&gt;1. 问题&lt;/h2&gt;&#xA;&lt;p&gt;对于实对称矩阵 $A \in \mathbb{R}^{n \times n}$ 和向量 $b \in \mathbb{R}^n$，求解&lt;/p&gt;&#xA;$$Ax = b$$&lt;p&gt;或者，等价的，&lt;/p&gt;&#xA;$$\text{argmin}_x f(x)$$&lt;p&gt;其中&lt;/p&gt;&#xA;$$f(x) = \frac{1}{2}x^T A x - b^T x$$&lt;h2 id=&#34;2-预备知识&#34;&gt;2. 预备知识&lt;/h2&gt;&#xA;&lt;h3 id=&#34;21-从高中学的二级结论说起&#34;&gt;2.1. 从高中学的二级结论说起&lt;/h3&gt;&#xA;&lt;p&gt;高中的时候我们学过椭圆：&lt;/p&gt;&#xA;$$a^{-2}x^2 + b^{-2}y^2 = 1$$&lt;p&gt;如果你记性好的话，你应该记得这个二级结论：&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;../images/2025-10-03-00-44-15.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;这是一个从圆里面推广而来的结论：如果 $a = b$，椭圆退化为圆，$k_{OM}k_l = -1$，即 $OM, l$ 两条直线垂直。&lt;/p&gt;&#xA;&lt;h3 id=&#34;22-最速下降法&#34;&gt;2.2. 最速下降法&lt;/h3&gt;&#xA;&lt;p&gt;首先，你应该知道梯度下降法：&lt;/p&gt;&#xA;$$x_{i+1} = x_i - \alpha\nabla f(x_i)$$&lt;p&gt;最速下降法就是在梯度下降法的基础上，选择 $\alpha$ 使得 $x_{i+1}$ 达到最小（在搜索方向上的最小值）：&lt;/p&gt;&#xA;$$\alpha^* = \text{argmin}_\alpha f(x_i - \alpha\nabla f(x_i))$$&lt;h2 id=&#34;3-共轭梯度法&#34;&gt;3. 共轭梯度法&lt;/h2&gt;&#xA;&lt;h3 id=&#34;31-记号&#34;&gt;3.1. 记号&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;$x_i$：第 $i$ 次循环之后的 $x$ 向量&lt;/p&gt;</description>
    </item>
    <item>
      <title>About</title>
      <link>http://localhost:1313/about/</link>
      <pubDate>Tue, 01 Jun 2004 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/about/</guid>
      <description>&lt;h1 id=&#34;个人信息&#34;&gt;个人信息&lt;/h1&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;名称：黛西&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;Nickname: Da1sypetals&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://drive.google.com/file/d/1LaMUEAR6m0tZpj-VpTIcS5DMKO6lRujL/view?usp=drive_link&#34;&gt;我的简历&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h1 id=&#34;爱好&#34;&gt;爱好&lt;/h1&gt;&#xA;&lt;p&gt;唱&lt;strong&gt;古风歌&lt;/strong&gt;。&lt;/p&gt;&#xA;&lt;p&gt;我会唱这些：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;《人间不值得》《楚歌起》 黄诗扶&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;《迟迟》《腐草为萤》 银临&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;《故事外的人》 慕寒&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;《惊鹊》《心上秋》 忘川风华录&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;《泼墨漓江》 泠鸢yousa&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;《敢归云间宿》 三无Marblue&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;《忘川》《霁夜茶》 小曲儿&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;《松烟入墨》《如是我闻》 Winky诗&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;《悦神》 KBShinya&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;《第三十八年夏至》《永定四十年》 河图&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;《东风志》 Aki阿杰&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://singings.netlify.app&#34;&gt;这里&lt;/a&gt;还有很多&amp;hellip;&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
  </channel>
</rss>
