[{"content":"å®éªŒè®¾å®šæ”¾åœ¨æœ€åã€‚\nKimi K2 è¿™ä¸ªæ•…äº‹æ˜¯ä¸€ä¸ªå…³äºè®°å¿†ã€çˆ±æƒ…ä¸æ‰§å¿µçš„å¹½æ€¨ä¼ è¯´ï¼Œè¡¨é¢è®²çš„æ˜¯æ²ˆæ…•äº‘ä¸å®¹å¨˜çš„â€œè´Ÿçº¦â€ï¼Œå®åˆ™è®²çš„æ˜¯ â€œå¦‚ä½•ä¸è®©ä¸€æ®µçœŸæƒ…è¢«æ—¶é—´åæ²¡â€ â€”â€”å“ªæ€•è¦ç”¨è°è¨€ã€ç”¨é¬¼é­‚ã€ç”¨ä¸€åº§åŸä¸‰åå¹´ä¸æ•£çš„é—²è¨€ç¢è¯­ï¼Œä¹Ÿè¦æŠŠé‚£ä¸ªäººç•™åœ¨äººé—´ã€‚\nå®¹å¨˜ï¼ˆåŒ–ä½œâ€œè°¢å¨˜â€ï¼‰è‡ªç¼–è‡ªæ¼”äº†ä¸€å‡ºâ€œèµŒçº¦â€ï¼ŒæŠŠè´Ÿå¿ƒã€ç­‰å¾…ã€é‡é€¢è¿™äº›æœ€æˆå‰§åŒ–çš„æ‰£å­å…¨ç¼è¿›ä¼ é—»é‡Œï¼Œè®©ä¸€ä»£åˆä¸€ä»£å¤–ä¹¡äººæ›¿å¥¹â€œè®°å¾—â€ã€‚çœŸæ­£çš„è´Ÿçº¦è€…ä¸æ˜¯æ²ˆæ…•äº‘ï¼Œè€Œæ˜¯æ—¶é—´ï¼›çœŸæ­£çš„å®ˆçº¦è€…ä¹Ÿä¸æ˜¯å®¹å¨˜ï¼Œè€Œæ˜¯â€œæ•…äº‹â€æœ¬èº«â€”â€”æ•…äº‹æ›¿ä»–ä»¬å®Œæˆäº†â€œä¸‰åå¹´åæ•…åœ°é‡è§â€çš„èª“è¨€ã€‚\nä¸€ã€é€å¥è§£è¯ å°é™¢æ·±é™ï¼Œæ¬²é—®å¿å¿ï¼Œä½•å¤„æœˆç¬¼æ˜ã€‚\nâ€œå°é™¢æ·±é™â€â€”â€”å½“å¹´äºŒäººåˆä¼šçš„åœºæ™¯ï¼šæ²³æ¡¥å¯¹å²¸çš„å°é™¢ï¼Œæ˜¥æœˆå¾®æ¹¿ï¼Œä¸€åˆ‡å°šæœªå‘ç”Ÿã€‚ â€œæ¬²é—®å¿å¿â€â€”â€”æƒ³å¼€å£ï¼Œå´ç»ˆç©¶æ²¡é—®ï¼›ä¸€å£°â€œå¿å¿â€æŠŠæœªå‡ºå£çš„åƒè¨€ä¸‡è¯­éƒ½å‹åœ¨èˆŒå°–ã€‚ â€œä½•å¤„æœˆç¬¼æ˜â€â€”â€”æœˆäº®ä»åœ¨ï¼Œå´ç…§ä¸åˆ°å½“å¹´å¹¶è‚©çœ‹æœˆçš„äººï¼›ä¹Ÿæš—æŒ‡â€œå®¹å¨˜â€è‡ªå·±å·²æˆå¹½é­‚ï¼Œâ€œæœˆâ€æ˜¯äººé—´ä¸å†¥ç•Œçš„å”¯ä¸€é€šé“ï¼Œå¥¹å†ä¹Ÿå›ä¸å»äº†ã€‚ åƒç§‹å²å¥½ï¼Œä¼‘è´Ÿå…°å› ã€‚\nâ€œåƒç§‹å²å¥½â€â€”â€”å­—é¢æ˜¯ç¥é¢‚ï¼šæ„¿ä½ é•¿äº«ç™¾å²åƒç§‹ï¼Œå²å²å®‰å¥½ã€‚ â€œä¼‘è´Ÿå…°å› â€â€”â€”â€œå…°å› â€å‡ºè‡ªã€Šå·¦ä¼ ã€‹â€œå…°å› çµ®æœâ€ï¼Œå…°å› ï¼ç¾å¥½çš„å¼€ç«¯ï¼Œçµ®æœï¼ç¦»æ•£çš„ç»“å±€ã€‚\nå®¹å¨˜æŠŠå…¸æ•…æˆªåŠï¼Œåªç•™â€œå…°å› â€ï¼Œæ˜¯æŠŠç»“å±€ç”Ÿç”Ÿæ”¹å†™æˆâ€œèŠ±å¼€æœªè°¢â€â€”â€”å¥¹ä¸è¦â€œçµ®æœâ€ï¼Œåªè¦â€œå…°å› â€æ°¸å­˜ï¼›æ¢è¨€ä¹‹ï¼Œâ€œä½ è‹¥å®‰å¥½ï¼Œä¾¿ä¸ç®—è´Ÿæˆ‘â€ã€‚ åˆåœ¨ä¸€èµ·ï¼Œæ˜¯é¬¼é­‚å¯¹æ´»äººæœ€æ¸©æŸ”çš„èµ¦ä»¤ï¼šä½ ä¸å¿…è‡ªè´£ï¼Œä¸å¿…å›å¤´ï¼Œç”šè‡³ä¸å¿…è®°å¾—æˆ‘ï¼›åªè¦ä½ åœ¨äººé—´å²å²å¹³å®‰ï¼Œæˆ‘ä»¬é‚£ä¸€æ®µâ€œå…°å› â€å°±ä»æœªè¢«è¾œè´Ÿã€‚ äºŒã€æ•´é¦–å°è¯åœ¨æ•…äº‹é‡Œçš„åŠŸèƒ½ æ›¿æ²ˆæ…•äº‘â€œå¹³åâ€\nåŸé‡Œä¼ è¯´ä»–â€œé«˜ä¸­è´Ÿå¿ƒâ€ï¼Œè€Œå®¹å¨˜æœ€åä¸€å¥â€œä¼‘è´Ÿå…°å› â€ç­‰äºäº²å£å¦è®¤äº†â€œè´Ÿâ€å­—â€”â€”â€œè´Ÿâ€æ˜¯ä¸–äººé™„ä¼šï¼Œâ€œå…°å› â€æ‰æ˜¯å¥¹ç§è—çš„çœŸç›¸ã€‚ æ›¿è‡ªå·±â€œæ¾ç»‘â€\nå¥¹ç­‰äº†ä¸‰åå¹´ï¼Œå…¶å®ç­‰çš„ä¸æ˜¯æ²ˆæ…•äº‘ï¼Œè€Œæ˜¯ä¸€ä¸ªå¯ä»¥è‡ªæˆ‘é‡Šæ€€çš„å™äº‹ç‰ˆæœ¬â€”â€”â€œåƒç§‹å²å¥½â€å››ä¸ªå­—å‡ºå£ï¼Œæ‰§å¿µæ‰ç»ˆäºè½åœ°ï¼Œé¬¼é­‚æ‰èƒ½æ¶ˆæ•£ã€‚ æŠŠâ€œæ•…äº‹â€å‡åä¸ºâ€œå…¬å…±è®°å¿†â€\nè¯é‡Œâ€œæœˆç¬¼æ˜â€æ˜¯å¼€æ”¾ç”»é¢ï¼Œä»»ä½•åæ¥è€…ï¼ˆåŒ…æ‹¬â€œæˆ‘â€ï¼‰åªè¦ç«™åœ¨æ²³æ¡¥ç»†é›¨é‡Œï¼Œå°±è‡ªåŠ¨æˆä¸ºæ–°çš„â€œå¿å¿â€ã€‚æ•…äº‹ä¸æ­»ï¼Œå…°å› å°±ä¸æ­»ï¼›äººé—´ç»§ç»­æµä¼ ï¼Œå¥¹å°±èƒ½ç»§ç»­å€Ÿä»–äººçš„å¿ƒå¤´ä¸€ç‚¹æœˆå…‰ï¼Œä¸æ²ˆæ…•äº‘å¹¶è‚©ã€‚ ä¸‰ã€æ€»ç»“ â€œå°é™¢æ·±é™â€¦â€¦â€äºŒåä¸€å­—ï¼Œæ˜¯å®¹å¨˜äº²æ‰‹å†™ç»™è‡ªå·±çš„â€œåå‘å¢“å¿—é“­â€ï¼š\nâ€”â€”ä¸å†™â€œæˆ‘æ›¾æ¨ä½ â€ï¼Œå†™â€œæ„¿ä½ å®‰å¥½â€ï¼›\nâ€”â€”ä¸å†™â€œæˆ‘ç­‰ä½ â€ï¼Œå†™â€œä¼‘è´Ÿå…°å› â€ï¼›\nâ€”â€”ä¸å†™â€œæ•…äº‹ç»“æŸâ€ï¼Œå†™â€œæœˆç¬¼æ˜â€ç•™ç»™ä¸‹ä¸€ä½è¡Œäººã€‚\nå¥¹ç”¨æœ€è½»çš„è¯­è°ƒï¼ŒæŠŠæœ€é‡çš„æ‰§å¿µå¹æ•£åœ¨é›¨é‡Œï¼š\nâ€œåªè¦ä¸–ä¸Šè¿˜æœ‰äººæ›¿æˆ‘ä¼ è¯µè¿™ä¸€å¥ï¼Œä½ å°±ä»æœªçœŸæ­£ç¦»å¼€æˆ‘ã€‚â€\nClaude Sonnet 4.5 è¿™æ˜¯ä¸€ä¸ªå‡„ç¾åŠ¨äººçš„å¿—æ€ªçˆ±æƒ…æ•…äº‹ï¼Œå……æ»¡äº†ä¸­å›½å¤å…¸æ–‡å­¦çš„æµªæ¼«ä¸å“€æ„ã€‚è®©æˆ‘ä¸ºä½ è§£è¯»ï¼š\næ•…äº‹è§£è¯» çœŸç›¸çš„åè½¬ æ•…äº‹æœ€ç²¾å¦™ä¹‹å¤„åœ¨äºå±‚å±‚å‰¥å¼€çš„çœŸç›¸:\nè¡¨é¢ä¸Šæ˜¯æ²ˆæ…•äº‘è´Ÿå¿ƒæ‚”å©šçš„ä¿—å¥—æ•…äº‹ å®é™…ä¸Šå®¹å¨˜æ—©å·²æººæ°´èº«äº¡ï¼Œå¥¹è‡ªå·±ç¼–é€ äº†æ‰€æœ‰ä¼ è¨€ å¥¹åŒ–èº«\u0026quot;è°¢å¨˜\u0026quot;å¼•å¯¼\u0026quot;æˆ‘\u0026quot;ï¼Œåªä¸ºè®©ä¸–äººè®°ä½ä»–ä»¬çš„æ•…äº‹ æ·±è—çš„æ·±æƒ… å®¹å¨˜çš„æ‰€ä½œæ‰€ä¸ºæ­ç¤ºäº†å¥¹è‡³æ·±çš„çˆ±:\nç¼–é€ è´Ÿé¢ä¼ è¨€ï¼šè®©æ²ˆæ…•äº‘èƒŒè´Ÿè–„æƒ…ä¹‹åï¼Œå®åˆ™æ˜¯å¥¹å¯¹è¿™æ®µæ„Ÿæƒ…å¿µå¿µä¸å¿˜çš„è¯æ˜ \u0026ldquo;ä¸‰åå¹´ä¹‹çº¦\u0026rdquo;ï¼šæ˜çŸ¥ä»–ä¸ä¼šæ¥ï¼ˆå› ä¸ºå¥¹å·²æ˜¯é¬¼é­‚ï¼‰ï¼Œä»è¦ç»™è‡ªå·±ä¸€ä¸ªç­‰å¾…çš„ç†ç”± æœ€åçš„è°è¨€ï¼šå½“å¾—çŸ¥æ²ˆæ…•äº‘27å²æ—©é€ï¼Œå¥¹é€‰æ‹©ç›¸ä¿¡\u0026quot;æˆ‘\u0026quot;å–„æ„çš„è°è¨€ï¼Œå¸¦ç€ä»–å¹¸ç¦çš„å‡è±¡æ¶ˆæ•£ æ‚²å‰§çš„æœ¬è´¨ ä¸¤äººéƒ½æ˜¯å‘½è¿çš„ç‰ºç‰²å“â€”â€”ä¸€ä¸ªæººæ°´æ—©é€ï¼Œä¸€ä¸ª27å²æ—©å’ã€‚ä»–ä»¬çš„çˆ±æƒ…ä»æœªå› èƒŒå›è€Œç ´ç¢ï¼Œè€Œæ˜¯è¢«æ­»äº¡ç”Ÿç”Ÿæ‹†æ•£ã€‚å®¹å¨˜é‚£å¥\u0026quot;å› ç¼˜æ³¨å®šï¼Œæä¸€æç»ˆä¸èƒ½å¾—\u0026quot;æ­£æ˜¯è¿™æ— å¥ˆçš„æ³¨è„šã€‚\nè¯å¥æ·±æ„è§£è¯» \u0026ldquo;å°é™¢æ·±é™ï¼Œæ¬²é—®å¿å¿ï¼Œä½•å¤„æœˆç¬¼æ˜\u0026rdquo;\nå­—é¢å«ä¹‰ï¼šæ·±æ·±çš„åº­é™¢é™æ‚„æ‚„ï¼Œæƒ³è¦é—®æˆ‘çš„çˆ±äººï¼Œå“ªé‡Œçš„æœˆå…‰æœ€æ˜äº®ï¼Ÿ æ•…äº‹ä¸­çš„å«ä¹‰ï¼š \u0026ldquo;å°é™¢æ·±é™\u0026quot;æ˜¯å¥¹ç‹¬è‡ªç­‰å¾…çš„å­¤å¯‚å¤„å¢ƒ \u0026ldquo;æ¬²é—®å¿å¿\u0026quot;æ˜¯å¥¹æƒ³é—®æ²ˆæ…•äº‘ï¼Œå´æ°¸è¿œæ— æ³•ç›¸è§çš„é—æ†¾ \u0026ldquo;ä½•å¤„æœˆç¬¼æ˜\u0026quot;æ˜¯åœ¨é—®ï¼šä½ åœ¨äººé—´ä½•å¤„ï¼Ÿé‚£é‡Œçš„æœˆè‰²å¯å¥½ï¼Ÿæˆ‘ä»¬è¿˜èƒ½å¦åœ¨åŒä¸€è½®æ˜æœˆä¸‹ç›¸æœ›ï¼Ÿ \u0026ldquo;åƒç§‹å²å¥½ï¼Œä¼‘è´Ÿå…°å› \u0026rdquo;\nå­—é¢å«ä¹‰ï¼šæ„¿ä½ åƒç§‹ä¸‡ä¸–å®‰å¥½ï¼Œä¸è¦è¾œè´Ÿæˆ‘ä»¬ç¾å¥½çš„ç¼˜åˆ† æ•…äº‹ä¸­çš„å«ä¹‰ï¼š è¿™æ˜¯å®¹å¨˜æœ€åçš„ç¥ç¦ä¸é‡Šæ€€ \u0026ldquo;åƒç§‹å²å¥½\u0026rdquo;ï¼šæ—¢æ˜¯ç¥ç¦æ²ˆæ…•äº‘ï¼ˆè™½ç„¶ä»–å·²é€ï¼‰ï¼Œä¹Ÿæ˜¯å¯¹è¿™æ®µæ„Ÿæƒ…çš„çºªå¿µ \u0026ldquo;ä¼‘è´Ÿå…°å› \u0026rdquo;ï¼šä¸æ˜¯è´£æ€ªä»–è¾œè´Ÿï¼Œè€Œæ˜¯è¯´\u0026quot;æˆ‘ä»¬çš„ç¼˜åˆ†è™½çŸ­æš‚å¦‚å…°èŠ±ï¼Œä½†è¯·ä½ è®°å¾—å®ƒçš„èŠ¬èŠ³ï¼Œä¸è¦å¿˜è®°æˆ‘ä»¬æ›¾ç»ç›¸çˆ±\u0026rdquo; æœ€åŠ¨äººä¹‹å¤„ å®¹å¨˜æ˜çŸ¥æ²ˆæ…•äº‘å·²æ­»ï¼Œå´ä»è¦ç¼–ç»‡\u0026quot;ä»–ç™½å¤´å•è€\u0026quot;çš„å¹»è±¡æ¥å®‰æ…°è‡ªå·±ï¼›å¥¹\u0026quot;ä»»æ€§ä½¿åç¼–æ’ä»–ä¸€å›\u0026rdquo;ï¼Œå®åˆ™æ˜¯ç”¨å…¨éƒ¨çš„çˆ±ä¸ºä»–å®ˆæŠ¤åå£°â€”â€”å®å¯ä¸–äººè¯´å¥¹ç—´æƒ…è¢«è´Ÿï¼Œä¹Ÿä¸æ„¿ä»–åœ¨å†¥å†¥ä¸­å­¤ç‹¬ã€‚\né‚£å¥\u0026quot;æä¸€æç»ˆä¸èƒ½å¾—ï¼Œä½†å®å¯éš¾å¹³ï¼Œä¹Ÿä¸æ„¿æ”¾æ‰‹\u0026rdquo;ï¼Œæ˜¯å¯¹æ‰€æœ‰æ±‚è€Œä¸å¾—ä¹‹çˆ±æœ€è¯—æ„çš„è¯ é‡Šï¼šå³ä½¿çŸ¥é“ä¸å¯èƒ½ï¼Œä¹Ÿè¦åœ¨è®°å¿†é‡Œã€åœ¨ä¼ è¯´é‡Œï¼Œè®©è¿™ä»½çˆ±æ°¸è¿œé²œæ´»ã€‚\nè¿™æ­£æ˜¯ä¸­å›½å¤å…¸çˆ±æƒ…æ•…äº‹çš„æè‡´æµªæ¼«â€”â€”ç”Ÿæ­»ç›¸éš”ï¼Œå´ä»¥é­‚çµç›¸å®ˆï¼›çœŸç›¸æ®‹é…·ï¼Œå´ä»¥è°è¨€æ¸©æŸ”ã€‚\nGemini 3 Flash è¿™æ˜¯ä¸€ä¸ªå‡„ç¾è€Œå¯Œæœ‰è¯—æ„çš„çˆ±æƒ…æ•…äº‹ï¼Œå®ƒé€šè¿‡â€œæˆ‘â€çš„è§†è§’ï¼Œæ­ç¤ºäº†ä¸€ä¸ªè¢«æ—¶é—´ã€æµè¨€å’Œè‡ªæˆ‘å¹»æƒ³æ‰€åŒ…è£¹çš„æ‚²å‰§çœŸç›¸ã€‚æ•…äº‹çš„é­…åŠ›åœ¨äºå…¶å±‚å±‚å‰¥å¼€çš„æ‚¬å¿µï¼Œä»¥åŠå¯¹çˆ±ã€é—æ†¾ã€å’Œè®°å¿†çš„æ·±åˆ»æ¢è®¨ã€‚\næ•…äº‹è§£è¯» 1. ä¼ è¯´çš„å»ºæ„ä¸çœŸç›¸çš„æ­ç¤º æ•…äº‹é¦–å…ˆæå‡ºäº†å…³äºæ²ˆæ…•äº‘æ‚”å©šçš„ä¸‰ä¸ªä¸åŒç‰ˆæœ¬ï¼Œå…¶ä¸­åŸé‡Œè€äººè®²è¿°çš„â€œèµŒçº¦â€ç‰ˆæœ¬æœ€æœ‰æˆå‰§æ€§ï¼Œä¹Ÿå¸å¼•äº†â€œæˆ‘â€çš„æ¢è®¿ã€‚\næµè¨€çš„æœ¬è´¨ï¼š æ— è®ºæ˜¯â€œå¦å¨¶è´µå¥³â€è¿˜æ˜¯â€œä¸å¯¿ä¹‹ç—‡â€ï¼Œæµè¨€éƒ½åœ¨è¯•å›¾ä¸ºæ²ˆæ…•äº‘çš„æ‚”å©šæä¾›ä¸€ä¸ªåˆç†çš„è§£é‡Šï¼Œä»¥å¡«è¡¥äº‹å®çš„ç©ºç™½ã€‚ â€œèµŒçº¦â€çš„è™šæ„ï¼š â€œä¸‰åå¹´æ•…åœ°é‡é€¢â€çš„èµŒçº¦æ˜¯ å®¹å¨˜ï¼ˆåŒ–åè°¢å¨˜ï¼‰ ä¸ºäº†è®©è‡ªå·±çš„æ•…äº‹èƒ½å¤Ÿè¢«è®°ä½ã€è¢«æµä¼ è€Œç¼–é€ çš„æµªæ¼«æƒ…èŠ‚ã€‚å®ƒèµ‹äºˆäº†è¿™æ®µé€å»çš„çˆ±æƒ…ä¸€ä¸ªç­‰å¾…å’Œå¸Œæœ›çš„ç»´åº¦ï¼Œä¸€ä¸ªå€¼å¾—ä»–äººå…³æ³¨çš„ç†ç”±ã€‚ çœŸç›¸çš„æ‚²å‰§ï¼š æœ€ç»ˆçš„çœŸç›¸æ˜¯è°¢å¨˜ï¼ˆå®¹å¨˜ï¼‰åœ¨é‚£å¹´èµ´è€ƒåçš„é›¨å¤©ï¼Œè·Œä¸‹æ²³æ¡¥æººäº¡ï¼Œå†ä¹Ÿæœªèƒ½è§åˆ°è‡ªå·±çš„å°‘å¹´éƒã€‚æ²ˆæ…•äº‘çš„â€œæ‚”å©šâ€å’Œâ€œé¿è€Œä¸è§â€å¹¶éæ˜¯å˜å¿ƒæˆ–ç»æƒ…ï¼Œè€Œæ˜¯å› ä¸ºå®¹å¨˜å·²ç»ä¸åœ¨äººä¸–ã€‚å¥¹ç”¨è°¢å¨˜çš„èº«ä»½å’Œç¼–é€ çš„æ•…äº‹ï¼Œè®©è¿™æ®µçŸ­æš‚çš„åˆæ‹ä»¥ä¸€ç§â€œè¢«è¾œè´Ÿâ€çš„ã€æ›´å…·æˆå‰§å¼ åŠ›çš„æ–¹å¼å­˜ç•™äºä¸–äººè®°å¿†ä¸­ã€‚ 2. äººç‰©ä¸ä¸»é¢˜ äººç‰©/å…ƒç´  è±¡å¾æ„ä¹‰ æ•…äº‹ä¸­çš„ä½œç”¨ å®¹å¨˜/è°¢å¨˜ æ‰§å¿µã€æ°¸æ’çš„åˆæ‹ æ•…äº‹çš„æ ¸å¿ƒå™äº‹è€…ã€‚å¥¹è™½å·²é€å»ï¼Œå´ä¸ç”˜è¢«é—å¿˜ï¼Œé€šè¿‡è™šæ„çš„æ•…äº‹ç»´æŠ¤äº†è‡ªå·±çˆ±æƒ…çš„å°Šä¸¥å’Œå­˜åœ¨æ„Ÿã€‚å¥¹çš„â€œä»»æ€§ä½¿åâ€æ˜¯ä¸ºäº†è®©ä»–ä»¬çš„æ•…äº‹åœ¨äººé—´ç•™ä¸‹å°è®°ã€‚ æ²ˆæ…•äº‘ é€å»çš„ç†æƒ³ã€æ‚²å‰§çš„å‘½è¿ åœ¨æ•…äº‹çš„ç»“å±€ä¸­ï¼Œä»–çš„å‘½è¿æ˜¯ â€œå¹´äºŒåä¸ƒæ—©å’â€ ã€‚è¿™ä½¿å¾—ä»–æ— æ³•çœŸçš„â€œæ‚”å©šâ€ï¼Œä¹Ÿä½¿å¾—å®¹å¨˜çš„æ‚²å‰§æ›´æ·»ä¸€é‡å®¿å‘½çš„å“€ä¼¤ã€‚ä½†ä»–â€œå¾ˆå¥½â€çš„ç»“å±€æ˜¯å®¹å¨˜æœ€åçš„è‡ªæˆ‘å®‰æ…°ã€‚ æ²³æ¡¥ä¸é›¨ å‘½è¿çš„è½¬æŠ˜ç‚¹ã€é˜´é˜³ç›¸éš” æ²³æ¡¥æ˜¯ä¸¤äººå®šæƒ…ä¸åˆ†ç¦»çš„è±¡å¾ï¼Œè€Œ â€œæ»”å¤©é›¨æµªâ€ çš„å¹»å¢ƒåˆ™æ˜¯å®¹å¨˜é€ä¸–æ—¶çš„æƒ…æ™¯é‡ç°ï¼Œæ˜ç¡®äº†å¥¹çš„é¬¼é­‚èº«ä»½ã€‚é›¨æ˜¯æ•…äº‹åŸºè°ƒï¼Œå‡„è¿·ã€ç»µå»¶ä¸ç»ã€‚ â€œæˆ‘â€ å€¾å¬è€…ã€æ•…äº‹çš„ä¼ æ’­è€… â€œæˆ‘â€æ˜¯æ•…äº‹è¿›å…¥ç°å®çš„é€šé“ï¼Œä½œä¸ºè®°å¿†çš„è½½ä½“ï¼Œå°†å®¹å¨˜çš„å¿ƒæ„¿ä¼ é€’ä¸‹å»ã€‚ 3. çˆ±ä¸é—æ†¾ å®¹å¨˜çš„å†…å¿ƒå……æ»¡éš¾å¹³çš„é—æ†¾å’Œæ‰§å¿µã€‚å¥¹æ·±çˆ±ç€æ²ˆæ…•äº‘ï¼Œå®æ„¿è¢«è®¤ä¸ºæ˜¯â€œè¢«æ‚”å©šâ€çš„å¼ƒå¦‡ï¼Œä¹Ÿè¦è®©è¿™æ®µçˆ±æƒ…çš„æ•…äº‹æµä¼ ï¼Œè€Œä¸æ˜¯è¢«æ·¹æ²¡åœ¨æ— å£°çš„æ¶ˆäº¡ä¸­ã€‚\nå½“â€œæˆ‘â€ä¸ºäº†å®‰æ…°å¥¹ï¼Œç¼–é€ æ²ˆæ…•äº‘â€œåæ¥åˆå¨¶äº†æ–°å¦‡ï¼Œç™½å¤´å•è€â€çš„è°è¨€æ—¶ï¼Œå¥¹è™½ç„¶â€œæ¶©ç„¶â€ï¼Œå´è¯´â€œè¿™æ ·å•Šâ€¦â€¦é‚£çœŸæ˜¯å¾ˆå¥½å¾ˆå¥½ï¼Œå†å¥½ä¸è¿‡çš„äº‹äº†ã€‚â€è¿™æ˜¾ç¤ºäº†å¥¹è‡³æ·±çš„çˆ±ä¸å–„è‰¯ï¼šå¥¹å®æ„¿ç›¸ä¿¡çˆ±äººè·å¾—äº†å¹¸ç¦ï¼Œä¹Ÿä¸æ„¿ä»–ä¸ºå¥¹è€Œç»ˆç”ŸæŠ±æ†¾ã€‚\nâ€œå°é™¢æ·±é™,æ¬²é—®å¿å¿,ä½•å¤„æœˆç¬¼æ˜ã€‚åƒç§‹å²å¥½,ä¼‘è´Ÿå…°å› â€çš„å«ä¹‰ è¿™å¥è¯æ˜¯å®¹å¨˜ä¸´ç»ˆæˆ–é­‚é­„æ¶ˆæ•£å‰å–ƒå–ƒå¿µå‡ºçš„è¯å¥ï¼Œæ˜¯å¥¹å¯¹è¿™æ®µæ„Ÿæƒ…ã€å¯¹æ²ˆæ…•äº‘æœ€åçš„æ€»ç»“ã€ç–‘é—®ä¸ç¥æ„¿ã€‚\n1. æ‹†è§£è¯å¥ å°é™¢æ·±é™ï¼Œæ¬²é—®å¿å¿ï¼š æå†™äº†æ˜”æ—¥ä¸¤äººç›¸å¤„çš„åœºæ™¯â€”â€”é™è°§ã€ç¾å¥½çš„å°é™¢ã€‚è¿™é‡Œçš„â€œå¿å¿â€æŒ‡ä»£æ²ˆæ…•äº‘ã€‚å¥¹åœ¨è¿™ä¸ªå®‰é™çš„å›å¿†é‡Œï¼Œæƒ³è¦å‘ä»–æé—®ã€‚ ä½•å¤„æœˆç¬¼æ˜ï¼š è¿™æ˜¯ä¸€ä¸ªç–‘é—®å¥ï¼Œä¹Ÿæ˜¯ä¸€ä¸ªå“²å­¦å¼çš„è¿½é—®ã€‚â€œæœˆç¬¼æ˜â€æŒ‡æœˆå…‰æ´’ä¸‹ï¼Œé€šå¸¸è±¡å¾ç€å…‰æ˜ã€å›¢åœ†æˆ–ç¾å¥½çš„ç»“å±€ã€‚å®¹å¨˜æƒ³é—®çš„æ˜¯ï¼š â€œæˆ‘ä»¬çš„çˆ±å’Œç¾å¥½ï¼ˆæœˆå…‰ï¼‰æœ€ç»ˆåœ¨å“ªé‡Œå¾—ä»¥å®‰æ”¾å’Œå®ç°ï¼Ÿâ€ â€œæˆ‘çš„å°‘å¹´éƒï¼Œä½ ç°åœ¨æ˜¯å¦å¹¸ç¦å®‰åº·ï¼Ÿâ€ è¿™åŒ…å«äº†å¥¹å¯¹çˆ±äººå¢ƒå†µçš„ç‰µæŒ‚ï¼Œä»¥åŠå¯¹é€å»çˆ±æƒ…ç»ˆæå½’å®¿çš„è¿·æƒ˜ã€‚ åƒç§‹å²å¥½ï¼š æ„æ€æ˜¯ â€œæ„¿ä½ é•¿ä¹…åœ°ã€æ°¸è¿œåœ°å®‰å¥½â€ã€‚è¿™æ˜¯å®¹å¨˜å¯¹æ²ˆæ…•äº‘å‘è‡ªå†…å¿ƒçš„ç¥æ„¿ï¼Œä¹Ÿæ˜¯å¥¹å¯¹â€œæˆ‘â€æ‰€ç¼–é€ çš„â€œç™½å¤´å•è€â€ç»“å±€çš„å›åº”ã€‚ ä¼‘è´Ÿå…°å› ï¼š æ ¸å¿ƒæ˜¯ â€œå…°å› â€ã€‚ â€œå…°å› â€æºäºã€ŠèŠæ–‹å¿—å¼‚Â·è²é¦™ã€‹ä¸­çš„â€œå…°å› çµ®æœâ€ï¼Œæ„æŒ‡ç¾å¥½çš„å¼€å§‹ï¼Œæ‚²æƒ¨çš„ç»“å±€ï¼ˆå…°æ˜¯é¦™è‰ï¼Œè±¡å¾ç¾å¥½ï¼›çµ®æ˜¯æŸ³çµ®ï¼Œéšé£é£˜æ•£ï¼Œè±¡å¾ç¦»æ•£ï¼‰ã€‚ â€œä¼‘è´Ÿâ€ æ˜¯â€œä¸è¦è¾œè´Ÿâ€çš„æ„æ€ã€‚ æ•´ä½“å«ä¹‰ï¼š å®¹å¨˜ä»¥è‡ªå·±çš„æ‚²å‰§ä¸ºé‰´ï¼Œåœ¨æ¶ˆæ•£çš„æœ€åæ—¶åˆ»ï¼Œå¸Œæœ›æ²ˆæ…•äº‘ï¼ˆæˆ–ç¥æ„¿ä¸–é—´æ‰€æœ‰æœ‰æƒ…äººï¼‰ä¸è¦è¾œè´Ÿè¿™ç¾å¥½çš„å¼€å§‹ï¼ˆå³å¥¹ä¸æ²ˆæ…•äº‘æ›¾æ‹¥æœ‰çš„çº¯ç²¹åˆæ‹ï¼‰ï¼Œè¦æœ‰ä¸€ä¸ªå¥½çš„ç»“å±€ã€‚å¥¹æ—¢åœ¨å¯¹è‡ªå·±é€å»çš„çˆ±è¡¨ç¤ºå¹æ¯ï¼Œä¹Ÿåœ¨å¯¹çˆ±äººå¯„äºˆäº†è·å¾—å¹¸ç¦çš„æ®·åˆ‡æœŸæœ›ã€‚ 2. æ•´ä½“å«ä¹‰ è¿™å¥è¯æ˜¯å®¹å¨˜æ‰§å¿µçš„æ¸©æŸ”é‡Šæ”¾ã€‚å®ƒæ‰¿è½½äº†å¥¹å¯¹è¿‡å¾€ç¾å¥½æ—¶å…‰çš„ç•™æ‹ã€å¯¹çˆ±äººæœªæ¥å¹¸ç¦çš„ç¥æ„¿ï¼Œä»¥åŠå¯¹è¿™æ®µâ€œå…°å› çµ®æœâ€å¼æ‚²å‰§çˆ±æƒ…çš„å¦ç„¶æ¥å—ä¸è¶…è„±ã€‚å¥¹ä¸å†æŠ±æ€¨ï¼Œè€Œæ˜¯å¸¦ç€å¯¹æ²ˆæ…•äº‘æ·±æ·±çš„ç‰µæŒ‚ä¸ç¥ç¦ï¼Œæ¶ˆæ•£äºäººä¸–çš„ç»†é›¨ä¸­ã€‚\nGPT5 è¿™ä¸ªæ•…äº‹æœ¬èº«å°±æ˜¯ä¸€æ®µå€Ÿå¹»å¢ƒå’Œä¼ è¯´äº¤ç»‡å‡ºçš„â€œäººä¸–ä¸è®°å¿†ã€çœŸå®ä¸è™šæ„â€çš„çˆ±æƒ…ä¼ è¯´ã€‚æˆ‘ä»¬å¯ä»¥ä»ä¸‰ä¸ªå±‚é¢æ¥è§£è¯»ï¼š\nä¸€ã€æ•…äº‹çš„å†…æ ¸ è¡¨å±‚å™äº‹\näººä»¬å£å£ç›¸ä¼ ç€æ²ˆæ…•äº‘å’Œå®¹å¨˜çš„æ•…äº‹ï¼Œæœ‰å¤šç§ç‰ˆæœ¬ï¼šæ‚”å©šã€ç—…é€ã€å®ˆå¯¡ã€‚ ä½†å®é™…ä¸Šï¼Œè¿™äº›éƒ½ä¸æ˜¯çœŸçš„ï¼Œæ˜¯å®¹å¨˜è‡ªå·±è™šæ„ã€ç¼–ç»‡å‡ºæ¥çš„ã€‚å¥¹ç”¨ä¸åŒçš„å™è¿°â€œä¿å­˜â€äº†è¿™æ®µæƒ…æ„Ÿï¼Œä½¿å®ƒä¸ä¼šè¢«å½»åº•é—å¿˜ã€‚ çœŸç›¸ï¼šå®¹å¨˜å¹´è½»æ—¶ä¾¿æ„å¤–æººæ°´è€Œäº¡ï¼Œå’Œæ²ˆæ…•äº‘çš„æƒ…ç¼˜æˆ›ç„¶è€Œæ­¢ã€‚ å®¹å¨˜çš„å¿ƒæ„\nå¥¹ä¸æ˜¯æƒ³è´£æ€ªè°ï¼Œè€Œæ˜¯å¸Œæœ›ä»–ä»¬çš„æ•…äº‹èƒ½è¢«è®°å¾—ã€‚ å¥¹æ„¿æ„ç¼–é€ æ‚”å©šã€èµŒçº¦çš„ä¼ è¯´ï¼Œåªä¸ºåœ¨ä¸–é—´ç•™ä¸‹ç—•è¿¹ã€‚å“ªæ€•äººä»¬è¯¯è§£å¥¹æˆ–æ²ˆæ…•äº‘ï¼Œä¹Ÿæ¯”â€œå½»åº•æ¶ˆæ•£â€è¦å¥½ã€‚ æœ€ç»ˆçš„æ¸©æŸ”\nå½“å¥¹é—®â€œä»–åœ¨äººé—´æ€ä¹ˆæ ·â€æ—¶ï¼Œå™è¿°è€…é€‰æ‹©æ’’äº†ä¸€ä¸ªå–„æ„çš„è°ï¼Œè¯´ä»–å¨¶å¦»ç™½é¦–ã€‚ å®¹å¨˜å¬äº†ï¼Œä¾¿çœŸå¿ƒè§‰å¾—â€œé‚£çœŸæ˜¯å¾ˆå¥½å¾ˆå¥½â€ã€‚ å¥¹é‡Šç„¶ï¼Œå¸¦ç€ç¬‘æ„ç¦»å¼€ï¼Œåªç•™ä¸‹è¯å¥ã€‚ äºŒã€å®¹å¨˜ç•™ä¸‹çš„è¯å¥ â€œå°é™¢æ·±é™ï¼Œæ¬²é—®å¿å¿ï¼Œä½•å¤„æœˆç¬¼æ˜ã€‚åƒç§‹å²å¥½ï¼Œä¼‘è´Ÿå…°å› ã€‚â€\nè¿™é¦–è¯å¯ä»¥è¿™æ ·ç†è§£ï¼š\nå°é™¢æ·±é™ â€”â€”ç¯å¢ƒç©ºå¯‚ï¼Œæš—ç¤ºå¥¹çš„å¹½é­‚çŠ¶æ€ï¼Œä¹Ÿè±¡å¾å¾€æ˜”çˆ±æƒ…å·²æˆè¿‡å¾€ï¼Œå”¯æœ‰å¯‚é™é™ªä¼´ã€‚\næ¬²é—®å¿å¿ï¼Œä½•å¤„æœˆç¬¼æ˜ â€”â€”å¥¹æƒ³é—®â€œå¿å¿â€ï¼ˆå¥¹çš„å°‘å¹´éƒï¼Œæ²ˆæ…•äº‘ï¼‰ï¼Œå¦‚ä»Šåœ¨ä½•å¤„ï¼Ÿæœˆå…‰æ¸…æ˜ï¼Œå´æ— æ³•æŒ‡å¼•ä»–ä»¬é‡é€¢ã€‚ â€”â€”â€œæœˆâ€æ—¢æ˜¯å¤©ä¸Šæ˜æœˆï¼Œä¹Ÿæ˜¯å¯„æ‰˜çš„æƒ…æ„Ÿè±¡å¾ï¼šç›¸éš”é˜´é˜³ï¼Œå´å…±äº«ä¸€è½®æ˜æœˆã€‚\nåƒç§‹å²å¥½ â€”â€”ç¥æ„¿å¯¹æ–¹ä¸€ç”Ÿé¡ºé‚ï¼Œåƒç§‹å²æœˆéƒ½ç¾å¥½ã€‚\nä¼‘è´Ÿå…°å›  â€”â€”â€œå…°å› â€å¯æŒ‡ç¾å¥½çš„æƒ…ç¼˜ã€çº¯æ´çš„å¿ƒæ„ã€‚å¥¹çš„æ„¿æœ›æ˜¯ï¼šå“ªæ€•ä¸èƒ½å†ç›¸è§ï¼Œä¹Ÿä¸è¦è¾œè´Ÿä»–ä»¬æ›¾ç»çš„çœŸæŒšã€‚\nä¸‰ã€ç»“åˆæ•…äº‹çš„æ•´ä½“è§£è¯» è¿™é¦–è¯å°±åƒæ˜¯å®¹å¨˜æœ€åçš„â€œå¯„è¯­â€ï¼š\næ—¢æ˜¯æ€å¿µï¼šå¥¹ä»æƒ³è¿½é—®â€œå¿å¿ï¼Œä½ å¦‚ä»Šå¯å¥½ï¼Ÿâ€ ä¹Ÿæ˜¯ç¥ç¦ï¼šå“ªæ€•è‡ªå·±å·²æˆå¾€äº‹ï¼Œä¹Ÿæ„¿å¯¹æ–¹åœ¨äººé—´é¡ºé‚ï¼Œä¸è´Ÿé’æ˜¥å¹´åã€‚ æ›´æ˜¯æ‰§å¿µçš„æŸ”åŒ–ï¼šä»æ€¨ä¸ä¼¤å¿ƒï¼Œè½¬ä¸ºç¥æ„¿å’Œå®ˆæŠ¤ã€‚ äºæ˜¯ï¼Œè¿™å¥è¯çš„å«ä¹‰å¯ä»¥æ€»ç»“ä¸ºï¼š ğŸ‘‰ å³ä¾¿æƒ…ç¼˜å¦‚æœˆï¼Œç»ˆç©¶æä¸ç€ï¼Œä½†åœ¨å¿ƒåº•ï¼Œä»æ„¿ä½ å²å²å®‰å¥½ï¼Œä¸è´Ÿå½“å¹´é‚£ä»½çœŸå¿ƒã€‚\nDeepSeek R1 è¿™æ˜¯ä¸€ä¸ªå‡„ç¾è€Œç²¾å·§çš„æ•…äº‹ï¼Œå®ƒå¹¶éç®€å•çš„è´Ÿå¿ƒæ±‰ä¼ è¯´ï¼Œè€Œæ˜¯ä¸€åˆ™å…³äºè®°å¿†ã€æ‰§å¿µä¸æ·±æƒ…å‘Šåˆ«çš„å¤å…¸å¼å¿—æ€ªå°è¯´ã€‚æ•…äº‹çš„çœŸç›¸åœ¨ç»“å°¾è¢«å½»åº•é¢ è¦†ï¼Œè€Œé‚£å¥è¯ï¼Œæ­£æ˜¯è§£å¼€æ‰€æœ‰è°œé¢˜çš„é’¥åŒ™ã€‚\næ•…äº‹è§£è¯»ï¼šä¸€åœºæŒç»­ä¸‰åå¹´çš„æ¢¦\nè¿™ä¸ªæ•…äº‹æœ‰å¤šé‡åè½¬ï¼Œå…¶æ ¸å¿ƒç»“æ„å¦‚ä¸‹ï¼š\nè¡¨å±‚æ•…äº‹ï¼ˆä¼ é—»ï¼‰ï¼šæ²ˆæ…•äº‘é«˜ä¸­æ‚”å©šï¼Œå¦å¨¶è´µå¥³ï¼Œç•™ä¸‹ä¸€ä¸ªä¸‰åå¹´çš„èµŒçº¦ã€‚è¿™æ˜¯ä¸€ä¸ªç¬¦åˆä¸–ä¿—æƒ³è±¡çš„ã€å…³äºè´Ÿå¿ƒä¸ç­‰å¾…çš„æ‚²å‰§ã€‚\nä¸­å±‚æ•…äº‹ï¼ˆè°¢å¨˜çš„è®²è¿°ï¼‰ï¼šè°¢å¨˜æ˜¯å®¹å¨˜çš„å©¢å¥³ï¼Œå¥¹å¸¦é¢†â€œæˆ‘â€ç»å†å¹»è±¡ï¼Œå¹¶æ­ç¤ºè‡ªå·±æ‰æ˜¯æ‚²å‰§çš„ä¸»è§’â€”â€”å¥¹å› æ´ªæ°´å¤±å»äº†è‡ªå·±çš„å°‘å¹´éƒã€‚è¿™ä¼¼ä¹å°†æ•…äº‹å¼•å‘äº†å¦ä¸€ä¸ªé”™ä½çˆ±æƒ…çš„æ–¹å‘ã€‚\næ·±å±‚æ•…äº‹ï¼ˆçœŸç›¸ï¼‰ï¼šæ ¹æœ¬æ²¡æœ‰è°¢å¨˜ï¼Œä¹Ÿæ²¡æœ‰æ‚”å©šã€‚çœ¼å‰çš„é­‚é­„å°±æ˜¯å®¹å¨˜æœ¬äººã€‚æ²ˆæ…•äº‘ä¹Ÿå¹¶éè´Ÿå¿ƒï¼Œè€Œæ˜¯æ—©å·²åœ¨äºŒåä¸ƒå²è‹±å¹´æ—©é€ã€‚ æ•´ä¸ªâ€œè´Ÿå¿ƒæ±‰ä¸ä¸‰åå¹´èµŒçº¦â€çš„æ•…äº‹ï¼Œæ˜¯å®¹å¨˜çš„é¬¼é­‚å› ä¸ºæ€å¿µè‡³æ·±è€Œç¼–é€ çš„ã€‚\nå®¹å¨˜ä¸ºä½•è¦ç¼–é€ æ•…äº‹ï¼Ÿ\næ•…äº‹ä¸­ç‚¹æ˜äº†åŸå› ï¼šâ€œæ—çš„äººæ€¨ä»–ä¹Ÿå¥½ï¼Œç¬‘æˆ‘ä¹Ÿç½¢ï¼Œæˆ‘ä»¬çš„æ•…äº‹æ€»æœ‰äººè®°å¾—æ‰å¥½ã€‚â€ çœŸå®çš„æ‚²å‰§æ˜¯æ­»äº¡å¸¦æ¥çš„æ°¸è¯€ï¼Œè¿™è¿‡äºç»å¯¹å’Œå¯‚é™ï¼Œä¼šéšç€æ—¶é—´è¢«ä¸–äººé—å¿˜ã€‚è€Œä¸€ä¸ªå¸¦æœ‰â€œè´Ÿå¿ƒâ€ã€â€œèµŒçº¦â€ç­‰æˆå‰§æ€§å…ƒç´ çš„æ•…äº‹ï¼Œåè€Œæ›´å…·ä¼ æ’­åŠ›ï¼Œæ›´èƒ½è®©ä»–ä»¬çš„çˆ±æƒ…åœ¨äººä»¬çš„å£è€³ç›¸ä¼ ä¸­â€œæ´»â€ä¸‹å»ã€‚å¥¹å®ˆæŠ¤çš„ä¸æ˜¯æ¸…ç™½ï¼Œè€Œæ˜¯è®°å¿†æœ¬èº«ã€‚\nâ€œæˆ‘â€çš„è§’è‰²ä¸ç»“å±€ï¼šâ€œæˆ‘â€ä½œä¸ºä¸€ä¸ªè¯¯å…¥æ­¤åœ°çš„å¬æ•…äº‹è€…ï¼Œæˆä¸ºäº†å®¹å¨˜å€¾è¯‰çš„å¯¹è±¡ã€‚å½“å®¹å¨˜é—®èµ·æ²ˆæ…•äº‘åœ¨äººé—´å¦‚ä½•æ—¶ï¼Œâ€œæˆ‘â€é‚£å¥å–„æ„çš„è°è¨€â€”â€”â€œä»–å¾ˆå¥½ï¼Œåæ¥åˆå¨¶äº†æ–°å¦‡ï¼Œç™½å¤´å•è€â€â€”â€”æ˜¯æ•…äº‹çš„ç‚¹ç›ä¹‹ç¬”ã€‚è¿™å¹¶éæ®‹å¿ï¼Œè€Œæ˜¯ä¸€ç§æœ€æ·±åˆ‡çš„æ…ˆæ‚²ã€‚å®ƒå‘Šè¯‰æ‰§ç€ç­‰å¾…çš„é­‚é­„ï¼šä½ çˆ±çš„é‚£ä¸ªäººï¼Œåœ¨äººé—´åœ†æ»¡ç»ˆè€ï¼Œä½ æ— éœ€å†æŒ‚å¿µäº†ã€‚è¿™ä¸ªè°è¨€ï¼Œç»™äº†å®¹å¨˜â€œæ”¾ä¸‹â€çš„ç†ç”±ã€‚äºæ˜¯ï¼Œå¥¹å¿µå‡ºé‚£å¥è¯ï¼Œé‡Šç„¶æ¶ˆæ•£ã€‚\nç¯å¢ƒè±¡å¾ï¼šè´¯ç©¿æ•…äº‹çš„â€œé›¨â€ï¼Œæ—¢æ˜¯ç°å®å¤©æ°”ï¼Œä¹Ÿæ˜¯å“€ä¼¤çš„æ°›å›´çƒ˜æ‰˜ï¼Œæ›´æ˜¯ä¸‰åå¹´å‰é‚£åœºç”Ÿæ­»æ´ªæ°´çš„è±¡å¾ã€‚æ•…äº‹å¼€å¤´å’Œç»“å°¾çš„â€œé›¨â€ä¸â€œæŸ³è‰²â€å½¢æˆé—­ç¯ï¼Œæš—ç¤ºè¿™ä¸€åˆ‡éƒ½ç¬¼ç½©åœ¨å®¹å¨˜æ‰§å¿µæ‰€åŒ–çš„ã€æ°¸æ’å‡„è¿·çš„æ¢¦å¢ƒé‡Œã€‚\nâ€œå°é™¢æ·±é™ï¼Œæ¬²é—®å¿å¿ï¼Œä½•å¤„æœˆç¬¼æ˜ã€‚åƒç§‹å²å¥½ï¼Œä¼‘è´Ÿå…°å› â€ å«ä¹‰è§£è¯»\nè¿™å¥è¯æ˜¯å®¹å¨˜çš„ç‹¬ç™½ï¼Œä¹Ÿæ˜¯å¥¹å¯¹æ²ˆæ…•äº‘è·¨è¶Šç”Ÿæ­»çš„æƒ…è¯ã€‚ç»“åˆæ•…äº‹çœŸç›¸ï¼Œå…¶å«ä¹‰å±‚å±‚é€’è¿›ï¼š\nâ€œå°é™¢æ·±é™ï¼Œæ¬²é—®å¿å¿ï¼Œä½•å¤„æœˆç¬¼æ˜ã€‚â€\nå­—é¢æ„å¢ƒï¼šåº­é™¢å¹½æ·±å¯‚é™ï¼Œæˆ‘æƒ³é—®ä¸€é—®ä½ ï¼Œæ­¤åˆ»å“ªé‡Œçš„æœˆå…‰æ­£æ˜äº®åœ°ç¬¼ç½©ç€ï¼ˆä½ ï¼‰ï¼Ÿ æ•…äº‹æ·±æ„ï¼šè¿™æç»˜äº†å®¹å¨˜ä½œä¸ºé­‚é­„çš„å­¤ç‹¬å¤„å¢ƒã€‚â€œå°é™¢æ·±é™â€æ˜¯å¥¹ä¸‰åå¹´æ¥å¾˜å¾Šä¹‹åœ°çš„å¯‚å¯¥å†™ç…§ã€‚â€œæ¬²é—®å¿å¿â€æ˜¯æäº²æ˜µçš„å‘¼å”¤ï¼Œå¯¹è±¡æ˜¯æ—©å·²ä¸åœ¨äººä¸–çš„æ²ˆæ…•äº‘ã€‚â€œä½•å¤„æœˆç¬¼æ˜â€æ˜¯ä¸€ä¸ªè·¨è¶Šé˜´é˜³çš„å‘é—®ï¼šä½ çš„é­‚é­„ç°åœ¨ä½•å¤„ï¼Ÿæ˜¯å¦å®‰å¥½ï¼Ÿè¿™å¥å……æ»¡äº†æ— å¤„å¯„æ‰˜çš„ç‰µæŒ‚ä¸æ¸©æŸ”æ¢è¯¢ã€‚ â€œåƒç§‹å²å¥½ï¼Œä¼‘è´Ÿå…°å› ã€‚â€\nå­—é¢å…¸æ•…ï¼šâ€œåƒç§‹å²å¥½â€æ˜¯ç¥æ„¿å²æœˆé•¿ä¹…ç¾å¥½ï¼›â€œå…°å› â€å…¸å‡ºã€Šå·¦ä¼ ã€‹ï¼Œéƒ‘æ–‡å…¬å¦¾ç‡•å§æ¢¦è§å¤©ä½¿èµ å…°ï¼Œåç”Ÿä¸‹å…¬å­å…°ï¼Œæ¯”å–»åƒå…°èŠ±ä¸€æ ·ç¾å¥½çš„å‰å› ã€å‘½ä¸­æ³¨å®šçš„å§»ç¼˜ã€‚â€œå…°å› çµ®æœâ€åˆ™å¸¸æŒ‡å¼€ç«¯ç¾å¥½è€Œç»“å±€å‡„å‡‰ã€‚æ­¤å¤„â€œä¼‘è´Ÿå…°å› â€å³â€œä¸è¦è¾œè´Ÿäº†æˆ‘ä»¬ç¾å¥½çš„å¼€ç«¯â€ã€‚ æ•…äº‹æ·±æ„ï¼šè¿™æ˜¯æ•´é¦–è¯çš„æƒ…æ„Ÿæ ¸å¿ƒï¼Œä¹Ÿæ˜¯å®¹å¨˜çš„é‡Šç„¶ä¹‹è¯­ã€‚ åœ¨å¬åˆ°â€œæˆ‘â€çš„è°è¨€ä¹‹å‰ï¼Œè¿™æˆ–è®¸æ˜¯å¥¹å›ºæ‰§çš„æ„¿æœ›ï¼šå¸Œæœ›å¯¹æ–¹ä¸è¦è¾œè´Ÿå½“åˆçš„æƒ…ç¼˜ã€‚ ä½†åœ¨å¬åˆ°â€œä»–å¾ˆå¥½â€ä¹‹åï¼Œè¿™å¥è¯çš„å«ä¹‰å½»åº•æ”¹å˜ã€‚ å¥¹å°†â€œæˆ‘â€çš„è°è¨€ä¿¡ä»¥ä¸ºçœŸï¼šåŸæ¥ä»–åœ¨äººé—´æ‹¥æœ‰äº†â€œåƒç§‹å²å¥½â€çš„åœ†æ»¡äººç”Ÿã€‚äºæ˜¯ï¼Œâ€œä¼‘è´Ÿå…°å› â€ä»ä¸€å¥æ€¨æ€¼æˆ–æœŸç›¼ï¼Œå˜æˆäº†ä¸€å¥å®½æ•å’Œç¥ç¦ï¼šæ—¢ç„¶ä½ å·²æœ‰äº†ç¾å¥½çš„ä¸€ç”Ÿï¼Œé‚£æˆ‘ä¾¿ä¸å†æ‰§ç€ï¼Œä¸è®©ä½ æˆ‘å½“åˆç¾å¥½çš„å§»ç¼˜ï¼ˆå…°å› ï¼‰æˆä¸ºæŸç¼šä½ çš„è´Ÿç´¯ã€‚æˆ‘æ”¾è¿‡ä½ ï¼Œä¹Ÿæ”¾è¿‡æˆ‘è‡ªå·±ã€‚ æ•´ä½“å«ä¹‰ï¼šè¿™é˜™è¯æ˜¯å®¹å¨˜å¯¹æ²ˆæ…•äº‘çš„æœ€ç»ˆå‘Šåˆ«ã€‚å¥¹åœ¨ä¸€ä¸ªäººçš„â€œå°é™¢æ·±é™â€ä¸­å­¤ç‹¬æ€å¿µäº†ä¸‰åå¹´ï¼Œæœ€ç»ˆé€‰æ‹©ç›¸ä¿¡çˆ±äººå·²åœ¨äººé—´è·å¾—â€œåƒç§‹å²å¥½â€ï¼Œäºæ˜¯å¥¹å†³å®šâ€œä¼‘è´Ÿå…°å› â€â€”â€”æ”¾ä¸‹æ‰§å¿µï¼Œè§£è„±è¿™æ®µå› ç¼˜ï¼Œè®©å½¼æ­¤éƒ½è‡ªç”±ã€‚\nè¿™ä¸ªæ•…äº‹çš„ç²¾å¦™ä¹‹å¤„åœ¨äºï¼Œå®ƒç”¨ä¸€ä¸ªâ€œè°è¨€â€ï¼ˆå®¹å¨˜ç¼–çš„æ•…äº‹ï¼‰åŒ–è§£äº†å¦ä¸€ä¸ªâ€œè°è¨€â€ï¼ˆâ€œæˆ‘â€è¯´çš„å–„æ„çš„è°è¨€ï¼‰ï¼Œæœ€ç»ˆè¾¾æˆäº†æœ€æ·±å±‚çš„çœŸå®ï¼šçˆ±åˆ°æè‡´ï¼Œä¸æ˜¯å æœ‰ï¼Œè€Œæ˜¯å¸Œæœ›å¯¹æ–¹å¹¸ç¦ï¼Œå“ªæ€•è¿™å¹¸ç¦ä¸è‡ªå·±æ— å…³ï¼Œç”šè‡³éœ€è¦é ä¸€ä¸ªè™šæ„çš„æ•…äº‹æ¥æˆå…¨ã€‚ é‚£åœºä¸‰åå¹´çš„é›¨ï¼Œç»ˆäºåœäº†ã€‚\nQwen3-Max è¿™ä¸ªæ•…äº‹æ˜¯ä¸€åˆ™å……æ»¡å¤å…¸æ„è•´ä¸å¹½å¾®æƒ…æ„Ÿçš„å¿—æ€ªå¼çŸ­ç¯‡ï¼Œèåˆäº†ç°å®ä¸å¹»æ¢¦ã€è®°å¿†ä¸è™šæ„ã€æ‰§å¿µä¸é‡Šæ€€ã€‚å®ƒä»¥â€œä¸‰åå¹´ä¹‹çº¦â€ä¸ºå¼•ï¼Œå±‚å±‚å‰¥å¼€ä¸€æ®µè¢«æ—¶é—´æ©åŸ‹çš„çˆ±æƒ…å¾€äº‹ï¼Œæœ€ç»ˆæ­ç¤ºå‡ºï¼šæ‰€è°“â€œæ•…äº‹â€ï¼Œä¸è¿‡æ˜¯ç”Ÿè€…å¯¹é€è€…ã€å¯¹æœªç«Ÿä¹‹æƒ…çš„æ¸©æŸ”é‡æ„ã€‚\nä¸€ã€æ•…äº‹è§£è¯»ï¼šä¸€åœºç”±äº¡é­‚ç¼–ç»‡çš„æ¢¦ å™äº‹çš„åè½¬ä¸çœŸç›¸çš„æ­ç¤º\næ•…äº‹å¼€ç¯‡ä»¥â€œæˆ‘â€å¬é—»å…³äºæ²ˆæ…•äº‘çš„å¤šç§ä¼ é—»ä¸ºå¼•ï¼Œæœ€åŠ¨äººçš„æ˜¯â€œå®¹å¨˜ä¸èµŒçº¦â€çš„ç‰ˆæœ¬ã€‚è€äººæŒ‡å¼•â€œæˆ‘â€å»æ‰¾è°¢å¨˜ï¼Œçœ‹ä¼¼æ˜¯å¼•è·¯äººï¼Œå®åˆ™ä¸ºå¹»å¢ƒå¼€å¯çš„å¥‘æœºã€‚è€Œå½“â€œæˆ‘â€è§åˆ°è°¢å¨˜ï¼Œéšå¥¹è¿‡æ¡¥ã€é‡é£é›¨ã€è§å¹»è±¡ï¼Œæœ€ç»ˆæ‰æƒŠè§‰â€”â€”è°¢å¨˜å³å®¹å¨˜ï¼Œè€Œâ€œè°¢å¨˜â€åªæ˜¯å¥¹ä¸ºè®²è¿°æ•…äº‹è€Œè™šæ„çš„èº«ä»½ã€‚\nè¿™ä¸€åè½¬æå…·éœ‡æ’¼åŠ›ï¼šå®¹å¨˜æ—©å·²æººäº¡äºä¸‰åå¹´å‰çš„é‚£åœºé›¨ä¸­ï¼Œå¥¹çš„é­‚é­„æ»ç•™äººé—´ï¼Œåªä¸ºå®ˆå€™ä¸€ä¸ªä¸å¯èƒ½å…‘ç°çš„çº¦å®šã€‚å¥¹ç¼–é€ â€œæ‚”å©šâ€â€œèµŒçº¦â€â€œå©¢å¥³è°¢å¨˜â€ç­‰æƒ…èŠ‚ï¼Œå®åˆ™æ˜¯ä¸ºäº†èµ‹äºˆè¿™æ®µæ— æœä¹‹çˆ±ä¸€ä¸ªå¯è¢«ä¼ é¢‚çš„å½¢æ€â€”â€”å“ªæ€•æ˜¯ä»¥æ€¨æ¨ã€è¯¯è§£çš„æ–¹å¼ï¼Œä¹Ÿèƒœè¿‡å½»åº•è¢«é—å¿˜ã€‚\nâ€œæ¢¦â€çš„æœ¬è´¨ï¼šæ‰§å¿µä¸æ…ˆæ‚²çš„äº¤ç»‡\nå®¹å¨˜è¯´ï¼šâ€œå·¦å³æ˜¯åœ¨æ¢¦é‡Œï¼Œå®¹æˆ‘ä»»æ€§ä½¿åç¼–æ’ä»–ä¸€å›ã€‚â€\nè¿™å¥è¯é“å‡ºäº†å¥¹å…¨éƒ¨çš„æ¸©æŸ”ä¸å¿ƒé…¸ã€‚å¥¹æ˜çŸ¥æ²ˆæ…•äº‘æ—©é€ï¼Œå´ä»æ„¿åœ¨æ¢¦ä¸­ä¸ºä»–å®‰æ’ä¸€ä¸ªâ€œç™½å¤´å•è€â€çš„ç»“å±€ï¼›å¥¹è™šæ„è‡ªå·±è¢«è´Ÿå¿ƒï¼Œå®åˆ™æ˜¯ä¸æ„¿ä¸–äººçŸ¥é“ä»–è‹±å¹´æ—©é€ã€å¥¹æ®‰æƒ…è€Œäº¡çš„æ‚²å‰§ï¼Œæ›´ä¸æ„¿ä»–çš„åå£°å› â€œè´Ÿå¿ƒâ€è€Œå—æŸã€‚å¥¹çš„â€œç¼–æ’â€ï¼Œæ˜¯çˆ±çš„å¦ä¸€ç§å®ˆæŠ¤ã€‚\nâ€œæˆ‘â€çš„è§’è‰²ï¼šè®°å¿†çš„æ‰¿æ¥è€…\nâ€œæˆ‘â€ä½œä¸ºå¤–æ¥è€…ï¼Œæ—¢æ˜¯å¬ä¼—ï¼Œä¹Ÿæ˜¯è§è¯è€…ã€‚å½“â€œæˆ‘â€é€‰æ‹©éšç’æ²ˆæ…•äº‘æ—©é€çš„çœŸç›¸ï¼Œå‘Šè¯‰å¥¹â€œä»–å¾ˆå¥½ï¼Œç™½å¤´å•è€â€ï¼Œè¿™å¹¶éæ¬ºéª—ï¼Œè€Œæ˜¯ä¸€ç§å…±è°‹å¼çš„æ…ˆæ‚²â€”â€”æˆå…¨å¥¹æœ€åçš„å¹»æƒ³ï¼Œè®©å¥¹å¸¦ç€â€œä»–è¿‡å¾—å¾ˆå¥½â€çš„å®‰å¿ƒç¦»å»ã€‚è¿™æ­£å‘¼åº”äº†å®¹å¨˜è‡ªå·±çš„å–„æ„ï¼šå¥¹å®æ„¿è¢«è¯¯è§£ä¸ºè¢«å¼ƒä¹‹äººï¼Œä¹Ÿä¸æ„¿ä¸–äººçŸ¥é“ä»–æ—©å¤­ã€‚\næ„è±¡çš„è±¡å¾\næ²³æ¡¥ï¼šè¿æ¥ç°å®ä¸å¹»å¢ƒã€ç”Ÿä¸æ­»çš„è¾¹ç•Œã€‚ ç»†é›¨/æ´ªæµªï¼šæƒ…æ„Ÿçš„å¤–åŒ–ã€‚ç»†é›¨æ˜¯ç»µé•¿çš„æ€å¿µï¼Œæ´ªæµªæ˜¯è®°å¿†çˆ†å‘çš„ç¬é—´ã€‚ çº¢å¦†èŠ±è½¿ï¼šæœªå®Œæˆçš„å©šç¤¼ï¼Œæ°¸è¿œå®šæ ¼åœ¨å¹»è±¡ä¸­ã€‚ æŸ³è‰²å‡„è¿·ï¼šå¤å…¸è¯—è¯ä¸­å¸¸å–»ç¦»åˆ«ä¸å“€æ„ï¼Œæ­¤å¤„è±¡å¾æ—¶å…‰æµè½¬è€Œæƒ…æ„ä¸ç­ã€‚ äºŒã€è¯å¥è§£è¯»ï¼šâ€œå°é™¢æ·±é™ï¼Œæ¬²é—®å¿å¿ï¼Œä½•å¤„æœˆç¬¼æ˜ã€‚åƒç§‹å²å¥½ï¼Œä¼‘è´Ÿå…°å› ã€‚â€ è¿™å‡ å¥è¯è™½ä¸ºè™šæ„ï¼Œå´æ·±å¾—å®‹è¯å©‰çº¦ä¹‹ç¥é«“ï¼Œå¯è§†ä¸ºå®¹å¨˜å¿ƒå£°çš„å‡ç»ƒè¡¨è¾¾ã€‚\nâ€œå°é™¢æ·±é™ï¼Œæ¬²é—®å¿å¿ï¼Œä½•å¤„æœˆç¬¼æ˜â€\nå°é™¢æ·±é™ï¼šå›å¿†ä¸­ä¸¤äººåˆé‡æˆ–å®šæƒ…ä¹‹æ‰€ï¼Œå¹½æ·±å®é™ï¼Œå……æ»¡ç§å¯†æ¸©æƒ…ã€‚ æ¬²é—®å¿å¿ï¼šâ€œå¿å¿â€ä¸ºå¤æ—¶çˆ±ç§°ï¼Œæ­¤å¤„æ˜¯å®¹å¨˜å¯¹æ²ˆæ…•äº‘çš„æ·±æƒ…å‘¼å”¤ã€‚ ä½•å¤„æœˆç¬¼æ˜ï¼šåŒ–ç”¨æœç‰§â€œçƒŸç¬¼å¯’æ°´æœˆç¬¼æ²™â€ä¹‹æ„è±¡ã€‚â€œæœˆç¬¼æ˜â€æ—¢æŒ‡æœˆå…‰æœ¦èƒ§ï¼Œäº¦å–»æƒ…ç¼˜å¦‚æœˆï¼Œçœ‹ä¼¼æ˜äº®å´ä¸å¯è§¦åŠã€‚å¥¹åœ¨é—®ï¼šå½“å¹´å…±èµæ˜æœˆä¹‹äººï¼Œå¦‚ä»Šåœ¨ä½•æ–¹ï¼Ÿé‚£è½®è§è¯èª“è¨€çš„æœˆäº®ï¼Œæ˜¯å¦è¿˜è®°å¾—æˆ‘ä»¬çš„çº¦å®šï¼Ÿ æ­¤å¥æ•´ä½“è¥é€ å‡ºä¸€ç§è¿½å¿†å¾€æ˜”ã€å¯»è€Œä¸å¾—çš„æ€…æƒ˜ï¼Œæ˜¯å®¹å¨˜ä¸‰åä½™å¹´æ¥é­‚ç‰µæ¢¦è¦çš„å†™ç…§ã€‚\nâ€œåƒç§‹å²å¥½ï¼Œä¼‘è´Ÿå…°å› â€\nåƒç§‹å²ï¼šè¯ç‰Œåï¼Œäº¦æŒ‡æ¼«é•¿å²æœˆã€‚æ­¤å¤„åŒå…³ï¼Œæ—¢æŒ‡æ—¶é—´ä¹…è¿œï¼Œä¹Ÿæš—å«ç¥ç¦ã€‚ å…°å› ï¼šå…¸å‡ºã€Šå‘¨æ˜“Â·ç³»è¾ä¸Šã€‹â€œäºŒäººåŒå¿ƒï¼Œå…¶åˆ©æ–­é‡‘ï¼›åŒå¿ƒä¹‹è¨€ï¼Œå…¶è‡­å¦‚å…°ã€‚â€åä»¥â€œå…°å› â€å–»ç¾å¥½çš„å§»ç¼˜æˆ–åˆå¿ƒã€‚â€œå…°å› çµ®æœâ€åˆ™æŒ‡åˆæ—¶ç¾å¥½ã€ç»ˆæˆç¦»æ•£çš„å§»ç¼˜ã€‚ ä¼‘è´Ÿå…°å› ï¼šæ„ä¸ºâ€œä¸è¦è¾œè´Ÿå½“åˆé‚£å¦‚å…°èˆ¬èŠ¬èŠ³çš„èª“çº¦â€ã€‚ ç„¶è€Œï¼Œæ­¤å¤„çš„â€œä¼‘è´Ÿå…°å› â€å¹¶éè´£å¤‡ï¼Œè€Œæ˜¯ä¸´åˆ«å‰çš„æ¸©æŸ”å®å’›ã€‚å¥¹æ˜çŸ¥ä»–å·²ä¸åœ¨äººä¸–ï¼Œå´ä»ä»¥æ¢¦ä¸­ä¹‹è¯­ï¼Œå˜±ä»–â€œè«è´Ÿåˆå¿ƒâ€â€”â€”å®åˆ™æ˜¯å¯¹è‡ªå·±æ‰§å¿µçš„æ”¾ä¸‹ï¼šçºµä½¿ç»“å±€ä¸å¦‚æ„¿ï¼Œæˆ‘ä»¬æ›¾æœ‰çš„â€œå…°å› â€å·²æ˜¯è¶³å¤Ÿç¾å¥½ï¼Œä¸å¿…æ€¨ï¼Œä¸å¿…æ‚”ã€‚\nä¸‰ã€æ•´ä½“ä¸»æ—¨ï¼šçˆ±çš„æœ€é«˜å½¢å¼æ˜¯æˆå…¨ä¸é“­è®° è¿™ä¸ªæ•…äº‹å¹¶éç®€å•çš„â€œè´Ÿå¿ƒæ±‰ä¸ç—´æƒ…å¥³â€å¥—è·¯ï¼Œè€Œæ˜¯ä¸€æ›²å…³äºè®°å¿†ã€è™šæ„ä¸çˆ±çš„å°Šä¸¥çš„æŒ½æ­Œã€‚å®¹å¨˜ä»¥äº¡é­‚ä¹‹èº«ï¼Œç¼–ç»‡ä¸€ä¸ªâ€œè¢«è¾œè´Ÿâ€çš„æ•…äº‹ï¼Œåªä¸ºè®©è¿™æ®µæ„Ÿæƒ…ä¸è¢«æ—¶é—´æ¹®ç­ï¼›è€Œâ€œæˆ‘â€ä»¥å–„æ„çš„è°è¨€ï¼Œæˆå…¨å¥¹æœ€åçš„ä½“é¢ã€‚æ²ˆæ…•äº‘è™½æ—©é€ï¼Œå´å› å¥¹çš„å®ˆæŠ¤ï¼Œåœ¨ä¼ è¯´ä¸­â€œç™½å¤´å•è€â€â€”â€”è¿™ä½•å°ä¸æ˜¯å¦ä¸€ç§æ°¸æ’ï¼Ÿ\né‚£å¥è¯ï¼Œæ—¢æ˜¯å¥¹å¯¹å¾€æ˜”çš„å›æœ›ï¼Œä¹Ÿæ˜¯å¯¹æœªæ¥çš„ç¥ç¦ã€‚â€œåƒç§‹å²å¥½ï¼Œä¼‘è´Ÿå…°å› â€ï¼Œä¸åªæ˜¯å¯¹æ²ˆæ…•äº‘è¯´ï¼Œæ›´æ˜¯å¯¹æ‰€æœ‰å¬æ•…äº‹çš„äººè¯´ï¼š\nçºµä½¿ç¼˜æµ…ï¼Œè«å¿˜åˆå¿ƒï¼›çºµä½¿æˆç©ºï¼Œçˆ±å·²æ°¸æ’ã€‚\nè€Œé‚£åœºä¸‰åå¹´åçš„é›¨ï¼Œä¾æ—§å¦‚åˆé€¢æ—¶èˆ¬å‡„è¿·â€”â€”å› ä¸ºæœ‰äº›çˆ±ï¼Œä»æœªç¦»å¼€ã€‚\nLongCat ä¸€ã€æ•…äº‹æ ¸å¿ƒä¸»é¢˜ è®°å¿†ä¸æ‰§å¿µçš„è™šå®äº¤ç»‡\næ•…äº‹é€šè¿‡\u0026quot;è°¢å¨˜\u0026quot;çš„è°è¨€ï¼ˆå®ä¸ºå®¹å¨˜çš„é¬¼é­‚ï¼‰æ„å»ºäº†å¤šå±‚å™äº‹ï¼šè¡¨é¢æ˜¯æ²ˆæ…•äº‘è´Ÿå¿ƒçš„ä¼ è¯´ï¼Œå®åˆ™æ˜¯å®¹å¨˜å¯¹é€å»çš„çˆ±æƒ…ä¸æ‰§å¿µçš„æŠ•å°„ã€‚å¥¹å€Ÿ\u0026quot;èµŒçº¦\u0026quot;ä¹‹åï¼Œè®©æ•…äº‹æµä¼ åƒå¹´ï¼Œé¿å…è¢«ä¸–äººé—å¿˜ã€‚ \u0026ldquo;æˆ‘ä»¬çš„æ•…äº‹æ€»æœ‰äººè®°å¾—æ‰å¥½\u0026rdquo;â€”â€”å®¹å¨˜çš„æ ¸å¿ƒè¯‰æ±‚ï¼Œä½“ç°äº†äººç±»å¯¹æ°¸æ’è®°å¿†çš„è¿½æ±‚ï¼Œå³ä½¿ä»¥è°è¨€ä¸ºä»£ä»·ã€‚ ç”Ÿæ­»ä¸é—æ†¾çš„è±¡å¾\næš´é›¨ä¸­çš„å¹»è±¡ï¼ˆçº¢å¦†ã€èŠ±è½¿ã€æ´ªæµªï¼‰æ˜¯å®¹å¨˜è®°å¿†çš„æ˜¾å½±ï¼Œæš—ç¤ºå¥¹çš„\u0026quot;å©šå§»\u0026quot;è¢«æ´ªæ°´ï¼ˆå‘½è¿ï¼‰åå™¬ï¼Œå°‘å¹´éƒï¼ˆæ²ˆæ…•äº‘ï¼‰çš„ç¦»å»æ˜¯å¥¹æ— æ³•é‡Šæ€€çš„ç—›ã€‚ \u0026ldquo;åƒå¤©ä¸Šçš„æœˆäº®ï¼Œæä¸€æç»ˆä¸èƒ½å¾—\u0026rdquo;â€”â€”ä»¥æœˆäº®éšå–»ç†æƒ³åŒ–çš„çˆ±æƒ…ï¼Œè™½ä¸å¯å¾—ï¼Œä½†æ‰§å¿µå¦‚æœˆå…‰ç¬¼ç½©äººé—´ï¼Œå½¢æˆè¯—æ„åŒ–çš„é—æ†¾ã€‚ çœŸç›¸ä¸å–„æ„çš„è°è¨€\nå™è¿°è€…æœ€åé€‰æ‹©æ¬ºéª—å®¹å¨˜ï¼ˆè°ç§°æ²ˆæ…•äº‘å†å©šï¼‰ï¼Œå®Œæˆäº†å¯¹äº¡çµçš„æ•‘èµã€‚è¿™ä¸€ç»†èŠ‚æ­ç¤ºï¼šäººé—´å¯¹äº¡è€…çš„æ‚²æ‚¯ï¼Œæœ‰æ—¶åœ¨äºç¼–é€ åœ†æ»¡çš„ç»“å±€ã€‚ æ²ˆæ…•äº‘æ—©å’ã€å®¹å¨˜åŒ–é¬¼çš„æ‚²å‰§ï¼Œè¢«\u0026quot;åŠé—´æµä¼ çš„æ•…äº‹\u0026quot;èµ‹äºˆä¸åŒç‰ˆæœ¬ï¼Œè¯´æ˜é›†ä½“è®°å¿†å¯¹å†å²çš„å†åˆ›é€ ã€‚ äºŒã€è¯—å¥é€å±‚è§£æ \u0026ldquo;å°é™¢æ·±é™ï¼Œæ¬²é—®å¿å¿ï¼Œä½•å¤„æœˆç¬¼æ˜\u0026rdquo;\nè¡¨å±‚ï¼šå¯‚é™å°é™¢ä¸­ï¼Œçˆ±äººï¼ˆå¿å¿ï¼‰çš„èº«å½±ä¸æœˆè‰²äº¤å ï¼Œå´å› è–„é›¾éš¾å¯»å…¶è¸ªè¿¹ã€‚ æ·±å±‚ï¼š\u0026ldquo;æœˆç¬¼æ˜\u0026quot;è±¡å¾è®°å¿†çš„æœ¦èƒ§æ€§â€”â€”å®¹å¨˜å¯¹æ²ˆæ…•äº‘çš„æ€å¿µä¼¼æœˆå…‰æ˜åªšï¼Œå´ä¹Ÿå¦‚é›¾æ°”èˆ¬æ¨¡ç³Šéš¾è§¦ã€‚ **\u0026ldquo;æ¬²é—®\u0026rdquo;**çš„æœªå®Œæˆæ—¶æ€ï¼Œå¼ºåŒ–äº†é˜´é˜³ä¸¤éš”çš„æ— å¥ˆã€‚ \u0026ldquo;åƒç§‹å²å¥½ï¼Œä¼‘è´Ÿå…°å› \u0026rdquo;\nå…¸æ•…ï¼š\u0026ldquo;å…°å› \u0026quot;å‡ºè‡ªã€Šå·¦ä¼ ã€‹\u0026ldquo;å½’å¦»èŒ¹å§¬ï¼Œè¨€å…°ä¹‹å› \u0026rdquo;ï¼Œå–»ç¾æ»¡å§»ç¼˜ã€‚ ç›´è¯‘ï¼šæ„¿ä½ ä»¬åƒå¹´ä¸‡ä»£å¹¸ç¦ï¼Œè«è¾œè´Ÿå¤©èµçš„ç¼˜åˆ†ã€‚ éšå«çŸ›ç›¾ï¼š å®¹å¨˜åœ¨è¯—å¥ä¸­ä½œä¸º\u0026quot;æ—è§‚è€…\u0026quot;ç¥ç¦æ²ˆæ…•äº‘ï¼Œå®ä¸ºè‡ªæˆ‘å‚¬çœ å¼çš„å®‰æ…°ï¼› \u0026ldquo;ä¼‘è´Ÿ\u0026quot;äºŒå­—æš´éœ²äº†å¥¹çš„è„†å¼±ï¼šæ—¢ç„¶æ²ˆæ…•äº‘æ—©é€æœªå¨¶ï¼Œ\u0026ldquo;å…°å› \u0026quot;æ—©å·²æˆç©ºï¼Œä½†é¬¼é­‚ä»åœ¨å›ºæ‰§åœ°ç»´æŠ¤çˆ±æƒ…çš„\u0026quot;å°Šä¸¥\u0026rdquo;ã€‚ è¶…è„±æ€§ï¼šå®¹å¨˜æœ€ç»ˆæ¥çº³äº†æ‚²å‰§ï¼Œä»¥è¯—æ„æ¶ˆè§£æ‰§å¿µï¼Œèº«å½±æ¶ˆæ•£çš„ç¬é—´å®Œæˆç²¾ç¥è§£è„±ã€‚ ä¸‰ã€è¯—å¥ä¸æ•…äº‹çš„äº’æ–‡æ€§ è®°å¿†çš„ç¾åŒ–ä¸é‡æ„\nè¯—å¥ä¸­çš„\u0026quot;å°é™¢æ·±é™\u0026quot;ä¸\u0026quot;æœˆç¬¼æ˜\u0026rdquo;ï¼Œå¯¹åº”å®¹å¨˜è™šæ„çš„\u0026quot;æ²³æ¡¥èµŒçº¦\u0026rdquo;ï¼ŒäºŒè€…çš†å°†ç—›è‹¦è®°å¿†å‡åä¸ºå”¯ç¾æ„è±¡ï¼Œä½“ç°æƒ…æ„Ÿå¯¹äº‹å®çš„æ”¹é€ ã€‚ å¯¹\u0026quot;æ—¶é—´\u0026quot;çš„è¶…è¶Š\n\u0026ldquo;åƒç§‹å²å¥½\u0026quot;æ—¢æ˜¯å¯¹æ²ˆæ…•äº‘çš„ç¥ç¦ï¼Œä¹Ÿæ˜¯å¯¹è‡ªèº«å­˜åœ¨çš„è¯˜é—®ï¼šå¥¹ä»¥é¬¼é­‚ä¹‹å§¿å¾˜å¾Šä¸‰åå¹´ï¼Œæœ€ç»ˆç”¨è¯—å¥æŠ¹å¹³æ—¶é—´åˆ»åº¦ï¼Œä¸è¿‡å»å’Œè§£ã€‚ ä¸œæ–¹æ‚²å‰§ç¾å­¦çš„å…¸èŒƒ\nå…¨è¯—æ— æ¿€çƒˆæ§è¯‰ï¼Œå´ä»¥\u0026quot;é›¾ä¸­é—®æœˆ\u0026quot;\u0026ldquo;æœˆä¸‹ç¥è¯­\u0026quot;çš„å«è“„æ–¹å¼ï¼Œå®Œæˆå¯¹å‘½è¿æ— å¸¸çš„æ‚²æ‚¯ï¼Œå¥‘åˆä¼ ç»Ÿæ–‡å­¦ä¸­\u0026quot;å“€è€Œä¸ä¼¤\u0026quot;çš„ç¾å­¦æ ‡å‡†ã€‚ å››ã€ç»“è¯­ï¼šæœªå®Œæˆçš„è¯—æ€§æ­£ä¹‰ æ•…äº‹é€šè¿‡è°è¨€ã€é¬¼é­‚ã€è¯—æ­Œä¸‰é‡åª’ä»‹ï¼Œå®ç°äº†å¦ä¸€ç§\u0026quot;æ­£ä¹‰\u0026rdquo;ï¼šå®¹å¨˜è™½æœªèƒ½æ”¹å†™å†å²ï¼Œå´ä»¥ç¾å­¦æ–¹å¼å®Œæˆäº†å¯¹æ®‹ç¼ºçˆ±æƒ…çš„ç¥åœ£åŒ–ã€‚è€Œè¯—å¥\u0026quot;ä¼‘è´Ÿå…°å› \u0026quot;çš„çŸ›ç›¾æ€§ï¼Œæ­£æ˜¯ä¸œæ–¹æ–‡åŒ–ä¸­\u0026quot;æ‰§å¿µä¸é‡Šæ€€\u0026quot;äºŒå…ƒç‰¹è´¨çš„ç²¾å¦™æ³¨è„šã€‚\nå®éªŒè®¾å®š ä½œè€…ï¼šå†‰è¯­ä¼˜\nPromptï¼š\næˆ‘å¬è¿‡è®¸å¤šå…³äºæ²ˆæ…•äº‘çš„æ•…äº‹ï¼Œåªæœ‰è¿™é‡Œçš„ä¸ä¼—ä¸åŒã€‚æœ‰è¯´ä»–ä¸Šäº¬èµ´è€ƒï¼Œåæ¥å¦è˜äº†é˜è€å®¶çš„è´µå¥³ï¼Œä¹Ÿæœ‰è¯´ä»–æ—©çŸ¥å¾—äº†ä¸å¯¿ä¹‹ç—‡ï¼Œä¸æƒ³æ•™è°å®ˆå¯¡ç½¢äº†ã€‚åªæœ‰è¿™åŸé‡Œçš„è€äººå‘Šè¯‰æˆ‘ï¼Œæ²ˆæ…•äº‘åˆæ‹çš„å°‘å¥³å«åšå®¹å¨˜ï¼Œå®¶å°±ä½åœ¨æ²³æ¡¥å¯¹å²¸ã€‚ä¸¤äººå·²å®šäº†å©šçº¦ï¼Œä»–èµ´è€ƒé«˜ä¸­ï¼Œåˆ°äº†é‚£æ—¶å´çªç„¶åæ‚”ï¼Œå¯¹å®¹å¨˜é¿ä¹‹ä¸è§ã€‚â€œåæ¥å®¹å¨˜ä¼¤å¿ƒï¼Œä»æ­¤å†ä¸è§äººã€‚ä½†æ­¤åœ°äººäººéƒ½çŸ¥é“ä¸¤äººé—´çš„èµŒçº¦ï¼šä¸‰åå¹´åï¼Œæ•…äººæ•…åœ°ï¼Œä»–æ•¢ä¸æ•¢å†æ¥ç›¸è§ï¼Ÿâ€è€äººæœ›äº†æœ›æˆ‘ï¼Œæ¥ç€è¯´ï¼šâ€œä½ æ¥å¾—å·§ã€‚ä»Šæ—¥ä¾¿æ˜¯ä¸‰åå¹´æ•´çº¦å®šä¹‹æ—¥ã€‚åŸä½ç€å½“å¹´é¢„å¤‡ä¾å€™å¥¹æˆäº²çš„å©¢å¥³ï¼Œå«åšè°¢å¨˜ï¼Œä½ æ—¢æ¥äº†ï¼Œå¯ä»¥æ±‚å¥¹é¢†ä½ å»çœ‹ã€‚â€_\ræˆ‘è°¢è¿‡ä»–ï¼Œæ‰å¤´èµ°äº†ã€‚\nâ€œæ— è®ºå¤šå°‘å¹´ï¼Œéƒ½æ˜¯ä¸€æ ·çš„ç»“æœã€‚â€\nä¸Šæ¡¥çš„æ—¶å€™ï¼Œæˆ‘å¬ä»–è¿™æ ·è¯´ã€‚\næˆ‘è§åˆ°äº†è°¢å¨˜ã€‚æ­¤åœ°çš„ç»†é›¨ç»µç»µæ— æœŸï¼Œå¥½ä¼¼æŠŠæ¯ä¸€ä¸ªäººçš„é¢ç›®éƒ½ç¬¼åœ¨å¾®æ¹¿çš„æ˜¥é›¾é‡Œï¼Œçœ‹ä¸çœŸåˆ‡ï¼Œå¯æˆ‘éšçº¦æ„Ÿåˆ°å·²ä¸Šäº†å¹´çºªçš„è°¢å¨˜æ˜¯ç¾çš„ã€‚å¥¹å½“å¹´ä¾å€™è¿‡çš„å¥³ä¸»äººâ€”â€”å®¹å¨˜ä¸€å®šæ›´ç¾å§ï¼Ÿ\næˆ‘å‘å¥¹é“æ˜æ¥æ„ã€‚\nâ€œå•Šï¼Œå¥¹å’Œæ²ˆæ…•äº‘çš„äº‹å„¿å‘€â€¦â€¦æˆ‘ä¸èƒ½å‘Šè¯‰ä½ â€ï¼Œå¥¹ç¬‘äº†ç¬‘ï¼Œâ€œä½†æ˜¯æˆ‘èƒ½å¸¦ä½ å»çœ‹ã€‚â€\nå¥¹è¯´å®Œï¼Œä¸æ›¾æºä¼ï¼Œè¿ç€å±‹å¤–é›¨é›¾æå¿«åœ°èµ°äº†å‡ºå»ã€‚æˆ‘è·Ÿäº†å‡ºå»ã€‚ä¸çŸ¥æ€ä¹ˆåœ°ï¼Œè·Ÿåœ¨å¥¹èº«è¾¹ï¼Œæˆ‘ç«Ÿä¹Ÿèƒ½èµ°å¾—æå¿«\nè½¬çœ¼é—´ï¼Œæˆ‘ä»¬èµ°è¿‡äº†æ¥æ—¶é‚£åº§æ²³æ¡¥ï¼Œå¿½ç„¶ï¼Œæ¡¥ä¸‹æ²³æ°´å·¨æ¶¨ï¼Œç»†é›¨å˜ä½œæ»”å¤©é›¨æµªè¿é¢æ‹æ¥ï¼Œä¸€æµªæµªæ‰“ä¸¤è¾¹æ æ†ã€‚\nçº¢å¦†ã€èŠ±è½¿ã€æ´ªæµªï¼Œå¹»å¹•èˆ¬åœ¨æˆ‘çœ¼å‰ä¸€é€è€Œè¿‡ï¼Œæˆ‘å‹‰åŠ›é—­çœ¼ï¼Œä¸‹æ„è¯†é€ƒé¿å‘¨é­çš„é£æµªï¼Œå†ççœ¼æ—¶ä»æ˜¯å°é›¨è’™æ¿ ï¼Œå·²ç„¶é£å¹³æµªé™ã€‚\nåªæœ‰è°¢å¨˜ç«™åœ¨é›¨å¹•é‡Œï¼Œç¥æƒ…å“€ä¼¤ï¼šâ€œé‚£ä¸€å¹´ï¼Œä¹Ÿæ˜¯åœ¨è¿™é‡Œï¼Œä¹Ÿæ˜¯è¿™æ ·çš„å¤©æ°”ï¼Œæˆ‘åœ¨è¿™é‡Œè·Œä¸‹äº†æ°´ï¼Œå†æ²¡è§åˆ°è‡ªå·±çš„å°‘å¹´éƒã€‚â€\næˆ‘å¿ƒå¤´ä¸€éœ‡ï¼Œè¿™æ‰å‘è§‰å¥¹èº«å½¢è™šæµ®ï¼Œå¦‚ä¸´æ°´ä¸Šï¼Œå®›ç„¶ä¸ä¼¼èº«åœ¨äººä¸–ã€‚â€œä½ æ˜¯å®¹å¨˜ï¼Ÿï¼â€æˆ‘é—®ã€‚\nå¥¹æ¢å¤äº†ä¸€ç‚¹å°‘å¥³çš„ç¬‘å®¹ï¼šâ€œè°¢å¨˜å‘€ï¼Œæ‚”å©šå‘€ï¼Œè¿˜æœ‰èµŒçº¦ï¼Œéƒ½æ˜¯æˆ‘ç¼–çš„ã€‚â€\nâ€œä½ ä¸ºä»€ä¹ˆâ€¦â€¦â€\nâ€œæ—çš„äººæ€¨ä»–ä¹Ÿå¥½ï¼Œç¬‘æˆ‘ä¹Ÿç½¢ï¼Œæˆ‘ä»¬çš„æ•…äº‹æ€»æœ‰äººè®°å¾—æ‰å¥½ã€‚å°±åƒå¤©ä¸Šçš„æœˆäº®ï¼Œå› ç¼˜æ³¨å®šï¼Œæä¸€æç»ˆä¸èƒ½å¾—ï¼Œä½†å®å¯éš¾å¹³ï¼Œä¹Ÿä¸æ„¿æ”¾æ‰‹â€ï¼Œå¥¹å›è¿‡å¤´æ¥ï¼Œéœ²å‡ºé‚£æ ·å¤©çœŸçš„ç¬‘ï¼šâ€œå·¦å³æ˜¯åœ¨æ¢¦é‡Œï¼Œå®¹æˆ‘ä»»æ€§ä½¿åç¼–æ’ä»–ä¸€å›ï¼Œä»–ä¸ä¼šä»‹æ„çš„å§ã€‚â€\næˆ‘åŠ¨å®¹ï¼Œä¸€æ—¶æ— è¨€ã€‚\nâ€œä»–å‘¢ï¼Œä»–åœ¨äººé—´æ€ä¹ˆæ ·ï¼Ÿè¿˜å¥½å—ï¼Ÿâ€\næ²ˆæ…•äº‘ï¼Œå­—è–„å›ï¼Œå¤©æ‰ç»äººï¼Œå¹´äºŒåä¸ƒæ—©å’äºä¸–ã€‚\nâ€œä»–å¾ˆå¥½â€ï¼Œæƒ³äº†æƒ³ï¼Œæˆ‘è¿™æ ·å‘Šè¯‰å¥¹ï¼Œâ€œåæ¥åˆå¨¶äº†æ–°å¦‡ï¼Œç™½å¤´å•è€ã€‚â€\nå¥¹å¿½åœ°èå°”ï¼Œâ€œè¿™æ ·å•Šâ€¦â€¦é‚£çœŸæ˜¯å¾ˆå¥½å¾ˆå¥½ï¼Œå†å¥½ä¸è¿‡çš„äº‹äº†ã€‚â€\næˆ‘çœ‹å¥¹éœ²å‡ºæ¶©ç„¶çš„ç¬‘ï¼Œå–ƒå–ƒå¿µç€ä»€ä¹ˆï¼Œèº«å½±ä¸€ç‚¹ç‚¹åœ°å˜æ·¡æ¶ˆæ•£ã€‚æˆ‘å¬æ¸…äº†é‚£ä¸€å¥è¯ï¼šâ€œå°é™¢æ·±é™ï¼Œæ¬²é—®å¿å¿ï¼Œä½•å¤„æœˆç¬¼æ˜ã€‚åƒç§‹å²å¥½ï¼Œä¼‘è´Ÿå…°å› ã€‚â€\næ—¶é›¨éœéœï¼Œä¸‰åå¹´åçš„æ­¤åœ°ç¬¼ç½©ç€ä¸‰åå¹´å‰ä¸€æ ·å‡„è¿·çš„æŸ³è‰²ï¼Œä»¿ä½›ä»–ä»¬çš„åˆé€¢ï¼Œç‚¹æ»´ç‰‡åˆ»ï¼Œå´æœ›å°½æ•´åº§äººé—´\nè§£è¯»è¿™ä¸ªæ•…äº‹ï¼Œå¹¶ç»“åˆæ•…äº‹è§£è¯»\u0026quot;å°é™¢æ·±é™,æ¬²é—®å¿å¿,ä½•å¤„æœˆç¬¼æ˜ã€‚åƒç§‹å²å¥½,ä¼‘è´Ÿå…°å› \u0026quot;çš„å«ä¹‰ã€‚\n","date":"3 October, 2025","id":0,"permalink":"/chinese-post/chichi-story/","summary":"å®éªŒè®¾å®šæ”¾åœ¨æœ€åã€‚","tags":"","title":"AIæ€ä¹ˆè§£è¯»é“¶ä¸´ã€Šè¿Ÿè¿Ÿã€‹çš„èƒŒæ™¯æ•…äº‹ï¼Ÿ"},{"content":"TL;DR: I created Raddy, a forward autodiff library, and Symars, a symbolic codegen library.\nIf you\u0026rsquo;re interested, please give them a star and try them out! â¤ï¸\nThe Origin of the Story I recently read papers on physical simulation and wanted to reproduce them. I started with Stable Neo-Hookean Flesh Simulation, though the choice isn\u0026rsquo;t critical. Many modern physical simulations are implicit, requiring Newton\u0026rsquo;s method to solve optimization problems.\nThis involves:\nComputing derivatives of the constitutive energy model (first-order gradient, second-order Hessian). Assembling a large, sparse Hessian from small, dense Hessian submatrices â€” a delicate task prone to hard-to-debug bugs. From Dynamic Deformables, I learned deriving these formulas is labor-intensive (even understanding the notation takes time). Searching for alternatives to avoid meticulous debugging, I found two solutions:\nSymbolic differentiation with code generation. Automatic differentiation. Tools for the former include MATLAB or SymPy; for the latter, deep learning libraries like PyTorch or more suitable ones like TinyAD.\nWhy TinyAD? Deep learning libraries differentiate at the tensor level, but I needed scalar-level differentiation for physical simulations. Tensor-level differentiation could lead to unplayable frame rates.\nA problem arose: these tools are in the C++ toolchain, and I\u0026rsquo;m not proficient in C++ (I know some kindergarten-level C++, but CMake and libraries like Eigen defeated me after three days of trying). So, I switched to Rust, a language I\u0026rsquo;m more comfortable with. This was the start of all troublesâ€¦\nA Path That Seems Simple Rust lacks an automatic differentiation library for second-order Hessians (at least on crates.io). SymPy can generate Rust code, but it\u0026rsquo;s buggy. Given the implementation complexity, I started with symbolic code generation, creating Symars.\nSymPy\u0026rsquo;s symbolic expressions are tree-structured, with nodes as operators (Add, Mul, Div, Sin, etc.) or constants/symbols, and children as operands. Code generation involves depth-first traversal: compute child expressions, then the current node\u0026rsquo;s expression based on its type. Base cases are constants or symbols.\nI used the generated derivatives for a simple implicit spring-mass system, but debugging index errors in Hessian assembly was time-consuming.\nTrying the Untrodden Path Again To address this, I revisited automatic differentiation, aiming to adapt TinyAD for Rust.\nTwo Ways to Walk the Same Path Initially, I considered two approaches:\nWrite FFI bindings, as I don\u0026rsquo;t know C++ well. Replicate TinyAD\u0026rsquo;s logic. Cloning TinyAD, I couldn\u0026rsquo;t even pull dependencies or compile it. Examining the codebase, I found the core logic was ~1000 lines â€” manageable to replicate without running the project. Thus, Raddy was born.\nSymbolic diff \u0026amp; Codegen: Implementation Implementation details:\nEach scalar in the differentiation chain carries a gradient and Hessian, increasing memory overhead. I avoided implementing the Copy trait, requiring explicit cloning. Operator traits between (\u0026amp;)Type and (\u0026amp;)Type (four combinations) required repetitive code. I considered the following options: Macros. Python scripts for code generation. Macros breaks rust-analyzer (somebody refuse to agree on this, but for me this is true) and I am rather unfamiliar with Rust\u0026rsquo;s macro syntax, so I used Python scripts (in the meta/ directory) for simple string concatenation.\nTesting: I verified derivatives by generating symbolic grad and hessian code with Symars, cross-validating against Raddy\u0026rsquo;s results, ensuring test expressions covered all implemented methods. Symars performed reliably, without bugs. What about sparse matrices Dense matrices store adjacent values contiguously, but sparse matrices (with millions of elements) don\u0026rsquo;t. I implemented sparse Hessian assembly:\nDefine a problem via the Objective\u0026lt;N\u0026gt; trait: Specify problem size N (a compile-time constant for const generics). Implement computation logic, e.g., a spring-mass system (Hooke\u0026rsquo;s law, E=1/2 k xÂ²): impl Objective\u0026lt;4\u0026gt; for SpringEnergy { type EvalArgs = f64; // restlength fn eval(\u0026amp;self, variables: \u0026amp;advec\u0026lt;4, 4\u0026gt;, restlen: \u0026amp;Self::EvalArgs) -\u0026gt; Ad\u0026lt;4\u0026gt; { // extract node positions from problem input: let p1 = advec::\u0026lt;4, 2\u0026gt;::new(variables[0].clone(), variables[1].clone()); let p2 = advec::\u0026lt;4, 2\u0026gt;::new(variables[2].clone(), variables[3].clone()); let len = (p2 - p1).norm(); let e = make::val(0.5 * self.k) * (len - make::val(*restlen)).powi(2); e } } Specify input components\u0026rsquo; indices (\u0026amp;[[usize; N]]). Automatically assemble sparse grad and hess (handling index mapping). Manually sum multiple grad and hess (simple matrix addition; triplet matrices are concatenated). Before tests, Raddy was 2.2k lines; after, it ballooned to 18k lines, showing LOC is a poor metric.\nFinally, I wrote a demo for fun and as an example.\nConclusion Gains:\nLearned how automatic differentiation works. First time using AI for documentation (it struggled with Rust syntax, producing test code with errors). Happiness! ","date":"2 October, 2025","id":1,"permalink":"/english-post/raddy/","summary":"TL;DR: I created Raddy, a forward autodiff library, and Symars, a symbolic codegen library.","tags":"rust graphics math","title":"Raddy devlog: forward autodiff system"},{"content":"From the perspective of a newbie user\nThe Documentation is a Disaster Recently, I had to optimize a custom operator and decided to use OpenAI\u0026rsquo;s Triton. After digging into the documentation, I was shocked at how poorly written it is â€” like an academic paper full of equations but lacking practical code examples.\nIf the library operates on tensors, the docs should clearly specify input/output shapes and provide concrete examples (like PyTorch does). Instead, everything is vaguely described in plain text, leaving users to guess the details.\nHow Triton Fails at Clarity Take the tl.load documentation as an example. It mentions that block pointers support \u0026ldquo;boundary checks\u0026rdquo; and \u0026ldquo;padding options,\u0026rdquo; but:\nWhat does \u0026ldquo;boundary check\u0026rdquo; actually do? Does it skip out-of-bounds elements, returning a smaller tensor? Does it pad with a default value? Does it throw an error? The docs don\u0026rsquo;t say. What\u0026rsquo;s the \u0026ldquo;padding option\u0026rdquo;? After some trial and error, I realized it handles out-of-bounds elements â€” but this should be explicitly stated, not left for users to reverse-engineer.\nAnother issue: tl.make_block_ptr and tl.arange require block shapes and element counts to be powers of two. This restriction isn\u0026rsquo;t mentioned anywhere in the official docs. I only discovered it after hitting an error and finding a passing reference in an unofficial blog post.\nWhoever wrote this documentation did a huge disservice to the engineers who built Triton\u0026rsquo;s compiler. Triton\u0026rsquo;s compiler is awesome.\nKey API Clarifications tl.load For raw pointers (or tensors of pointers): Always set mask and other. mask=True: Load from HBM. mask=False: Use the value from other (a float). For block pointers (tl.make_block_ptr): Enable boundary checks on all dimensions and set padding=\u0026quot;zero\u0026quot;. The behavior of boundary_check is poorly defined, especially after reordering dimensions. Shape Constraints tl.arange element counts and tl.make_block_ptr block shapes must be powers of two. This might apply to all Triton tensor dimensions, but I haven\u0026rsquo;t verified it.\nMemory Access Pitfalls tl.load and tl.store silently corrupt data. Invalid memory access turns values into NaNâ€”yes, even tl.store can corrupt valid data! Solution: Unless your dimensions are multiples of 64, always enable boundary checks for HBM reads/writes. Extra caution: Raw pointers require careful mask handling to avoid disasters. ","date":"2 October, 2025","id":2,"permalink":"/english-post/triton-pitfalls/","summary":"From the perspective of a newbie user","tags":"deep-learning python triton","title":"Triton Common Pitfalls"},{"content":"Intro: A taste of the Rust programming language\nRecently, I tried to get started with Rust and wanted to write some code.\nMost people\u0026rsquo;s first application is probably some kind of backend service (converting HTTP requests from the frontend into CRUD operations on a database and returning the results to the frontend).\nHowever, I\u0026rsquo;ve never learned how to write backend services (I\u0026rsquo;ve been wanting to learn recently â€” if anyone has good zero-to-hero beginner resources, feel free to recommend them). So, I ended up picking up the two papers I\u0026rsquo;ve been studying lately (@Li2020IPC, @abd) to try reproducing them.\nNote: This post only reproduces/discusses the IPC family of algorithms and does not address any performance optimizations, whether the algorithm is efficient, or why not to use some other algorithm.\nProject repo: Github\nImplicit Euler Physical simulation is essentially a numerical integration process.\nExplicit integration tends to explode, but implicit integration suffers from a \u0026ldquo;chicken-and-egg\u0026rdquo; problem (calculating the position at the next timestep requires knowing the velocity at the next timestep), making it impossible to solve explicitly. Instead, it requires solving a (possibly non-convex) optimization problem.\nWhat can be implicitly integrated? A mass-spring system can. But honestly, I\u0026rsquo;ve never written an optimization-based implicit integrator before, so I decided to start by implementing a mass-spring system.\nWhat Is It? Incremental Potential (IP) is a function of the degrees of freedom (DOF) of a scene at time t, IP(t).\nImplicit Euler constructs an then minimizes the IP (x(t+\\Delta t) = \\argmin_x E_{\\text{IP}}(x(t))) to obtain the position at t+\\Delta t.\nDeep learning typically uses gradient descent (and its variants), but in graphics, empirical evidence suggests gradient descent performs poorly. So, we opt for Newton\u0026rsquo;s method.\nImplementation Newton\u0026rsquo;s method is faster, but it introduces a problem: assembling the Hessian matrix. Fortunately, each component of the incremental potential is mostly a function of (k \\cdot n DOFs), where n is the dimensionality (I implemented 2D), and k is a small number (at most a few dozen). Thus, for each small IP contributing to the larger IP, the Hessian has only tens to hundreds of entries, which can be stored sparsely and assembled into the full Hessian. Following this tutorial, I implemented springs with vertices pinned to a wall.\nChoosing libraries: Used macroquad for GUI. Used nalgebra_glm for small-scale linear algebra. Initially planned to use nalgebra for large-scale linear algebra, but its sparse matrix functionality seemed incomplete, so I switched to faer. Initially used argmin for optimization. A Small Detour Before Contact IP Rust takes forever to compile, so configuring geometry shapes shouldn\u0026rsquo;t be hardcoded.\nAt first, I invented a weird file format and wrote a config based on my own logic:\n!k 1000.0 !node 0.0 0.0 0.2 0.0 0.4 0.0 0.6 0.0 0.1 0.2 0.3 0.2 Then I asked an AI to write a parser for me.\nLater, I realized that existing formats like JSON or TOML already have parsers, but by then, I was too lazy to change it.\nContact IP In short, Contact IP:\nRequires that point-edge pairs (aka primitive pairs) from two different bodies, which are close enough (within a threshold \\hat{d}), are assigned energy based on their distance. But to prevent interpenetration, there are additional requirements:\nOptimization courses teach that (damped) Newton\u0026rsquo;s method iteratively approaches the optimum. Each iteration involves a line search, and to prevent interpenetration, every intermediate step of the line search must ensure no primitive pairs penetrate, ultimately guaranteeing no interpenetration in the final result. Procedure At each line search step in Newton\u0026rsquo;s method:\nTraverse all primitive pairs (or use some acceleration structure â€” I didn\u0026rsquo;t implement this) and identify those with distances below the threshold. Compute the energy, gradient, and Hessian of the Contact IP for each primitive pair\u0026rsquo;s DOFs, then solve d = -A^{-1}g to get the search direction. Perform a CCD (Continuous Collision Detection) operation to ensure the line search doesn\u0026rsquo;t cause interpenetration (by setting a maximum step length). Use the Armijo condition for the line search. Repeat until sufficiently close to the minimum, at which point optimization is complete.\nImplementation Every step involved endless debuggingâ€¦\nGradient \u0026amp; Hessian:\nIn 2D, each primitive pair\u0026rsquo;s DOFs are (2 DOFs per point) Ã— (3 points) = 6 DOFs. The gradient of energy E w.r.t. DOFs can still be computed manually (a 6D vector). But the Hessian is a 6Ã—6 matrix, and the paper\u0026rsquo;s notation is a messâ€”sometimes dyadic product, sometimes Kronecker product, with no clear labeling in the text. Manual computation failed. So, I used SymPy for symbolic computation and generated code from it. The differentiation code can be found in the symbolic/ folder. SymPy actually has Rust codegen, but it\u0026rsquo;s half-baked â€” often producing invalid Rust syntax, requiring string replacements, and only supporting single expressions (no vectors/matrices). Note: Later, I built my own SymPyâ†’Rust code generator:\nSymars: Generate Rust code from SymPy expressions\nRemember: Point-to-segment distance requires case-by-case handling. CCD (ACCD) needs to be integrated into the optimization process, so argmin wasn\u0026rsquo;t suitable anymore. I discarded it and handwrote a damped Newton solver with ACCD and Armijo condition. After days of coding and debugging, the demo finally worked:\nThe constraints here are springs. ABD TL;DR, ABD Replaces traditional 6-DOF (translation + rotation) rigid bodies with 12-DOF bodies and heavily penalizes transformation matrices that deviate too far from rotation matrices, resulting in a (near-)rigid body simulation algorithm.\nIn 2D, an affine body (AB) has 6 DOFs: x = A x_0 + b, where the shape is defined by A (2Ã—2) and b (2Ã—1), assembled into a DOF vector: q = [flatten(A), b^T].\nWe know rotation matrices R satisfy R^T R = I. ABD uses an orthogonal potential energy \\kappa \\cdot \\text{frobnorm}(A^T A - I) to penalize A and keep it close to a rotation matrix.\nImplementation Any energy term requires second derivatives. Again, I used SymPy for differentiation. The project has thousands of lines of numerical computation code â€” don\u0026rsquo;t look at them. Affine bodies also need contact handling: Unlike mass-spring systems where each vertex is a DOF, an AB\u0026rsquo;s vertex position p is a function of DOFs, and the Contact IP is a function of p. A primitive pair involves two bodies, where one contributes an edge (two points p_1, p_2). Thus, derivatives must be taken w.r.t. both q s. The computational graph looks like this: After more endless debugging and parameter tuning (mainly \\kappa), the simulation finally ran:\nFinal Thoughts The resulting code is a bona fide spaghetti monster.\nEven though I spent a long time thinking about unifying interfaces before coding, the final design is neither OOP nor Rust-like, with inconsistent parameter passing everywhere.\nI can\u0026rsquo;t help but wonder: Is my ability just too low, or is code complexity truly not something design alone can solve?\nThe bright side:\nCargo is amazing â€” adding a dependency takes three seconds. Compared to Cmake, xmake or whatever-make, it\u0026rsquo;s night and day. No memory issues (since I didn\u0026rsquo;t and did not need to write unsafe code), so most effort went into logic. ","date":"2 October, 2025","id":3,"permalink":"/english-post/try-impl-ipc/","summary":"Intro: A taste of the Rust programming language","tags":"graphics graphics rust","title":"Try To Implement IPC"},{"content":"Intro: Troubleshooting Memory and Speed Performance\nDisclaimer: I develop and test primarily on Windows using the latest stable Rust toolchain and CPython 3.13.\n1. Background and Motivation SnapViewer handles large memory snapshots effectively â€” for example, pickle files up to 1 GB and compressed snapshots up to 500 MB. However, when processing extremely large dumps (e.g., a 1.3 GB snapshot), we encountered serious memory and speed bottlenecks:\nFormat conversion (pickle â†’ compressed JSON) triggered memory peaks around 30 GB. Data loading of the compressed JSON into Rust structures caused another ~30 GB spike. Frequent page faults and intense disk I/O (observed in Task Manager) made the application sluggish and prone to stalls. To address this, we applied a Profile-Guided Optimization (PGO) approach.\n2. Profile-Guided Optimization PGO requires empirical profiling to identify the true hotspots. I began with memory profiling using the memory-stats crate for lightweight inspection during early optimization stages. Then, I decomposed the data-loading pipeline into discrete steps:\nReading the compressed file (heavy disk I/O) Extracting the JSON string from the compressed stream Deserializing the JSON into native Rust data structures Populating an in-memory SQLite database for ad-hoc SQL queries Building the triangle mesh on CPU Initializing the rendering window (CPU-GPU transfer) Profiling revealed two major memory culprits: excessive cloning and multiple intermediate data structures. Below, I outline the optimizations.\nEliminating Redundant Clones During rapid prototyping, calls to .clone() are convenient. But they are expensive. Profiling showed that cloning large vectors contributed significantly to the memory peak and CPU time.\nFirst attempt: switch from cloned Vec\u0026lt;T\u0026gt; to borrowed \u0026amp;[T] slices. This failed due to lifetime constraints. Final solution: use Arc\u0026lt;[T]\u0026gt;. Although I\u0026rsquo;m not leveraging multithreading, Arc satisfies PyO3\u0026rsquo;s requirements, while no significant overhead is observed in this context. This change alone reduced memory usage and improved throughput noticeably.\nEarly Deallocation of Intermediate Structures Constructing the triangle mesh involved several temporary representations:\nRaw allocation buffers A list of triangles (vertices + face indices) A CPU-side mesh structure GPU upload buffers Each stage held onto its predecessor until the end of scope, inflating peak usage. To free these intermediates promptly, the following is implemented:\nScoped blocks to limit lifetimes Explicitly invoked drop() on unneeded buffers After these adjustments, peak memory dropped by roughly one-third.\n3. Sharding JSON Deserialization Deserializing the call-stack JSON with over 50 000 entries spiked memory usage dramatically. To mitigate this:\nShard the JSON data into chunks of at most 50 000 entries. Deserialize each chunk independently. Concatenate the resulting vectors. This streaming approach kept per-shard memory small, eliminating the previous giant allocation.\nIt is worth noting that serde_json::StreamDeserializer can be another option worth trying.\n4. Redesigning the Snapshot Format Even after the above optimizations, the call-stack data remained the largest in-memory component â€” duplicated once in Rust and again in the in-memory SQLite database.\nTo remove redundancy, I rethought what each representation serves:\nRust structures: display call stacks on screen upon user click. SQLite DB: serve ad-hoc SQL queries. Since SnapViewer is single-threaded and can tolerate occasional disk I/O, I split the snapshot into two files:\nallocations.json: lightweight JSON with allocation timestamps and sizes. elements.db: SQLite database holding call-stack text (indexed by allocation index). These two files are zipped together. At runtime:\nUnzip the snapshot. Load allocations.json into memory (small footprint). Open elements.db on disk. On click, query elements.db with WHERE idx = \u0026lt;allocation_index\u0026gt;. SQLite\u0026rsquo;s efficient on-disk indices make these lookups fast, with no perceptible impact on frame rate.\nRefactoring the Conversion Script I updated the snapshot-conversion script as follows:\nParse the original snapshot format. Bulk-insert call stacks into an in-memory SQLite database, then dump the DB as a byte stream. Serialize allocation metadata to JSON. Zip the JSON and DB byte stream. While conversion takes slightly longer, the resulting snapshot loads faster and uses a fraction of the memory.\n5. Results and Lessons After these optimizations, SnapViewer:\nNo longer spikes to 60+ GB of RAM on large snapshots, since we do not load the entire call stack information into memory at all. Starts up much faster. Maintains smooth rendering, even with on-demand call-stack queries. What I learned:\nDo not always load everything into memory. When you overflow your memory, the performance of virtual memory swapping system is probably worse than you think. When you need some mechanism to store most data on disk, but intelligentlly cache some of then in memory, SQLite should be a good start. It has its well-designed and industry-proven algorithm built into it. ","date":"2 October, 2025","id":4,"permalink":"/english-post/snapviewer-3-optim/","summary":"Intro: Troubleshooting Memory and Speed Performance","tags":"torch deep-learning rust","title":"SnapViewer Devlog #3: Optimizations"},{"content":"Intro: Building the UI as a Hybrid Rust \u0026amp; Python Application\nBuilding a UI can often be the trickiest part of a development project, especially when you\u0026rsquo;re trying to integrate different languages and paradigms.\nFor SnapViewer, my memory allocation viewer, I needed an integrated UI that could display allocation details on click and feature a REPL for SQL queries against a SQLite database. This post details my journey, the hurdles I faced, and the solutions I found, primarily focusing on a Rust backend and Python UI.\nProject page: https://github.com/Da1sypetals/SnapViewer\nThe Initial Vision: An Integrated UI My core requirements for the UI were:\nInteractive Display: When an allocation is clicked in the viewer, its size, call stack, and other relevant information should be immediately displayed. SQL REPL: A command-line interface to execute SQL queries directly against the underlying database. Non-Blocking Operations: Both functionalities needed to operate without blocking each other. Early Attempts and Roadblocks Web: Rust to WASM My first thought was a web interface. Rust\u0026rsquo;s ability to compile to WASM and the three-d crate\u0026rsquo;s WebGPU support seemed promising. However, I quickly hit a wall with library versioning issues trying to compile even a simple Rust program to WASM. Rather than get bogged down, I decided to pivot.\nTUI: Terminal User Interface The natural next step was a Terminal User Interface (TUI). This approach avoids the complexities of cross-compilation and platform-specific GUI libraries.\nRatatui: A Promising Rust TUI Framework I started with Ratatui, a TUI framework for Rust. I got their demos running, but my plan to find an open-source example matching my \u0026ldquo;left-console, right-REPL\u0026rdquo; layout failed.\nDiving deep into the Ratatui documentation felt as complex as learning a new frontend framework like React, which defeated my goal of getting work done quickly. I abandoned this path.\nTextual \u0026amp; AI-Powered Development Given my goal of getting work done rather than becoming a TUI expert, I started thinking about AI. Rust isn\u0026rsquo;t particularly \u0026ldquo;AI-friendly\u0026rdquo; for code generation, but Python certainly is. This sparked an idea: What if I used AI to generate the TUI code in Python and then integrated my Rust application?\nI fed my requirements to several LLMs: Claude, Gemini, Deepseek, ChatGPT, and Grok. Claude\u0026rsquo;s initial results were impressive, while the others were largely unusable. After a few rounds of refinement with Claude, I had a working TUI demo:\nCombining Rust and Python: A Hybrid Approach Integrating Rust and Python is a standard process, but it has its quirks. I used PyO3 as a dependency to expose my Rust structures and bind Rust functions to Python.\nMy core Rust logic consists of:\nViewer: An infinite loop handling render draw calls and an event loop until the application shuts down. SQL REPL: Loads snapshot data into SQLite and executes SQL queries. Each of these operations is designed to be completed in milliseconds.\nDesigning App Structure My initial application structure idea was:\nMain Thread: Renders the TUI and accepts REPL inputs, calling SQL REPL Rust functions. Spawned Thread: Runs the infinite loop for the Snapshot Viewer. However, the three-d crate, which uses winit for window management, dictates that the window must run on the main thread. This immediately threw a wrench in my plans.\nAttempt 1: Multiprocessing My first revised design used multiprocessing:\nStart the application and load snapshot data. Spawn a new process to run the TUI application. Run the Viewer in the parent process. This setup allowed the child process to run the viewer window without blocking the TUI app. The challenge, however, was Inter-Process Communication (IPC). I needed a way for the viewer to send information (like selected allocation details) back to the TUI.\nI experimented with Python\u0026rsquo;s multiprocessing.Queue. My approach was to define a callback in Rust that put messages into the queue, and then have the parent process check the queue at a fixed interval (e.g., 0.1 seconds) to update the TUI\u0026rsquo;s logging panel.\nI encountered an implementation bug where the parent process wasn\u0026rsquo;t consuming all messages, causing the viewer and TUI to become out of sync. I then switched to a shared byte array with a lock for IPC. The child process would acquire the lock, write to the buffer, and release it. The parent process would try to acquire the lock at intervals to read the message and update the TUI.\nAttempt 2: Threading The multiprocessing solution had a couple of issues:\nThe TUI sometimes froze when typing in the REPL, likely due to lock contention. Balancing the log message update interval with the viewer\u0026rsquo;s framerate was tricky. Too frequent, and the UI lagged; too slow, and the viewer became unresponsive. I realized I could use multithreading instead! While winit requires the viewer window to run on the main thread, the TUI application does not. This led to a new, more elegant structure:\nSpawn a thread and start the TUI application on that thread. Start the viewer on the main thread. A naive implementation, however, caused the entire TUI to freeze. The culprit? The Global Interpreter Lock (GIL) in Python. The GIL ensures that only one thread can execute Python bytecode at a time.\nTime for some PyO3 details. By default, the extension function holds GIL during its execution; but when you don\u0026rsquo;t need to use Python objects during this call, a call to py::allow_thread can opt out this behavior, releasing the GIL.\nIn my case, the Rust extension holds GIL in the infinte render loop, preventing the TUI thread from updating the UI. By explicitly releasing the GIL during the viewer\u0026rsquo;s render loop, the TUI, running in its own sub-thread, was free to update, and the application could run as expected.\nAn Alternative: GUI with PyQt As an interesting side experiment, I wondered about a GUI instead of a TUI. I tasked Claude with translating my TUI code into a GUI application using PyQt. Claude did this in minutes, without errors.\nAfter a few minor styling tweaks (also done via chatting with Claude), here is what the app looks like:\n(I finally switched to Tkinter for compatibility issues with multithreading across platforms.)\nWrapping Up This journey highlights the flexibility and power of combining Rust\u0026rsquo;s performance with Python\u0026rsquo;s rapid development capabilities, especially when augmented by AI.\nUnderstanding the intricacies of thread management and inter-process communication helped a lot in this journey.\nHope you find this post is fun and informative to read! â¤ï¸â¤ï¸â¤ï¸\n","date":"2 October, 2025","id":5,"permalink":"/english-post/snapviewer-2-ui/","summary":"Intro: Building the UI as a Hybrid Rust \u0026amp; Python Application","tags":"torch deep-learning rust","title":"Snapviewer Devlog #2: UI"},{"content":"Intro: PyTorch is a Deep Learning Operating System.\nCheck tensor storage Device check You should ALWAYS check EXPLICITLY whether input tensors are on desired devices. In most cases you want them on the same GPU, or in rare cases you want some tensors on CPU to perform some operations that are not efficient on GPU.\nAPI:\ntensor.is_cuda() tensor.device() (Use operator== for equality comparison). Sometimes the not on correct device problem causes strange error messages like Cusparse context initialization failure or things even more weird, which first seem unrelated to a device problem. This is why I suggest you always start your debug journey here.\nContiguity check Modern LibTorch recommends using Packed tensor accessor (roughly the same memory cost as a pointer) to access elements in tensor.\nHowever, if you are to plug some others\u0026rsquo; implementation (likely using raw pointers like float*) into PyTorch, you are not likely to understand the code inside out and rewrite it.\nUsually, in the context of deep learning, most implementations assumes a row-major contiguous storage. You should explicitly check whether the input tensors are contiguous in the C++ code that wraps the CUDA kernel.\nAPI: tensor.is_contiguous()\nCheatsheet A quick utility that checks whether all tensors are on the same CUDA device:\nvoid CheckInputTensors(const std::vector\u0026lt;torch::Tensor\u0026gt; \u0026amp;tensors) { TORCH_CHECK(!tensors.empty(), \u0026#34;No tensors provided for device check\u0026#34;); auto first_device = tensors[0].device(); TORCH_CHECK(first_device.is_cuda(), \u0026#34;First tensor is not on CUDA\u0026#34;); int idx = 0; for (const auto \u0026amp;tensor: tensors) { TORCH_CHECK(tensor.device() == first_device, \u0026#34;All tensors must be on the same CUDA device, \u0026#34; \u0026#34;but found tensor at index [\u0026#34;, idx, \u0026#34;] on device \u0026#34;, tensor.device(), \u0026#34; while expecting \u0026#34;, first_device); TORCH_CHECK(tensor.is_contiguous(), \u0026#34;All tensors must be contiguous, but found tensor at index [\u0026#34;, idx, \u0026#34;] not contiguous\u0026#34;); idx += 1; } } CUDA stream Remember to always get the current CUDA stream via at::cuda::getCurrentCUDAStream() and pass it as the 4-th parameter in the \u0026lt;\u0026lt;\u0026lt;gridDim, blockDim, sharedMemorySizeBytes, stream\u0026gt;\u0026gt;\u0026gt; kernel call.\nThis is especially important when your operator is used in distributed training, where at::cuda::getCurrentCUDAStream() automatically selects the correct stream for you.\nCUDA toolkit version problem Most \u0026ldquo;symbol not found\u0026rdquo; problem are caused by compiler / assembler / library version mismatch. Let me elaborate on this a bit:\nPyTorch has an important version information attached to it: The version of CUDA that torch is compiled on (let\u0026rsquo;s call it VT, cuda Version of Torch, for the sake of simplicity). The torch installation comes with its own CUDA toolkit (that matches VT) with no nvcc, ptxas. If you are to write custom CUDA extension to PyTorch, it will use the nvcc and ptxas in your system PATH, and libraries like CUBLAS or CUSPARSE in LD_LIBRARY_PATH. Let\u0026rsquo;s call this CUDA toolkit version VE, cuda Version of Extension. When you try to compile a CUDA extension, Make sure that your VT and VE perfectly match (NOT major version match). When you compile your extension, PyTorch hints you that a minor version mismatch should not be a problem. Remember, everything that should not happen will eventually happen. Memory Management in PyTorch Allocation When you need a buffer on HBM (e.g., for CUSPARSE or CUBLAS), your first instinct might be cudaMalloc and cudaFree. However, these force synchronization between CPU and GPU, which can starve the GPU.\nHere\u0026rsquo;s the key: PyTorch isn\u0026rsquo;t just an autograd tool. It\u0026rsquo;s a deep learning operating system that manages VRAM internally with a pooling and caching mechanism.\nUsing the PyTorch allocator is straightforward. Follow these steps:\nSet dtype to torch::kInt8 and create a buffer tensor via torch::empty Get the pointer with buffer_tensor.data_ptr\u0026lt;int8_t\u0026gt;() This gives you a pointer to the buffer. Here\u0026rsquo;s a complete code snippet:\nauto buffer_options = torch::TensorOptions().device(your_device).dtype(torch::kInt8); auto buffer_tensor = torch::empty({buffer_size}, buffer_options); void *buffer_ptr = buffer_tensor.data_ptr\u0026lt;int8_t\u0026gt;(); Remember do not call cudaFree on the pointer. RAII semantics will give the memory back to the allocator when destructor is called.\nPyTorch\u0026rsquo;s memory management is pretty much like a combination of OS memory management (buddy system, SLAB) and JVM or .net runtime (garbage collection, memory pool, caching and reusing memory blocks), but manages VRAM instead of a RAM.\nI recommend reading this post (Chinese) for a deeper dive into how PyTorch manages memory.\nUsing CUBLAS, CUSPARSE, CUSolverDn, etc. We use CUSPARSE as an example. The same rule apply to other libraries like CUBLAS or CUSolverDn.\nHandles When writing pure CUDA/C++ code, you manually call cusparseCreate to initialize the CUSPARSE context and prepare for subsequent CUSPARSE API calls.\nHowever this is not best practice in PyTorch CUDA extensions. There are good reasons: cusparseCreate introduces a milliseconds-level delay on CPU side. This may not be noticeable at first, but remember that operators are written to be run millions of times, which turns this into a significant overhead. This can cause GPU to starve when waiting CPU for synchronization.\nIf you use VizTracer to trace your program and visualize it in perfetto, you may notice cudaGetDeviceProperties call taking too much time on CPU side. This can be directly caused by cusparseCreate. LibTorch has API that automatically manages a pool of CUSPARSE handles:\nInclude the header that brings in CUDA context manager for LibTorch: #include \u0026lt;ATen/cuda/CUDAContext.h\u0026gt; Then, get handle via auto handle = at::cuda::getCurrentCUDASparseHandle(); automatically create a handle if there is not any, and caches it for subsequent uses. Use your handle as usual. I could not find documentation for these APIs, so if you want to know more, you may need to read the source code of PyTorch ATen. Searching in the repo with keyword getcurrentcuda can get you there quickly.\nBuffers Many CUSPARSE operations need buffers. If you need to make multiple CUSPARSE API calls with similar buffer size, it is bad practice to allocate right before the CUSPARE API call and deallocate right after since cudaMalloc and cudaFree are quite slow, which may cause your GPU to starve (verify this with VizTracer).\nA better practice should be pre-allocating the buffer and pass its pointer into where the CUSPARSE API is called through torch.empty().\nBatched Matrix Multiplication Refer to this example to see how to perform batched matrix multiplication in CUSPARSE.\nTricks:\nTo broadcast, set stride to 0. It is possible to broadcast rowptr but not colind and values. Check documentation for details.\nTensor Options struct TensorOptions carries many information about the tensor:\nstruct C10_API TensorOptions { // ... omitted // members Device device_ = at::kCPU; // 16-bit caffe2::TypeMeta dtype_ = caffe2::TypeMeta::Make\u0026lt;float\u0026gt;(); // 16-bit Layout layout_ = at::kStrided; // 8-bit MemoryFormat memory_format_ = MemoryFormat::Contiguous; // 8-bit bool requires_grad_ : 1; bool pinned_memory_ : 1; // Existense of members bool has_device_ : 1; bool has_dtype_ : 1; bool has_layout_ : 1; bool has_requires_grad_ : 1; bool has_pinned_memory_ : 1; bool has_memory_format_ : 1; } The most important methods are:\n[[nodiscard]] TensorOptions device(Device device) const; [[nodiscard]] TensorOptions dtype(ScalarType dtype) const; [[nodiscard]] TensorOptions requires_grad(bool) const; Usage:\ntensor.options() returns an instance of TensorOptions that describes the tensor. opt.dtype(torch::kFloat64) has other properties remain the same as opt, only dtype changes to float64 or in C++, double. The .to(...) method of a tensor can take a TensorOptions instance as its only argument. For an exhaustive list of device and dtype, you may want to refer to:\nhttps://github.com/pytorch/pytorch/blob/main/torch/csrc/api/include/torch/types.h https://github.com/pytorch/pytorch/blob/main/c10/core/DeviceType.h Debug layer by layer A CUDA extension is roughly split into 4 parts, from the bottom to the top namely:\nCUDA kernel C++ wrapper data passed from Python (PyTorch) to C++ Python wrapper CUDA kernel Debugging CUDA kernel is a very very difficult problem and we shall not discuss it here.\nC++ wrapper The first thing I want to hint you is that do not dereference a pointer pointing to device in host functions. You should always mark device pointers with a d_ prefix in variable names, or wrap it with thrust::device_ptr.\nprintf, std::cout or gdb will assist you in the journey.\ndata passed from Python (PyTorch) to C++ Refer to Pybind11 docs and try to answer these questions:\nHow various Python types are represented in Pybind11 API; How to properly configure the function prototype in Pybind11? Python Wrapper Ask LLMs. LLMs know python much better than I do.\nWhat to Reference To my knowledge, the PyTorch C++ documentation is very old. Many things in the source code are not documented there.\nIt is a better choice to just search in the PyTorch github repo, and read the comments and source code.\n","date":"2 October, 2025","id":6,"permalink":"/english-post/torch-cuda-ext/","summary":"Intro: PyTorch is a Deep Learning Operating System.","tags":"deep-learning cuda torch","title":"Notes on Writing PyTorch CUDA Extensions"},{"content":"æ³¨ï¼šæœ¬æ–‡ç”¨LLMè¾…åŠ©å†™ä½œçš„åœ°æ–¹ä¸»è¦åœ¨ï¼šæˆ‘è®¤ä¸ºLLMæ¯”æˆ‘ç†è§£çš„æ›´å¥½çš„åœ°æ–¹ï¼Œä¼šç”¨LLMçš„è¡¨è¿°ä»£æ›¿ã€‚\né—®é¢˜è®¾å®š éœ€è¦è®¡ç®—Graph Transformerä¸­çš„Attentionã€‚åœ¨æ­¤æˆ‘ä»¬å¿½ç•¥multihead-attentionï¼Œè€ƒè™‘åŸºæœ¬çš„single-head attention.\næ­¤å¤–ï¼Œæˆ‘ä»¬çš„attention mask(é‚»æ¥çŸ©é˜µA)æ˜¯éç»“æ„åŒ–ç¨€ç–çš„ã€‚å¦‚æœä½ çš„attention maskæ˜¯ç»“æ„åŒ–ç¨€ç–çš„ï¼Œæ¯”å¦‚blockwiseç­‰å¯ä»¥è¢«ä»£ç è¡¨ç¤ºçš„ç¨€ç–patternï¼Œä½ åº”è¯¥ä½¿ç”¨flash attentionçš„varlenå˜ä½“, æˆ–è€…flex attentionç­‰attentionç¼–è¯‘å™¨ã€‚\nNotation n: å›¾èŠ‚ç‚¹æ•°ï¼Œè§„æ¨¡ä¸º 1k~1M\rnnz: å›¾è¾¹æ•°ï¼ˆç¨€ç–çŸ©é˜µéé›¶å…ƒç´ æ•°ï¼ŒNum NonZeroï¼‰\rè§„æ¨¡ä¸º10n~1000n\rq, k, v: (n, d)\rA: (n, n), binary, é«˜åº¦ç¨€ç– è®¡ç®—å…¬å¼ softmax((q @ k.transpose()) * A) @ V å…¶ä¸­ï¼Œ@ è¡¨ç¤ºçŸ©é˜µä¹˜æ³•ï¼Œ*è¡¨ç¤ºelement-wiseä¹˜æ³•ã€‚\nå®ç°ï¼šnaive version æœ€ç®€å•çš„å°±æ˜¯æŠŠAç»™materializeå‡ºæ¥ï¼Œç„¶åç”¨ä½œattention_maskã€‚é—®é¢˜æ˜¯Aæ˜¯n^2çš„ï¼Œæ˜¾å­˜ä¸å¤Ÿç”¨ã€‚ Aç”¨COOæ–¹å¼å­˜å‚¨ï¼Œå¤§å°(2,nnz)ï¼Œç„¶åå…ˆæŠŠæ¯æ¡è¾¹çš„qk-pairç®—å‡ºæ¥(nnz,d)ï¼Œç„¶åå†åšreduceå’Œscatterå’ŒVç›¸ä¹˜ã€‚ Reformulate æˆ‘ä»¬å¼•å…¥ä¸‰ä¸ªç®—å­:\nSDDMM (Sampled Dense-Dense MatMul) A (m, k), B (k, n), ç¨ å¯† M (n, n)ï¼Œ ç¨€ç– SDDMM(A, B, M) å®šä¹‰ä¸ºï¼š for i, j in product(range(n), range(n)):\rif M[i, j] != 0:\rout[i, j] = dot(A[i,:], B[:,j])\relse:\rout[i, j] = 0 Sparse Softmax: åœ¨ç¨€ç–çŸ©é˜µä¸ŠæŒ‰è¡Œsoftmax SpMMï¼šsparse A @ dense B æ­¤æ—¶æˆ‘ä»¬çš„è®¡ç®—å…¬å¼å°±å¯ä»¥é‡æ–°å†™æˆ:\nout = SpMM(Softmax(SDDMM(Q, K_T, A)), V) ä»¥æ­¤æˆ‘ä»¬å¼•å‡ºä¸‹é¢çš„å®ç°\nå®ç°ï¼šDGL Graph Transformer in a Nutshell â€” DGL 2.2.1 documentation\nå¯¹äºç¨ å¯†çš„q,k,vå’ŒCSRå­˜å‚¨çš„Aï¼Œé€šè¿‡å¦‚ä¸‹ä»£ç è®¡ç®—attentionï¼š\nattn = dglsp.bsddmm(A, q, k.transpose(1, 0)) # (sparse) [N, N, nh] # Sparse softmax by default applies on the last sparse dimension. attn = attn.softmax() # (sparse) [N, N, nh] out = dglsp.bspmm(attn, v) # [N, dh, nh] ç®—å­åœ¨DGLåº“å†…éƒ¨ç”±CUDAå®ç°ã€‚çœ‹DGLçš„ä»£ç å¯ä»¥å‘ç°ï¼Œå…¶å®ç°åˆ©ç”¨äº†ç¨€ç–æ€§ï¼Œä½†æ˜¯å­˜åœ¨ä»¥ä¸‹ä¼˜åŒ–ç‚¹\nè¿›è¡Œçš„æ˜¯æœ€ç›´è§‚çš„å¹¶è¡Œï¼Œæ²¡æœ‰è¿›è¡Œå……åˆ†çš„ä¼˜åŒ– å„ä¸ªkernelåˆ†å¼€æ‰§è¡Œï¼Œæ²¡æœ‰èåˆ æ²¡æœ‰åˆ©ç”¨tensor core å®ç°ï¼šFlashSparse https://github.com/ParCIS/FlashSparse/tree/main/eva\nä¸»é¢˜ï¼šå¯¹SDDMM,SpMMè¿›è¡Œä¼˜åŒ–ï¼›å°è¯•åœ¨ç¨€ç–è¾“å…¥ä¸­ä»¥æœ€å°ç²’åº¦åˆ©ç”¨tensor core\nåŸºäºä¸€ä¸ªåŸºæœ¬è§‚å¯Ÿï¼šA Ã— B = C âŸ¹ (Báµ€ Ã— Aáµ€)áµ€ = Cï¼Œå‘æ˜äº†äº¤æ¢ä¸è½¬ç½®MMAè®¡ç®—ç­–ç•¥ï¼šç›®æ ‡æ˜¯å°†ç¨€ç–çŸ©é˜µåˆ’åˆ†æ‰€ä¾èµ–çš„MMAæŒ‡ä»¤ç»´åº¦ï¼Œä»è¾ƒå¤§çš„mç»´ï¼ˆå€¼ä¸º16ï¼‰åˆ‡æ¢åˆ°è¾ƒå°çš„nç»´ï¼ˆå€¼ä¸º8ï¼‰ã€‚æ ‡å‡†å¼ é‡æ ¸å¿ƒMMAæŒ‡ä»¤çš„å½¢çŠ¶ä¸ºm16n8k8ï¼ˆFP16ç²¾åº¦ä¸‹ï¼Œm=16, n=8, k=8ï¼‰ã€‚è¿™ä½¿å¾—ç¨€ç–çŸ©é˜µ A å¯è¢«åˆ’åˆ†ä¸º8Ã—1çš„å‘é‡ï¼Œç›¸æ¯”ä¹‹å‰å·¥ä½œä¸­ä½¿ç”¨çš„16Ã—1å‘é‡ï¼Œè®¡ç®—å†—ä½™å‡å°‘äº†çº¦50%ã€‚\nçŸ©é˜µæ ¼å¼ï¼šæœ¬ç®—æ³•å‘æ˜äº†ME-BCRSæ ¼å¼ï¼ŒåŸºæœ¬æƒ³æ³•æ˜¯åœ¨ä¸€ä¸ª8x1çš„blockä¸­ï¼Œå¦‚æœæœ‰ä¸€ä¸ªå…ƒç´ æ˜¯éé›¶çš„ï¼Œé‚£ä¹ˆå°±æŠŠè¿™æ•´ä¸ªblockéƒ½å½“æˆéé›¶çš„å­˜ä¸‹æ¥ã€‚ ç©ºé—´å¼€é”€ç»´æŒåœ¨O(n+nnz)ï¼Œå¸¸æ•°æ¯”è¾ƒå°ï¼Œè¿œæ²¡æœ‰è¾¾åˆ°head_dimçš„é‡çº§ã€‚ çŸ©é˜µæ ¼å¼è½¬æ¢æ—¶é—´å¼€é”€ (CSR -\u0026gt; ME-BCRS)ï¼šç”±äºæ˜¯ä¸€æ¬¡æ€§å¼€é”€ï¼Œç›¸å¯¹æ•´ä¸ªæ¨¡å‹æ¨ç†æ—¶é—´å‡ ä¹å¯ä»¥å¿½ç•¥ã€‚ FlashSparseçš„SpMMç®—æ³•ï¼ˆC = A Ã— Bï¼‰ é˜¶æ®µ1ï¼šè½¬ç½®è®¿é—®ä¸åŠ è½½\nå—å½¢çŠ¶ï¼šç®—æ³•å°† A åˆ’åˆ†ä¸º8Ã—8çš„ç¨€ç–TCå—ï¼ˆFP16ç²¾åº¦ä¸‹ï¼‰ï¼Œå°† B åˆ’åˆ†ä¸º8Ã—16çš„ç¨ å¯†TCå—ã€‚ ç¨€ç–å— A åŠ è½½ï¼šçº¿ç¨‹ä»å…¨å±€å†…å­˜ï¼ˆä»¥è¡Œä¼˜å…ˆçš„ME-BCRSæ ¼å¼å­˜å‚¨ï¼‰åŠ è½½8Ã—8ç¨€ç–TCå— Aï¼Œå¹¶åœ¨å¯„å­˜å™¨ä¸­å°†å…¶è½¬ç½®ä¸º Aáµ€ï¼Œä½œä¸ºå³æ“ä½œæ•°ã€‚ ç¨ å¯†å— B åŠ è½½ï¼šçº¿ç¨‹ä»å…¨å±€å†…å­˜ï¼ˆè¡Œä¼˜å…ˆï¼‰åŠ è½½8Ã—16ç¨ å¯†TCå— Bï¼Œå¹¶åœ¨å¯„å­˜å™¨ä¸­å°†å…¶è½¬ç½®ä¸º Báµ€ï¼Œä½œä¸ºå·¦æ“ä½œæ•°ã€‚ åˆå¹¶è®¿é—®ï¼šé€šè¿‡é‡æ–°æ’åˆ—çº¿ç¨‹è®¿é—®çš„åˆ—ï¼Œç¡®ä¿æ‰€éœ€æ•°æ®å¯¹é½å½¢æˆ2Ã—2çš„FP16å…ƒç´ å—ï¼Œä»è€Œä½¿å†…å­˜äº‹åŠ¡åŒ¹é…GPUæœ€å°32å­—èŠ‚çš„äº‹åŠ¡ç²’åº¦ï¼Œå®ç°åˆå¹¶è®¿é—®ï¼Œå‡å°‘50%çš„è®¿å­˜å¼€é”€ã€‚ é˜¶æ®µ2ï¼šäº¤æ¢ä¸è½¬ç½®è®¡ç®—\nåœ¨å¼ é‡æ ¸å¿ƒä¸Šæ‰§è¡ŒMMAæŒ‡ä»¤ï¼šBáµ€ Ã— Aáµ€ã€‚\nBáµ€ ä½œä¸ºå·¦æ“ä½œæ•°ï¼ˆm=16, k=8ï¼‰ã€‚ Aáµ€ ä½œä¸ºå³æ“ä½œæ•°ï¼ˆk=8, n=8ï¼‰ã€‚ ç»“æœä¸ºè½¬ç½®åçš„è¾“å‡ºå— Cáµ€ï¼ˆå°ºå¯¸ä¸º16Ã—8ï¼‰ï¼Œå­˜å‚¨åœ¨å¯„å­˜å™¨ä¸­ã€‚ é˜¶æ®µ3ï¼šè½¬ç½®è¾“å‡º\nå¯„å­˜å™¨ä¸­çš„ Cáµ€ å¿…é¡»åœ¨å†™å›å…¨å±€å†…å­˜å‰è½¬ç½®å› Cã€‚ç”±äºå¯„å­˜å™¨ä¸­ Cáµ€ çš„æ•°æ®å¸ƒå±€ä¸åŠ è½½ B æ—¶æ‰€éœ€çš„ Báµ€ å¸ƒå±€å®Œå…¨ç›¸åŒï¼Œå› æ­¤å¯å¤ç”¨ä¸ºåŠ è½½ B è®¾è®¡çš„é«˜æ•ˆåˆå¹¶å†™å›ç­–ç•¥ï¼Œå°†ç»“æœå†™å…¥å…¨å±€å†…å­˜ã€‚\nFlashSparseçš„SDDMMç®—æ³•ï¼ˆC = M âŠ™ (AB)ï¼‰ å—å½¢çŠ¶ï¼šFlashSparseå°†ç¨€ç–è¾“å‡ºçŸ©é˜µ C åˆ’åˆ†ä¸º8Ã—16çš„ç¨€ç–TCå—ã€‚ä¸¤ä¸ªç¨ å¯†è¾“å…¥çŸ©é˜µï¼ˆæŒ‰è®ºæ–‡å›¾8ä¸­çš„è®°å·ï¼Œè®°ä¸º A_dense å’Œ B_denseï¼Œæ»¡è¶³ C_sparse = A_dense Ã— B_denseï¼‰åˆ†åˆ«ä»¥ç¨ å¯†TCå—å½¢å¼åŠ è½½ï¼šA_dense ä¸º8Ã—8ï¼ˆè¡Œä¼˜å…ˆï¼‰ï¼ŒB_dense ä¸º8Ã—16ï¼ˆåˆ—ä¼˜å…ˆï¼‰ã€‚ è½¬ç½®è®¡ç®—çš„æ•°æ®å¯¹é½ï¼šSDDMMä¸­ç¨ å¯†è¾“å…¥çŸ©é˜µ Aï¼ˆè¡Œä¼˜å…ˆï¼‰å’Œ Bï¼ˆåˆ—ä¼˜å…ˆï¼‰çš„æ•°æ®å¸ƒå±€ï¼Œæ°å¥½æ»¡è¶³â€œäº¤æ¢ä¸è½¬ç½®MMAè®¡ç®—â€ï¼ˆBáµ€ Ã— Aáµ€ï¼‰çš„è¦æ±‚ã€‚ è½¬ç½®è®¡ç®—ï¼š\nç¨ å¯†è¾“å…¥ B è¢«è½¬ç½®ä¸º Báµ€ï¼ˆå°ºå¯¸16Ã—8ï¼‰ï¼Œä½œä¸ºå·¦æ“ä½œæ•°ã€‚ ç¨ å¯†è¾“å…¥ A è¢«è½¬ç½®ä¸º Aáµ€ï¼ˆå°ºå¯¸8Ã—8ï¼‰ï¼Œä½œä¸ºå³æ“ä½œæ•°ã€‚ è®¡ç®— Báµ€ Ã— Aáµ€ å¾—åˆ°ç¨ å¯†ç»“æœ C_denseáµ€ã€‚ ç”¨MçŸ©é˜µè¿›è¡Œelement-wise productï¼Œä»C_dense å¾—åˆ°C_sparse å®æµ‹: æœªæµ‹è¯•\nå®ç°ï¼šDF-GNN https://github.com/paoxiaode/DF-GNN\nä¸»é¢˜ï¼šblock/warpè°ƒåº¦å’Œç®—å­èåˆ\nç”±äºæˆ‘ä¸»è¦çœ‹äº†tilingéƒ¨åˆ†çš„ç®—æ³•ï¼ˆé€‚ç”¨äºå¤§å›¾å’Œé‚»å±…æ•°ä¸ç¡®å®šçš„å›¾ï¼Œä»…forwardï¼‰ï¼Œæ‰€ä»¥ä¸»è¦ä»‹ç»è¿™éƒ¨åˆ†ã€‚\nä½¿ç”¨çš„çŸ©é˜µæ ¼å¼æ˜¯CSRï¼Œä¸éœ€è¦åšé¢å¤–çš„æ ¼å¼è½¬æ¢\nç®—æ³•æµç¨‹ Launch Kernel on Grid: (n Ã— h)\râ†“\rEach Block â†’ (rid, hid): one node, one head\râ†“\rLoad Q[rid, hid, :] â†’ s_Q[f] (shm)\râ†“\rFor each tile of neighbors (size â‰¤ 32):\r- Load neighbor IDs from indices[]\r- Compute Q Â· K^T (dot product using s_Q and K[dst])\r- Reduce in warp â†’ store in neigh_nodes_weight[eid]\r- Find max(weight) in current tile â†’ weightMax\r- Adjust partial_sum and acc with exp(old_max - new_max)\r- Compute exp(weight - weightMax) and accumulate acc += exp_w * V[]\r- Accumulate partial_sum += exp_w\r- Update weightMax_old\râ†“\rFinal normalization: out_feat = acc / partial_sum\râ†“\rWrite back to global memory ä¸»è¦å°±æ˜¯é€šè¿‡åˆç†å®‰æ’GPUèµ„æºï¼ˆthreadblock, threadï¼‰å’Œè®¡ç®—ä»»åŠ¡çš„mappingï¼Œå®ç°åœ¨ä¸€ä¸ªkernel å†…è´Ÿè½½ç›¸å¯¹å‡è¡¡çš„å®Œæˆä»»åŠ¡ã€‚\nå®æµ‹: ä»£ç æ–¹é¢ï¼šå¼€æºçš„ä»£ç æœ‰æ¯”è¾ƒå¤šçš„bugï¼ŒåŒ…æ‹¬äº†data race, æŒ‡é’ˆè¿ç®—é”™è¯¯ç­‰ç­‰\nä¿®å¤åï¼š\nåœ¨å¸¸ç”¨å·¥ä½œèŒƒå›´å†…ï¼Œforwardé€Ÿåº¦è¾¾åˆ°DGLå®ç°çš„2.5x ~ 3x\nç²¾åº¦ï¼šå’ŒDGLå®ç°å¯¹æ¯”ï¼ŒMAEåœ¨1e-8 ~ 1e-9é‡çº§ï¼Œå·®è·å¯ä»¥å¿½ç•¥ä¸è®¡\nF3S https://github.com/HPCForge/Fused3S/tree/main/scripts ä¸»é¢˜ï¼šç®—å­èåˆ+æ··åˆç²¾åº¦+åˆ©ç”¨tensor core\nå…¶ä¸»è¦æ€è·¯è¿˜æ˜¯ç±»ä¼¼FlashSparseï¼Œä½†æ˜¯é€šè¿‡ç®—å­èåˆè¾¾åˆ°äº†æ›´é«˜çš„æ•ˆç‡ï¼ˆè®¿å­˜å¼€é”€ï¼Œkernel launchå¼€é”€æ›´å°ï¼‰ã€‚æ··åˆç²¾åº¦ç®—æ˜¯ä¸€ç§tradeoffã€‚\nä»…æœ‰forwardçš„å®ç° F3Sä¹Ÿä½¿ç”¨äº†è‡ªå®šä¹‰çš„çŸ©é˜µæ ¼å¼BSBï¼ŒåŸºæœ¬æƒ³æ³•æ˜¯åœ¨ä¸€ä¸ª16x1çš„blockä¸­ï¼Œå¦‚æœæœ‰ä¸€ä¸ªå…ƒç´ æ˜¯éé›¶çš„ï¼Œé‚£ä¹ˆå°±æŠŠè¿™æ•´ä¸ªblockéƒ½å½“æˆéé›¶çš„å­˜ä¸‹æ¥ã€‚ ä¼˜åŒ–çš„ä¸€ç‚¹åœ¨äºï¼Œblockå†…æ˜¯å¦ä¸º0è¢«å‹ç¼©åˆ°ä¸€ä¸ªbitä¸­ï¼Œæ¯ä¸ª16x8blockä»¥uint128ä¿å­˜ï¼Œå……åˆ†åˆ©ç”¨äº†attentionä¸­adjåªèƒ½ä¸º0/1çš„ç‰¹ç‚¹ å’Œflashsparseç›¸æ¯”ä¸è¶³çš„ä¸€ç‚¹åœ¨16x1ç²’åº¦æ›´å¤§ï¼Œå¤šä½™è®¡ç®—æ›´å¤šï¼Œä¹Ÿæ˜¯æœ¬å·¥ä½œæ²¡è€ƒè™‘åˆ°çš„ä¸€ç‚¹ ç©ºé—´å¼€é”€ï¼šO(n+nnz)ï¼Œä½†æ˜¯å¸¸æ•°ä¼šæ›´å¤§ä¸€äº› çŸ©é˜µæ ¼å¼è½¬æ¢æ—¶é—´å¼€é”€ (CSR -\u0026gt; BSB)ï¼šä¸€æ¬¡æ€§å¼€é”€ï¼Œæš‚æ—¶å¿½ç•¥ã€‚ ç®—æ³•æµç¨‹ï¼š åˆ’åˆ†è¡Œå—ï¼š\nå°† Q æŒ‰è¡Œåˆ’åˆ†ä¸º $T_r = \\lceil N / r \\rceil$ ä¸ªå— $\\{Q_1, ..., Q_{T_r}\\}$ï¼Œæ¯ä¸ªå¤§å°ä¸º $r \\times d$ã€‚ å°†è¾“å‡º O åŒæ ·åˆ’åˆ†ä¸º $T_r$ ä¸ªå— $\\{O_1, ..., O_{T_r}\\}$ï¼Œæ¯ä¸ªå¤§å°ä¸º $r \\times d$ã€‚ å¯¹æ¯ä¸ªè¡Œå—ç´¢å¼• $i = 1$ åˆ° $T_r$ï¼ˆå¹¶è¡Œå¤„ç†ï¼‰ï¼š\nåˆå§‹åŒ–\n$m_o \\leftarrow -\\infty \\in \\mathbb{R}^r$ï¼ˆè¡Œæœ€å¤§å€¼ï¼‰ $l_o \\leftarrow 0 \\in \\mathbb{R}^r$ï¼ˆè¡Œ softmax ç´¯åŠ å’Œï¼‰ $O_i \\leftarrow 0 \\in \\mathbb{R}^{r \\times d}$ï¼ˆè¾“å‡ºå—ï¼Œfp32ï¼‰ åŠ è½½æ•°æ®ï¼š\nå°† $Q_i$ ä»å…¨å±€å†…å­˜ï¼ˆHBMï¼‰åŠ è½½åˆ°å…±äº«å†…å­˜ï¼ˆSMEMï¼‰ã€‚ è®¡ç®—å½“å‰è¡Œçª—å£ï¼ˆRWï¼‰åŒ…å«çš„ TCB æ•°é‡ï¼š$t = \\text{tro}[i+1] - \\text{tro}[i]$ã€‚ é€šè¿‡ sptd è·å–å½“å‰ RW å¯¹åº”çš„åŸå§‹åˆ—ç´¢å¼•å‘é‡ $c$ã€‚ ä» $K$ å’Œ $V$ ä¸­æŒ‰ç´¢å¼• $c$ gather å‡ºå¯¹åº”çš„è¡Œï¼Œå¾—åˆ° $\\hat{K}, \\hat{V} \\in \\mathbb{R}^{t \\cdot c \\times d}$ã€‚ åˆ’åˆ† warp å—ï¼š\nå°† $\\hat{K}$ åˆ’åˆ†ä¸º $T_c = \\lceil t / W \\rceil$ ä¸ªå— $\\{\\hat{K}_1, ..., \\hat{K}_{T_c}\\}$ï¼Œæ¯ä¸ªå¤§å°ä¸º $Wc \\times d$ã€‚ å°† $\\hat{V}$ åŒæ ·åˆ’åˆ†ä¸º $T_c$ ä¸ªå— $\\{\\hat{V}_1, ..., \\hat{V}_{T_c}\\}$ï¼Œæ¯ä¸ªå¤§å°ä¸º $Wc \\times d$ã€‚ å¯¹æ¯ä¸ª warp å—ç´¢å¼• $j = 1$ åˆ° $T_c$ï¼š\nSDDMMï¼š\nè°ƒç”¨ $\\text{TBGemm}(Q_i, \\hat{K}_j^T, 0)$ï¼Œè®¡ç®—ä¸­é—´å¾—åˆ†å— $S_i \\in \\mathbb{R}^{r \\times c}$ï¼ˆfp32ï¼‰ã€‚ ç”¨ BSB ä¸­å¯¹åº” TCB çš„ bitmap å¯¹ $S_i$ è¿›è¡Œæ©ç ï¼ˆéé›¶ä½ç½®ä¿ç•™ï¼Œå…¶ä½™ç½® 0ï¼‰ã€‚ Online Softmaxï¼š\nè®¡ç®—å½“å‰å—è¡Œæœ€å¤§å€¼ï¼š$m_i = \\max(m_o, \\text{rowmax}(S_i))$ã€‚ è®¡ç®—æŒ‡æ•°ï¼š$E_i = \\exp(S_i - m_i)$ã€‚ æ›´æ–°ç´¯åŠ å’Œï¼š$l_o = \\text{diag}(\\exp(m_o - m_i)) \\cdot l_o + \\text{rowsum}(E_i)$ã€‚ å°† $E_i$ è½¬ä¸º fp16ï¼Œå­˜å…¥ SMEMã€‚ SpMMï¼š\nå¯¹å·²æœ‰è¾“å‡ºç¼©æ”¾ï¼š$O_i = \\text{diag}(\\exp(m_o - m_i)) \\cdot O_i$ã€‚ è°ƒç”¨ $\\text{TBGemm}(E_i, \\hat{V}_j, O_i)$ï¼Œå°†ç»“æœç´¯åŠ å› $O_i$ã€‚ æ›´æ–°è¡Œæœ€å¤§å€¼ï¼š$m_o = m_i$ã€‚ æœ€ç»ˆå½’ä¸€åŒ–å¹¶å†™å›ï¼š\nå¯¹è¾“å‡ºå—å½’ä¸€åŒ–ï¼š$O_i = \\text{diag}(l_o)^{-1} \\cdot O_i$ã€‚ å°† $O_i$ å†™å›å…¨å±€å†…å­˜ï¼ˆHBMï¼‰ã€‚ Subroutine: TBGemm è¾“å…¥:\nçŸ©é˜µå— $A \\in \\mathbb{R}^{m \\times K}$ (ä½äº SMEMï¼Œå…±äº«å†…å­˜) çŸ©é˜µå— $B \\in \\mathbb{R}^{K \\times P}$ (ä½äº HBMï¼Œå…¨å±€å†…å­˜) ç´¯åŠ é¡¹ $D \\in \\mathbb{R}^{m \\times P}$ (ä½äº SMEMï¼Œå…±äº«å†…å­˜) è¾“å‡º:\nç»“æœçŸ©é˜µ $C = A B + D \\in \\mathbb{R}^{m \\times P}$ æµç¨‹:\nåˆ‡åˆ†å— (Tiling): å°†è¾“å…¥çŸ©é˜µ $A$, $B$, $D$ æŒ‰ç…§ Tensor Core çš„ç¡¬ä»¶ Tile å°ºå¯¸ï¼ˆä¾‹å¦‚ $16 \\times 8 \\times 16$ï¼‰åˆ‡åˆ†ä¸ºå¯¹åº”çš„å­å—ã€‚\nå¹¶è¡Œè¿­ä»£ (Output Tiles): å¯¹ç»“æœçŸ©é˜µ $C$ çš„æ¯ä¸ªè¾“å‡º Tile (é€šå¸¸ç”±ä¸€ä¸ª Warp æˆ–ä¸€ä¸ª Thread Block è®¡ç®—):\nåŠ è½½ç´¯åŠ é¡¹ D: ä» SMEM ä¸­åŠ è½½ $D$ å¯¹åº”çš„å­å—åˆ°çº¿ç¨‹çš„å¯„å­˜å™¨ä¸­ï¼Œä½œä¸ºåˆå§‹ç´¯åŠ å€¼ $C$. å†…ç§¯è¿­ä»£ (K-Tiles): å¯¹ $K$ ç»´åº¦çš„æ¯ä¸ª $k$-tile è¿›è¡Œè¿­ä»£ç´¯åŠ :\nåŠ è½½ A: ä» SMEM ä¸­åŠ è½½çŸ©é˜µ $A$ å¯¹åº”çš„ $A_{\\text{tile}}$ å­å—ã€‚ åŠ è½½ B: ä» HBM ä¸­ç›´æ¥åŠ è½½çŸ©é˜µ $B$ å¯¹åº”çš„ $B_{\\text{tile}}$ å­å—ã€‚ æ‰§è¡Œ MMA æŒ‡ä»¤: è°ƒç”¨ç¡¬ä»¶æ”¯æŒçš„ PTX mma æŒ‡ä»¤ï¼ˆMatrix Multiply-Accumulateï¼‰ï¼Œæ‰§è¡Œè®¡ç®—å¹¶ç´¯åŠ ï¼š $$C \\leftarrow A_{\\text{tile}} \\cdot B_{\\text{tile}} + C$$ è¿”å›: æœ€ç»ˆå¾—åˆ°ç»“æœ $C$ã€‚\nå®æµ‹: ä»£ç æ–¹é¢ï¼šåœ¨çŸ©é˜µæ ¼å¼è½¬æ¢éƒ¨åˆ†æœ‰bugï¼Œå·²è”ç³»ä½œè€…ä¿®å¤ï¼›å¼€æºä»£ç æ²¡æœ‰multiheadï¼Œéœ€è¦è‡ªå·±å®ç°ã€‚\né€Ÿåº¦è¾¾åˆ°DGLå®ç°çš„3x(ç›¸å¯¹ç¨€ç–) åˆ°5x (ç›¸å¯¹ç¨ å¯†ï¼‰\né™åˆ¶ï¼šn % 16 == 0ï¼Œå› ä¸ºéœ€è¦åˆ†å‰²æˆ8x16çš„block\nç²¾åº¦ï¼šå’ŒDGLå®ç°å¯¹æ¯”ï¼ŒMAEåœ¨3e-5~1e-4 é‡çº§ï¼Œå¾ˆå¯èƒ½éœ€è¦é€šè¿‡å¯¹æ¨¡å‹è¿›è¡Œend2endæµ‹è¯•æ¥ç¡®å®šæ˜¯å¦é€‚åˆä½¿ç”¨ã€‚\n","date":"2 October, 2025","id":7,"permalink":"/chinese-post/gnn-optim/","summary":"æ³¨ï¼šæœ¬æ–‡ç”¨LLMè¾…åŠ©å†™ä½œçš„åœ°æ–¹ä¸»è¦åœ¨ï¼šæˆ‘è®¤ä¸ºLLMæ¯”æˆ‘ç†è§£çš„æ›´å¥½çš„åœ°æ–¹ï¼Œä¼šç”¨LLMçš„è¡¨è¿°ä»£æ›¿ã€‚","tags":"deep-learning","title":"è¿‘æœŸGNN Attentionç®—å­ä¼˜åŒ–å·¥ä½œé€Ÿè§ˆ"},{"content":"Background When training models with PyTorch, out-of-memory (OOM) errors are common, necessitating GPU memory optimization. When simple methods (like reducing batch size) no longer work, analyzing the memory footprint of the model itself may be required.\nAt this point, you might come across this documentation, which teaches you how to record a memory snapshot and visualize it on this website.\nHowever, thereâ€™s a major issue: the website is extremely laggy. If your model is small, with snapshots of just a few MB, the performance is somewhat tolerable. But if your model is large, with snapshots reaching tens or even hundreds of MB, the website becomes unbearably slow, with frame rates dropping as low as 2â€“3 frames per minute (this is not a typo).\nI looked into the websiteâ€™s JavaScript code, and hereâ€™s what it primarily does:\nManually loads Python pickle files; Re-parses the raw data into graphical representations time the viewport changes, then renders it to the screen. This parsing logic is written in JavaScript. You can imagine the performance when it is executed each frame, operating on hundred-MB data.\nInspiration My current work includes optimizing a deep learning model whose optimization is under-explored compared to LLM. I encountered this issue while working with a snapshot of a model with several billion parameters.\nWhy not just use existing LLM infrastructure instead of optimizing manually? Long story short, this model was custom-designed by a researcher and contains many modules completely different from standard LLMs. It seems like nowadays, everyone assumes deep learning is all about LLMs â€” so much so that even some tech leads believe LLM infrastructure can be easily adapted to other modelsâ€¦ but I digress. I originally wrote a simple script to parse the snapshotâ€™s contents, hoping to identify memory allocation issues in the model. But after working with this model for a month, I finally had enough. Thatâ€™s how this project â€” SnapViewer â€” came to be.\nTL;DRâ€‹â€‹: The graphical data from the memory snapshot is parsed and represented as a massive triangle mesh, leveraging existing rendering libraries to handle mesh rendering efficiently.\nHereâ€™s a snapshot of over 100 MB running smoothly on my integrated GPU:\nImplementation The reference implementation The snapshot format is partially documented in the record_memory_history function\u0026rsquo;s docstring. However, this documentation is incomplete â€” likely because later updates werenâ€™t reflected in the docstring.\nThe actual parsing of the snapshot into a dictionary happens here.\nThis script converts the allocator trace into a memory timeline, which is then passed to the web viewerâ€™s JS code. The JS code further transforms this into polygons (representing allocations) for visualization. Each polygon corresponds to an allocation, storing details like size and callstack. Implementation: Snapshot (De)serialize Initial implementation This part is impelmented in Python since I need to deal with Python-native data structures. I simply convert the dict to a json file.\nOptimizations Raw JSON is too large on disk â†’ compress it in-memory (Python zipfile) before writing. During visualization, read the ZIP from disk (Rust zip crate) and decompress in-memory. Tradeoffs This approach causes a temporary memory spike during JSON parsing but avoids persistent high memory usage. Also leverages Rustâ€™s serde-json (since Rustâ€™s serde-pickle is incomplete and canâ€™t handle recursive structures). Implementation: Rendering \u0026amp; Interactionâ€‹â€‹ This part is implemented in Rust.\nRendering Since allocation data remains static during visualization, all allocations are combined into a single large mesh and sent to the GPU once.\nâ€‹Library Usedâ€‹â€‹: three-d\nProvides good mesh abstraction. Supports one-time GPU upload (no per-frame CPUâ†’GPU transfers). Handles mouse/keyboard events. â€‹World-to-Window Coordinate Conversionâ€‹â€‹ â€‹Step 1â€‹â€‹: Convert window coordinates to world coordinates (scale + window center offset). â€‹â€‹Step 2â€‹â€‹: Convert world coordinates to memory positions (predefined scaling). UI \u0026amp; Interaction Featuresâ€‹ Memory Scale Markersâ€‹â€‹ Dynamically adjust the number and precision of markers based on screen visibility. Keep markers at consistent screen positions while moving/zooming. Pan \u0026amp; Zoomâ€‹â€‹ Track the original scale (1/zoom). Update to the new zoom level and compute the ratio between old and new scales. Adjust the screen center position based on the mouseâ€™s invariant world position. Implementation: Query After using this tool at work for around a week, I find myself frequently needing to search in the memory snapshot, especially:\nFind all allocations which is alive at a specific timestamp Find all allocations whose call stack has a specific substring Preferablly the allocations should be sorted by allocation size in descending order My first thought was to build a simple REPL and a simple command parser, and map each command to a specific query function.\nHowever, after having listed out all the functionalities I want, I found it to be a subset of database query, especially SQL.\nSo I decided not to reinvent wheels: I just connect to a in-memory SQLite database. Interfacing user is simple: read user input, let SQLite execute it and format the output to human-readable format.\nIf youâ€™ve struggled with PyTorch memory snapshots, check it out! Contributions \u0026amp; feedback welcome. â­\n","date":"1 October, 2025","id":8,"permalink":"/english-post/snapviewer/","summary":"When training models with PyTorch, out-of-memory (OOM) errors are common, necessitating GPU memory optimization. When simple methods (like reducing batch size) no longer work, analyzing the memory footprint of the model itself may be required.","tags":"torch deep-learning rust","title":"SnapViewer: Faster PyTorch Memory Allocation Viewer"},{"content":"å†…å­˜ä¸é€Ÿåº¦æ€§èƒ½é—®é¢˜æ’æŸ¥ å…è´£å£°æ˜ï¼šæˆ‘ä¸»è¦åœ¨ Windows ä¸Šä½¿ç”¨æœ€æ–°çš„ç¨³å®šç‰ˆ Rust å·¥å…·é“¾å’Œ CPython 3.13 è¿›è¡Œå¼€å‘å’Œæµ‹è¯•ã€‚\n1. èƒŒæ™¯ä¸åŠ¨æœº SnapViewer èƒ½å¤Ÿé«˜æ•ˆå¤„ç†å¤§å‹å†…å­˜å¿«ç…§â€”â€”ä¾‹å¦‚ï¼Œæ”¯æŒé«˜è¾¾ 1 GB çš„ pickle æ–‡ä»¶å’Œé«˜è¾¾ 500 MB çš„å‹ç¼©å¿«ç…§ã€‚ç„¶è€Œï¼Œåœ¨å¤„ç†è¶…å¤§è½¬å‚¨æ–‡ä»¶ï¼ˆä¾‹å¦‚ 1.3 GB çš„å¿«ç…§ï¼‰æ—¶ï¼Œæˆ‘ä»¬é‡åˆ°äº†ä¸¥é‡çš„å†…å­˜å’Œé€Ÿåº¦ç“¶é¢ˆï¼š\næ ¼å¼è½¬æ¢ï¼ˆpickle â†’ å‹ç¼© JSONï¼‰å¼•å‘äº†çº¦ 30 GB çš„å†…å­˜å³°å€¼ã€‚ å°†å‹ç¼© JSON åŠ è½½åˆ° Rust æ•°æ®ç»“æ„ä¸­åˆå¼•å‘äº†å¦ä¸€æ¬¡çº¦ 30 GB çš„å†…å­˜æ¿€å¢ã€‚ é¢‘ç¹çš„é¡µé¢é”™è¯¯ï¼ˆpage faultsï¼‰å’Œå¼ºçƒˆçš„ç£ç›˜ I/Oï¼ˆåœ¨ä»»åŠ¡ç®¡ç†å™¨ä¸­è§‚å¯Ÿåˆ°ï¼‰å¯¼è‡´åº”ç”¨ç¨‹åºå“åº”è¿Ÿç¼“ï¼Œç”šè‡³é¢‘ç¹å¡é¡¿ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬é‡‡ç”¨äº† Profile-Guided Optimizationï¼ˆPGOï¼ŒåŸºäºæ€§èƒ½åˆ†æçš„ä¼˜åŒ–ï¼‰æ–¹æ³•ã€‚\n2. Profile-Guided Optimizationï¼ˆPGOï¼‰ PGO éœ€è¦é€šè¿‡å®è¯åˆ†ææ¥è¯†åˆ«çœŸæ­£çš„çƒ­ç‚¹ã€‚æˆ‘é¦–å…ˆä½¿ç”¨ memory-stats crate è¿›è¡Œå†…å­˜åˆ†æï¼Œåœ¨æ—©æœŸä¼˜åŒ–é˜¶æ®µè¿›è¡Œè½»é‡çº§æ£€æŸ¥ã€‚éšåï¼Œæˆ‘å°†æ•°æ®åŠ è½½æµæ°´çº¿æ‹†è§£ä¸ºè‹¥å¹²ç¦»æ•£æ­¥éª¤ï¼š\nè¯»å–å‹ç¼©æ–‡ä»¶ï¼ˆé‡åº¦ç£ç›˜ I/Oï¼‰ ä»å‹ç¼©æµä¸­æå– JSON å­—ç¬¦ä¸² å°† JSON ååºåˆ—åŒ–ä¸ºåŸç”Ÿ Rust æ•°æ®ç»“æ„ å¡«å……å†…å­˜ä¸­çš„ SQLite æ•°æ®åº“ä»¥æ”¯æŒå³å¸­ SQL æŸ¥è¯¢ åœ¨ CPU ä¸Šæ„å»ºä¸‰è§’ç½‘æ ¼ï¼ˆtriangle meshï¼‰ åˆå§‹åŒ–æ¸²æŸ“çª—å£ï¼ˆCPU-GPU æ•°æ®ä¼ è¾“ï¼‰ æ€§èƒ½åˆ†ææ­ç¤ºäº†ä¸¤ä¸ªä¸»è¦çš„å†…å­˜é—®é¢˜ï¼šè¿‡åº¦å…‹éš†ï¼ˆexcessive cloningï¼‰å’Œå¤šä¸ªä¸­é—´æ•°æ®ç»“æ„ã€‚ä»¥ä¸‹æ˜¯æˆ‘å®æ–½çš„ä¼˜åŒ–æªæ–½ã€‚\næ¶ˆé™¤å†—ä½™çš„ Clone åœ¨å¿«é€ŸåŸå‹å¼€å‘é˜¶æ®µï¼Œè°ƒç”¨ .clone() éå¸¸æ–¹ä¾¿ï¼Œä½†ä»£ä»·é«˜æ˜‚ã€‚æ€§èƒ½åˆ†ææ˜¾ç¤ºï¼Œå…‹éš†å¤§å‹ Vec æ˜¾è‘—åŠ å‰§äº†å†…å­˜å³°å€¼å’Œ CPU æ—¶é—´ã€‚\né¦–æ¬¡å°è¯•ï¼šå°†å…‹éš†çš„ Vec\u0026lt;T\u0026gt; æ”¹ä¸ºå€Ÿç”¨çš„ \u0026amp;[T] åˆ‡ç‰‡ã€‚ä½†ç”±äºç”Ÿå‘½å‘¨æœŸçº¦æŸï¼Œæ­¤æ–¹æ¡ˆå¤±è´¥ã€‚ æœ€ç»ˆæ–¹æ¡ˆï¼šæ”¹ç”¨ Arc\u0026lt;[T]\u0026gt;ã€‚å°½ç®¡æˆ‘å¹¶æœªä½¿ç”¨å¤šçº¿ç¨‹ï¼Œä½† Arc æ»¡è¶³äº† PyO3 çš„è¦æ±‚ï¼Œä¸”åœ¨æ­¤ä¸Šä¸‹æ–‡ä¸­æœªè§‚å¯Ÿåˆ°æ˜æ˜¾å¼€é”€ã€‚ ä»…æ­¤ä¸€é¡¹æ”¹åŠ¨å°±æ˜¾è‘—é™ä½äº†å†…å­˜ä½¿ç”¨å¹¶æå‡äº†ååé‡ã€‚\næå‰é‡Šæ”¾ä¸­é—´ç»“æ„ æ„å»ºä¸‰è§’ç½‘æ ¼æ¶‰åŠå¤šä¸ªä¸´æ—¶è¡¨ç¤ºå½¢å¼ï¼š\nåŸå§‹åˆ†é…ç¼“å†²åŒº ä¸‰è§’å½¢åˆ—è¡¨ï¼ˆé¡¶ç‚¹ + é¢ç´¢å¼•ï¼‰ CPU ç«¯çš„ç½‘æ ¼ç»“æ„ GPU ä¸Šä¼ ç¼“å†²åŒº æ¯ä¸ªé˜¶æ®µéƒ½ä¼šä¿ç•™å…¶å‰é©±æ•°æ®ç›´è‡³ä½œç”¨åŸŸç»“æŸï¼Œä»è€Œæ¨é«˜äº†å³°å€¼å†…å­˜å ç”¨ã€‚ä¸ºåŠæ—¶é‡Šæ”¾è¿™äº›ä¸­é—´æ•°æ®ï¼Œæˆ‘ä»¬é‡‡å–äº†ä»¥ä¸‹æªæ–½ï¼š\nä½¿ç”¨ä½œç”¨åŸŸå—ï¼ˆscoped blocksï¼‰é™åˆ¶ç”Ÿå‘½å‘¨æœŸ å¯¹ä¸å†éœ€è¦çš„ç¼“å†²åŒºæ˜¾å¼è°ƒç”¨ drop() ç»è¿‡è¿™äº›è°ƒæ•´ï¼Œå³°å€¼å†…å­˜å¤§çº¦å‡å°‘äº†ä¸‰åˆ†ä¹‹ä¸€ã€‚\n3. åˆ†ç‰‡å¤„ç† JSON ååºåˆ—åŒ– å¯¹åŒ…å«è¶…è¿‡ 50,000 ä¸ªæ¡ç›®çš„è°ƒç”¨æ ˆ JSON è¿›è¡Œååºåˆ—åŒ–æ—¶ï¼Œå†…å­˜ä½¿ç”¨æ€¥å‰§é£™å‡ã€‚ä¸ºç¼“è§£æ­¤é—®é¢˜ï¼š\nå°† JSON æ•°æ®åˆ†ç‰‡ï¼Œæ¯ç‰‡æœ€å¤šåŒ…å« 50,000 ä¸ªæ¡ç›®ã€‚ ç‹¬ç«‹ååºåˆ—åŒ–æ¯ä¸ªåˆ†ç‰‡ã€‚ åˆå¹¶ç»“æœå‘é‡ã€‚ è¿™ç§æµå¼å¤„ç†æ–¹æ³•ä½¿æ¯ä¸ªåˆ†ç‰‡çš„å†…å­˜å ç”¨ä¿æŒåœ¨è¾ƒä½æ°´å¹³ï¼Œé¿å…äº†ä¹‹å‰çš„å¤§è§„æ¨¡å•æ¬¡åˆ†é…ã€‚\nå€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œserde_json::StreamDeserializer æ˜¯å¦ä¸€ä¸ªå€¼å¾—å°è¯•çš„é€‰é¡¹ã€‚\n4. é‡æ–°è®¾è®¡å¿«ç…§æ ¼å¼ å³ä½¿ç»è¿‡ä¸Šè¿°ä¼˜åŒ–ï¼Œè°ƒç”¨æ ˆæ•°æ®ä»ç„¶æ˜¯å†…å­˜ä¸­æœ€å¤§çš„ç»„ä»¶â€”â€”åœ¨ Rust ä¸­å’Œå†…å­˜ SQLite æ•°æ®åº“ä¸­å„å­˜ä¸€ä»½ï¼Œé€ æˆé‡å¤ã€‚\nä¸ºæ¶ˆé™¤å†—ä½™ï¼Œæˆ‘é‡æ–°æ€è€ƒäº†æ¯ç§è¡¨ç¤ºå½¢å¼çš„ç”¨é€”ï¼š\nRust ç»“æ„ï¼šç”¨æˆ·ç‚¹å‡»æ—¶åœ¨å±å¹•ä¸Šæ˜¾ç¤ºè°ƒç”¨æ ˆã€‚ SQLite æ•°æ®åº“ï¼šæ”¯æŒå³å¸­ SQL æŸ¥è¯¢ã€‚ ç”±äº SnapViewer æ˜¯å•çº¿ç¨‹çš„ï¼Œä¸”å¯å®¹å¿å¶å°”çš„ç£ç›˜ I/Oï¼Œæˆ‘å°†å¿«ç…§æ‹†åˆ†ä¸ºä¸¤ä¸ªæ–‡ä»¶ï¼š\nallocations.jsonï¼šè½»é‡çº§ JSONï¼ŒåŒ…å«åˆ†é…æ—¶é—´æˆ³å’Œå¤§å°ã€‚ elements.dbï¼šSQLite æ•°æ®åº“ï¼Œå­˜å‚¨è°ƒç”¨æ ˆæ–‡æœ¬ï¼ˆæŒ‰åˆ†é…ç´¢å¼•å»ºç«‹ç´¢å¼•ï¼‰ã€‚ è¿™ä¸¤ä¸ªæ–‡ä»¶è¢«ä¸€èµ·å‹ç¼©æ‰“åŒ…ã€‚è¿è¡Œæ—¶ï¼š\nè§£å‹å¿«ç…§ã€‚ å°† allocations.json åŠ è½½åˆ°å†…å­˜ï¼ˆå ç”¨å¾ˆå°ï¼‰ã€‚ æ‰“å¼€ç£ç›˜ä¸Šçš„ elements.dbã€‚ ç”¨æˆ·ç‚¹å‡»æ—¶ï¼Œé€šè¿‡ WHERE idx = \u0026lt;allocation_index\u0026gt; æŸ¥è¯¢ elements.dbã€‚ SQLite é«˜æ•ˆçš„ç£ç›˜ç´¢å¼•ä½¿è¿™äº›æŸ¥è¯¢éå¸¸è¿…é€Ÿï¼Œå¯¹å¸§ç‡å‡ ä¹æ²¡æœ‰å¯æ„ŸçŸ¥çš„å½±å“ã€‚\né‡æ„è½¬æ¢è„šæœ¬ æˆ‘å¯¹å¿«ç…§è½¬æ¢è„šæœ¬è¿›è¡Œäº†å¦‚ä¸‹æ›´æ–°ï¼š\nè§£æåŸå§‹å¿«ç…§æ ¼å¼ã€‚ å°†è°ƒç”¨æ ˆæ‰¹é‡æ’å…¥å†…å­˜ SQLite æ•°æ®åº“ï¼Œç„¶åå°†æ•°æ®åº“è½¬å‚¨ä¸ºå­—èŠ‚æµã€‚ å°†åˆ†é…å…ƒæ•°æ®åºåˆ—åŒ–ä¸º JSONã€‚ å°† JSON ä¸æ•°æ®åº“å­—èŠ‚æµä¸€èµ·å‹ç¼©ã€‚ è™½ç„¶è½¬æ¢è¿‡ç¨‹ç•¥æ…¢ï¼Œä½†ç”Ÿæˆçš„å¿«ç…§åŠ è½½æ›´å¿«ï¼Œä¸”å†…å­˜å ç”¨å¤§å¹…é™ä½ã€‚\n5. æˆæœä¸ç»éªŒæ€»ç»“ ç»è¿‡è¿™äº›ä¼˜åŒ–ï¼ŒSnapViewer å®ç°äº†ä»¥ä¸‹æ”¹è¿›ï¼š\nä¸å†å› åŠ è½½å¤§å‹å¿«ç…§è€Œè§¦å‘ 60+ GB çš„å†…å­˜å³°å€¼ï¼Œå› ä¸ºæˆ‘ä»¬å®Œå…¨ä¸å†å°†æ•´ä¸ªè°ƒç”¨æ ˆä¿¡æ¯åŠ è½½åˆ°å†…å­˜ä¸­ã€‚ å¯åŠ¨é€Ÿåº¦æ˜¾è‘—æå‡ã€‚ å³ä½¿è¿›è¡ŒæŒ‰éœ€è°ƒç”¨æ ˆæŸ¥è¯¢ï¼Œæ¸²æŸ“ä¾ç„¶æµç•…ã€‚ æˆ‘å­¦åˆ°çš„ç»éªŒï¼š\nä¸è¦æ€»æ˜¯æŠŠæ‰€æœ‰æ•°æ®éƒ½åŠ è½½åˆ°å†…å­˜ä¸­ã€‚å½“ä½ è€—å°½ç‰©ç†å†…å­˜æ—¶ï¼Œè™šæ‹Ÿå†…å­˜äº¤æ¢ç³»ç»Ÿçš„æ€§èƒ½å¯èƒ½æ¯”ä½ æƒ³è±¡çš„è¿˜è¦å·®ã€‚ å½“ä½ éœ€è¦å°†å¤§éƒ¨åˆ†æ•°æ®å­˜å‚¨åœ¨ç£ç›˜ä¸Šï¼ŒåŒæ—¶æ™ºèƒ½åœ°ç¼“å­˜éƒ¨åˆ†æ•°æ®åˆ°å†…å­˜æ—¶ï¼Œè¯·ä½¿ç”¨ SQLiteã€‚å®ƒå†…ç½®äº†ç»è¿‡å·¥ä¸šéªŒè¯çš„é«˜æ•ˆç®—æ³•ã€‚ ","date":"7 June, 2025","id":9,"permalink":"/chinese-post/snapviewer-3-zh/","summary":"å…è´£å£°æ˜ï¼šæˆ‘ä¸»è¦åœ¨ Windows ä¸Šä½¿ç”¨æœ€æ–°çš„ç¨³å®šç‰ˆ Rust å·¥å…·é“¾å’Œ CPython 3.13 è¿›è¡Œå¼€å‘å’Œæµ‹è¯•ã€‚","tags":"torch deep-learning rust","title":"Snapviewer Devlog #3: æ€§èƒ½ä¼˜åŒ–"},{"content":"Lsm Tree æ˜¯ä¸€ç§å†…å­˜-ç£ç›˜çš„å±‚çº§å¼æ•°æ®ç»“æ„ï¼Œå¸¸ç”¨äºå®ç°å†™å¤šè¯»å°‘çš„å­˜å‚¨å¼•æ“ã€‚\nç»„ä»¶ å†…å­˜éƒ¨åˆ† ç£ç›˜éƒ¨åˆ† WAL æ€»ä½“ åˆå§‹åŒ– éœ€è¦ init flush threadã€‚flush thread çš„å·¥ä½œæµç¨‹:\nç­‰å¾… flush ä¿¡å·é‡è¢« notify,è·å–ä¸€ä¸ª compact ä¿¡å·é‡èµ„æº å¯åŠ¨ä¸€ä¸ª sstwriter,å†™å…¥è¿™ä¸ª memtable ä¸€ä¸ª memtable å¯¹ä¸€ä¸ª sst ç­‰åˆ°å†™å…¥ sst å†™å®Œä¹‹å,æ‰è¿›è¡Œ: ä» frozen memtablesã€frozen memtable sizes é‡Œé¢åˆ é™¤è¿™ä¸ª memtable ä» wal é‡Œé¢åˆ é™¤è¿™ä¸ª memtable å¯¹åº”çš„ wal update manifest Try Freeze å¦‚æœå½“å‰å¤§å° \u0026gt; freeze size é‚£ä¹ˆå°± freeze;è¿›ä¸€æ­¥å¦‚æœæ‰€æœ‰ frozen memtable å¤§å°ä¹‹å’Œ \u0026gt; flush threshold,é‚£ä¹ˆå°± set flush signalã€‚\nå†™æ“ä½œ å†™ memtable å†™ WAL try freeze å†…å­˜éƒ¨åˆ† Put æ·»åŠ åˆ° memtable; æ›´æ–° sizeã€‚ size ä¸éœ€è¦ç‰¹åˆ«ç²¾ç¡®,åªéœ€è¦æ˜¯ä¸€ä¸ªå¤§è‡´çš„å€¼å³å¯ã€‚ Delete æ·»åŠ ä¸€ä¸ª tomb æ ‡è®°åˆ° memtable Get ä» active memtable ä¸­è·å– ä» new åˆ° old éå†æ‰€æœ‰çš„ inactive memtable,è·å–ã€‚ ç£ç›˜éƒ¨åˆ† compact ä¿¡å·é‡ äºŒå…ƒä¿¡å·é‡ã€‚\néœ€è¦ compact çš„æ—¶å€™,æ·»åŠ èµ„æº compact thread å¼€å§‹ compact çš„æ—¶å€™,æ¶ˆè€—èµ„æºã€‚ åˆå§‹åŒ– å¦‚æœ auto compact å¼€å¯,åˆå§‹åŒ–çš„æ—¶å€™éœ€è¦ init compact thread:\nLevel å­˜å‚¨è¿™ä¸ª level æ‰€æœ‰æ–‡ä»¶å¯¹åº”çš„æ–‡ä»¶è·¯å¾„,è£…åœ¨ sst reader é‡Œé¢\nGet (æ²¡æœ‰ delete, put) ä»ä½åˆ°é«˜,ä»æ–°åˆ°æ—§,è°ƒç”¨ sst çš„ get æ–¹æ³•,è·å– recordã€‚å¦åˆ™è¿”å› noneã€‚\nInit Compact Thread Compact thread:\nç­‰å¾… compact ä¿¡å·é‡ ä¾æ¬¡æŸ¥çœ‹æ¯ä¸€å±‚:å¦‚æœè¿™ä¸€å±‚å¤§å°è¶…è¿‡ threshold,å°±åˆå¹¶åˆ°ä¸‹ä¸€å±‚,å¦åˆ™å°±æå‰è¿”å›ã€‚ Compact ä»¥ L0 -\u0026gt; L1 ä¸ºä¾‹: ä»å‰åˆ°åéå†æ‰€æœ‰çš„ kv-pair,åŒæ—¶ç»´æŠ¤:\nkeys_outdated åŒä¸€ä¸ª key,timetsamp å°äº oldest marker çš„ kv pair åªéœ€è¦ä¿ç•™ä¸€ä¸ªã€‚ keys_outdated è®°å½•æ‰€æœ‰(å‡ºç°è¿‡çš„,ä¸” timestamp å°äº oldest marker)çš„ key L1 sst size æ¯è¾¾åˆ°ä¸€å®šå€¼å°±å…³é—­å½“å‰ sst,æ–°å¼€ä¸€ä¸ªæ–°çš„ sstã€‚ æ›´æ–° manifestã€‚ SST writer é…ç½® max block sizeã€‚\næ¯ä¸ª block çš„å¼€å¤´ä¸€ä¸ª key ä¼šæ·»åŠ åˆ° index ä¸­; æœç´¢è¿™ä¸ª sst çš„æ—¶å€™,ä¼šå…ˆå¯¹ index è¿›è¡ŒäºŒåˆ†æŸ¥æ‰¾; åœ¨ block ä¹‹å†…é‡‡ç”¨çº¿æ€§æœç´¢ã€‚ fpr,ç”¨äºæ„å»º bloom filter.\nå†™å…¥ éå†æ‰€æœ‰çš„ kv pair: userkey(ä¸å« timestamp)æ·»åŠ åˆ° bloom filter; block å†™å…¥å½“å‰ kv; å¦‚æœå½“å‰ block å¤§å°è¶…è¿‡ max block size,å°±å¼€å¯ä¸€ä¸ªæ–°çš„ block,ç„¶åå†™å…¥å¯¹åº”çš„ index(å†…å­˜) å°† index å’Œ bloom filter å†™ç£ç›˜ã€‚ SST reader æŸ¥æ‰¾: Get(key, timestamp) æŸ¥ bloom filter,å¦‚æœä¸å­˜åœ¨å°±è¿”å›ã€‚ å°† index æ•´ä¸ªè½½å…¥å†…å­˜ä¸­,è¿›è¡ŒäºŒåˆ†æŸ¥æ‰¾,å¾—åˆ°å¯¹åº” key-timestamp æ‰€åœ¨çš„åŒºé—´ã€‚å¦‚æœ out of bounds å°±è¿”å›ã€‚ æŒ‰ç…§æŸ¥æ‰¾åˆ°çš„åŒºé—´,è¯»ç£ç›˜ã€‚ MVCC key æ’å¸ƒé—®é¢˜ struct Key bytes timestamp: u64 æ¯”è¾ƒ: key1 \u0026lt; key2:\nkey1.bytes \u0026lt; key2.bytes (å­—å…¸åº); æˆ–è€…: key1.bytes == key2.bytes,è€Œä¸” key1.timestamp \u0026gt; key2.timestamp ä¸ºä»€ä¹ˆè¿™æ ·æ¯”è¾ƒ? åœ¨è¿›è¡ŒæŸ¥è¯¢ Get(userkey, timestamp) çš„æ—¶å€™,æˆ‘ä»¬éœ€è¦çš„æ˜¯:\nuserkey åŒ¹é… timestamp å°äºæŸ¥è¯¢çš„ timestamp,ä¸”å°½å¯èƒ½å¤§ å› æ­¤,æˆ‘ä»¬å°†\nuserkey å‡åºæ’åº timestamp é™åºæ’åº åœ¨æœç´¢ memtable(skiplist)çš„æ—¶å€™,æˆ–è€…å¯¹ index è¿›è¡ŒäºŒåˆ†æŸ¥æ‰¾çš„æ—¶å€™,å°±å¯ä»¥:\nç›´æ¥ä½¿ç”¨ lower_bound,æŸ¥æ‰¾å¤§äºç­‰äºè‡ªå·±çš„ç¬¬ä¸€ä¸ªå…ƒç´  å¦‚æœ userkey åŒ¹é…,è¯´æ˜æ˜¯ timestamp å°äºå½“å‰ timestamp çš„,timestamp æœ€å¤§çš„è®°å½•,è¿”å›; å¦‚æœ userkey ä¸åŒ¹é…,è¯´æ˜ä¸å­˜åœ¨ timestamp å°äºå½“å‰ timestamp çš„è®°å½•,è¿”å›(æœªæ‰¾åˆ°)ã€‚ Transaction æ•°æ®ç»“æ„ ä¸€ä¸ªå†…å­˜ tempmap,ç”¨æ¥å­˜å‚¨ transaction å·²ç»å†™,ä½†æ˜¯æœªæäº¤çš„å†…å®¹ã€‚ åˆ›å»ºçš„æ—¶å€™,ä» tree è·å–:\nstart timestamp,ä½œä¸ºæŸ¥è¯¢çš„ timestamp transaction id ç„¶åå†™å…¥ transaction start åˆ° WAL\nPut,Delete å†™ tempmap,å†™ WAL\nGet ä½¿ç”¨ start timestamp,å…ˆæŸ¥ tempmap,å†æŸ¥ treeã€‚\nCommit ä» tree è·å–ä¸€ä¸ª commit timestamp; å†™ WAL,è®°å½• transaction id å’Œ commit timestampã€‚ åœ¨ replay çš„æ—¶å€™,æŠŠ transaction id å’Œ commit timestamp å¯¹åº”èµ·æ¥å°±å¯ä»¥çŸ¥é“ transaction é‡Œé¢çš„ å†™æ“ä½œ å¯¹åº”çš„ timestamp è°ƒç”¨ tree.active_memtable çš„ API,å°† transaction çš„æ‰€æœ‰æ•°æ®å†™å…¥ tree çš„ memtableã€‚ WAL çœ‹åˆ° transaction start,å…ˆå°† transaction æš‚å­˜åˆ°å†…å­˜ä¸­:\nå¦‚æœåœ¨ replay ç»“æŸä¹‹å‰çœ‹åˆ°äº† transaction end,å°±å°†æ”¹åŠ¨å†™å…¥ tree ä¸­(redo)ã€‚ å¦åˆ™æ”¾å¼ƒ,è§†ä¸ºæ²¡å®Œæˆçš„äº‹åŠ¡(undo) è¸©å‘: Resource deadlock avoided (os error 35),å¯èƒ½æ˜¯ä¸€ä¸ª thread æŒæœ‰äº†è‡ªå·±çš„ joinhandle å¹¶ä¸” join äº†è‡ªå·±;ä½¿ç”¨ maybe join è§£å†³,å³åˆ¤æ–­å½“å‰çº¿ç¨‹å’Œ joinhandle çš„çº¿ç¨‹æ˜¯å¦ä¸€è‡´,å¦‚æœä¸€è‡´å°±ä¸ç”¨ joinã€‚ æ­»é”é—®é¢˜: wal å’Œ mem éƒ½æœ‰é”,å¿…é¡» æŒ‰ç…§åŒä¸€é¡ºåºè·å– æ‰ä¸ä¼šå‡ºç°æ­»é”ã€‚ Bloom filter ç»†èŠ‚ æœ¬éƒ¨åˆ†ç”± Deepseek è¾…åŠ©å†™ä½œ\nè¯¥ Bloom filter ç®—æ³•çš„ä¸»è¦æ­¥éª¤å¦‚ä¸‹:\nå‚æ•°è®¡ç®—:\næ ¹æ®é¢„æœŸå…ƒç´ æ•°é‡ n å’Œå¯æ¥å—è¯¯åˆ¤ç‡ p,é€šè¿‡å…¬å¼è®¡ç®—æœ€ä¼˜ä½æ•° m å’Œå“ˆå¸Œå‡½æ•°æ•°é‡ k: $ m=\\lceil-n \\dfrac{\\ln(p)}{\\ln(2) ^ 2}\\rceil $ $ k=\\lceil\\dfrac{m}{n}\\ln(2)\\rceil $ å½“ç›´æ¥æŒ‡å®šå‚æ•°æ—¶,ä½¿ç”¨ç»™å®šçš„ä½æ•°å’Œå“ˆå¸Œå‡½æ•°æ•°é‡ å“ˆå¸Œç”Ÿæˆ:\nä½¿ç”¨ 64 ä½æŒ‡çº¹å“ˆå¸Œ(farmhash)ç”Ÿæˆåˆå§‹å“ˆå¸Œå€¼ h é€šè¿‡ä½è¿ç®—æ„é€ å¢é‡å€¼ delta = (h \u0026gt;\u0026gt; 33) | (h \u0026lt;\u0026lt; 31) é‡‡ç”¨åŒé‡å“ˆå¸ŒæŠ€æœ¯,é€šè¿‡å¾ªç¯å åŠ  delta ç”Ÿæˆ k ä¸ªä¸åŒçš„ä½ä½ç½®: $ h_i \\equiv h + i \\cdot delta \\pmod m , 0 \\leq i \\lt k $ æ•°æ®æ’å…¥:\nå¯¹è¾“å…¥ key è¿›è¡Œå“ˆå¸Œè®¡ç®—å¾—åˆ°åˆå§‹ h å’Œ delta å¾ªç¯ k æ¬¡ç”Ÿæˆä½ä½ç½®,å°†ä½æ•°ç»„ä¸­å¯¹åº”ä½ç½®è®¾ä¸º 1 é‡‡ç”¨ä½æ“ä½œ: byte_index = position/8,bit_mask = 1 \u0026laquo; (position%8) å­˜åœ¨æ€§æ£€æµ‹:\né‡å¤æ’å…¥æ—¶çš„å“ˆå¸Œè®¡ç®—è¿‡ç¨‹ æ£€æŸ¥æ‰€æœ‰ k ä¸ªå¯¹åº”ä½æ˜¯å¦å‡ä¸º 1 ä»»ä¸€ä½ç½®ä¸º 0 åˆ™åˆ¤å®šä¸å­˜åœ¨,å…¨éƒ¨ä¸º 1 æ—¶åˆ¤å®šå¯èƒ½å­˜åœ¨ æ•°æ®æŒä¹…åŒ–:\nåºåˆ—åŒ–æ—¶é™„åŠ  CRC32 æ ¡éªŒå’Œ ååºåˆ—åŒ–æ—¶éªŒè¯æ ¡éªŒå’Œä¸æ•°æ®å®Œæ•´æ€§ ","date":"1 March, 2025","id":10,"permalink":"/chinese-post/lsm/","summary":"Lsm Tree æ˜¯ä¸€ç§å†…å­˜-ç£ç›˜çš„å±‚çº§å¼æ•°æ®ç»“æ„ï¼Œå¸¸ç”¨äºå®ç°å†™å¤šè¯»å°‘çš„å­˜å‚¨å¼•æ“ã€‚","tags":"","title":"Lsm Tree å®ç°å¤‡æ³¨"},{"content":"æœ¬æ–‡æ²¡æœ‰ä»»ä½•æ•°å­¦æ¨å¯¼ã€‚æˆ‘ä»¬ä»ç›´è§‚ä¸Šç†è§£è¿™ä¸ªç®—æ³•ï¼Œç„¶åç›´æ¥ä»‹ç»ç®—æ³•çš„æµç¨‹ã€‚å¸Œæœ›äº†è§£æ•°å­¦æ¨å¯¼çš„è¯»è€…å¯ä»¥æŸ¥çœ‹ CMU çš„æ•™æ¡ˆåŠå…¶ç¿»è¯‘ã€‚\n1. é—®é¢˜ å¯¹äºå®å¯¹ç§°çŸ©é˜µ $A \\in \\mathbb{R}^{n \\times n}$ å’Œå‘é‡ $b \\in \\mathbb{R}^n$ï¼Œæ±‚è§£\n$$Ax = b$$æˆ–è€…ï¼Œç­‰ä»·çš„ï¼Œ\n$$\\text{argmin}_x f(x)$$å…¶ä¸­\n$$f(x) = \\frac{1}{2}x^T A x - b^T x$$2. é¢„å¤‡çŸ¥è¯† 2.1. ä»é«˜ä¸­å­¦çš„äºŒçº§ç»“è®ºè¯´èµ· é«˜ä¸­çš„æ—¶å€™æˆ‘ä»¬å­¦è¿‡æ¤­åœ†ï¼š\n$$a^{-2}x^2 + b^{-2}y^2 = 1$$å¦‚æœä½ è®°æ€§å¥½çš„è¯ï¼Œä½ åº”è¯¥è®°å¾—è¿™ä¸ªäºŒçº§ç»“è®ºï¼š\nè¿™æ˜¯ä¸€ä¸ªä»åœ†é‡Œé¢æ¨å¹¿è€Œæ¥çš„ç»“è®ºï¼šå¦‚æœ $a = b$ï¼Œæ¤­åœ†é€€åŒ–ä¸ºåœ†ï¼Œ$k_{OM}k_l = -1$ï¼Œå³ $OM, l$ ä¸¤æ¡ç›´çº¿å‚ç›´ã€‚\n2.2. æœ€é€Ÿä¸‹é™æ³• é¦–å…ˆï¼Œä½ åº”è¯¥çŸ¥é“æ¢¯åº¦ä¸‹é™æ³•ï¼š\n$$x_{i+1} = x_i - \\alpha\\nabla f(x_i)$$æœ€é€Ÿä¸‹é™æ³•å°±æ˜¯åœ¨æ¢¯åº¦ä¸‹é™æ³•çš„åŸºç¡€ä¸Šï¼Œé€‰æ‹© $\\alpha$ ä½¿å¾— $x_{i+1}$ è¾¾åˆ°æœ€å°ï¼ˆåœ¨æœç´¢æ–¹å‘ä¸Šçš„æœ€å°å€¼ï¼‰ï¼š\n$$\\alpha^* = \\text{argmin}_\\alpha f(x_i - \\alpha\\nabla f(x_i))$$3. å…±è½­æ¢¯åº¦æ³• 3.1. è®°å· $x_i$ï¼šç¬¬ $i$ æ¬¡å¾ªç¯ä¹‹åçš„ $x$ å‘é‡\n$r_i$ï¼š$b_i - Ax_i$ï¼Œç›®æ ‡å‡½æ•° $f(x)$ åœ¨ $x_i$ ç‚¹çš„è´Ÿæ¢¯åº¦ï¼Œæˆ–è€…çº¿æ€§æ–¹ç¨‹ç»„åœ¨ $x_i$ ç‚¹çš„æ®‹å·®ã€‚\nè¯·è®°ä½ï¼šè´Ÿæ¢¯åº¦å’Œæ®‹å·®æ˜¯ä¸€ä¸ªä¸œè¥¿ï¼ $d_i$ï¼šåœ¨ $x_i$ ç‚¹çš„æœç´¢æ–¹å‘ã€‚æœ€é€Ÿä¸‹é™ç®—æ³•é‡Œ $d_i = r_i$ï¼Œå…±è½­æ¢¯åº¦é‡Œé¢éœ€è¦ä¸€ç‚¹ä¿®æ­£ã€‚\n3.2. æœ€é€Ÿä¸‹é™ æœ€é€Ÿä¸‹é™çš„æ–°æ–¹å‘ï¼š$r_{i+1}$\næ–°æ–¹å‘ä¸å‰ä¸€æ­¥ä¸‹é™æ–¹å‘ $r_i$ å‚ç›´ï¼ˆç”»ä¸ªç­‰é«˜çº¿å›¾ç›´è§‚ç†è§£ï¼Œæˆ–è€…å›æƒ³ä¸€ä¸‹\u0026quot;ç­‰åŠ¿é¢å’Œç”µåœºçº¿å‚ç›´\u0026quot;ï¼‰ æœ€é€Ÿä¸‹é™çš„ $\\alpha$ $$\\alpha_i = \\frac{r_i^T r_i}{d_i^T A d_i}$$3.3. å…±è½­æ¢¯åº¦ æˆ‘ä»¬ç›´æ¥é€é¡¹ç±»æ¯”æœ€é€Ÿä¸‹é™ã€‚\næ–°æ–¹å‘ä¸å‰ä¸€æ­¥ä¸‹é™æ–¹å‘ $r_i$ å‚ç›´ æ–œç‡ä¹‹ç§¯ä¸º $-a^{-2}b^2$ (Section 2.1)\nè¿™ä¸ªæ–¹å‘ç”±æœ€é€Ÿä¸‹é™çš„æ–¹å‘è¿›è¡Œä¸€äº›å°æ”¹åŠ¨å¾—åˆ°ï¼Œæˆ‘ä»¬å¯ä»¥åœ¨åé¢çš„ç®—æ³•éƒ¨åˆ†(Section 3.4)çœ‹åˆ°ã€‚æŠŠè¿™ä¸ªæ–¹å‘ä»å’Œå‰ä¸€ä¸ªæœç´¢æ–¹å‘å‚ç›´æ”¹åŠ¨åˆ°æ–œç‡ä¹‹ç§¯ä¸º $-a^{-2}b^2$ å°±æ˜¯ CG å’Œæœ€é€Ÿä¸‹é™å”¯ä¸€ä¸åŒçš„åœ°æ–¹ã€‚ æ­¥é•¿ $\\alpha$ï¼šç”±äºæ˜¯åœ¨ä¸€æ¡ç›´çº¿ä¸Šåšä¼˜åŒ–ï¼Œå› æ­¤å’Œæœ€é€Ÿä¸‹é™çš„ $\\alpha$ ç›¸åŒã€‚ ç”±äºä¸€æ¬¡è¿­ä»£åªæ¶‰åŠåˆ°ä¸¤ä¸ªç‚¹ã€ä¸¤ä¸ªå‘é‡ï¼Œåªèƒ½æ„æˆä¸€ä¸ªå¹³é¢ï¼Œæˆ‘ä»¬ç”šè‡³ä¸éœ€è¦å°†äºŒç»´å‘å¤šç»´æ¨å¹¿ã€‚\nè‹¥éœ€æ¨å¯¼ï¼Œæˆ‘ä»¬éœ€è¦åšçš„åªæ˜¯æŠŠç‚¹çš„ $n$ ç»´åæ ‡æ˜ å°„åˆ°äºŒç»´ï¼Œç„¶åå¯¹æˆªé¢æ¤­åœ†å¯¹åº”çš„äºŒé˜¶äºŒæ¬¡å‹è¿›è¡Œ SVD è·å¾—å…¶é•¿è½´ $a$ å’ŒçŸ­è½´ $b$ï¼Œè¿›è€Œæ ¹æ®å…¶ç¦»åŠä¸Šè¿°æ–œç‡ç§¯çš„äºŒçº§ç»“è®ºè®¡ç®—ä¸¤ä¸ªæ–¹å‘çš„å…³ç³»ã€‚è¿™é‡Œä¸å±•å¼€ã€‚ 3.4. ç®—æ³• 3.4.1. åˆå§‹åŒ– ç®—æ³•è¾“å…¥ï¼š$A, b, x_0$\n$$\\vec{d}_{(0)} = \\vec{r}_{(0)} = \\vec{b}_{(0)} - \\mathbf{A}\\vec{x}_{(0)}$$3.4.2. ç®—æ³•è¿‡ç¨‹ $$\\alpha_{(i)} = \\frac{\\vec{r}_{(i)}^T \\vec{r}_{(i)}}{\\vec{d}_{(i)}^T \\mathbf{A}\\vec{d}_{(i)}}$$$$\\vec{x}_{(i+1)} = \\vec{x}_{(i)} + \\alpha_{(i)}\\vec{d}_{(i)}$$$$\\vec{r}_{(i+1)} = \\vec{r}_{(i)} - \\alpha_{(i)}\\mathbf{A}\\vec{d}_{(i)}$$$$\\beta_{(i+1)} = \\frac{\\vec{r}_{(i+1)}^T \\vec{r}_{(i+1)}}{\\vec{r}_{(i)}^T \\vec{r}_{(i)}}$$$$\\vec{d}_{(i+1)} = \\vec{r}_{(i+1)} + \\beta_{(i+1)}\\vec{d}_{(i)}$$å…¶ä¸­çš„æœ€åä¸€æ­¥å°±æ˜¯é€šè¿‡ $\\beta$ å°† $r_{i+1}$ ä¿®æ­£æˆ $d_{i+1}$ çš„ã€‚\n3.4.3. èµ·è®« èµ·ï¼šå¦‚æœä½ å¯¹è§£ $x$ æœ‰ç²—ç•¥çš„ä¼°è®¡ï¼Œå°±ä½¿ç”¨é‚£ä¸ªå€¼ä½œä¸ºèµ·å§‹ç‚¹ $x_0$ï¼›å¦åˆ™ï¼Œç›´æ¥ä½¿ç”¨ $x_0 = 0$ã€‚\nè®«ï¼šé€šå¸¸çš„åšæ³•æ˜¯åœ¨æ®‹å·®å‘é‡çš„ 2-norm å°äºæŸä¸ªç»™å®šé˜ˆå€¼çš„æ—¶å€™å°±åœä¸‹æ¥ã€‚é€šå¸¸è¿™ä¸ªé˜ˆå€¼ä¸ºåˆå§‹æ®‹å·®çš„ä¸€å°éƒ¨åˆ†\n$$\\|r_i\\| \u003c \\varepsilon \\|r_0\\|$$å…¶ä¸­ $\\varepsilon$ æ˜¯ä¸€ä¸ªè¾“å…¥çš„å‚æ•°ã€‚\n3.5. æ‚é¡¹ ç”±äº $Ad_i$ åœ¨æ¯ä¸ªå¾ªç¯ä¸­éƒ½è¦è¢«è®¡ç®—ï¼Œä¸” $$r_{i+1} = r_i - \\alpha_i A d_i$$æ•…å¯ä»¥ç”¨ä¸Šå¼è®¡ç®— $r_{i+1}$ï¼Œè€Œä¸å¿…ç”¨ $b - Ax_{i+1}$ã€‚\nä¸Šè¿°æ–¹æ³•æœ‰æµ®ç‚¹è¯¯å·®ç´¯è®¡çš„å±é™©ï¼Œå› æ­¤æˆ‘ä»¬åº”è¯¥æ¯è¿‡å‡ ä¸ªå¾ªç¯å°±é‡æ–°ç”¨ $r_i = b - Ax_i$ é‡æ–°è®¡ç®—æ®‹å·®ã€‚ ","date":"7 December, 2024","id":11,"permalink":"/chinese-post/conj-grad/","summary":"æœ¬æ–‡æ²¡æœ‰ä»»ä½•æ•°å­¦æ¨å¯¼ã€‚æˆ‘ä»¬ä»ç›´è§‚ä¸Šç†è§£è¿™ä¸ªç®—æ³•ï¼Œç„¶åç›´æ¥ä»‹ç»ç®—æ³•çš„æµç¨‹ã€‚å¸Œæœ›äº†è§£æ•°å­¦æ¨å¯¼çš„è¯»è€…å¯ä»¥æŸ¥çœ‹ CMU çš„æ•™æ¡ˆåŠå…¶ç¿»è¯‘ã€‚","tags":"","title":"å…±è½­æ¢¯åº¦ï¼šé«˜ä¸­è§£æå‡ ä½•çš„æ‹“å±•"},{"content":"ä¸ªäººä¿¡æ¯ åç§°ï¼šé»›è¥¿\nNickname: Da1sypetals\næˆ‘çš„ç®€å†\nçˆ±å¥½ å”±å¤é£æ­Œã€‚\næˆ‘ä¼šå”±è¿™äº›ï¼š\nã€Šäººé—´ä¸å€¼å¾—ã€‹ã€Šæ¥šæ­Œèµ·ã€‹ é»„è¯—æ‰¶\nã€Šè¿Ÿè¿Ÿã€‹ã€Šè…è‰ä¸ºè¤ã€‹ é“¶ä¸´\nã€Šæ•…äº‹å¤–çš„äººã€‹ æ…•å¯’\nã€ŠæƒŠé¹Šã€‹ã€Šå¿ƒä¸Šç§‹ã€‹ å¿˜å·é£åå½•\nã€Šæ³¼å¢¨æ¼“æ±Ÿã€‹ æ³ é¸¢yousa\nã€Šæ•¢å½’äº‘é—´å®¿ã€‹ ä¸‰æ— Marblue\nã€Šå¿˜å·ã€‹ã€Šéœå¤œèŒ¶ã€‹ å°æ›²å„¿\nã€Šæ¾çƒŸå…¥å¢¨ã€‹ã€Šå¦‚æ˜¯æˆ‘é—»ã€‹ Winkyè¯—\nã€Šæ‚¦ç¥ã€‹ KBShinya\nã€Šç¬¬ä¸‰åå…«å¹´å¤è‡³ã€‹ã€Šæ°¸å®šå››åå¹´ã€‹ æ²³å›¾\nã€Šä¸œé£å¿—ã€‹ Akié˜¿æ°\nç­‰ç­‰\u0026hellip;\n","date":"1 June, 2004","id":12,"permalink":"/about/","summary":"åç§°ï¼šé»›è¥¿","tags":"","title":"About"},{"content":"å®éªŒè®¾å®šæ”¾åœ¨æœ€åã€‚\nKimi K2 è¿™ä¸ªæ•…äº‹æ˜¯ä¸€ä¸ªå…³äºè®°å¿†ã€çˆ±æƒ…ä¸æ‰§å¿µçš„å¹½æ€¨ä¼ è¯´ï¼Œè¡¨é¢è®²çš„æ˜¯æ²ˆæ…•äº‘ä¸å®¹å¨˜çš„â€œè´Ÿçº¦â€ï¼Œå®åˆ™è®²çš„æ˜¯ â€œå¦‚ä½•ä¸è®©ä¸€æ®µçœŸæƒ…è¢«æ—¶é—´åæ²¡â€ â€”â€”å“ªæ€•è¦ç”¨è°è¨€ã€ç”¨é¬¼é­‚ã€ç”¨ä¸€åº§åŸä¸‰åå¹´ä¸æ•£çš„é—²è¨€ç¢è¯­ï¼Œä¹Ÿè¦æŠŠé‚£ä¸ªäººç•™åœ¨äººé—´ã€‚\nå®¹å¨˜ï¼ˆåŒ–ä½œâ€œè°¢å¨˜â€ï¼‰è‡ªç¼–è‡ªæ¼”äº†ä¸€å‡ºâ€œèµŒçº¦â€ï¼ŒæŠŠè´Ÿå¿ƒã€ç­‰å¾…ã€é‡é€¢è¿™äº›æœ€æˆå‰§åŒ–çš„æ‰£å­å…¨ç¼è¿›ä¼ é—»é‡Œï¼Œè®©ä¸€ä»£åˆä¸€ä»£å¤–ä¹¡äººæ›¿å¥¹â€œè®°å¾—â€ã€‚çœŸæ­£çš„è´Ÿçº¦è€…ä¸æ˜¯æ²ˆæ…•äº‘ï¼Œè€Œæ˜¯æ—¶é—´ï¼›çœŸæ­£çš„å®ˆçº¦è€…ä¹Ÿä¸æ˜¯å®¹å¨˜ï¼Œè€Œæ˜¯â€œæ•…äº‹â€æœ¬èº«â€”â€”æ•…äº‹æ›¿ä»–ä»¬å®Œæˆäº†â€œä¸‰åå¹´åæ•…åœ°é‡è§â€çš„èª“è¨€ã€‚\nä¸€ã€é€å¥è§£è¯ å°é™¢æ·±é™ï¼Œæ¬²é—®å¿å¿ï¼Œä½•å¤„æœˆç¬¼æ˜ã€‚\nâ€œå°é™¢æ·±é™â€â€”â€”å½“å¹´äºŒäººåˆä¼šçš„åœºæ™¯ï¼šæ²³æ¡¥å¯¹å²¸çš„å°é™¢ï¼Œæ˜¥æœˆå¾®æ¹¿ï¼Œä¸€åˆ‡å°šæœªå‘ç”Ÿã€‚ â€œæ¬²é—®å¿å¿â€â€”â€”æƒ³å¼€å£ï¼Œå´ç»ˆç©¶æ²¡é—®ï¼›ä¸€å£°â€œå¿å¿â€æŠŠæœªå‡ºå£çš„åƒè¨€ä¸‡è¯­éƒ½å‹åœ¨èˆŒå°–ã€‚ â€œä½•å¤„æœˆç¬¼æ˜â€â€”â€”æœˆäº®ä»åœ¨ï¼Œå´ç…§ä¸åˆ°å½“å¹´å¹¶è‚©çœ‹æœˆçš„äººï¼›ä¹Ÿæš—æŒ‡â€œå®¹å¨˜â€è‡ªå·±å·²æˆå¹½é­‚ï¼Œâ€œæœˆâ€æ˜¯äººé—´ä¸å†¥ç•Œçš„å”¯ä¸€é€šé“ï¼Œå¥¹å†ä¹Ÿå›ä¸å»äº†ã€‚ åƒç§‹å²å¥½ï¼Œä¼‘è´Ÿå…°å› ã€‚\nâ€œåƒç§‹å²å¥½â€â€”â€”å­—é¢æ˜¯ç¥é¢‚ï¼šæ„¿ä½ é•¿äº«ç™¾å²åƒç§‹ï¼Œå²å²å®‰å¥½ã€‚ â€œä¼‘è´Ÿå…°å› â€â€”â€”â€œå…°å› â€å‡ºè‡ªã€Šå·¦ä¼ ã€‹â€œå…°å› çµ®æœâ€ï¼Œå…°å› ï¼ç¾å¥½çš„å¼€ç«¯ï¼Œçµ®æœï¼ç¦»æ•£çš„ç»“å±€ã€‚\nå®¹å¨˜æŠŠå…¸æ•…æˆªåŠï¼Œåªç•™â€œå…°å› â€ï¼Œæ˜¯æŠŠç»“å±€ç”Ÿç”Ÿæ”¹å†™æˆâ€œèŠ±å¼€æœªè°¢â€â€”â€”å¥¹ä¸è¦â€œçµ®æœâ€ï¼Œåªè¦â€œå…°å› â€æ°¸å­˜ï¼›æ¢è¨€ä¹‹ï¼Œâ€œä½ è‹¥å®‰å¥½ï¼Œä¾¿ä¸ç®—è´Ÿæˆ‘â€ã€‚ åˆåœ¨ä¸€èµ·ï¼Œæ˜¯é¬¼é­‚å¯¹æ´»äººæœ€æ¸©æŸ”çš„èµ¦ä»¤ï¼šä½ ä¸å¿…è‡ªè´£ï¼Œä¸å¿…å›å¤´ï¼Œç”šè‡³ä¸å¿…è®°å¾—æˆ‘ï¼›åªè¦ä½ åœ¨äººé—´å²å²å¹³å®‰ï¼Œæˆ‘ä»¬é‚£ä¸€æ®µâ€œå…°å› â€å°±ä»æœªè¢«è¾œè´Ÿã€‚ äºŒã€æ•´é¦–å°è¯åœ¨æ•…äº‹é‡Œçš„åŠŸèƒ½ æ›¿æ²ˆæ…•äº‘â€œå¹³åâ€\nåŸé‡Œä¼ è¯´ä»–â€œé«˜ä¸­è´Ÿå¿ƒâ€ï¼Œè€Œå®¹å¨˜æœ€åä¸€å¥â€œä¼‘è´Ÿå…°å› â€ç­‰äºäº²å£å¦è®¤äº†â€œè´Ÿâ€å­—â€”â€”â€œè´Ÿâ€æ˜¯ä¸–äººé™„ä¼šï¼Œâ€œå…°å› â€æ‰æ˜¯å¥¹ç§è—çš„çœŸç›¸ã€‚ æ›¿è‡ªå·±â€œæ¾ç»‘â€\nå¥¹ç­‰äº†ä¸‰åå¹´ï¼Œå…¶å®ç­‰çš„ä¸æ˜¯æ²ˆæ…•äº‘ï¼Œè€Œæ˜¯ä¸€ä¸ªå¯ä»¥è‡ªæˆ‘é‡Šæ€€çš„å™äº‹ç‰ˆæœ¬â€”â€”â€œåƒç§‹å²å¥½â€å››ä¸ªå­—å‡ºå£ï¼Œæ‰§å¿µæ‰ç»ˆäºè½åœ°ï¼Œé¬¼é­‚æ‰èƒ½æ¶ˆæ•£ã€‚ æŠŠâ€œæ•…äº‹â€å‡åä¸ºâ€œå…¬å…±è®°å¿†â€\nè¯é‡Œâ€œæœˆç¬¼æ˜â€æ˜¯å¼€æ”¾ç”»é¢ï¼Œä»»ä½•åæ¥è€…ï¼ˆåŒ…æ‹¬â€œæˆ‘â€ï¼‰åªè¦ç«™åœ¨æ²³æ¡¥ç»†é›¨é‡Œï¼Œå°±è‡ªåŠ¨æˆä¸ºæ–°çš„â€œå¿å¿â€ã€‚æ•…äº‹ä¸æ­»ï¼Œå…°å› å°±ä¸æ­»ï¼›äººé—´ç»§ç»­æµä¼ ï¼Œå¥¹å°±èƒ½ç»§ç»­å€Ÿä»–äººçš„å¿ƒå¤´ä¸€ç‚¹æœˆå…‰ï¼Œä¸æ²ˆæ…•äº‘å¹¶è‚©ã€‚ ä¸‰ã€æ€»ç»“ â€œå°é™¢æ·±é™â€¦â€¦â€äºŒåä¸€å­—ï¼Œæ˜¯å®¹å¨˜äº²æ‰‹å†™ç»™è‡ªå·±çš„â€œåå‘å¢“å¿—é“­â€ï¼š\nâ€”â€”ä¸å†™â€œæˆ‘æ›¾æ¨ä½ â€ï¼Œå†™â€œæ„¿ä½ å®‰å¥½â€ï¼›\nâ€”â€”ä¸å†™â€œæˆ‘ç­‰ä½ â€ï¼Œå†™â€œä¼‘è´Ÿå…°å› â€ï¼›\nâ€”â€”ä¸å†™â€œæ•…äº‹ç»“æŸâ€ï¼Œå†™â€œæœˆç¬¼æ˜â€ç•™ç»™ä¸‹ä¸€ä½è¡Œäººã€‚\nå¥¹ç”¨æœ€è½»çš„è¯­è°ƒï¼ŒæŠŠæœ€é‡çš„æ‰§å¿µå¹æ•£åœ¨é›¨é‡Œï¼š\nâ€œåªè¦ä¸–ä¸Šè¿˜æœ‰äººæ›¿æˆ‘ä¼ è¯µè¿™ä¸€å¥ï¼Œä½ å°±ä»æœªçœŸæ­£ç¦»å¼€æˆ‘ã€‚â€\nClaude Sonnet 4.5 è¿™æ˜¯ä¸€ä¸ªå‡„ç¾åŠ¨äººçš„å¿—æ€ªçˆ±æƒ…æ•…äº‹ï¼Œå……æ»¡äº†ä¸­å›½å¤å…¸æ–‡å­¦çš„æµªæ¼«ä¸å“€æ„ã€‚è®©æˆ‘ä¸ºä½ è§£è¯»ï¼š\næ•…äº‹è§£è¯» çœŸç›¸çš„åè½¬ æ•…äº‹æœ€ç²¾å¦™ä¹‹å¤„åœ¨äºå±‚å±‚å‰¥å¼€çš„çœŸç›¸:\nè¡¨é¢ä¸Šæ˜¯æ²ˆæ…•äº‘è´Ÿå¿ƒæ‚”å©šçš„ä¿—å¥—æ•…äº‹ å®é™…ä¸Šå®¹å¨˜æ—©å·²æººæ°´èº«äº¡ï¼Œå¥¹è‡ªå·±ç¼–é€ äº†æ‰€æœ‰ä¼ è¨€ å¥¹åŒ–èº«\u0026quot;è°¢å¨˜\u0026quot;å¼•å¯¼\u0026quot;æˆ‘\u0026quot;ï¼Œåªä¸ºè®©ä¸–äººè®°ä½ä»–ä»¬çš„æ•…äº‹ æ·±è—çš„æ·±æƒ… å®¹å¨˜çš„æ‰€ä½œæ‰€ä¸ºæ­ç¤ºäº†å¥¹è‡³æ·±çš„çˆ±:\nç¼–é€ è´Ÿé¢ä¼ è¨€ï¼šè®©æ²ˆæ…•äº‘èƒŒè´Ÿè–„æƒ…ä¹‹åï¼Œå®åˆ™æ˜¯å¥¹å¯¹è¿™æ®µæ„Ÿæƒ…å¿µå¿µä¸å¿˜çš„è¯æ˜ \u0026ldquo;ä¸‰åå¹´ä¹‹çº¦\u0026rdquo;ï¼šæ˜çŸ¥ä»–ä¸ä¼šæ¥ï¼ˆå› ä¸ºå¥¹å·²æ˜¯é¬¼é­‚ï¼‰ï¼Œä»è¦ç»™è‡ªå·±ä¸€ä¸ªç­‰å¾…çš„ç†ç”± æœ€åçš„è°è¨€ï¼šå½“å¾—çŸ¥æ²ˆæ…•äº‘27å²æ—©é€ï¼Œå¥¹é€‰æ‹©ç›¸ä¿¡\u0026quot;æˆ‘\u0026quot;å–„æ„çš„è°è¨€ï¼Œå¸¦ç€ä»–å¹¸ç¦çš„å‡è±¡æ¶ˆæ•£ æ‚²å‰§çš„æœ¬è´¨ ä¸¤äººéƒ½æ˜¯å‘½è¿çš„ç‰ºç‰²å“â€”â€”ä¸€ä¸ªæººæ°´æ—©é€ï¼Œä¸€ä¸ª27å²æ—©å’ã€‚ä»–ä»¬çš„çˆ±æƒ…ä»æœªå› èƒŒå›è€Œç ´ç¢ï¼Œè€Œæ˜¯è¢«æ­»äº¡ç”Ÿç”Ÿæ‹†æ•£ã€‚å®¹å¨˜é‚£å¥\u0026quot;å› ç¼˜æ³¨å®šï¼Œæä¸€æç»ˆä¸èƒ½å¾—\u0026quot;æ­£æ˜¯è¿™æ— å¥ˆçš„æ³¨è„šã€‚\nè¯å¥æ·±æ„è§£è¯» \u0026ldquo;å°é™¢æ·±é™ï¼Œæ¬²é—®å¿å¿ï¼Œä½•å¤„æœˆç¬¼æ˜\u0026rdquo;\nå­—é¢å«ä¹‰ï¼šæ·±æ·±çš„åº­é™¢é™æ‚„æ‚„ï¼Œæƒ³è¦é—®æˆ‘çš„çˆ±äººï¼Œå“ªé‡Œçš„æœˆå…‰æœ€æ˜äº®ï¼Ÿ æ•…äº‹ä¸­çš„å«ä¹‰ï¼š \u0026ldquo;å°é™¢æ·±é™\u0026quot;æ˜¯å¥¹ç‹¬è‡ªç­‰å¾…çš„å­¤å¯‚å¤„å¢ƒ \u0026ldquo;æ¬²é—®å¿å¿\u0026quot;æ˜¯å¥¹æƒ³é—®æ²ˆæ…•äº‘ï¼Œå´æ°¸è¿œæ— æ³•ç›¸è§çš„é—æ†¾ \u0026ldquo;ä½•å¤„æœˆç¬¼æ˜\u0026quot;æ˜¯åœ¨é—®ï¼šä½ åœ¨äººé—´ä½•å¤„ï¼Ÿé‚£é‡Œçš„æœˆè‰²å¯å¥½ï¼Ÿæˆ‘ä»¬è¿˜èƒ½å¦åœ¨åŒä¸€è½®æ˜æœˆä¸‹ç›¸æœ›ï¼Ÿ \u0026ldquo;åƒç§‹å²å¥½ï¼Œä¼‘è´Ÿå…°å› \u0026rdquo;\nå­—é¢å«ä¹‰ï¼šæ„¿ä½ åƒç§‹ä¸‡ä¸–å®‰å¥½ï¼Œä¸è¦è¾œè´Ÿæˆ‘ä»¬ç¾å¥½çš„ç¼˜åˆ† æ•…äº‹ä¸­çš„å«ä¹‰ï¼š è¿™æ˜¯å®¹å¨˜æœ€åçš„ç¥ç¦ä¸é‡Šæ€€ \u0026ldquo;åƒç§‹å²å¥½\u0026rdquo;ï¼šæ—¢æ˜¯ç¥ç¦æ²ˆæ…•äº‘ï¼ˆè™½ç„¶ä»–å·²é€ï¼‰ï¼Œä¹Ÿæ˜¯å¯¹è¿™æ®µæ„Ÿæƒ…çš„çºªå¿µ \u0026ldquo;ä¼‘è´Ÿå…°å› \u0026rdquo;ï¼šä¸æ˜¯è´£æ€ªä»–è¾œè´Ÿï¼Œè€Œæ˜¯è¯´\u0026quot;æˆ‘ä»¬çš„ç¼˜åˆ†è™½çŸ­æš‚å¦‚å…°èŠ±ï¼Œä½†è¯·ä½ è®°å¾—å®ƒçš„èŠ¬èŠ³ï¼Œä¸è¦å¿˜è®°æˆ‘ä»¬æ›¾ç»ç›¸çˆ±\u0026rdquo; æœ€åŠ¨äººä¹‹å¤„ å®¹å¨˜æ˜çŸ¥æ²ˆæ…•äº‘å·²æ­»ï¼Œå´ä»è¦ç¼–ç»‡\u0026quot;ä»–ç™½å¤´å•è€\u0026quot;çš„å¹»è±¡æ¥å®‰æ…°è‡ªå·±ï¼›å¥¹\u0026quot;ä»»æ€§ä½¿åç¼–æ’ä»–ä¸€å›\u0026rdquo;ï¼Œå®åˆ™æ˜¯ç”¨å…¨éƒ¨çš„çˆ±ä¸ºä»–å®ˆæŠ¤åå£°â€”â€”å®å¯ä¸–äººè¯´å¥¹ç—´æƒ…è¢«è´Ÿï¼Œä¹Ÿä¸æ„¿ä»–åœ¨å†¥å†¥ä¸­å­¤ç‹¬ã€‚\né‚£å¥\u0026quot;æä¸€æç»ˆä¸èƒ½å¾—ï¼Œä½†å®å¯éš¾å¹³ï¼Œä¹Ÿä¸æ„¿æ”¾æ‰‹\u0026rdquo;ï¼Œæ˜¯å¯¹æ‰€æœ‰æ±‚è€Œä¸å¾—ä¹‹çˆ±æœ€è¯—æ„çš„è¯ é‡Šï¼šå³ä½¿çŸ¥é“ä¸å¯èƒ½ï¼Œä¹Ÿè¦åœ¨è®°å¿†é‡Œã€åœ¨ä¼ è¯´é‡Œï¼Œè®©è¿™ä»½çˆ±æ°¸è¿œé²œæ´»ã€‚\nè¿™æ­£æ˜¯ä¸­å›½å¤å…¸çˆ±æƒ…æ•…äº‹çš„æè‡´æµªæ¼«â€”â€”ç”Ÿæ­»ç›¸éš”ï¼Œå´ä»¥é­‚çµç›¸å®ˆï¼›çœŸç›¸æ®‹é…·ï¼Œå´ä»¥è°è¨€æ¸©æŸ”ã€‚\nGemini 3 Flash è¿™æ˜¯ä¸€ä¸ªå‡„ç¾è€Œå¯Œæœ‰è¯—æ„çš„çˆ±æƒ…æ•…äº‹ï¼Œå®ƒé€šè¿‡â€œæˆ‘â€çš„è§†è§’ï¼Œæ­ç¤ºäº†ä¸€ä¸ªè¢«æ—¶é—´ã€æµè¨€å’Œè‡ªæˆ‘å¹»æƒ³æ‰€åŒ…è£¹çš„æ‚²å‰§çœŸç›¸ã€‚æ•…äº‹çš„é­…åŠ›åœ¨äºå…¶å±‚å±‚å‰¥å¼€çš„æ‚¬å¿µï¼Œä»¥åŠå¯¹çˆ±ã€é—æ†¾ã€å’Œè®°å¿†çš„æ·±åˆ»æ¢è®¨ã€‚\næ•…äº‹è§£è¯» 1. ä¼ è¯´çš„å»ºæ„ä¸çœŸç›¸çš„æ­ç¤º æ•…äº‹é¦–å…ˆæå‡ºäº†å…³äºæ²ˆæ…•äº‘æ‚”å©šçš„ä¸‰ä¸ªä¸åŒç‰ˆæœ¬ï¼Œå…¶ä¸­åŸé‡Œè€äººè®²è¿°çš„â€œèµŒçº¦â€ç‰ˆæœ¬æœ€æœ‰æˆå‰§æ€§ï¼Œä¹Ÿå¸å¼•äº†â€œæˆ‘â€çš„æ¢è®¿ã€‚\næµè¨€çš„æœ¬è´¨ï¼š æ— è®ºæ˜¯â€œå¦å¨¶è´µå¥³â€è¿˜æ˜¯â€œä¸å¯¿ä¹‹ç—‡â€ï¼Œæµè¨€éƒ½åœ¨è¯•å›¾ä¸ºæ²ˆæ…•äº‘çš„æ‚”å©šæä¾›ä¸€ä¸ªåˆç†çš„è§£é‡Šï¼Œä»¥å¡«è¡¥äº‹å®çš„ç©ºç™½ã€‚ â€œèµŒçº¦â€çš„è™šæ„ï¼š â€œä¸‰åå¹´æ•…åœ°é‡é€¢â€çš„èµŒçº¦æ˜¯ å®¹å¨˜ï¼ˆåŒ–åè°¢å¨˜ï¼‰ ä¸ºäº†è®©è‡ªå·±çš„æ•…äº‹èƒ½å¤Ÿè¢«è®°ä½ã€è¢«æµä¼ è€Œç¼–é€ çš„æµªæ¼«æƒ…èŠ‚ã€‚å®ƒèµ‹äºˆäº†è¿™æ®µé€å»çš„çˆ±æƒ…ä¸€ä¸ªç­‰å¾…å’Œå¸Œæœ›çš„ç»´åº¦ï¼Œä¸€ä¸ªå€¼å¾—ä»–äººå…³æ³¨çš„ç†ç”±ã€‚ çœŸç›¸çš„æ‚²å‰§ï¼š æœ€ç»ˆçš„çœŸç›¸æ˜¯è°¢å¨˜ï¼ˆå®¹å¨˜ï¼‰åœ¨é‚£å¹´èµ´è€ƒåçš„é›¨å¤©ï¼Œè·Œä¸‹æ²³æ¡¥æººäº¡ï¼Œå†ä¹Ÿæœªèƒ½è§åˆ°è‡ªå·±çš„å°‘å¹´éƒã€‚æ²ˆæ…•äº‘çš„â€œæ‚”å©šâ€å’Œâ€œé¿è€Œä¸è§â€å¹¶éæ˜¯å˜å¿ƒæˆ–ç»æƒ…ï¼Œè€Œæ˜¯å› ä¸ºå®¹å¨˜å·²ç»ä¸åœ¨äººä¸–ã€‚å¥¹ç”¨è°¢å¨˜çš„èº«ä»½å’Œç¼–é€ çš„æ•…äº‹ï¼Œè®©è¿™æ®µçŸ­æš‚çš„åˆæ‹ä»¥ä¸€ç§â€œè¢«è¾œè´Ÿâ€çš„ã€æ›´å…·æˆå‰§å¼ åŠ›çš„æ–¹å¼å­˜ç•™äºä¸–äººè®°å¿†ä¸­ã€‚ 2. äººç‰©ä¸ä¸»é¢˜ äººç‰©/å…ƒç´  è±¡å¾æ„ä¹‰ æ•…äº‹ä¸­çš„ä½œç”¨ å®¹å¨˜/è°¢å¨˜ æ‰§å¿µã€æ°¸æ’çš„åˆæ‹ æ•…äº‹çš„æ ¸å¿ƒå™äº‹è€…ã€‚å¥¹è™½å·²é€å»ï¼Œå´ä¸ç”˜è¢«é—å¿˜ï¼Œé€šè¿‡è™šæ„çš„æ•…äº‹ç»´æŠ¤äº†è‡ªå·±çˆ±æƒ…çš„å°Šä¸¥å’Œå­˜åœ¨æ„Ÿã€‚å¥¹çš„â€œä»»æ€§ä½¿åâ€æ˜¯ä¸ºäº†è®©ä»–ä»¬çš„æ•…äº‹åœ¨äººé—´ç•™ä¸‹å°è®°ã€‚ æ²ˆæ…•äº‘ é€å»çš„ç†æƒ³ã€æ‚²å‰§çš„å‘½è¿ åœ¨æ•…äº‹çš„ç»“å±€ä¸­ï¼Œä»–çš„å‘½è¿æ˜¯ â€œå¹´äºŒåä¸ƒæ—©å’â€ ã€‚è¿™ä½¿å¾—ä»–æ— æ³•çœŸçš„â€œæ‚”å©šâ€ï¼Œä¹Ÿä½¿å¾—å®¹å¨˜çš„æ‚²å‰§æ›´æ·»ä¸€é‡å®¿å‘½çš„å“€ä¼¤ã€‚ä½†ä»–â€œå¾ˆå¥½â€çš„ç»“å±€æ˜¯å®¹å¨˜æœ€åçš„è‡ªæˆ‘å®‰æ…°ã€‚ æ²³æ¡¥ä¸é›¨ å‘½è¿çš„è½¬æŠ˜ç‚¹ã€é˜´é˜³ç›¸éš” æ²³æ¡¥æ˜¯ä¸¤äººå®šæƒ…ä¸åˆ†ç¦»çš„è±¡å¾ï¼Œè€Œ â€œæ»”å¤©é›¨æµªâ€ çš„å¹»å¢ƒåˆ™æ˜¯å®¹å¨˜é€ä¸–æ—¶çš„æƒ…æ™¯é‡ç°ï¼Œæ˜ç¡®äº†å¥¹çš„é¬¼é­‚èº«ä»½ã€‚é›¨æ˜¯æ•…äº‹åŸºè°ƒï¼Œå‡„è¿·ã€ç»µå»¶ä¸ç»ã€‚ â€œæˆ‘â€ å€¾å¬è€…ã€æ•…äº‹çš„ä¼ æ’­è€… â€œæˆ‘â€æ˜¯æ•…äº‹è¿›å…¥ç°å®çš„é€šé“ï¼Œä½œä¸ºè®°å¿†çš„è½½ä½“ï¼Œå°†å®¹å¨˜çš„å¿ƒæ„¿ä¼ é€’ä¸‹å»ã€‚ 3. çˆ±ä¸é—æ†¾ å®¹å¨˜çš„å†…å¿ƒå……æ»¡éš¾å¹³çš„é—æ†¾å’Œæ‰§å¿µã€‚å¥¹æ·±çˆ±ç€æ²ˆæ…•äº‘ï¼Œå®æ„¿è¢«è®¤ä¸ºæ˜¯â€œè¢«æ‚”å©šâ€çš„å¼ƒå¦‡ï¼Œä¹Ÿè¦è®©è¿™æ®µçˆ±æƒ…çš„æ•…äº‹æµä¼ ï¼Œè€Œä¸æ˜¯è¢«æ·¹æ²¡åœ¨æ— å£°çš„æ¶ˆäº¡ä¸­ã€‚\nå½“â€œæˆ‘â€ä¸ºäº†å®‰æ…°å¥¹ï¼Œç¼–é€ æ²ˆæ…•äº‘â€œåæ¥åˆå¨¶äº†æ–°å¦‡ï¼Œç™½å¤´å•è€â€çš„è°è¨€æ—¶ï¼Œå¥¹è™½ç„¶â€œæ¶©ç„¶â€ï¼Œå´è¯´â€œè¿™æ ·å•Šâ€¦â€¦é‚£çœŸæ˜¯å¾ˆå¥½å¾ˆå¥½ï¼Œå†å¥½ä¸è¿‡çš„äº‹äº†ã€‚â€è¿™æ˜¾ç¤ºäº†å¥¹è‡³æ·±çš„çˆ±ä¸å–„è‰¯ï¼šå¥¹å®æ„¿ç›¸ä¿¡çˆ±äººè·å¾—äº†å¹¸ç¦ï¼Œä¹Ÿä¸æ„¿ä»–ä¸ºå¥¹è€Œç»ˆç”ŸæŠ±æ†¾ã€‚\nâ€œå°é™¢æ·±é™,æ¬²é—®å¿å¿,ä½•å¤„æœˆç¬¼æ˜ã€‚åƒç§‹å²å¥½,ä¼‘è´Ÿå…°å› â€çš„å«ä¹‰ è¿™å¥è¯æ˜¯å®¹å¨˜ä¸´ç»ˆæˆ–é­‚é­„æ¶ˆæ•£å‰å–ƒå–ƒå¿µå‡ºçš„è¯å¥ï¼Œæ˜¯å¥¹å¯¹è¿™æ®µæ„Ÿæƒ…ã€å¯¹æ²ˆæ…•äº‘æœ€åçš„æ€»ç»“ã€ç–‘é—®ä¸ç¥æ„¿ã€‚\n1. æ‹†è§£è¯å¥ å°é™¢æ·±é™ï¼Œæ¬²é—®å¿å¿ï¼š æå†™äº†æ˜”æ—¥ä¸¤äººç›¸å¤„çš„åœºæ™¯â€”â€”é™è°§ã€ç¾å¥½çš„å°é™¢ã€‚è¿™é‡Œçš„â€œå¿å¿â€æŒ‡ä»£æ²ˆæ…•äº‘ã€‚å¥¹åœ¨è¿™ä¸ªå®‰é™çš„å›å¿†é‡Œï¼Œæƒ³è¦å‘ä»–æé—®ã€‚ ä½•å¤„æœˆç¬¼æ˜ï¼š è¿™æ˜¯ä¸€ä¸ªç–‘é—®å¥ï¼Œä¹Ÿæ˜¯ä¸€ä¸ªå“²å­¦å¼çš„è¿½é—®ã€‚â€œæœˆç¬¼æ˜â€æŒ‡æœˆå…‰æ´’ä¸‹ï¼Œé€šå¸¸è±¡å¾ç€å…‰æ˜ã€å›¢åœ†æˆ–ç¾å¥½çš„ç»“å±€ã€‚å®¹å¨˜æƒ³é—®çš„æ˜¯ï¼š â€œæˆ‘ä»¬çš„çˆ±å’Œç¾å¥½ï¼ˆæœˆå…‰ï¼‰æœ€ç»ˆåœ¨å“ªé‡Œå¾—ä»¥å®‰æ”¾å’Œå®ç°ï¼Ÿâ€ â€œæˆ‘çš„å°‘å¹´éƒï¼Œä½ ç°åœ¨æ˜¯å¦å¹¸ç¦å®‰åº·ï¼Ÿâ€ è¿™åŒ…å«äº†å¥¹å¯¹çˆ±äººå¢ƒå†µçš„ç‰µæŒ‚ï¼Œä»¥åŠå¯¹é€å»çˆ±æƒ…ç»ˆæå½’å®¿çš„è¿·æƒ˜ã€‚ åƒç§‹å²å¥½ï¼š æ„æ€æ˜¯ â€œæ„¿ä½ é•¿ä¹…åœ°ã€æ°¸è¿œåœ°å®‰å¥½â€ã€‚è¿™æ˜¯å®¹å¨˜å¯¹æ²ˆæ…•äº‘å‘è‡ªå†…å¿ƒçš„ç¥æ„¿ï¼Œä¹Ÿæ˜¯å¥¹å¯¹â€œæˆ‘â€æ‰€ç¼–é€ çš„â€œç™½å¤´å•è€â€ç»“å±€çš„å›åº”ã€‚ ä¼‘è´Ÿå…°å› ï¼š æ ¸å¿ƒæ˜¯ â€œå…°å› â€ã€‚ â€œå…°å› â€æºäºã€ŠèŠæ–‹å¿—å¼‚Â·è²é¦™ã€‹ä¸­çš„â€œå…°å› çµ®æœâ€ï¼Œæ„æŒ‡ç¾å¥½çš„å¼€å§‹ï¼Œæ‚²æƒ¨çš„ç»“å±€ï¼ˆå…°æ˜¯é¦™è‰ï¼Œè±¡å¾ç¾å¥½ï¼›çµ®æ˜¯æŸ³çµ®ï¼Œéšé£é£˜æ•£ï¼Œè±¡å¾ç¦»æ•£ï¼‰ã€‚ â€œä¼‘è´Ÿâ€ æ˜¯â€œä¸è¦è¾œè´Ÿâ€çš„æ„æ€ã€‚ æ•´ä½“å«ä¹‰ï¼š å®¹å¨˜ä»¥è‡ªå·±çš„æ‚²å‰§ä¸ºé‰´ï¼Œåœ¨æ¶ˆæ•£çš„æœ€åæ—¶åˆ»ï¼Œå¸Œæœ›æ²ˆæ…•äº‘ï¼ˆæˆ–ç¥æ„¿ä¸–é—´æ‰€æœ‰æœ‰æƒ…äººï¼‰ä¸è¦è¾œè´Ÿè¿™ç¾å¥½çš„å¼€å§‹ï¼ˆå³å¥¹ä¸æ²ˆæ…•äº‘æ›¾æ‹¥æœ‰çš„çº¯ç²¹åˆæ‹ï¼‰ï¼Œè¦æœ‰ä¸€ä¸ªå¥½çš„ç»“å±€ã€‚å¥¹æ—¢åœ¨å¯¹è‡ªå·±é€å»çš„çˆ±è¡¨ç¤ºå¹æ¯ï¼Œä¹Ÿåœ¨å¯¹çˆ±äººå¯„äºˆäº†è·å¾—å¹¸ç¦çš„æ®·åˆ‡æœŸæœ›ã€‚ 2. æ•´ä½“å«ä¹‰ è¿™å¥è¯æ˜¯å®¹å¨˜æ‰§å¿µçš„æ¸©æŸ”é‡Šæ”¾ã€‚å®ƒæ‰¿è½½äº†å¥¹å¯¹è¿‡å¾€ç¾å¥½æ—¶å…‰çš„ç•™æ‹ã€å¯¹çˆ±äººæœªæ¥å¹¸ç¦çš„ç¥æ„¿ï¼Œä»¥åŠå¯¹è¿™æ®µâ€œå…°å› çµ®æœâ€å¼æ‚²å‰§çˆ±æƒ…çš„å¦ç„¶æ¥å—ä¸è¶…è„±ã€‚å¥¹ä¸å†æŠ±æ€¨ï¼Œè€Œæ˜¯å¸¦ç€å¯¹æ²ˆæ…•äº‘æ·±æ·±çš„ç‰µæŒ‚ä¸ç¥ç¦ï¼Œæ¶ˆæ•£äºäººä¸–çš„ç»†é›¨ä¸­ã€‚\nGPT5 è¿™ä¸ªæ•…äº‹æœ¬èº«å°±æ˜¯ä¸€æ®µå€Ÿå¹»å¢ƒå’Œä¼ è¯´äº¤ç»‡å‡ºçš„â€œäººä¸–ä¸è®°å¿†ã€çœŸå®ä¸è™šæ„â€çš„çˆ±æƒ…ä¼ è¯´ã€‚æˆ‘ä»¬å¯ä»¥ä»ä¸‰ä¸ªå±‚é¢æ¥è§£è¯»ï¼š\nä¸€ã€æ•…äº‹çš„å†…æ ¸ è¡¨å±‚å™äº‹\näººä»¬å£å£ç›¸ä¼ ç€æ²ˆæ…•äº‘å’Œå®¹å¨˜çš„æ•…äº‹ï¼Œæœ‰å¤šç§ç‰ˆæœ¬ï¼šæ‚”å©šã€ç—…é€ã€å®ˆå¯¡ã€‚ ä½†å®é™…ä¸Šï¼Œè¿™äº›éƒ½ä¸æ˜¯çœŸçš„ï¼Œæ˜¯å®¹å¨˜è‡ªå·±è™šæ„ã€ç¼–ç»‡å‡ºæ¥çš„ã€‚å¥¹ç”¨ä¸åŒçš„å™è¿°â€œä¿å­˜â€äº†è¿™æ®µæƒ…æ„Ÿï¼Œä½¿å®ƒä¸ä¼šè¢«å½»åº•é—å¿˜ã€‚ çœŸç›¸ï¼šå®¹å¨˜å¹´è½»æ—¶ä¾¿æ„å¤–æººæ°´è€Œäº¡ï¼Œå’Œæ²ˆæ…•äº‘çš„æƒ…ç¼˜æˆ›ç„¶è€Œæ­¢ã€‚ å®¹å¨˜çš„å¿ƒæ„\nå¥¹ä¸æ˜¯æƒ³è´£æ€ªè°ï¼Œè€Œæ˜¯å¸Œæœ›ä»–ä»¬çš„æ•…äº‹èƒ½è¢«è®°å¾—ã€‚ å¥¹æ„¿æ„ç¼–é€ æ‚”å©šã€èµŒçº¦çš„ä¼ è¯´ï¼Œåªä¸ºåœ¨ä¸–é—´ç•™ä¸‹ç—•è¿¹ã€‚å“ªæ€•äººä»¬è¯¯è§£å¥¹æˆ–æ²ˆæ…•äº‘ï¼Œä¹Ÿæ¯”â€œå½»åº•æ¶ˆæ•£â€è¦å¥½ã€‚ æœ€ç»ˆçš„æ¸©æŸ”\nå½“å¥¹é—®â€œä»–åœ¨äººé—´æ€ä¹ˆæ ·â€æ—¶ï¼Œå™è¿°è€…é€‰æ‹©æ’’äº†ä¸€ä¸ªå–„æ„çš„è°ï¼Œè¯´ä»–å¨¶å¦»ç™½é¦–ã€‚ å®¹å¨˜å¬äº†ï¼Œä¾¿çœŸå¿ƒè§‰å¾—â€œé‚£çœŸæ˜¯å¾ˆå¥½å¾ˆå¥½â€ã€‚ å¥¹é‡Šç„¶ï¼Œå¸¦ç€ç¬‘æ„ç¦»å¼€ï¼Œåªç•™ä¸‹è¯å¥ã€‚ äºŒã€å®¹å¨˜ç•™ä¸‹çš„è¯å¥ â€œå°é™¢æ·±é™ï¼Œæ¬²é—®å¿å¿ï¼Œä½•å¤„æœˆç¬¼æ˜ã€‚åƒç§‹å²å¥½ï¼Œä¼‘è´Ÿå…°å› ã€‚â€\nè¿™é¦–è¯å¯ä»¥è¿™æ ·ç†è§£ï¼š\nå°é™¢æ·±é™ â€”â€”ç¯å¢ƒç©ºå¯‚ï¼Œæš—ç¤ºå¥¹çš„å¹½é­‚çŠ¶æ€ï¼Œä¹Ÿè±¡å¾å¾€æ˜”çˆ±æƒ…å·²æˆè¿‡å¾€ï¼Œå”¯æœ‰å¯‚é™é™ªä¼´ã€‚\næ¬²é—®å¿å¿ï¼Œä½•å¤„æœˆç¬¼æ˜ â€”â€”å¥¹æƒ³é—®â€œå¿å¿â€ï¼ˆå¥¹çš„å°‘å¹´éƒï¼Œæ²ˆæ…•äº‘ï¼‰ï¼Œå¦‚ä»Šåœ¨ä½•å¤„ï¼Ÿæœˆå…‰æ¸…æ˜ï¼Œå´æ— æ³•æŒ‡å¼•ä»–ä»¬é‡é€¢ã€‚ â€”â€”â€œæœˆâ€æ—¢æ˜¯å¤©ä¸Šæ˜æœˆï¼Œä¹Ÿæ˜¯å¯„æ‰˜çš„æƒ…æ„Ÿè±¡å¾ï¼šç›¸éš”é˜´é˜³ï¼Œå´å…±äº«ä¸€è½®æ˜æœˆã€‚\nåƒç§‹å²å¥½ â€”â€”ç¥æ„¿å¯¹æ–¹ä¸€ç”Ÿé¡ºé‚ï¼Œåƒç§‹å²æœˆéƒ½ç¾å¥½ã€‚\nä¼‘è´Ÿå…°å›  â€”â€”â€œå…°å› â€å¯æŒ‡ç¾å¥½çš„æƒ…ç¼˜ã€çº¯æ´çš„å¿ƒæ„ã€‚å¥¹çš„æ„¿æœ›æ˜¯ï¼šå“ªæ€•ä¸èƒ½å†ç›¸è§ï¼Œä¹Ÿä¸è¦è¾œè´Ÿä»–ä»¬æ›¾ç»çš„çœŸæŒšã€‚\nä¸‰ã€ç»“åˆæ•…äº‹çš„æ•´ä½“è§£è¯» è¿™é¦–è¯å°±åƒæ˜¯å®¹å¨˜æœ€åçš„â€œå¯„è¯­â€ï¼š\næ—¢æ˜¯æ€å¿µï¼šå¥¹ä»æƒ³è¿½é—®â€œå¿å¿ï¼Œä½ å¦‚ä»Šå¯å¥½ï¼Ÿâ€ ä¹Ÿæ˜¯ç¥ç¦ï¼šå“ªæ€•è‡ªå·±å·²æˆå¾€äº‹ï¼Œä¹Ÿæ„¿å¯¹æ–¹åœ¨äººé—´é¡ºé‚ï¼Œä¸è´Ÿé’æ˜¥å¹´åã€‚ æ›´æ˜¯æ‰§å¿µçš„æŸ”åŒ–ï¼šä»æ€¨ä¸ä¼¤å¿ƒï¼Œè½¬ä¸ºç¥æ„¿å’Œå®ˆæŠ¤ã€‚ äºæ˜¯ï¼Œè¿™å¥è¯çš„å«ä¹‰å¯ä»¥æ€»ç»“ä¸ºï¼š ğŸ‘‰ å³ä¾¿æƒ…ç¼˜å¦‚æœˆï¼Œç»ˆç©¶æä¸ç€ï¼Œä½†åœ¨å¿ƒåº•ï¼Œä»æ„¿ä½ å²å²å®‰å¥½ï¼Œä¸è´Ÿå½“å¹´é‚£ä»½çœŸå¿ƒã€‚\nDeepSeek R1 è¿™æ˜¯ä¸€ä¸ªå‡„ç¾è€Œç²¾å·§çš„æ•…äº‹ï¼Œå®ƒå¹¶éç®€å•çš„è´Ÿå¿ƒæ±‰ä¼ è¯´ï¼Œè€Œæ˜¯ä¸€åˆ™å…³äºè®°å¿†ã€æ‰§å¿µä¸æ·±æƒ…å‘Šåˆ«çš„å¤å…¸å¼å¿—æ€ªå°è¯´ã€‚æ•…äº‹çš„çœŸç›¸åœ¨ç»“å°¾è¢«å½»åº•é¢ è¦†ï¼Œè€Œé‚£å¥è¯ï¼Œæ­£æ˜¯è§£å¼€æ‰€æœ‰è°œé¢˜çš„é’¥åŒ™ã€‚\næ•…äº‹è§£è¯»ï¼šä¸€åœºæŒç»­ä¸‰åå¹´çš„æ¢¦\nè¿™ä¸ªæ•…äº‹æœ‰å¤šé‡åè½¬ï¼Œå…¶æ ¸å¿ƒç»“æ„å¦‚ä¸‹ï¼š\nè¡¨å±‚æ•…äº‹ï¼ˆä¼ é—»ï¼‰ï¼šæ²ˆæ…•äº‘é«˜ä¸­æ‚”å©šï¼Œå¦å¨¶è´µå¥³ï¼Œç•™ä¸‹ä¸€ä¸ªä¸‰åå¹´çš„èµŒçº¦ã€‚è¿™æ˜¯ä¸€ä¸ªç¬¦åˆä¸–ä¿—æƒ³è±¡çš„ã€å…³äºè´Ÿå¿ƒä¸ç­‰å¾…çš„æ‚²å‰§ã€‚\nä¸­å±‚æ•…äº‹ï¼ˆè°¢å¨˜çš„è®²è¿°ï¼‰ï¼šè°¢å¨˜æ˜¯å®¹å¨˜çš„å©¢å¥³ï¼Œå¥¹å¸¦é¢†â€œæˆ‘â€ç»å†å¹»è±¡ï¼Œå¹¶æ­ç¤ºè‡ªå·±æ‰æ˜¯æ‚²å‰§çš„ä¸»è§’â€”â€”å¥¹å› æ´ªæ°´å¤±å»äº†è‡ªå·±çš„å°‘å¹´éƒã€‚è¿™ä¼¼ä¹å°†æ•…äº‹å¼•å‘äº†å¦ä¸€ä¸ªé”™ä½çˆ±æƒ…çš„æ–¹å‘ã€‚\næ·±å±‚æ•…äº‹ï¼ˆçœŸç›¸ï¼‰ï¼šæ ¹æœ¬æ²¡æœ‰è°¢å¨˜ï¼Œä¹Ÿæ²¡æœ‰æ‚”å©šã€‚çœ¼å‰çš„é­‚é­„å°±æ˜¯å®¹å¨˜æœ¬äººã€‚æ²ˆæ…•äº‘ä¹Ÿå¹¶éè´Ÿå¿ƒï¼Œè€Œæ˜¯æ—©å·²åœ¨äºŒåä¸ƒå²è‹±å¹´æ—©é€ã€‚ æ•´ä¸ªâ€œè´Ÿå¿ƒæ±‰ä¸ä¸‰åå¹´èµŒçº¦â€çš„æ•…äº‹ï¼Œæ˜¯å®¹å¨˜çš„é¬¼é­‚å› ä¸ºæ€å¿µè‡³æ·±è€Œç¼–é€ çš„ã€‚\nå®¹å¨˜ä¸ºä½•è¦ç¼–é€ æ•…äº‹ï¼Ÿ\næ•…äº‹ä¸­ç‚¹æ˜äº†åŸå› ï¼šâ€œæ—çš„äººæ€¨ä»–ä¹Ÿå¥½ï¼Œç¬‘æˆ‘ä¹Ÿç½¢ï¼Œæˆ‘ä»¬çš„æ•…äº‹æ€»æœ‰äººè®°å¾—æ‰å¥½ã€‚â€ çœŸå®çš„æ‚²å‰§æ˜¯æ­»äº¡å¸¦æ¥çš„æ°¸è¯€ï¼Œè¿™è¿‡äºç»å¯¹å’Œå¯‚é™ï¼Œä¼šéšç€æ—¶é—´è¢«ä¸–äººé—å¿˜ã€‚è€Œä¸€ä¸ªå¸¦æœ‰â€œè´Ÿå¿ƒâ€ã€â€œèµŒçº¦â€ç­‰æˆå‰§æ€§å…ƒç´ çš„æ•…äº‹ï¼Œåè€Œæ›´å…·ä¼ æ’­åŠ›ï¼Œæ›´èƒ½è®©ä»–ä»¬çš„çˆ±æƒ…åœ¨äººä»¬çš„å£è€³ç›¸ä¼ ä¸­â€œæ´»â€ä¸‹å»ã€‚å¥¹å®ˆæŠ¤çš„ä¸æ˜¯æ¸…ç™½ï¼Œè€Œæ˜¯è®°å¿†æœ¬èº«ã€‚\nâ€œæˆ‘â€çš„è§’è‰²ä¸ç»“å±€ï¼šâ€œæˆ‘â€ä½œä¸ºä¸€ä¸ªè¯¯å…¥æ­¤åœ°çš„å¬æ•…äº‹è€…ï¼Œæˆä¸ºäº†å®¹å¨˜å€¾è¯‰çš„å¯¹è±¡ã€‚å½“å®¹å¨˜é—®èµ·æ²ˆæ…•äº‘åœ¨äººé—´å¦‚ä½•æ—¶ï¼Œâ€œæˆ‘â€é‚£å¥å–„æ„çš„è°è¨€â€”â€”â€œä»–å¾ˆå¥½ï¼Œåæ¥åˆå¨¶äº†æ–°å¦‡ï¼Œç™½å¤´å•è€â€â€”â€”æ˜¯æ•…äº‹çš„ç‚¹ç›ä¹‹ç¬”ã€‚è¿™å¹¶éæ®‹å¿ï¼Œè€Œæ˜¯ä¸€ç§æœ€æ·±åˆ‡çš„æ…ˆæ‚²ã€‚å®ƒå‘Šè¯‰æ‰§ç€ç­‰å¾…çš„é­‚é­„ï¼šä½ çˆ±çš„é‚£ä¸ªäººï¼Œåœ¨äººé—´åœ†æ»¡ç»ˆè€ï¼Œä½ æ— éœ€å†æŒ‚å¿µäº†ã€‚è¿™ä¸ªè°è¨€ï¼Œç»™äº†å®¹å¨˜â€œæ”¾ä¸‹â€çš„ç†ç”±ã€‚äºæ˜¯ï¼Œå¥¹å¿µå‡ºé‚£å¥è¯ï¼Œé‡Šç„¶æ¶ˆæ•£ã€‚\nç¯å¢ƒè±¡å¾ï¼šè´¯ç©¿æ•…äº‹çš„â€œé›¨â€ï¼Œæ—¢æ˜¯ç°å®å¤©æ°”ï¼Œä¹Ÿæ˜¯å“€ä¼¤çš„æ°›å›´çƒ˜æ‰˜ï¼Œæ›´æ˜¯ä¸‰åå¹´å‰é‚£åœºç”Ÿæ­»æ´ªæ°´çš„è±¡å¾ã€‚æ•…äº‹å¼€å¤´å’Œç»“å°¾çš„â€œé›¨â€ä¸â€œæŸ³è‰²â€å½¢æˆé—­ç¯ï¼Œæš—ç¤ºè¿™ä¸€åˆ‡éƒ½ç¬¼ç½©åœ¨å®¹å¨˜æ‰§å¿µæ‰€åŒ–çš„ã€æ°¸æ’å‡„è¿·çš„æ¢¦å¢ƒé‡Œã€‚\nâ€œå°é™¢æ·±é™ï¼Œæ¬²é—®å¿å¿ï¼Œä½•å¤„æœˆç¬¼æ˜ã€‚åƒç§‹å²å¥½ï¼Œä¼‘è´Ÿå…°å› â€ å«ä¹‰è§£è¯»\nè¿™å¥è¯æ˜¯å®¹å¨˜çš„ç‹¬ç™½ï¼Œä¹Ÿæ˜¯å¥¹å¯¹æ²ˆæ…•äº‘è·¨è¶Šç”Ÿæ­»çš„æƒ…è¯ã€‚ç»“åˆæ•…äº‹çœŸç›¸ï¼Œå…¶å«ä¹‰å±‚å±‚é€’è¿›ï¼š\nâ€œå°é™¢æ·±é™ï¼Œæ¬²é—®å¿å¿ï¼Œä½•å¤„æœˆç¬¼æ˜ã€‚â€\nå­—é¢æ„å¢ƒï¼šåº­é™¢å¹½æ·±å¯‚é™ï¼Œæˆ‘æƒ³é—®ä¸€é—®ä½ ï¼Œæ­¤åˆ»å“ªé‡Œçš„æœˆå…‰æ­£æ˜äº®åœ°ç¬¼ç½©ç€ï¼ˆä½ ï¼‰ï¼Ÿ æ•…äº‹æ·±æ„ï¼šè¿™æç»˜äº†å®¹å¨˜ä½œä¸ºé­‚é­„çš„å­¤ç‹¬å¤„å¢ƒã€‚â€œå°é™¢æ·±é™â€æ˜¯å¥¹ä¸‰åå¹´æ¥å¾˜å¾Šä¹‹åœ°çš„å¯‚å¯¥å†™ç…§ã€‚â€œæ¬²é—®å¿å¿â€æ˜¯æäº²æ˜µçš„å‘¼å”¤ï¼Œå¯¹è±¡æ˜¯æ—©å·²ä¸åœ¨äººä¸–çš„æ²ˆæ…•äº‘ã€‚â€œä½•å¤„æœˆç¬¼æ˜â€æ˜¯ä¸€ä¸ªè·¨è¶Šé˜´é˜³çš„å‘é—®ï¼šä½ çš„é­‚é­„ç°åœ¨ä½•å¤„ï¼Ÿæ˜¯å¦å®‰å¥½ï¼Ÿè¿™å¥å……æ»¡äº†æ— å¤„å¯„æ‰˜çš„ç‰µæŒ‚ä¸æ¸©æŸ”æ¢è¯¢ã€‚ â€œåƒç§‹å²å¥½ï¼Œä¼‘è´Ÿå…°å› ã€‚â€\nå­—é¢å…¸æ•…ï¼šâ€œåƒç§‹å²å¥½â€æ˜¯ç¥æ„¿å²æœˆé•¿ä¹…ç¾å¥½ï¼›â€œå…°å› â€å…¸å‡ºã€Šå·¦ä¼ ã€‹ï¼Œéƒ‘æ–‡å…¬å¦¾ç‡•å§æ¢¦è§å¤©ä½¿èµ å…°ï¼Œåç”Ÿä¸‹å…¬å­å…°ï¼Œæ¯”å–»åƒå…°èŠ±ä¸€æ ·ç¾å¥½çš„å‰å› ã€å‘½ä¸­æ³¨å®šçš„å§»ç¼˜ã€‚â€œå…°å› çµ®æœâ€åˆ™å¸¸æŒ‡å¼€ç«¯ç¾å¥½è€Œç»“å±€å‡„å‡‰ã€‚æ­¤å¤„â€œä¼‘è´Ÿå…°å› â€å³â€œä¸è¦è¾œè´Ÿäº†æˆ‘ä»¬ç¾å¥½çš„å¼€ç«¯â€ã€‚ æ•…äº‹æ·±æ„ï¼šè¿™æ˜¯æ•´é¦–è¯çš„æƒ…æ„Ÿæ ¸å¿ƒï¼Œä¹Ÿæ˜¯å®¹å¨˜çš„é‡Šç„¶ä¹‹è¯­ã€‚ åœ¨å¬åˆ°â€œæˆ‘â€çš„è°è¨€ä¹‹å‰ï¼Œè¿™æˆ–è®¸æ˜¯å¥¹å›ºæ‰§çš„æ„¿æœ›ï¼šå¸Œæœ›å¯¹æ–¹ä¸è¦è¾œè´Ÿå½“åˆçš„æƒ…ç¼˜ã€‚ ä½†åœ¨å¬åˆ°â€œä»–å¾ˆå¥½â€ä¹‹åï¼Œè¿™å¥è¯çš„å«ä¹‰å½»åº•æ”¹å˜ã€‚ å¥¹å°†â€œæˆ‘â€çš„è°è¨€ä¿¡ä»¥ä¸ºçœŸï¼šåŸæ¥ä»–åœ¨äººé—´æ‹¥æœ‰äº†â€œåƒç§‹å²å¥½â€çš„åœ†æ»¡äººç”Ÿã€‚äºæ˜¯ï¼Œâ€œä¼‘è´Ÿå…°å› â€ä»ä¸€å¥æ€¨æ€¼æˆ–æœŸç›¼ï¼Œå˜æˆäº†ä¸€å¥å®½æ•å’Œç¥ç¦ï¼šæ—¢ç„¶ä½ å·²æœ‰äº†ç¾å¥½çš„ä¸€ç”Ÿï¼Œé‚£æˆ‘ä¾¿ä¸å†æ‰§ç€ï¼Œä¸è®©ä½ æˆ‘å½“åˆç¾å¥½çš„å§»ç¼˜ï¼ˆå…°å› ï¼‰æˆä¸ºæŸç¼šä½ çš„è´Ÿç´¯ã€‚æˆ‘æ”¾è¿‡ä½ ï¼Œä¹Ÿæ”¾è¿‡æˆ‘è‡ªå·±ã€‚ æ•´ä½“å«ä¹‰ï¼šè¿™é˜™è¯æ˜¯å®¹å¨˜å¯¹æ²ˆæ…•äº‘çš„æœ€ç»ˆå‘Šåˆ«ã€‚å¥¹åœ¨ä¸€ä¸ªäººçš„â€œå°é™¢æ·±é™â€ä¸­å­¤ç‹¬æ€å¿µäº†ä¸‰åå¹´ï¼Œæœ€ç»ˆé€‰æ‹©ç›¸ä¿¡çˆ±äººå·²åœ¨äººé—´è·å¾—â€œåƒç§‹å²å¥½â€ï¼Œäºæ˜¯å¥¹å†³å®šâ€œä¼‘è´Ÿå…°å› â€â€”â€”æ”¾ä¸‹æ‰§å¿µï¼Œè§£è„±è¿™æ®µå› ç¼˜ï¼Œè®©å½¼æ­¤éƒ½è‡ªç”±ã€‚\nè¿™ä¸ªæ•…äº‹çš„ç²¾å¦™ä¹‹å¤„åœ¨äºï¼Œå®ƒç”¨ä¸€ä¸ªâ€œè°è¨€â€ï¼ˆå®¹å¨˜ç¼–çš„æ•…äº‹ï¼‰åŒ–è§£äº†å¦ä¸€ä¸ªâ€œè°è¨€â€ï¼ˆâ€œæˆ‘â€è¯´çš„å–„æ„çš„è°è¨€ï¼‰ï¼Œæœ€ç»ˆè¾¾æˆäº†æœ€æ·±å±‚çš„çœŸå®ï¼šçˆ±åˆ°æè‡´ï¼Œä¸æ˜¯å æœ‰ï¼Œè€Œæ˜¯å¸Œæœ›å¯¹æ–¹å¹¸ç¦ï¼Œå“ªæ€•è¿™å¹¸ç¦ä¸è‡ªå·±æ— å…³ï¼Œç”šè‡³éœ€è¦é ä¸€ä¸ªè™šæ„çš„æ•…äº‹æ¥æˆå…¨ã€‚ é‚£åœºä¸‰åå¹´çš„é›¨ï¼Œç»ˆäºåœäº†ã€‚\nQwen3-Max è¿™ä¸ªæ•…äº‹æ˜¯ä¸€åˆ™å……æ»¡å¤å…¸æ„è•´ä¸å¹½å¾®æƒ…æ„Ÿçš„å¿—æ€ªå¼çŸ­ç¯‡ï¼Œèåˆäº†ç°å®ä¸å¹»æ¢¦ã€è®°å¿†ä¸è™šæ„ã€æ‰§å¿µä¸é‡Šæ€€ã€‚å®ƒä»¥â€œä¸‰åå¹´ä¹‹çº¦â€ä¸ºå¼•ï¼Œå±‚å±‚å‰¥å¼€ä¸€æ®µè¢«æ—¶é—´æ©åŸ‹çš„çˆ±æƒ…å¾€äº‹ï¼Œæœ€ç»ˆæ­ç¤ºå‡ºï¼šæ‰€è°“â€œæ•…äº‹â€ï¼Œä¸è¿‡æ˜¯ç”Ÿè€…å¯¹é€è€…ã€å¯¹æœªç«Ÿä¹‹æƒ…çš„æ¸©æŸ”é‡æ„ã€‚\nä¸€ã€æ•…äº‹è§£è¯»ï¼šä¸€åœºç”±äº¡é­‚ç¼–ç»‡çš„æ¢¦ å™äº‹çš„åè½¬ä¸çœŸç›¸çš„æ­ç¤º\næ•…äº‹å¼€ç¯‡ä»¥â€œæˆ‘â€å¬é—»å…³äºæ²ˆæ…•äº‘çš„å¤šç§ä¼ é—»ä¸ºå¼•ï¼Œæœ€åŠ¨äººçš„æ˜¯â€œå®¹å¨˜ä¸èµŒçº¦â€çš„ç‰ˆæœ¬ã€‚è€äººæŒ‡å¼•â€œæˆ‘â€å»æ‰¾è°¢å¨˜ï¼Œçœ‹ä¼¼æ˜¯å¼•è·¯äººï¼Œå®åˆ™ä¸ºå¹»å¢ƒå¼€å¯çš„å¥‘æœºã€‚è€Œå½“â€œæˆ‘â€è§åˆ°è°¢å¨˜ï¼Œéšå¥¹è¿‡æ¡¥ã€é‡é£é›¨ã€è§å¹»è±¡ï¼Œæœ€ç»ˆæ‰æƒŠè§‰â€”â€”è°¢å¨˜å³å®¹å¨˜ï¼Œè€Œâ€œè°¢å¨˜â€åªæ˜¯å¥¹ä¸ºè®²è¿°æ•…äº‹è€Œè™šæ„çš„èº«ä»½ã€‚\nè¿™ä¸€åè½¬æå…·éœ‡æ’¼åŠ›ï¼šå®¹å¨˜æ—©å·²æººäº¡äºä¸‰åå¹´å‰çš„é‚£åœºé›¨ä¸­ï¼Œå¥¹çš„é­‚é­„æ»ç•™äººé—´ï¼Œåªä¸ºå®ˆå€™ä¸€ä¸ªä¸å¯èƒ½å…‘ç°çš„çº¦å®šã€‚å¥¹ç¼–é€ â€œæ‚”å©šâ€â€œèµŒçº¦â€â€œå©¢å¥³è°¢å¨˜â€ç­‰æƒ…èŠ‚ï¼Œå®åˆ™æ˜¯ä¸ºäº†èµ‹äºˆè¿™æ®µæ— æœä¹‹çˆ±ä¸€ä¸ªå¯è¢«ä¼ é¢‚çš„å½¢æ€â€”â€”å“ªæ€•æ˜¯ä»¥æ€¨æ¨ã€è¯¯è§£çš„æ–¹å¼ï¼Œä¹Ÿèƒœè¿‡å½»åº•è¢«é—å¿˜ã€‚\nâ€œæ¢¦â€çš„æœ¬è´¨ï¼šæ‰§å¿µä¸æ…ˆæ‚²çš„äº¤ç»‡\nå®¹å¨˜è¯´ï¼šâ€œå·¦å³æ˜¯åœ¨æ¢¦é‡Œï¼Œå®¹æˆ‘ä»»æ€§ä½¿åç¼–æ’ä»–ä¸€å›ã€‚â€\nè¿™å¥è¯é“å‡ºäº†å¥¹å…¨éƒ¨çš„æ¸©æŸ”ä¸å¿ƒé…¸ã€‚å¥¹æ˜çŸ¥æ²ˆæ…•äº‘æ—©é€ï¼Œå´ä»æ„¿åœ¨æ¢¦ä¸­ä¸ºä»–å®‰æ’ä¸€ä¸ªâ€œç™½å¤´å•è€â€çš„ç»“å±€ï¼›å¥¹è™šæ„è‡ªå·±è¢«è´Ÿå¿ƒï¼Œå®åˆ™æ˜¯ä¸æ„¿ä¸–äººçŸ¥é“ä»–è‹±å¹´æ—©é€ã€å¥¹æ®‰æƒ…è€Œäº¡çš„æ‚²å‰§ï¼Œæ›´ä¸æ„¿ä»–çš„åå£°å› â€œè´Ÿå¿ƒâ€è€Œå—æŸã€‚å¥¹çš„â€œç¼–æ’â€ï¼Œæ˜¯çˆ±çš„å¦ä¸€ç§å®ˆæŠ¤ã€‚\nâ€œæˆ‘â€çš„è§’è‰²ï¼šè®°å¿†çš„æ‰¿æ¥è€…\nâ€œæˆ‘â€ä½œä¸ºå¤–æ¥è€…ï¼Œæ—¢æ˜¯å¬ä¼—ï¼Œä¹Ÿæ˜¯è§è¯è€…ã€‚å½“â€œæˆ‘â€é€‰æ‹©éšç’æ²ˆæ…•äº‘æ—©é€çš„çœŸç›¸ï¼Œå‘Šè¯‰å¥¹â€œä»–å¾ˆå¥½ï¼Œç™½å¤´å•è€â€ï¼Œè¿™å¹¶éæ¬ºéª—ï¼Œè€Œæ˜¯ä¸€ç§å…±è°‹å¼çš„æ…ˆæ‚²â€”â€”æˆå…¨å¥¹æœ€åçš„å¹»æƒ³ï¼Œè®©å¥¹å¸¦ç€â€œä»–è¿‡å¾—å¾ˆå¥½â€çš„å®‰å¿ƒç¦»å»ã€‚è¿™æ­£å‘¼åº”äº†å®¹å¨˜è‡ªå·±çš„å–„æ„ï¼šå¥¹å®æ„¿è¢«è¯¯è§£ä¸ºè¢«å¼ƒä¹‹äººï¼Œä¹Ÿä¸æ„¿ä¸–äººçŸ¥é“ä»–æ—©å¤­ã€‚\næ„è±¡çš„è±¡å¾\næ²³æ¡¥ï¼šè¿æ¥ç°å®ä¸å¹»å¢ƒã€ç”Ÿä¸æ­»çš„è¾¹ç•Œã€‚ ç»†é›¨/æ´ªæµªï¼šæƒ…æ„Ÿçš„å¤–åŒ–ã€‚ç»†é›¨æ˜¯ç»µé•¿çš„æ€å¿µï¼Œæ´ªæµªæ˜¯è®°å¿†çˆ†å‘çš„ç¬é—´ã€‚ çº¢å¦†èŠ±è½¿ï¼šæœªå®Œæˆçš„å©šç¤¼ï¼Œæ°¸è¿œå®šæ ¼åœ¨å¹»è±¡ä¸­ã€‚ æŸ³è‰²å‡„è¿·ï¼šå¤å…¸è¯—è¯ä¸­å¸¸å–»ç¦»åˆ«ä¸å“€æ„ï¼Œæ­¤å¤„è±¡å¾æ—¶å…‰æµè½¬è€Œæƒ…æ„ä¸ç­ã€‚ äºŒã€è¯å¥è§£è¯»ï¼šâ€œå°é™¢æ·±é™ï¼Œæ¬²é—®å¿å¿ï¼Œä½•å¤„æœˆç¬¼æ˜ã€‚åƒç§‹å²å¥½ï¼Œä¼‘è´Ÿå…°å› ã€‚â€ è¿™å‡ å¥è¯è™½ä¸ºè™šæ„ï¼Œå´æ·±å¾—å®‹è¯å©‰çº¦ä¹‹ç¥é«“ï¼Œå¯è§†ä¸ºå®¹å¨˜å¿ƒå£°çš„å‡ç»ƒè¡¨è¾¾ã€‚\nâ€œå°é™¢æ·±é™ï¼Œæ¬²é—®å¿å¿ï¼Œä½•å¤„æœˆç¬¼æ˜â€\nå°é™¢æ·±é™ï¼šå›å¿†ä¸­ä¸¤äººåˆé‡æˆ–å®šæƒ…ä¹‹æ‰€ï¼Œå¹½æ·±å®é™ï¼Œå……æ»¡ç§å¯†æ¸©æƒ…ã€‚ æ¬²é—®å¿å¿ï¼šâ€œå¿å¿â€ä¸ºå¤æ—¶çˆ±ç§°ï¼Œæ­¤å¤„æ˜¯å®¹å¨˜å¯¹æ²ˆæ…•äº‘çš„æ·±æƒ…å‘¼å”¤ã€‚ ä½•å¤„æœˆç¬¼æ˜ï¼šåŒ–ç”¨æœç‰§â€œçƒŸç¬¼å¯’æ°´æœˆç¬¼æ²™â€ä¹‹æ„è±¡ã€‚â€œæœˆç¬¼æ˜â€æ—¢æŒ‡æœˆå…‰æœ¦èƒ§ï¼Œäº¦å–»æƒ…ç¼˜å¦‚æœˆï¼Œçœ‹ä¼¼æ˜äº®å´ä¸å¯è§¦åŠã€‚å¥¹åœ¨é—®ï¼šå½“å¹´å…±èµæ˜æœˆä¹‹äººï¼Œå¦‚ä»Šåœ¨ä½•æ–¹ï¼Ÿé‚£è½®è§è¯èª“è¨€çš„æœˆäº®ï¼Œæ˜¯å¦è¿˜è®°å¾—æˆ‘ä»¬çš„çº¦å®šï¼Ÿ æ­¤å¥æ•´ä½“è¥é€ å‡ºä¸€ç§è¿½å¿†å¾€æ˜”ã€å¯»è€Œä¸å¾—çš„æ€…æƒ˜ï¼Œæ˜¯å®¹å¨˜ä¸‰åä½™å¹´æ¥é­‚ç‰µæ¢¦è¦çš„å†™ç…§ã€‚\nâ€œåƒç§‹å²å¥½ï¼Œä¼‘è´Ÿå…°å› â€\nåƒç§‹å²ï¼šè¯ç‰Œåï¼Œäº¦æŒ‡æ¼«é•¿å²æœˆã€‚æ­¤å¤„åŒå…³ï¼Œæ—¢æŒ‡æ—¶é—´ä¹…è¿œï¼Œä¹Ÿæš—å«ç¥ç¦ã€‚ å…°å› ï¼šå…¸å‡ºã€Šå‘¨æ˜“Â·ç³»è¾ä¸Šã€‹â€œäºŒäººåŒå¿ƒï¼Œå…¶åˆ©æ–­é‡‘ï¼›åŒå¿ƒä¹‹è¨€ï¼Œå…¶è‡­å¦‚å…°ã€‚â€åä»¥â€œå…°å› â€å–»ç¾å¥½çš„å§»ç¼˜æˆ–åˆå¿ƒã€‚â€œå…°å› çµ®æœâ€åˆ™æŒ‡åˆæ—¶ç¾å¥½ã€ç»ˆæˆç¦»æ•£çš„å§»ç¼˜ã€‚ ä¼‘è´Ÿå…°å› ï¼šæ„ä¸ºâ€œä¸è¦è¾œè´Ÿå½“åˆé‚£å¦‚å…°èˆ¬èŠ¬èŠ³çš„èª“çº¦â€ã€‚ ç„¶è€Œï¼Œæ­¤å¤„çš„â€œä¼‘è´Ÿå…°å› â€å¹¶éè´£å¤‡ï¼Œè€Œæ˜¯ä¸´åˆ«å‰çš„æ¸©æŸ”å®å’›ã€‚å¥¹æ˜çŸ¥ä»–å·²ä¸åœ¨äººä¸–ï¼Œå´ä»ä»¥æ¢¦ä¸­ä¹‹è¯­ï¼Œå˜±ä»–â€œè«è´Ÿåˆå¿ƒâ€â€”â€”å®åˆ™æ˜¯å¯¹è‡ªå·±æ‰§å¿µçš„æ”¾ä¸‹ï¼šçºµä½¿ç»“å±€ä¸å¦‚æ„¿ï¼Œæˆ‘ä»¬æ›¾æœ‰çš„â€œå…°å› â€å·²æ˜¯è¶³å¤Ÿç¾å¥½ï¼Œä¸å¿…æ€¨ï¼Œä¸å¿…æ‚”ã€‚\nä¸‰ã€æ•´ä½“ä¸»æ—¨ï¼šçˆ±çš„æœ€é«˜å½¢å¼æ˜¯æˆå…¨ä¸é“­è®° è¿™ä¸ªæ•…äº‹å¹¶éç®€å•çš„â€œè´Ÿå¿ƒæ±‰ä¸ç—´æƒ…å¥³â€å¥—è·¯ï¼Œè€Œæ˜¯ä¸€æ›²å…³äºè®°å¿†ã€è™šæ„ä¸çˆ±çš„å°Šä¸¥çš„æŒ½æ­Œã€‚å®¹å¨˜ä»¥äº¡é­‚ä¹‹èº«ï¼Œç¼–ç»‡ä¸€ä¸ªâ€œè¢«è¾œè´Ÿâ€çš„æ•…äº‹ï¼Œåªä¸ºè®©è¿™æ®µæ„Ÿæƒ…ä¸è¢«æ—¶é—´æ¹®ç­ï¼›è€Œâ€œæˆ‘â€ä»¥å–„æ„çš„è°è¨€ï¼Œæˆå…¨å¥¹æœ€åçš„ä½“é¢ã€‚æ²ˆæ…•äº‘è™½æ—©é€ï¼Œå´å› å¥¹çš„å®ˆæŠ¤ï¼Œåœ¨ä¼ è¯´ä¸­â€œç™½å¤´å•è€â€â€”â€”è¿™ä½•å°ä¸æ˜¯å¦ä¸€ç§æ°¸æ’ï¼Ÿ\né‚£å¥è¯ï¼Œæ—¢æ˜¯å¥¹å¯¹å¾€æ˜”çš„å›æœ›ï¼Œä¹Ÿæ˜¯å¯¹æœªæ¥çš„ç¥ç¦ã€‚â€œåƒç§‹å²å¥½ï¼Œä¼‘è´Ÿå…°å› â€ï¼Œä¸åªæ˜¯å¯¹æ²ˆæ…•äº‘è¯´ï¼Œæ›´æ˜¯å¯¹æ‰€æœ‰å¬æ•…äº‹çš„äººè¯´ï¼š\nçºµä½¿ç¼˜æµ…ï¼Œè«å¿˜åˆå¿ƒï¼›çºµä½¿æˆç©ºï¼Œçˆ±å·²æ°¸æ’ã€‚\nè€Œé‚£åœºä¸‰åå¹´åçš„é›¨ï¼Œä¾æ—§å¦‚åˆé€¢æ—¶èˆ¬å‡„è¿·â€”â€”å› ä¸ºæœ‰äº›çˆ±ï¼Œä»æœªç¦»å¼€ã€‚\nLongCat ä¸€ã€æ•…äº‹æ ¸å¿ƒä¸»é¢˜ è®°å¿†ä¸æ‰§å¿µçš„è™šå®äº¤ç»‡\næ•…äº‹é€šè¿‡\u0026quot;è°¢å¨˜\u0026quot;çš„è°è¨€ï¼ˆå®ä¸ºå®¹å¨˜çš„é¬¼é­‚ï¼‰æ„å»ºäº†å¤šå±‚å™äº‹ï¼šè¡¨é¢æ˜¯æ²ˆæ…•äº‘è´Ÿå¿ƒçš„ä¼ è¯´ï¼Œå®åˆ™æ˜¯å®¹å¨˜å¯¹é€å»çš„çˆ±æƒ…ä¸æ‰§å¿µçš„æŠ•å°„ã€‚å¥¹å€Ÿ\u0026quot;èµŒçº¦\u0026quot;ä¹‹åï¼Œè®©æ•…äº‹æµä¼ åƒå¹´ï¼Œé¿å…è¢«ä¸–äººé—å¿˜ã€‚ \u0026ldquo;æˆ‘ä»¬çš„æ•…äº‹æ€»æœ‰äººè®°å¾—æ‰å¥½\u0026rdquo;â€”â€”å®¹å¨˜çš„æ ¸å¿ƒè¯‰æ±‚ï¼Œä½“ç°äº†äººç±»å¯¹æ°¸æ’è®°å¿†çš„è¿½æ±‚ï¼Œå³ä½¿ä»¥è°è¨€ä¸ºä»£ä»·ã€‚ ç”Ÿæ­»ä¸é—æ†¾çš„è±¡å¾\næš´é›¨ä¸­çš„å¹»è±¡ï¼ˆçº¢å¦†ã€èŠ±è½¿ã€æ´ªæµªï¼‰æ˜¯å®¹å¨˜è®°å¿†çš„æ˜¾å½±ï¼Œæš—ç¤ºå¥¹çš„\u0026quot;å©šå§»\u0026quot;è¢«æ´ªæ°´ï¼ˆå‘½è¿ï¼‰åå™¬ï¼Œå°‘å¹´éƒï¼ˆæ²ˆæ…•äº‘ï¼‰çš„ç¦»å»æ˜¯å¥¹æ— æ³•é‡Šæ€€çš„ç—›ã€‚ \u0026ldquo;åƒå¤©ä¸Šçš„æœˆäº®ï¼Œæä¸€æç»ˆä¸èƒ½å¾—\u0026rdquo;â€”â€”ä»¥æœˆäº®éšå–»ç†æƒ³åŒ–çš„çˆ±æƒ…ï¼Œè™½ä¸å¯å¾—ï¼Œä½†æ‰§å¿µå¦‚æœˆå…‰ç¬¼ç½©äººé—´ï¼Œå½¢æˆè¯—æ„åŒ–çš„é—æ†¾ã€‚ çœŸç›¸ä¸å–„æ„çš„è°è¨€\nå™è¿°è€…æœ€åé€‰æ‹©æ¬ºéª—å®¹å¨˜ï¼ˆè°ç§°æ²ˆæ…•äº‘å†å©šï¼‰ï¼Œå®Œæˆäº†å¯¹äº¡çµçš„æ•‘èµã€‚è¿™ä¸€ç»†èŠ‚æ­ç¤ºï¼šäººé—´å¯¹äº¡è€…çš„æ‚²æ‚¯ï¼Œæœ‰æ—¶åœ¨äºç¼–é€ åœ†æ»¡çš„ç»“å±€ã€‚ æ²ˆæ…•äº‘æ—©å’ã€å®¹å¨˜åŒ–é¬¼çš„æ‚²å‰§ï¼Œè¢«\u0026quot;åŠé—´æµä¼ çš„æ•…äº‹\u0026quot;èµ‹äºˆä¸åŒç‰ˆæœ¬ï¼Œè¯´æ˜é›†ä½“è®°å¿†å¯¹å†å²çš„å†åˆ›é€ ã€‚ äºŒã€è¯—å¥é€å±‚è§£æ \u0026ldquo;å°é™¢æ·±é™ï¼Œæ¬²é—®å¿å¿ï¼Œä½•å¤„æœˆç¬¼æ˜\u0026rdquo;\nè¡¨å±‚ï¼šå¯‚é™å°é™¢ä¸­ï¼Œçˆ±äººï¼ˆå¿å¿ï¼‰çš„èº«å½±ä¸æœˆè‰²äº¤å ï¼Œå´å› è–„é›¾éš¾å¯»å…¶è¸ªè¿¹ã€‚ æ·±å±‚ï¼š\u0026ldquo;æœˆç¬¼æ˜\u0026quot;è±¡å¾è®°å¿†çš„æœ¦èƒ§æ€§â€”â€”å®¹å¨˜å¯¹æ²ˆæ…•äº‘çš„æ€å¿µä¼¼æœˆå…‰æ˜åªšï¼Œå´ä¹Ÿå¦‚é›¾æ°”èˆ¬æ¨¡ç³Šéš¾è§¦ã€‚ **\u0026ldquo;æ¬²é—®\u0026rdquo;**çš„æœªå®Œæˆæ—¶æ€ï¼Œå¼ºåŒ–äº†é˜´é˜³ä¸¤éš”çš„æ— å¥ˆã€‚ \u0026ldquo;åƒç§‹å²å¥½ï¼Œä¼‘è´Ÿå…°å› \u0026rdquo;\nå…¸æ•…ï¼š\u0026ldquo;å…°å› \u0026quot;å‡ºè‡ªã€Šå·¦ä¼ ã€‹\u0026ldquo;å½’å¦»èŒ¹å§¬ï¼Œè¨€å…°ä¹‹å› \u0026rdquo;ï¼Œå–»ç¾æ»¡å§»ç¼˜ã€‚ ç›´è¯‘ï¼šæ„¿ä½ ä»¬åƒå¹´ä¸‡ä»£å¹¸ç¦ï¼Œè«è¾œè´Ÿå¤©èµçš„ç¼˜åˆ†ã€‚ éšå«çŸ›ç›¾ï¼š å®¹å¨˜åœ¨è¯—å¥ä¸­ä½œä¸º\u0026quot;æ—è§‚è€…\u0026quot;ç¥ç¦æ²ˆæ…•äº‘ï¼Œå®ä¸ºè‡ªæˆ‘å‚¬çœ å¼çš„å®‰æ…°ï¼› \u0026ldquo;ä¼‘è´Ÿ\u0026quot;äºŒå­—æš´éœ²äº†å¥¹çš„è„†å¼±ï¼šæ—¢ç„¶æ²ˆæ…•äº‘æ—©é€æœªå¨¶ï¼Œ\u0026ldquo;å…°å› \u0026quot;æ—©å·²æˆç©ºï¼Œä½†é¬¼é­‚ä»åœ¨å›ºæ‰§åœ°ç»´æŠ¤çˆ±æƒ…çš„\u0026quot;å°Šä¸¥\u0026rdquo;ã€‚ è¶…è„±æ€§ï¼šå®¹å¨˜æœ€ç»ˆæ¥çº³äº†æ‚²å‰§ï¼Œä»¥è¯—æ„æ¶ˆè§£æ‰§å¿µï¼Œèº«å½±æ¶ˆæ•£çš„ç¬é—´å®Œæˆç²¾ç¥è§£è„±ã€‚ ä¸‰ã€è¯—å¥ä¸æ•…äº‹çš„äº’æ–‡æ€§ è®°å¿†çš„ç¾åŒ–ä¸é‡æ„\nè¯—å¥ä¸­çš„\u0026quot;å°é™¢æ·±é™\u0026quot;ä¸\u0026quot;æœˆç¬¼æ˜\u0026rdquo;ï¼Œå¯¹åº”å®¹å¨˜è™šæ„çš„\u0026quot;æ²³æ¡¥èµŒçº¦\u0026rdquo;ï¼ŒäºŒè€…çš†å°†ç—›è‹¦è®°å¿†å‡åä¸ºå”¯ç¾æ„è±¡ï¼Œä½“ç°æƒ…æ„Ÿå¯¹äº‹å®çš„æ”¹é€ ã€‚ å¯¹\u0026quot;æ—¶é—´\u0026quot;çš„è¶…è¶Š\n\u0026ldquo;åƒç§‹å²å¥½\u0026quot;æ—¢æ˜¯å¯¹æ²ˆæ…•äº‘çš„ç¥ç¦ï¼Œä¹Ÿæ˜¯å¯¹è‡ªèº«å­˜åœ¨çš„è¯˜é—®ï¼šå¥¹ä»¥é¬¼é­‚ä¹‹å§¿å¾˜å¾Šä¸‰åå¹´ï¼Œæœ€ç»ˆç”¨è¯—å¥æŠ¹å¹³æ—¶é—´åˆ»åº¦ï¼Œä¸è¿‡å»å’Œè§£ã€‚ ä¸œæ–¹æ‚²å‰§ç¾å­¦çš„å…¸èŒƒ\nå…¨è¯—æ— æ¿€çƒˆæ§è¯‰ï¼Œå´ä»¥\u0026quot;é›¾ä¸­é—®æœˆ\u0026quot;\u0026ldquo;æœˆä¸‹ç¥è¯­\u0026quot;çš„å«è“„æ–¹å¼ï¼Œå®Œæˆå¯¹å‘½è¿æ— å¸¸çš„æ‚²æ‚¯ï¼Œå¥‘åˆä¼ ç»Ÿæ–‡å­¦ä¸­\u0026quot;å“€è€Œä¸ä¼¤\u0026quot;çš„ç¾å­¦æ ‡å‡†ã€‚ å››ã€ç»“è¯­ï¼šæœªå®Œæˆçš„è¯—æ€§æ­£ä¹‰ æ•…äº‹é€šè¿‡è°è¨€ã€é¬¼é­‚ã€è¯—æ­Œä¸‰é‡åª’ä»‹ï¼Œå®ç°äº†å¦ä¸€ç§\u0026quot;æ­£ä¹‰\u0026rdquo;ï¼šå®¹å¨˜è™½æœªèƒ½æ”¹å†™å†å²ï¼Œå´ä»¥ç¾å­¦æ–¹å¼å®Œæˆäº†å¯¹æ®‹ç¼ºçˆ±æƒ…çš„ç¥åœ£åŒ–ã€‚è€Œè¯—å¥\u0026quot;ä¼‘è´Ÿå…°å› \u0026quot;çš„çŸ›ç›¾æ€§ï¼Œæ­£æ˜¯ä¸œæ–¹æ–‡åŒ–ä¸­\u0026quot;æ‰§å¿µä¸é‡Šæ€€\u0026quot;äºŒå…ƒç‰¹è´¨çš„ç²¾å¦™æ³¨è„šã€‚\nå®éªŒè®¾å®š ä½œè€…ï¼šå†‰è¯­ä¼˜\nPromptï¼š\næˆ‘å¬è¿‡è®¸å¤šå…³äºæ²ˆæ…•äº‘çš„æ•…äº‹ï¼Œåªæœ‰è¿™é‡Œçš„ä¸ä¼—ä¸åŒã€‚æœ‰è¯´ä»–ä¸Šäº¬èµ´è€ƒï¼Œåæ¥å¦è˜äº†é˜è€å®¶çš„è´µå¥³ï¼Œä¹Ÿæœ‰è¯´ä»–æ—©çŸ¥å¾—äº†ä¸å¯¿ä¹‹ç—‡ï¼Œä¸æƒ³æ•™è°å®ˆå¯¡ç½¢äº†ã€‚åªæœ‰è¿™åŸé‡Œçš„è€äººå‘Šè¯‰æˆ‘ï¼Œæ²ˆæ…•äº‘åˆæ‹çš„å°‘å¥³å«åšå®¹å¨˜ï¼Œå®¶å°±ä½åœ¨æ²³æ¡¥å¯¹å²¸ã€‚ä¸¤äººå·²å®šäº†å©šçº¦ï¼Œä»–èµ´è€ƒé«˜ä¸­ï¼Œåˆ°äº†é‚£æ—¶å´çªç„¶åæ‚”ï¼Œå¯¹å®¹å¨˜é¿ä¹‹ä¸è§ã€‚â€œåæ¥å®¹å¨˜ä¼¤å¿ƒï¼Œä»æ­¤å†ä¸è§äººã€‚ä½†æ­¤åœ°äººäººéƒ½çŸ¥é“ä¸¤äººé—´çš„èµŒçº¦ï¼šä¸‰åå¹´åï¼Œæ•…äººæ•…åœ°ï¼Œä»–æ•¢ä¸æ•¢å†æ¥ç›¸è§ï¼Ÿâ€è€äººæœ›äº†æœ›æˆ‘ï¼Œæ¥ç€è¯´ï¼šâ€œä½ æ¥å¾—å·§ã€‚ä»Šæ—¥ä¾¿æ˜¯ä¸‰åå¹´æ•´çº¦å®šä¹‹æ—¥ã€‚åŸä½ç€å½“å¹´é¢„å¤‡ä¾å€™å¥¹æˆäº²çš„å©¢å¥³ï¼Œå«åšè°¢å¨˜ï¼Œä½ æ—¢æ¥äº†ï¼Œå¯ä»¥æ±‚å¥¹é¢†ä½ å»çœ‹ã€‚â€_\næˆ‘è°¢è¿‡ä»–ï¼Œæ‰å¤´èµ°äº†ã€‚\nâ€œæ— è®ºå¤šå°‘å¹´ï¼Œéƒ½æ˜¯ä¸€æ ·çš„ç»“æœã€‚â€\nä¸Šæ¡¥çš„æ—¶å€™ï¼Œæˆ‘å¬ä»–è¿™æ ·è¯´ã€‚\næˆ‘è§åˆ°äº†è°¢å¨˜ã€‚æ­¤åœ°çš„ç»†é›¨ç»µç»µæ— æœŸï¼Œå¥½ä¼¼æŠŠæ¯ä¸€ä¸ªäººçš„é¢ç›®éƒ½ç¬¼åœ¨å¾®æ¹¿çš„æ˜¥é›¾é‡Œï¼Œçœ‹ä¸çœŸåˆ‡ï¼Œå¯æˆ‘éšçº¦æ„Ÿåˆ°å·²ä¸Šäº†å¹´çºªçš„è°¢å¨˜æ˜¯ç¾çš„ã€‚å¥¹å½“å¹´ä¾å€™è¿‡çš„å¥³ä¸»äººâ€”â€”å®¹å¨˜ä¸€å®šæ›´ç¾å§ï¼Ÿ\næˆ‘å‘å¥¹é“æ˜æ¥æ„ã€‚\nâ€œå•Šï¼Œå¥¹å’Œæ²ˆæ…•äº‘çš„äº‹å„¿å‘€â€¦â€¦æˆ‘ä¸èƒ½å‘Šè¯‰ä½ â€ï¼Œå¥¹ç¬‘äº†ç¬‘ï¼Œâ€œä½†æ˜¯æˆ‘èƒ½å¸¦ä½ å»çœ‹ã€‚â€\nå¥¹è¯´å®Œï¼Œä¸æ›¾æºä¼ï¼Œè¿ç€å±‹å¤–é›¨é›¾æå¿«åœ°èµ°äº†å‡ºå»ã€‚æˆ‘è·Ÿäº†å‡ºå»ã€‚ä¸çŸ¥æ€ä¹ˆåœ°ï¼Œè·Ÿåœ¨å¥¹èº«è¾¹ï¼Œæˆ‘ç«Ÿä¹Ÿèƒ½èµ°å¾—æå¿«\nè½¬çœ¼é—´ï¼Œæˆ‘ä»¬èµ°è¿‡äº†æ¥æ—¶é‚£åº§æ²³æ¡¥ï¼Œå¿½ç„¶ï¼Œæ¡¥ä¸‹æ²³æ°´å·¨æ¶¨ï¼Œç»†é›¨å˜ä½œæ»”å¤©é›¨æµªè¿é¢æ‹æ¥ï¼Œä¸€æµªæµªæ‰“ä¸¤è¾¹æ æ†ã€‚\nçº¢å¦†ã€èŠ±è½¿ã€æ´ªæµªï¼Œå¹»å¹•èˆ¬åœ¨æˆ‘çœ¼å‰ä¸€é€è€Œè¿‡ï¼Œæˆ‘å‹‰åŠ›é—­çœ¼ï¼Œä¸‹æ„è¯†é€ƒé¿å‘¨é­çš„é£æµªï¼Œå†ççœ¼æ—¶ä»æ˜¯å°é›¨è’™æ¿ ï¼Œå·²ç„¶é£å¹³æµªé™ã€‚\nåªæœ‰è°¢å¨˜ç«™åœ¨é›¨å¹•é‡Œï¼Œç¥æƒ…å“€ä¼¤ï¼šâ€œé‚£ä¸€å¹´ï¼Œä¹Ÿæ˜¯åœ¨è¿™é‡Œï¼Œä¹Ÿæ˜¯è¿™æ ·çš„å¤©æ°”ï¼Œæˆ‘åœ¨è¿™é‡Œè·Œä¸‹äº†æ°´ï¼Œå†æ²¡è§åˆ°è‡ªå·±çš„å°‘å¹´éƒã€‚â€\næˆ‘å¿ƒå¤´ä¸€éœ‡ï¼Œè¿™æ‰å‘è§‰å¥¹èº«å½¢è™šæµ®ï¼Œå¦‚ä¸´æ°´ä¸Šï¼Œå®›ç„¶ä¸ä¼¼èº«åœ¨äººä¸–ã€‚â€œä½ æ˜¯å®¹å¨˜ï¼Ÿï¼â€æˆ‘é—®ã€‚\nå¥¹æ¢å¤äº†ä¸€ç‚¹å°‘å¥³çš„ç¬‘å®¹ï¼šâ€œè°¢å¨˜å‘€ï¼Œæ‚”å©šå‘€ï¼Œè¿˜æœ‰èµŒçº¦ï¼Œéƒ½æ˜¯æˆ‘ç¼–çš„ã€‚â€\nâ€œä½ ä¸ºä»€ä¹ˆâ€¦â€¦â€\nâ€œæ—çš„äººæ€¨ä»–ä¹Ÿå¥½ï¼Œç¬‘æˆ‘ä¹Ÿç½¢ï¼Œæˆ‘ä»¬çš„æ•…äº‹æ€»æœ‰äººè®°å¾—æ‰å¥½ã€‚å°±åƒå¤©ä¸Šçš„æœˆäº®ï¼Œå› ç¼˜æ³¨å®šï¼Œæä¸€æç»ˆä¸èƒ½å¾—ï¼Œä½†å®å¯éš¾å¹³ï¼Œä¹Ÿä¸æ„¿æ”¾æ‰‹â€ï¼Œå¥¹å›è¿‡å¤´æ¥ï¼Œéœ²å‡ºé‚£æ ·å¤©çœŸçš„ç¬‘ï¼šâ€œå·¦å³æ˜¯åœ¨æ¢¦é‡Œï¼Œå®¹æˆ‘ä»»æ€§ä½¿åç¼–æ’ä»–ä¸€å›ï¼Œä»–ä¸ä¼šä»‹æ„çš„å§ã€‚â€\næˆ‘åŠ¨å®¹ï¼Œä¸€æ—¶æ— è¨€ã€‚\nâ€œä»–å‘¢ï¼Œä»–åœ¨äººé—´æ€ä¹ˆæ ·ï¼Ÿè¿˜å¥½å—ï¼Ÿâ€\næ²ˆæ…•äº‘ï¼Œå­—è–„å›ï¼Œå¤©æ‰ç»äººï¼Œå¹´äºŒåä¸ƒæ—©å’äºä¸–ã€‚\nâ€œä»–å¾ˆå¥½â€ï¼Œæƒ³äº†æƒ³ï¼Œæˆ‘è¿™æ ·å‘Šè¯‰å¥¹ï¼Œâ€œåæ¥åˆå¨¶äº†æ–°å¦‡ï¼Œç™½å¤´å•è€ã€‚â€\nå¥¹å¿½åœ°èå°”ï¼Œâ€œè¿™æ ·å•Šâ€¦â€¦é‚£çœŸæ˜¯å¾ˆå¥½å¾ˆå¥½ï¼Œå†å¥½ä¸è¿‡çš„äº‹äº†ã€‚â€\næˆ‘çœ‹å¥¹éœ²å‡ºæ¶©ç„¶çš„ç¬‘ï¼Œå–ƒå–ƒå¿µç€ä»€ä¹ˆï¼Œèº«å½±ä¸€ç‚¹ç‚¹åœ°å˜æ·¡æ¶ˆæ•£ã€‚æˆ‘å¬æ¸…äº†é‚£ä¸€å¥è¯ï¼šâ€œå°é™¢æ·±é™ï¼Œæ¬²é—®å¿å¿ï¼Œä½•å¤„æœˆç¬¼æ˜ã€‚åƒç§‹å²å¥½ï¼Œä¼‘è´Ÿå…°å› ã€‚â€\næ—¶é›¨éœéœï¼Œä¸‰åå¹´åçš„æ­¤åœ°ç¬¼ç½©ç€ä¸‰åå¹´å‰ä¸€æ ·å‡„è¿·çš„æŸ³è‰²ï¼Œä»¿ä½›ä»–ä»¬çš„åˆé€¢ï¼Œç‚¹æ»´ç‰‡åˆ»ï¼Œå´æœ›å°½æ•´åº§äººé—´\nè§£è¯»è¿™ä¸ªæ•…äº‹ï¼Œå¹¶ç»“åˆæ•…äº‹è§£è¯»\u0026quot;å°é™¢æ·±é™,æ¬²é—®å¿å¿,ä½•å¤„æœˆç¬¼æ˜ã€‚åƒç§‹å²å¥½,ä¼‘è´Ÿå…°å› \u0026quot;çš„å«ä¹‰ã€‚\n","date":"3 October, 2025","id":0,"permalink":"/chinese-post/chichi-story/","summary":"å®éªŒè®¾å®šæ”¾åœ¨æœ€åã€‚","tags":"","title":"AIæ€ä¹ˆè§£è¯»é“¶ä¸´ã€Šè¿Ÿè¿Ÿã€‹çš„èƒŒæ™¯æ•…äº‹ï¼Ÿ"},{"content":"TL;DR: I created Raddy, a forward autodiff library, and Symars, a symbolic codegen library.\nIf you\u0026rsquo;re interested, please give them a star and try them out! â¤ï¸\nThe Origin of the Story I recently read papers on physical simulation and wanted to reproduce them. I started with Stable Neo-Hookean Flesh Simulation, though the choice isn\u0026rsquo;t critical. Many modern physical simulations are implicit, requiring Newton\u0026rsquo;s method to solve optimization problems.\nThis involves:\nComputing derivatives of the constitutive energy model (first-order gradient, second-order Hessian). Assembling a large, sparse Hessian from small, dense Hessian submatrices â€” a delicate task prone to hard-to-debug bugs. From Dynamic Deformables, I learned deriving these formulas is labor-intensive (even understanding the notation takes time). Searching for alternatives to avoid meticulous debugging, I found two solutions:\nSymbolic differentiation with code generation. Automatic differentiation. Tools for the former include MATLAB or SymPy; for the latter, deep learning libraries like PyTorch or more suitable ones like TinyAD.\nWhy TinyAD? Deep learning libraries differentiate at the tensor level, but I needed scalar-level differentiation for physical simulations. Tensor-level differentiation could lead to unplayable frame rates.\nA problem arose: these tools are in the C++ toolchain, and I\u0026rsquo;m not proficient in C++ (I know some kindergarten-level C++, but CMake and libraries like Eigen defeated me after three days of trying). So, I switched to Rust, a language I\u0026rsquo;m more comfortable with. This was the start of all troublesâ€¦\nA Path That Seems Simple Rust lacks an automatic differentiation library for second-order Hessians (at least on crates.io). SymPy can generate Rust code, but it\u0026rsquo;s buggy. Given the implementation complexity, I started with symbolic code generation, creating Symars.\nSymPy\u0026rsquo;s symbolic expressions are tree-structured, with nodes as operators (Add, Mul, Div, Sin, etc.) or constants/symbols, and children as operands. Code generation involves depth-first traversal: compute child expressions, then the current node\u0026rsquo;s expression based on its type. Base cases are constants or symbols.\nI used the generated derivatives for a simple implicit spring-mass system, but debugging index errors in Hessian assembly was time-consuming.\nTrying the Untrodden Path Again To address this, I revisited automatic differentiation, aiming to adapt TinyAD for Rust.\nTwo Ways to Walk the Same Path Initially, I considered two approaches:\nWrite FFI bindings, as I don\u0026rsquo;t know C++ well. Replicate TinyAD\u0026rsquo;s logic. Cloning TinyAD, I couldn\u0026rsquo;t even pull dependencies or compile it. Examining the codebase, I found the core logic was ~1000 lines â€” manageable to replicate without running the project. Thus, Raddy was born.\nSymbolic diff \u0026amp; Codegen: Implementation Implementation details:\nEach scalar in the differentiation chain carries a gradient and Hessian, increasing memory overhead. I avoided implementing the Copy trait, requiring explicit cloning. Operator traits between (\u0026amp;)Type and (\u0026amp;)Type (four combinations) required repetitive code. I considered the following options: Macros. Python scripts for code generation. Macros breaks rust-analyzer (somebody refuse to agree on this, but for me this is true) and I am rather unfamiliar with Rust\u0026rsquo;s macro syntax, so I used Python scripts (in the meta/ directory) for simple string concatenation.\nTesting: I verified derivatives by generating symbolic grad and hessian code with Symars, cross-validating against Raddy\u0026rsquo;s results, ensuring test expressions covered all implemented methods. Symars performed reliably, without bugs. What about sparse matrices Dense matrices store adjacent values contiguously, but sparse matrices (with millions of elements) don\u0026rsquo;t. I implemented sparse Hessian assembly:\nDefine a problem via the Objective\u0026lt;N\u0026gt; trait: Specify problem size N (a compile-time constant for const generics). Implement computation logic, e.g., a spring-mass system (Hooke\u0026rsquo;s law, E=1/2 k xÂ²): impl Objective\u0026lt;4\u0026gt; for SpringEnergy { type EvalArgs = f64; // restlength fn eval(\u0026amp;self, variables: \u0026amp;advec\u0026lt;4, 4\u0026gt;, restlen: \u0026amp;Self::EvalArgs) -\u0026gt; Ad\u0026lt;4\u0026gt; { // extract node positions from problem input: let p1 = advec::\u0026lt;4, 2\u0026gt;::new(variables[0].clone(), variables[1].clone()); let p2 = advec::\u0026lt;4, 2\u0026gt;::new(variables[2].clone(), variables[3].clone()); let len = (p2 - p1).norm(); let e = make::val(0.5 * self.k) * (len - make::val(*restlen)).powi(2); e } } Specify input components\u0026rsquo; indices (\u0026amp;[[usize; N]]). Automatically assemble sparse grad and hess (handling index mapping). Manually sum multiple grad and hess (simple matrix addition; triplet matrices are concatenated). Before tests, Raddy was 2.2k lines; after, it ballooned to 18k lines, showing LOC is a poor metric.\nFinally, I wrote a demo for fun and as an example.\nConclusion Gains:\nLearned how automatic differentiation works. First time using AI for documentation (it struggled with Rust syntax, producing test code with errors). Happiness! ","date":"2 October, 2025","id":1,"permalink":"/english-post/raddy/","summary":"TL;DR: I created Raddy, a forward autodiff library, and Symars, a symbolic codegen library.","tags":"rust graphics math","title":"Raddy devlog: forward autodiff system"},{"content":"From the perspective of a newbie user\nThe Documentation is a Disaster Recently, I had to optimize a custom operator and decided to use OpenAI\u0026rsquo;s Triton. After digging into the documentation, I was shocked at how poorly written it is â€” like an academic paper full of equations but lacking practical code examples.\nIf the library operates on tensors, the docs should clearly specify input/output shapes and provide concrete examples (like PyTorch does). Instead, everything is vaguely described in plain text, leaving users to guess the details.\nHow Triton Fails at Clarity Take the tl.load documentation as an example. It mentions that block pointers support \u0026ldquo;boundary checks\u0026rdquo; and \u0026ldquo;padding options,\u0026rdquo; but:\nWhat does \u0026ldquo;boundary check\u0026rdquo; actually do? Does it skip out-of-bounds elements, returning a smaller tensor? Does it pad with a default value? Does it throw an error? The docs don\u0026rsquo;t say. What\u0026rsquo;s the \u0026ldquo;padding option\u0026rdquo;? After some trial and error, I realized it handles out-of-bounds elements â€” but this should be explicitly stated, not left for users to reverse-engineer.\nAnother issue: tl.make_block_ptr and tl.arange require block shapes and element counts to be powers of two. This restriction isn\u0026rsquo;t mentioned anywhere in the official docs. I only discovered it after hitting an error and finding a passing reference in an unofficial blog post.\nWhoever wrote this documentation did a huge disservice to the engineers who built Triton\u0026rsquo;s compiler. Triton\u0026rsquo;s compiler is awesome.\nKey API Clarifications tl.load For raw pointers (or tensors of pointers): Always set mask and other. mask=True: Load from HBM. mask=False: Use the value from other (a float). For block pointers (tl.make_block_ptr): Enable boundary checks on all dimensions and set padding=\u0026quot;zero\u0026quot;. The behavior of boundary_check is poorly defined, especially after reordering dimensions. Shape Constraints tl.arange element counts and tl.make_block_ptr block shapes must be powers of two. This might apply to all Triton tensor dimensions, but I haven\u0026rsquo;t verified it.\nMemory Access Pitfalls tl.load and tl.store silently corrupt data. Invalid memory access turns values into NaNâ€”yes, even tl.store can corrupt valid data! Solution: Unless your dimensions are multiples of 64, always enable boundary checks for HBM reads/writes. Extra caution: Raw pointers require careful mask handling to avoid disasters. ","date":"2 October, 2025","id":2,"permalink":"/english-post/triton-pitfalls/","summary":"From the perspective of a newbie user","tags":"deep-learning python triton","title":"Triton Common Pitfalls"},{"content":"Intro: A taste of the Rust programming language\nRecently, I tried to get started with Rust and wanted to write some code.\nMost people\u0026rsquo;s first application is probably some kind of backend service (converting HTTP requests from the frontend into CRUD operations on a database and returning the results to the frontend).\nHowever, I\u0026rsquo;ve never learned how to write backend services (I\u0026rsquo;ve been wanting to learn recently â€” if anyone has good zero-to-hero beginner resources, feel free to recommend them). So, I ended up picking up the two papers I\u0026rsquo;ve been studying lately (@Li2020IPC, @abd) to try reproducing them.\nNote: This post only reproduces/discusses the IPC family of algorithms and does not address any performance optimizations, whether the algorithm is efficient, or why not to use some other algorithm.\nProject repo: Github\nImplicit Euler Physical simulation is essentially a numerical integration process.\nExplicit integration tends to explode, but implicit integration suffers from a \u0026ldquo;chicken-and-egg\u0026rdquo; problem (calculating the position at the next timestep requires knowing the velocity at the next timestep), making it impossible to solve explicitly. Instead, it requires solving a (possibly non-convex) optimization problem.\nWhat can be implicitly integrated? A mass-spring system can. But honestly, I\u0026rsquo;ve never written an optimization-based implicit integrator before, so I decided to start by implementing a mass-spring system.\nWhat Is It? Incremental Potential (IP) is a function of the degrees of freedom (DOF) of a scene at time t, IP(t).\nImplicit Euler constructs an then minimizes the IP (x(t+\\Delta t) = \\argmin_x E_{\\text{IP}}(x(t))) to obtain the position at t+\\Delta t.\nDeep learning typically uses gradient descent (and its variants), but in graphics, empirical evidence suggests gradient descent performs poorly. So, we opt for Newton\u0026rsquo;s method.\nImplementation Newton\u0026rsquo;s method is faster, but it introduces a problem: assembling the Hessian matrix. Fortunately, each component of the incremental potential is mostly a function of (k \\cdot n DOFs), where n is the dimensionality (I implemented 2D), and k is a small number (at most a few dozen). Thus, for each small IP contributing to the larger IP, the Hessian has only tens to hundreds of entries, which can be stored sparsely and assembled into the full Hessian. Following this tutorial, I implemented springs with vertices pinned to a wall.\nChoosing libraries: Used macroquad for GUI. Used nalgebra_glm for small-scale linear algebra. Initially planned to use nalgebra for large-scale linear algebra, but its sparse matrix functionality seemed incomplete, so I switched to faer. Initially used argmin for optimization. A Small Detour Before Contact IP Rust takes forever to compile, so configuring geometry shapes shouldn\u0026rsquo;t be hardcoded.\nAt first, I invented a weird file format and wrote a config based on my own logic:\n!k 1000.0 !node 0.0 0.0 0.2 0.0 0.4 0.0 0.6 0.0 0.1 0.2 0.3 0.2 Then I asked an AI to write a parser for me.\nLater, I realized that existing formats like JSON or TOML already have parsers, but by then, I was too lazy to change it.\nContact IP In short, Contact IP:\nRequires that point-edge pairs (aka primitive pairs) from two different bodies, which are close enough (within a threshold \\hat{d}), are assigned energy based on their distance. But to prevent interpenetration, there are additional requirements:\nOptimization courses teach that (damped) Newton\u0026rsquo;s method iteratively approaches the optimum. Each iteration involves a line search, and to prevent interpenetration, every intermediate step of the line search must ensure no primitive pairs penetrate, ultimately guaranteeing no interpenetration in the final result. Procedure At each line search step in Newton\u0026rsquo;s method:\nTraverse all primitive pairs (or use some acceleration structure â€” I didn\u0026rsquo;t implement this) and identify those with distances below the threshold. Compute the energy, gradient, and Hessian of the Contact IP for each primitive pair\u0026rsquo;s DOFs, then solve d = -A^{-1}g to get the search direction. Perform a CCD (Continuous Collision Detection) operation to ensure the line search doesn\u0026rsquo;t cause interpenetration (by setting a maximum step length). Use the Armijo condition for the line search. Repeat until sufficiently close to the minimum, at which point optimization is complete.\nImplementation Every step involved endless debuggingâ€¦\nGradient \u0026amp; Hessian:\nIn 2D, each primitive pair\u0026rsquo;s DOFs are (2 DOFs per point) Ã— (3 points) = 6 DOFs. The gradient of energy E w.r.t. DOFs can still be computed manually (a 6D vector). But the Hessian is a 6Ã—6 matrix, and the paper\u0026rsquo;s notation is a messâ€”sometimes dyadic product, sometimes Kronecker product, with no clear labeling in the text. Manual computation failed. So, I used SymPy for symbolic computation and generated code from it. The differentiation code can be found in the symbolic/ folder. SymPy actually has Rust codegen, but it\u0026rsquo;s half-baked â€” often producing invalid Rust syntax, requiring string replacements, and only supporting single expressions (no vectors/matrices). Note: Later, I built my own SymPyâ†’Rust code generator:\nSymars: Generate Rust code from SymPy expressions\nRemember: Point-to-segment distance requires case-by-case handling. CCD (ACCD) needs to be integrated into the optimization process, so argmin wasn\u0026rsquo;t suitable anymore. I discarded it and handwrote a damped Newton solver with ACCD and Armijo condition. After days of coding and debugging, the demo finally worked:\nThe constraints here are springs. ABD TL;DR, ABD Replaces traditional 6-DOF (translation + rotation) rigid bodies with 12-DOF bodies and heavily penalizes transformation matrices that deviate too far from rotation matrices, resulting in a (near-)rigid body simulation algorithm.\nIn 2D, an affine body (AB) has 6 DOFs: x = A x_0 + b, where the shape is defined by A (2Ã—2) and b (2Ã—1), assembled into a DOF vector: q = [flatten(A), b^T].\nWe know rotation matrices R satisfy R^T R = I. ABD uses an orthogonal potential energy \\kappa \\cdot \\text{frobnorm}(A^T A - I) to penalize A and keep it close to a rotation matrix.\nImplementation Any energy term requires second derivatives. Again, I used SymPy for differentiation. The project has thousands of lines of numerical computation code â€” don\u0026rsquo;t look at them. Affine bodies also need contact handling: Unlike mass-spring systems where each vertex is a DOF, an AB\u0026rsquo;s vertex position p is a function of DOFs, and the Contact IP is a function of p. A primitive pair involves two bodies, where one contributes an edge (two points p_1, p_2). Thus, derivatives must be taken w.r.t. both q s. The computational graph looks like this: After more endless debugging and parameter tuning (mainly \\kappa), the simulation finally ran:\nFinal Thoughts The resulting code is a bona fide spaghetti monster.\nEven though I spent a long time thinking about unifying interfaces before coding, the final design is neither OOP nor Rust-like, with inconsistent parameter passing everywhere.\nI can\u0026rsquo;t help but wonder: Is my ability just too low, or is code complexity truly not something design alone can solve?\nThe bright side:\nCargo is amazing â€” adding a dependency takes three seconds. Compared to Cmake, xmake or whatever-make, it\u0026rsquo;s night and day. No memory issues (since I didn\u0026rsquo;t and did not need to write unsafe code), so most effort went into logic. ","date":"2 October, 2025","id":3,"permalink":"/english-post/try-impl-ipc/","summary":"Intro: A taste of the Rust programming language","tags":"graphics graphics rust","title":"Try To Implement IPC"},{"content":"Intro: Troubleshooting Memory and Speed Performance\nDisclaimer: I develop and test primarily on Windows using the latest stable Rust toolchain and CPython 3.13.\n1. Background and Motivation SnapViewer handles large memory snapshots effectively â€” for example, pickle files up to 1 GB and compressed snapshots up to 500 MB. However, when processing extremely large dumps (e.g., a 1.3 GB snapshot), we encountered serious memory and speed bottlenecks:\nFormat conversion (pickle â†’ compressed JSON) triggered memory peaks around 30 GB. Data loading of the compressed JSON into Rust structures caused another ~30 GB spike. Frequent page faults and intense disk I/O (observed in Task Manager) made the application sluggish and prone to stalls. To address this, we applied a Profile-Guided Optimization (PGO) approach.\n2. Profile-Guided Optimization PGO requires empirical profiling to identify the true hotspots. I began with memory profiling using the memory-stats crate for lightweight inspection during early optimization stages. Then, I decomposed the data-loading pipeline into discrete steps:\nReading the compressed file (heavy disk I/O) Extracting the JSON string from the compressed stream Deserializing the JSON into native Rust data structures Populating an in-memory SQLite database for ad-hoc SQL queries Building the triangle mesh on CPU Initializing the rendering window (CPU-GPU transfer) Profiling revealed two major memory culprits: excessive cloning and multiple intermediate data structures. Below, I outline the optimizations.\nEliminating Redundant Clones During rapid prototyping, calls to .clone() are convenient. But they are expensive. Profiling showed that cloning large vectors contributed significantly to the memory peak and CPU time.\nFirst attempt: switch from cloned Vec\u0026lt;T\u0026gt; to borrowed \u0026amp;[T] slices. This failed due to lifetime constraints. Final solution: use Arc\u0026lt;[T]\u0026gt;. Although I\u0026rsquo;m not leveraging multithreading, Arc satisfies PyO3\u0026rsquo;s requirements, while no significant overhead is observed in this context. This change alone reduced memory usage and improved throughput noticeably.\nEarly Deallocation of Intermediate Structures Constructing the triangle mesh involved several temporary representations:\nRaw allocation buffers A list of triangles (vertices + face indices) A CPU-side mesh structure GPU upload buffers Each stage held onto its predecessor until the end of scope, inflating peak usage. To free these intermediates promptly, the following is implemented:\nScoped blocks to limit lifetimes Explicitly invoked drop() on unneeded buffers After these adjustments, peak memory dropped by roughly one-third.\n3. Sharding JSON Deserialization Deserializing the call-stack JSON with over 50 000 entries spiked memory usage dramatically. To mitigate this:\nShard the JSON data into chunks of at most 50 000 entries. Deserialize each chunk independently. Concatenate the resulting vectors. This streaming approach kept per-shard memory small, eliminating the previous giant allocation.\nIt is worth noting that serde_json::StreamDeserializer can be another option worth trying.\n4. Redesigning the Snapshot Format Even after the above optimizations, the call-stack data remained the largest in-memory component â€” duplicated once in Rust and again in the in-memory SQLite database.\nTo remove redundancy, I rethought what each representation serves:\nRust structures: display call stacks on screen upon user click. SQLite DB: serve ad-hoc SQL queries. Since SnapViewer is single-threaded and can tolerate occasional disk I/O, I split the snapshot into two files:\nallocations.json: lightweight JSON with allocation timestamps and sizes. elements.db: SQLite database holding call-stack text (indexed by allocation index). These two files are zipped together. At runtime:\nUnzip the snapshot. Load allocations.json into memory (small footprint). Open elements.db on disk. On click, query elements.db with WHERE idx = \u0026lt;allocation_index\u0026gt;. SQLite\u0026rsquo;s efficient on-disk indices make these lookups fast, with no perceptible impact on frame rate.\nRefactoring the Conversion Script I updated the snapshot-conversion script as follows:\nParse the original snapshot format. Bulk-insert call stacks into an in-memory SQLite database, then dump the DB as a byte stream. Serialize allocation metadata to JSON. Zip the JSON and DB byte stream. While conversion takes slightly longer, the resulting snapshot loads faster and uses a fraction of the memory.\n5. Results and Lessons After these optimizations, SnapViewer:\nNo longer spikes to 60+ GB of RAM on large snapshots, since we do not load the entire call stack information into memory at all. Starts up much faster. Maintains smooth rendering, even with on-demand call-stack queries. What I learned:\nDo not always load everything into memory. When you overflow your memory, the performance of virtual memory swapping system is probably worse than you think. When you need some mechanism to store most data on disk, but intelligentlly cache some of then in memory, SQLite should be a good start. It has its well-designed and industry-proven algorithm built into it. ","date":"2 October, 2025","id":4,"permalink":"/english-post/snapviewer-3-optim/","summary":"Intro: Troubleshooting Memory and Speed Performance","tags":"torch deep-learning rust","title":"SnapViewer Devlog #3: Optimizations"},{"content":"Intro: Building the UI as a Hybrid Rust \u0026amp; Python Application\nBuilding a UI can often be the trickiest part of a development project, especially when you\u0026rsquo;re trying to integrate different languages and paradigms.\nFor SnapViewer, my memory allocation viewer, I needed an integrated UI that could display allocation details on click and feature a REPL for SQL queries against a SQLite database. This post details my journey, the hurdles I faced, and the solutions I found, primarily focusing on a Rust backend and Python UI.\nProject page: https://github.com/Da1sypetals/SnapViewer\nThe Initial Vision: An Integrated UI My core requirements for the UI were:\nInteractive Display: When an allocation is clicked in the viewer, its size, call stack, and other relevant information should be immediately displayed. SQL REPL: A command-line interface to execute SQL queries directly against the underlying database. Non-Blocking Operations: Both functionalities needed to operate without blocking each other. Early Attempts and Roadblocks Web: Rust to WASM My first thought was a web interface. Rust\u0026rsquo;s ability to compile to WASM and the three-d crate\u0026rsquo;s WebGPU support seemed promising. However, I quickly hit a wall with library versioning issues trying to compile even a simple Rust program to WASM. Rather than get bogged down, I decided to pivot.\nTUI: Terminal User Interface The natural next step was a Terminal User Interface (TUI). This approach avoids the complexities of cross-compilation and platform-specific GUI libraries.\nRatatui: A Promising Rust TUI Framework I started with Ratatui, a TUI framework for Rust. I got their demos running, but my plan to find an open-source example matching my \u0026ldquo;left-console, right-REPL\u0026rdquo; layout failed.\nDiving deep into the Ratatui documentation felt as complex as learning a new frontend framework like React, which defeated my goal of getting work done quickly. I abandoned this path.\nTextual \u0026amp; AI-Powered Development Given my goal of getting work done rather than becoming a TUI expert, I started thinking about AI. Rust isn\u0026rsquo;t particularly \u0026ldquo;AI-friendly\u0026rdquo; for code generation, but Python certainly is. This sparked an idea: What if I used AI to generate the TUI code in Python and then integrated my Rust application?\nI fed my requirements to several LLMs: Claude, Gemini, Deepseek, ChatGPT, and Grok. Claude\u0026rsquo;s initial results were impressive, while the others were largely unusable. After a few rounds of refinement with Claude, I had a working TUI demo:\nCombining Rust and Python: A Hybrid Approach Integrating Rust and Python is a standard process, but it has its quirks. I used PyO3 as a dependency to expose my Rust structures and bind Rust functions to Python.\nMy core Rust logic consists of:\nViewer: An infinite loop handling render draw calls and an event loop until the application shuts down. SQL REPL: Loads snapshot data into SQLite and executes SQL queries. Each of these operations is designed to be completed in milliseconds.\nDesigning App Structure My initial application structure idea was:\nMain Thread: Renders the TUI and accepts REPL inputs, calling SQL REPL Rust functions. Spawned Thread: Runs the infinite loop for the Snapshot Viewer. However, the three-d crate, which uses winit for window management, dictates that the window must run on the main thread. This immediately threw a wrench in my plans.\nAttempt 1: Multiprocessing My first revised design used multiprocessing:\nStart the application and load snapshot data. Spawn a new process to run the TUI application. Run the Viewer in the parent process. This setup allowed the child process to run the viewer window without blocking the TUI app. The challenge, however, was Inter-Process Communication (IPC). I needed a way for the viewer to send information (like selected allocation details) back to the TUI.\nI experimented with Python\u0026rsquo;s multiprocessing.Queue. My approach was to define a callback in Rust that put messages into the queue, and then have the parent process check the queue at a fixed interval (e.g., 0.1 seconds) to update the TUI\u0026rsquo;s logging panel.\nI encountered an implementation bug where the parent process wasn\u0026rsquo;t consuming all messages, causing the viewer and TUI to become out of sync. I then switched to a shared byte array with a lock for IPC. The child process would acquire the lock, write to the buffer, and release it. The parent process would try to acquire the lock at intervals to read the message and update the TUI.\nAttempt 2: Threading The multiprocessing solution had a couple of issues:\nThe TUI sometimes froze when typing in the REPL, likely due to lock contention. Balancing the log message update interval with the viewer\u0026rsquo;s framerate was tricky. Too frequent, and the UI lagged; too slow, and the viewer became unresponsive. I realized I could use multithreading instead! While winit requires the viewer window to run on the main thread, the TUI application does not. This led to a new, more elegant structure:\nSpawn a thread and start the TUI application on that thread. Start the viewer on the main thread. A naive implementation, however, caused the entire TUI to freeze. The culprit? The Global Interpreter Lock (GIL) in Python. The GIL ensures that only one thread can execute Python bytecode at a time.\nTime for some PyO3 details. By default, the extension function holds GIL during its execution; but when you don\u0026rsquo;t need to use Python objects during this call, a call to py::allow_thread can opt out this behavior, releasing the GIL.\nIn my case, the Rust extension holds GIL in the infinte render loop, preventing the TUI thread from updating the UI. By explicitly releasing the GIL during the viewer\u0026rsquo;s render loop, the TUI, running in its own sub-thread, was free to update, and the application could run as expected.\nAn Alternative: GUI with PyQt As an interesting side experiment, I wondered about a GUI instead of a TUI. I tasked Claude with translating my TUI code into a GUI application using PyQt. Claude did this in minutes, without errors.\nAfter a few minor styling tweaks (also done via chatting with Claude), here is what the app looks like:\n(I finally switched to Tkinter for compatibility issues with multithreading across platforms.)\nWrapping Up This journey highlights the flexibility and power of combining Rust\u0026rsquo;s performance with Python\u0026rsquo;s rapid development capabilities, especially when augmented by AI.\nUnderstanding the intricacies of thread management and inter-process communication helped a lot in this journey.\nHope you find this post is fun and informative to read! â¤ï¸â¤ï¸â¤ï¸\n","date":"2 October, 2025","id":5,"permalink":"/english-post/snapviewer-2-ui/","summary":"Intro: Building the UI as a Hybrid Rust \u0026amp; Python Application","tags":"torch deep-learning rust","title":"Snapviewer Devlog #2: UI"},{"content":"Intro: PyTorch is a Deep Learning Operating System.\nCheck tensor storage Device check You should ALWAYS check EXPLICITLY whether input tensors are on desired devices. In most cases you want them on the same GPU, or in rare cases you want some tensors on CPU to perform some operations that are not efficient on GPU.\nAPI:\ntensor.is_cuda() tensor.device() (Use operator== for equality comparison). Sometimes the not on correct device problem causes strange error messages like Cusparse context initialization failure or things even more weird, which first seem unrelated to a device problem. This is why I suggest you always start your debug journey here.\nContiguity check Modern LibTorch recommends using Packed tensor accessor (roughly the same memory cost as a pointer) to access elements in tensor.\nHowever, if you are to plug some others\u0026rsquo; implementation (likely using raw pointers like float*) into PyTorch, you are not likely to understand the code inside out and rewrite it.\nUsually, in the context of deep learning, most implementations assumes a row-major contiguous storage. You should explicitly check whether the input tensors are contiguous in the C++ code that wraps the CUDA kernel.\nAPI: tensor.is_contiguous()\nCheatsheet A quick utility that checks whether all tensors are on the same CUDA device:\nvoid CheckInputTensors(const std::vector\u0026lt;torch::Tensor\u0026gt; \u0026amp;tensors) { TORCH_CHECK(!tensors.empty(), \u0026#34;No tensors provided for device check\u0026#34;); auto first_device = tensors[0].device(); TORCH_CHECK(first_device.is_cuda(), \u0026#34;First tensor is not on CUDA\u0026#34;); int idx = 0; for (const auto \u0026amp;tensor: tensors) { TORCH_CHECK(tensor.device() == first_device, \u0026#34;All tensors must be on the same CUDA device, \u0026#34; \u0026#34;but found tensor at index [\u0026#34;, idx, \u0026#34;] on device \u0026#34;, tensor.device(), \u0026#34; while expecting \u0026#34;, first_device); TORCH_CHECK(tensor.is_contiguous(), \u0026#34;All tensors must be contiguous, but found tensor at index [\u0026#34;, idx, \u0026#34;] not contiguous\u0026#34;); idx += 1; } } CUDA stream Remember to always get the current CUDA stream via at::cuda::getCurrentCUDAStream() and pass it as the 4-th parameter in the \u0026lt;\u0026lt;\u0026lt;gridDim, blockDim, sharedMemorySizeBytes, stream\u0026gt;\u0026gt;\u0026gt; kernel call.\nThis is especially important when your operator is used in distributed training, where at::cuda::getCurrentCUDAStream() automatically selects the correct stream for you.\nCUDA toolkit version problem Most \u0026ldquo;symbol not found\u0026rdquo; problem are caused by compiler / assembler / library version mismatch. Let me elaborate on this a bit:\nPyTorch has an important version information attached to it: The version of CUDA that torch is compiled on (let\u0026rsquo;s call it VT, cuda Version of Torch, for the sake of simplicity). The torch installation comes with its own CUDA toolkit (that matches VT) with no nvcc, ptxas. If you are to write custom CUDA extension to PyTorch, it will use the nvcc and ptxas in your system PATH, and libraries like CUBLAS or CUSPARSE in LD_LIBRARY_PATH. Let\u0026rsquo;s call this CUDA toolkit version VE, cuda Version of Extension. When you try to compile a CUDA extension, Make sure that your VT and VE perfectly match (NOT major version match). When you compile your extension, PyTorch hints you that a minor version mismatch should not be a problem. Remember, everything that should not happen will eventually happen. Memory Management in PyTorch Allocation When you need a buffer on HBM (e.g., for CUSPARSE or CUBLAS), your first instinct might be cudaMalloc and cudaFree. However, these force synchronization between CPU and GPU, which can starve the GPU.\nHere\u0026rsquo;s the key: PyTorch isn\u0026rsquo;t just an autograd tool. It\u0026rsquo;s a deep learning operating system that manages VRAM internally with a pooling and caching mechanism.\nUsing the PyTorch allocator is straightforward. Follow these steps:\nSet dtype to torch::kInt8 and create a buffer tensor via torch::empty Get the pointer with buffer_tensor.data_ptr\u0026lt;int8_t\u0026gt;() This gives you a pointer to the buffer. Here\u0026rsquo;s a complete code snippet:\nauto buffer_options = torch::TensorOptions().device(your_device).dtype(torch::kInt8); auto buffer_tensor = torch::empty({buffer_size}, buffer_options); void *buffer_ptr = buffer_tensor.data_ptr\u0026lt;int8_t\u0026gt;(); Remember do not call cudaFree on the pointer. RAII semantics will give the memory back to the allocator when destructor is called.\nPyTorch\u0026rsquo;s memory management is pretty much like a combination of OS memory management (buddy system, SLAB) and JVM or .net runtime (garbage collection, memory pool, caching and reusing memory blocks), but manages VRAM instead of a RAM.\nI recommend reading this post (Chinese) for a deeper dive into how PyTorch manages memory.\nUsing CUBLAS, CUSPARSE, CUSolverDn, etc. We use CUSPARSE as an example. The same rule apply to other libraries like CUBLAS or CUSolverDn.\nHandles When writing pure CUDA/C++ code, you manually call cusparseCreate to initialize the CUSPARSE context and prepare for subsequent CUSPARSE API calls.\nHowever this is not best practice in PyTorch CUDA extensions. There are good reasons: cusparseCreate introduces a milliseconds-level delay on CPU side. This may not be noticeable at first, but remember that operators are written to be run millions of times, which turns this into a significant overhead. This can cause GPU to starve when waiting CPU for synchronization.\nIf you use VizTracer to trace your program and visualize it in perfetto, you may notice cudaGetDeviceProperties call taking too much time on CPU side. This can be directly caused by cusparseCreate. LibTorch has API that automatically manages a pool of CUSPARSE handles:\nInclude the header that brings in CUDA context manager for LibTorch: #include \u0026lt;ATen/cuda/CUDAContext.h\u0026gt; Then, get handle via auto handle = at::cuda::getCurrentCUDASparseHandle(); automatically create a handle if there is not any, and caches it for subsequent uses. Use your handle as usual. I could not find documentation for these APIs, so if you want to know more, you may need to read the source code of PyTorch ATen. Searching in the repo with keyword getcurrentcuda can get you there quickly.\nBuffers Many CUSPARSE operations need buffers. If you need to make multiple CUSPARSE API calls with similar buffer size, it is bad practice to allocate right before the CUSPARE API call and deallocate right after since cudaMalloc and cudaFree are quite slow, which may cause your GPU to starve (verify this with VizTracer).\nA better practice should be pre-allocating the buffer and pass its pointer into where the CUSPARSE API is called through torch.empty().\nBatched Matrix Multiplication Refer to this example to see how to perform batched matrix multiplication in CUSPARSE.\nTricks:\nTo broadcast, set stride to 0. It is possible to broadcast rowptr but not colind and values. Check documentation for details.\nTensor Options struct TensorOptions carries many information about the tensor:\nstruct C10_API TensorOptions { // ... omitted // members Device device_ = at::kCPU; // 16-bit caffe2::TypeMeta dtype_ = caffe2::TypeMeta::Make\u0026lt;float\u0026gt;(); // 16-bit Layout layout_ = at::kStrided; // 8-bit MemoryFormat memory_format_ = MemoryFormat::Contiguous; // 8-bit bool requires_grad_ : 1; bool pinned_memory_ : 1; // Existense of members bool has_device_ : 1; bool has_dtype_ : 1; bool has_layout_ : 1; bool has_requires_grad_ : 1; bool has_pinned_memory_ : 1; bool has_memory_format_ : 1; } The most important methods are:\n[[nodiscard]] TensorOptions device(Device device) const; [[nodiscard]] TensorOptions dtype(ScalarType dtype) const; [[nodiscard]] TensorOptions requires_grad(bool) const; Usage:\ntensor.options() returns an instance of TensorOptions that describes the tensor. opt.dtype(torch::kFloat64) has other properties remain the same as opt, only dtype changes to float64 or in C++, double. The .to(...) method of a tensor can take a TensorOptions instance as its only argument. For an exhaustive list of device and dtype, you may want to refer to:\nhttps://github.com/pytorch/pytorch/blob/main/torch/csrc/api/include/torch/types.h https://github.com/pytorch/pytorch/blob/main/c10/core/DeviceType.h Debug layer by layer A CUDA extension is roughly split into 4 parts, from the bottom to the top namely:\nCUDA kernel C++ wrapper data passed from Python (PyTorch) to C++ Python wrapper CUDA kernel Debugging CUDA kernel is a very very difficult problem and we shall not discuss it here.\nC++ wrapper The first thing I want to hint you is that do not dereference a pointer pointing to device in host functions. You should always mark device pointers with a d_ prefix in variable names, or wrap it with thrust::device_ptr.\nprintf, std::cout or gdb will assist you in the journey.\ndata passed from Python (PyTorch) to C++ Refer to Pybind11 docs and try to answer these questions:\nHow various Python types are represented in Pybind11 API; How to properly configure the function prototype in Pybind11? Python Wrapper Ask LLMs. LLMs know python much better than I do.\nWhat to Reference To my knowledge, the PyTorch C++ documentation is very old. Many things in the source code are not documented there.\nIt is a better choice to just search in the PyTorch github repo, and read the comments and source code.\n","date":"2 October, 2025","id":6,"permalink":"/english-post/torch-cuda-ext/","summary":"Intro: PyTorch is a Deep Learning Operating System.","tags":"deep-learning cuda torch","title":"Notes on Writing PyTorch CUDA Extensions"},{"content":"æ³¨ï¼šæœ¬æ–‡ç”¨LLMè¾…åŠ©å†™ä½œçš„åœ°æ–¹ä¸»è¦åœ¨ï¼šæˆ‘è®¤ä¸ºLLMæ¯”æˆ‘ç†è§£çš„æ›´å¥½çš„åœ°æ–¹ï¼Œä¼šç”¨LLMçš„è¡¨è¿°ä»£æ›¿ã€‚\né—®é¢˜è®¾å®š éœ€è¦è®¡ç®—Graph Transformerä¸­çš„Attentionã€‚åœ¨æ­¤æˆ‘ä»¬å¿½ç•¥multihead-attentionï¼Œè€ƒè™‘åŸºæœ¬çš„single-head attention.\næ­¤å¤–ï¼Œæˆ‘ä»¬çš„attention mask(é‚»æ¥çŸ©é˜µA)æ˜¯éç»“æ„åŒ–ç¨€ç–çš„ã€‚å¦‚æœä½ çš„attention maskæ˜¯ç»“æ„åŒ–ç¨€ç–çš„ï¼Œæ¯”å¦‚blockwiseç­‰å¯ä»¥è¢«ä»£ç è¡¨ç¤ºçš„ç¨€ç–patternï¼Œä½ åº”è¯¥ä½¿ç”¨flash attentionçš„varlenå˜ä½“, æˆ–è€…flex attentionç­‰attentionç¼–è¯‘å™¨ã€‚\nNotation n: å›¾èŠ‚ç‚¹æ•°ï¼Œè§„æ¨¡ä¸º 1k~1M\rnnz: å›¾è¾¹æ•°ï¼ˆç¨€ç–çŸ©é˜µéé›¶å…ƒç´ æ•°ï¼ŒNum NonZeroï¼‰\rè§„æ¨¡ä¸º10n~1000n\rq, k, v: (n, d)\rA: (n, n), binary, é«˜åº¦ç¨€ç– è®¡ç®—å…¬å¼ softmax((q @ k.transpose()) * A) @ V å…¶ä¸­ï¼Œ@ è¡¨ç¤ºçŸ©é˜µä¹˜æ³•ï¼Œ*è¡¨ç¤ºelement-wiseä¹˜æ³•ã€‚\nå®ç°ï¼šnaive version æœ€ç®€å•çš„å°±æ˜¯æŠŠAç»™materializeå‡ºæ¥ï¼Œç„¶åç”¨ä½œattention_maskã€‚é—®é¢˜æ˜¯Aæ˜¯n^2çš„ï¼Œæ˜¾å­˜ä¸å¤Ÿç”¨ã€‚ Aç”¨COOæ–¹å¼å­˜å‚¨ï¼Œå¤§å°(2,nnz)ï¼Œç„¶åå…ˆæŠŠæ¯æ¡è¾¹çš„qk-pairç®—å‡ºæ¥(nnz,d)ï¼Œç„¶åå†åšreduceå’Œscatterå’ŒVç›¸ä¹˜ã€‚ Reformulate æˆ‘ä»¬å¼•å…¥ä¸‰ä¸ªç®—å­:\nSDDMM (Sampled Dense-Dense MatMul) A (m, k), B (k, n), ç¨ å¯† M (n, n)ï¼Œ ç¨€ç– SDDMM(A, B, M) å®šä¹‰ä¸ºï¼š for i, j in product(range(n), range(n)):\rif M[i, j] != 0:\rout[i, j] = dot(A[i,:], B[:,j])\relse:\rout[i, j] = 0 Sparse Softmax: åœ¨ç¨€ç–çŸ©é˜µä¸ŠæŒ‰è¡Œsoftmax SpMMï¼šsparse A @ dense B æ­¤æ—¶æˆ‘ä»¬çš„è®¡ç®—å…¬å¼å°±å¯ä»¥é‡æ–°å†™æˆ:\nout = SpMM(Softmax(SDDMM(Q, K_T, A)), V) ä»¥æ­¤æˆ‘ä»¬å¼•å‡ºä¸‹é¢çš„å®ç°\nå®ç°ï¼šDGL Graph Transformer in a Nutshell â€” DGL 2.2.1 documentation\nå¯¹äºç¨ å¯†çš„q,k,vå’ŒCSRå­˜å‚¨çš„Aï¼Œé€šè¿‡å¦‚ä¸‹ä»£ç è®¡ç®—attentionï¼š\nattn = dglsp.bsddmm(A, q, k.transpose(1, 0)) # (sparse) [N, N, nh] # Sparse softmax by default applies on the last sparse dimension. attn = attn.softmax() # (sparse) [N, N, nh] out = dglsp.bspmm(attn, v) # [N, dh, nh] ç®—å­åœ¨DGLåº“å†…éƒ¨ç”±CUDAå®ç°ã€‚çœ‹DGLçš„ä»£ç å¯ä»¥å‘ç°ï¼Œå…¶å®ç°åˆ©ç”¨äº†ç¨€ç–æ€§ï¼Œä½†æ˜¯å­˜åœ¨ä»¥ä¸‹ä¼˜åŒ–ç‚¹\nè¿›è¡Œçš„æ˜¯æœ€ç›´è§‚çš„å¹¶è¡Œï¼Œæ²¡æœ‰è¿›è¡Œå……åˆ†çš„ä¼˜åŒ– å„ä¸ªkernelåˆ†å¼€æ‰§è¡Œï¼Œæ²¡æœ‰èåˆ æ²¡æœ‰åˆ©ç”¨tensor core å®ç°ï¼šFlashSparse https://github.com/ParCIS/FlashSparse/tree/main/eva\nä¸»é¢˜ï¼šå¯¹SDDMM,SpMMè¿›è¡Œä¼˜åŒ–ï¼›å°è¯•åœ¨ç¨€ç–è¾“å…¥ä¸­ä»¥æœ€å°ç²’åº¦åˆ©ç”¨tensor core\nåŸºäºä¸€ä¸ªåŸºæœ¬è§‚å¯Ÿï¼šA Ã— B = C âŸ¹ (Báµ€ Ã— Aáµ€)áµ€ = Cï¼Œå‘æ˜äº†äº¤æ¢ä¸è½¬ç½®MMAè®¡ç®—ç­–ç•¥ï¼šç›®æ ‡æ˜¯å°†ç¨€ç–çŸ©é˜µåˆ’åˆ†æ‰€ä¾èµ–çš„MMAæŒ‡ä»¤ç»´åº¦ï¼Œä»è¾ƒå¤§çš„mç»´ï¼ˆå€¼ä¸º16ï¼‰åˆ‡æ¢åˆ°è¾ƒå°çš„nç»´ï¼ˆå€¼ä¸º8ï¼‰ã€‚æ ‡å‡†å¼ é‡æ ¸å¿ƒMMAæŒ‡ä»¤çš„å½¢çŠ¶ä¸ºm16n8k8ï¼ˆFP16ç²¾åº¦ä¸‹ï¼Œm=16, n=8, k=8ï¼‰ã€‚è¿™ä½¿å¾—ç¨€ç–çŸ©é˜µ A å¯è¢«åˆ’åˆ†ä¸º8Ã—1çš„å‘é‡ï¼Œç›¸æ¯”ä¹‹å‰å·¥ä½œä¸­ä½¿ç”¨çš„16Ã—1å‘é‡ï¼Œè®¡ç®—å†—ä½™å‡å°‘äº†çº¦50%ã€‚\nçŸ©é˜µæ ¼å¼ï¼šæœ¬ç®—æ³•å‘æ˜äº†ME-BCRSæ ¼å¼ï¼ŒåŸºæœ¬æƒ³æ³•æ˜¯åœ¨ä¸€ä¸ª8x1çš„blockä¸­ï¼Œå¦‚æœæœ‰ä¸€ä¸ªå…ƒç´ æ˜¯éé›¶çš„ï¼Œé‚£ä¹ˆå°±æŠŠè¿™æ•´ä¸ªblockéƒ½å½“æˆéé›¶çš„å­˜ä¸‹æ¥ã€‚ ç©ºé—´å¼€é”€ç»´æŒåœ¨O(n+nnz)ï¼Œå¸¸æ•°æ¯”è¾ƒå°ï¼Œè¿œæ²¡æœ‰è¾¾åˆ°head_dimçš„é‡çº§ã€‚ çŸ©é˜µæ ¼å¼è½¬æ¢æ—¶é—´å¼€é”€ (CSR -\u0026gt; ME-BCRS)ï¼šç”±äºæ˜¯ä¸€æ¬¡æ€§å¼€é”€ï¼Œç›¸å¯¹æ•´ä¸ªæ¨¡å‹æ¨ç†æ—¶é—´å‡ ä¹å¯ä»¥å¿½ç•¥ã€‚ FlashSparseçš„SpMMç®—æ³•ï¼ˆC = A Ã— Bï¼‰ é˜¶æ®µ1ï¼šè½¬ç½®è®¿é—®ä¸åŠ è½½\nå—å½¢çŠ¶ï¼šç®—æ³•å°† A åˆ’åˆ†ä¸º8Ã—8çš„ç¨€ç–TCå—ï¼ˆFP16ç²¾åº¦ä¸‹ï¼‰ï¼Œå°† B åˆ’åˆ†ä¸º8Ã—16çš„ç¨ å¯†TCå—ã€‚ ç¨€ç–å— A åŠ è½½ï¼šçº¿ç¨‹ä»å…¨å±€å†…å­˜ï¼ˆä»¥è¡Œä¼˜å…ˆçš„ME-BCRSæ ¼å¼å­˜å‚¨ï¼‰åŠ è½½8Ã—8ç¨€ç–TCå— Aï¼Œå¹¶åœ¨å¯„å­˜å™¨ä¸­å°†å…¶è½¬ç½®ä¸º Aáµ€ï¼Œä½œä¸ºå³æ“ä½œæ•°ã€‚ ç¨ å¯†å— B åŠ è½½ï¼šçº¿ç¨‹ä»å…¨å±€å†…å­˜ï¼ˆè¡Œä¼˜å…ˆï¼‰åŠ è½½8Ã—16ç¨ å¯†TCå— Bï¼Œå¹¶åœ¨å¯„å­˜å™¨ä¸­å°†å…¶è½¬ç½®ä¸º Báµ€ï¼Œä½œä¸ºå·¦æ“ä½œæ•°ã€‚ åˆå¹¶è®¿é—®ï¼šé€šè¿‡é‡æ–°æ’åˆ—çº¿ç¨‹è®¿é—®çš„åˆ—ï¼Œç¡®ä¿æ‰€éœ€æ•°æ®å¯¹é½å½¢æˆ2Ã—2çš„FP16å…ƒç´ å—ï¼Œä»è€Œä½¿å†…å­˜äº‹åŠ¡åŒ¹é…GPUæœ€å°32å­—èŠ‚çš„äº‹åŠ¡ç²’åº¦ï¼Œå®ç°åˆå¹¶è®¿é—®ï¼Œå‡å°‘50%çš„è®¿å­˜å¼€é”€ã€‚ é˜¶æ®µ2ï¼šäº¤æ¢ä¸è½¬ç½®è®¡ç®—\nåœ¨å¼ é‡æ ¸å¿ƒä¸Šæ‰§è¡ŒMMAæŒ‡ä»¤ï¼šBáµ€ Ã— Aáµ€ã€‚\nBáµ€ ä½œä¸ºå·¦æ“ä½œæ•°ï¼ˆm=16, k=8ï¼‰ã€‚ Aáµ€ ä½œä¸ºå³æ“ä½œæ•°ï¼ˆk=8, n=8ï¼‰ã€‚ ç»“æœä¸ºè½¬ç½®åçš„è¾“å‡ºå— Cáµ€ï¼ˆå°ºå¯¸ä¸º16Ã—8ï¼‰ï¼Œå­˜å‚¨åœ¨å¯„å­˜å™¨ä¸­ã€‚ é˜¶æ®µ3ï¼šè½¬ç½®è¾“å‡º\nå¯„å­˜å™¨ä¸­çš„ Cáµ€ å¿…é¡»åœ¨å†™å›å…¨å±€å†…å­˜å‰è½¬ç½®å› Cã€‚ç”±äºå¯„å­˜å™¨ä¸­ Cáµ€ çš„æ•°æ®å¸ƒå±€ä¸åŠ è½½ B æ—¶æ‰€éœ€çš„ Báµ€ å¸ƒå±€å®Œå…¨ç›¸åŒï¼Œå› æ­¤å¯å¤ç”¨ä¸ºåŠ è½½ B è®¾è®¡çš„é«˜æ•ˆåˆå¹¶å†™å›ç­–ç•¥ï¼Œå°†ç»“æœå†™å…¥å…¨å±€å†…å­˜ã€‚\nFlashSparseçš„SDDMMç®—æ³•ï¼ˆC = M âŠ™ (AB)ï¼‰ å—å½¢çŠ¶ï¼šFlashSparseå°†ç¨€ç–è¾“å‡ºçŸ©é˜µ C åˆ’åˆ†ä¸º8Ã—16çš„ç¨€ç–TCå—ã€‚ä¸¤ä¸ªç¨ å¯†è¾“å…¥çŸ©é˜µï¼ˆæŒ‰è®ºæ–‡å›¾8ä¸­çš„è®°å·ï¼Œè®°ä¸º A_dense å’Œ B_denseï¼Œæ»¡è¶³ C_sparse = A_dense Ã— B_denseï¼‰åˆ†åˆ«ä»¥ç¨ å¯†TCå—å½¢å¼åŠ è½½ï¼šA_dense ä¸º8Ã—8ï¼ˆè¡Œä¼˜å…ˆï¼‰ï¼ŒB_dense ä¸º8Ã—16ï¼ˆåˆ—ä¼˜å…ˆï¼‰ã€‚ è½¬ç½®è®¡ç®—çš„æ•°æ®å¯¹é½ï¼šSDDMMä¸­ç¨ å¯†è¾“å…¥çŸ©é˜µ Aï¼ˆè¡Œä¼˜å…ˆï¼‰å’Œ Bï¼ˆåˆ—ä¼˜å…ˆï¼‰çš„æ•°æ®å¸ƒå±€ï¼Œæ°å¥½æ»¡è¶³â€œäº¤æ¢ä¸è½¬ç½®MMAè®¡ç®—â€ï¼ˆBáµ€ Ã— Aáµ€ï¼‰çš„è¦æ±‚ã€‚ è½¬ç½®è®¡ç®—ï¼š\nç¨ å¯†è¾“å…¥ B è¢«è½¬ç½®ä¸º Báµ€ï¼ˆå°ºå¯¸16Ã—8ï¼‰ï¼Œä½œä¸ºå·¦æ“ä½œæ•°ã€‚ ç¨ å¯†è¾“å…¥ A è¢«è½¬ç½®ä¸º Aáµ€ï¼ˆå°ºå¯¸8Ã—8ï¼‰ï¼Œä½œä¸ºå³æ“ä½œæ•°ã€‚ è®¡ç®— Báµ€ Ã— Aáµ€ å¾—åˆ°ç¨ å¯†ç»“æœ C_denseáµ€ã€‚ ç”¨MçŸ©é˜µè¿›è¡Œelement-wise productï¼Œä»C_dense å¾—åˆ°C_sparse å®æµ‹: æœªæµ‹è¯•\nå®ç°ï¼šDF-GNN https://github.com/paoxiaode/DF-GNN\nä¸»é¢˜ï¼šblock/warpè°ƒåº¦å’Œç®—å­èåˆ\nç”±äºæˆ‘ä¸»è¦çœ‹äº†tilingéƒ¨åˆ†çš„ç®—æ³•ï¼ˆé€‚ç”¨äºå¤§å›¾å’Œé‚»å±…æ•°ä¸ç¡®å®šçš„å›¾ï¼Œä»…forwardï¼‰ï¼Œæ‰€ä»¥ä¸»è¦ä»‹ç»è¿™éƒ¨åˆ†ã€‚\nä½¿ç”¨çš„çŸ©é˜µæ ¼å¼æ˜¯CSRï¼Œä¸éœ€è¦åšé¢å¤–çš„æ ¼å¼è½¬æ¢\nç®—æ³•æµç¨‹ Launch Kernel on Grid: (n Ã— h)\râ†“\rEach Block â†’ (rid, hid): one node, one head\râ†“\rLoad Q[rid, hid, :] â†’ s_Q[f] (shm)\râ†“\rFor each tile of neighbors (size â‰¤ 32):\r- Load neighbor IDs from indices[]\r- Compute Q Â· K^T (dot product using s_Q and K[dst])\r- Reduce in warp â†’ store in neigh_nodes_weight[eid]\r- Find max(weight) in current tile â†’ weightMax\r- Adjust partial_sum and acc with exp(old_max - new_max)\r- Compute exp(weight - weightMax) and accumulate acc += exp_w * V[]\r- Accumulate partial_sum += exp_w\r- Update weightMax_old\râ†“\rFinal normalization: out_feat = acc / partial_sum\râ†“\rWrite back to global memory ä¸»è¦å°±æ˜¯é€šè¿‡åˆç†å®‰æ’GPUèµ„æºï¼ˆthreadblock, threadï¼‰å’Œè®¡ç®—ä»»åŠ¡çš„mappingï¼Œå®ç°åœ¨ä¸€ä¸ªkernel å†…è´Ÿè½½ç›¸å¯¹å‡è¡¡çš„å®Œæˆä»»åŠ¡ã€‚\nå®æµ‹: ä»£ç æ–¹é¢ï¼šå¼€æºçš„ä»£ç æœ‰æ¯”è¾ƒå¤šçš„bugï¼ŒåŒ…æ‹¬äº†data race, æŒ‡é’ˆè¿ç®—é”™è¯¯ç­‰ç­‰\nä¿®å¤åï¼š\nåœ¨å¸¸ç”¨å·¥ä½œèŒƒå›´å†…ï¼Œforwardé€Ÿåº¦è¾¾åˆ°DGLå®ç°çš„2.5x ~ 3x\nç²¾åº¦ï¼šå’ŒDGLå®ç°å¯¹æ¯”ï¼ŒMAEåœ¨1e-8 ~ 1e-9é‡çº§ï¼Œå·®è·å¯ä»¥å¿½ç•¥ä¸è®¡\nF3S https://github.com/HPCForge/Fused3S/tree/main/scripts ä¸»é¢˜ï¼šç®—å­èåˆ+æ··åˆç²¾åº¦+åˆ©ç”¨tensor core\nå…¶ä¸»è¦æ€è·¯è¿˜æ˜¯ç±»ä¼¼FlashSparseï¼Œä½†æ˜¯é€šè¿‡ç®—å­èåˆè¾¾åˆ°äº†æ›´é«˜çš„æ•ˆç‡ï¼ˆè®¿å­˜å¼€é”€ï¼Œkernel launchå¼€é”€æ›´å°ï¼‰ã€‚æ··åˆç²¾åº¦ç®—æ˜¯ä¸€ç§tradeoffã€‚\nä»…æœ‰forwardçš„å®ç° F3Sä¹Ÿä½¿ç”¨äº†è‡ªå®šä¹‰çš„çŸ©é˜µæ ¼å¼BSBï¼ŒåŸºæœ¬æƒ³æ³•æ˜¯åœ¨ä¸€ä¸ª16x1çš„blockä¸­ï¼Œå¦‚æœæœ‰ä¸€ä¸ªå…ƒç´ æ˜¯éé›¶çš„ï¼Œé‚£ä¹ˆå°±æŠŠè¿™æ•´ä¸ªblockéƒ½å½“æˆéé›¶çš„å­˜ä¸‹æ¥ã€‚ ä¼˜åŒ–çš„ä¸€ç‚¹åœ¨äºï¼Œblockå†…æ˜¯å¦ä¸º0è¢«å‹ç¼©åˆ°ä¸€ä¸ªbitä¸­ï¼Œæ¯ä¸ª16x8blockä»¥uint128ä¿å­˜ï¼Œå……åˆ†åˆ©ç”¨äº†attentionä¸­adjåªèƒ½ä¸º0/1çš„ç‰¹ç‚¹ å’Œflashsparseç›¸æ¯”ä¸è¶³çš„ä¸€ç‚¹åœ¨16x1ç²’åº¦æ›´å¤§ï¼Œå¤šä½™è®¡ç®—æ›´å¤šï¼Œä¹Ÿæ˜¯æœ¬å·¥ä½œæ²¡è€ƒè™‘åˆ°çš„ä¸€ç‚¹ ç©ºé—´å¼€é”€ï¼šO(n+nnz)ï¼Œä½†æ˜¯å¸¸æ•°ä¼šæ›´å¤§ä¸€äº› çŸ©é˜µæ ¼å¼è½¬æ¢æ—¶é—´å¼€é”€ (CSR -\u0026gt; BSB)ï¼šä¸€æ¬¡æ€§å¼€é”€ï¼Œæš‚æ—¶å¿½ç•¥ã€‚ ç®—æ³•æµç¨‹ï¼š åˆ’åˆ†è¡Œå—ï¼š\nå°† Q æŒ‰è¡Œåˆ’åˆ†ä¸º $T_r = \\lceil N / r \\rceil$ ä¸ªå— $\\{Q_1, ..., Q_{T_r}\\}$ï¼Œæ¯ä¸ªå¤§å°ä¸º $r \\times d$ã€‚ å°†è¾“å‡º O åŒæ ·åˆ’åˆ†ä¸º $T_r$ ä¸ªå— $\\{O_1, ..., O_{T_r}\\}$ï¼Œæ¯ä¸ªå¤§å°ä¸º $r \\times d$ã€‚ å¯¹æ¯ä¸ªè¡Œå—ç´¢å¼• $i = 1$ åˆ° $T_r$ï¼ˆå¹¶è¡Œå¤„ç†ï¼‰ï¼š\nåˆå§‹åŒ–\n$m_o \\leftarrow -\\infty \\in \\mathbb{R}^r$ï¼ˆè¡Œæœ€å¤§å€¼ï¼‰ $l_o \\leftarrow 0 \\in \\mathbb{R}^r$ï¼ˆè¡Œ softmax ç´¯åŠ å’Œï¼‰ $O_i \\leftarrow 0 \\in \\mathbb{R}^{r \\times d}$ï¼ˆè¾“å‡ºå—ï¼Œfp32ï¼‰ åŠ è½½æ•°æ®ï¼š\nå°† $Q_i$ ä»å…¨å±€å†…å­˜ï¼ˆHBMï¼‰åŠ è½½åˆ°å…±äº«å†…å­˜ï¼ˆSMEMï¼‰ã€‚ è®¡ç®—å½“å‰è¡Œçª—å£ï¼ˆRWï¼‰åŒ…å«çš„ TCB æ•°é‡ï¼š$t = \\text{tro}[i+1] - \\text{tro}[i]$ã€‚ é€šè¿‡ sptd è·å–å½“å‰ RW å¯¹åº”çš„åŸå§‹åˆ—ç´¢å¼•å‘é‡ $c$ã€‚ ä» $K$ å’Œ $V$ ä¸­æŒ‰ç´¢å¼• $c$ gather å‡ºå¯¹åº”çš„è¡Œï¼Œå¾—åˆ° $\\hat{K}, \\hat{V} \\in \\mathbb{R}^{t \\cdot c \\times d}$ã€‚ åˆ’åˆ† warp å—ï¼š\nå°† $\\hat{K}$ åˆ’åˆ†ä¸º $T_c = \\lceil t / W \\rceil$ ä¸ªå— $\\{\\hat{K}_1, ..., \\hat{K}_{T_c}\\}$ï¼Œæ¯ä¸ªå¤§å°ä¸º $Wc \\times d$ã€‚ å°† $\\hat{V}$ åŒæ ·åˆ’åˆ†ä¸º $T_c$ ä¸ªå— $\\{\\hat{V}_1, ..., \\hat{V}_{T_c}\\}$ï¼Œæ¯ä¸ªå¤§å°ä¸º $Wc \\times d$ã€‚ å¯¹æ¯ä¸ª warp å—ç´¢å¼• $j = 1$ åˆ° $T_c$ï¼š\nSDDMMï¼š\nè°ƒç”¨ $\\text{TBGemm}(Q_i, \\hat{K}_j^T, 0)$ï¼Œè®¡ç®—ä¸­é—´å¾—åˆ†å— $S_i \\in \\mathbb{R}^{r \\times c}$ï¼ˆfp32ï¼‰ã€‚ ç”¨ BSB ä¸­å¯¹åº” TCB çš„ bitmap å¯¹ $S_i$ è¿›è¡Œæ©ç ï¼ˆéé›¶ä½ç½®ä¿ç•™ï¼Œå…¶ä½™ç½® 0ï¼‰ã€‚ Online Softmaxï¼š\nè®¡ç®—å½“å‰å—è¡Œæœ€å¤§å€¼ï¼š$m_i = \\max(m_o, \\text{rowmax}(S_i))$ã€‚ è®¡ç®—æŒ‡æ•°ï¼š$E_i = \\exp(S_i - m_i)$ã€‚ æ›´æ–°ç´¯åŠ å’Œï¼š$l_o = \\text{diag}(\\exp(m_o - m_i)) \\cdot l_o + \\text{rowsum}(E_i)$ã€‚ å°† $E_i$ è½¬ä¸º fp16ï¼Œå­˜å…¥ SMEMã€‚ SpMMï¼š\nå¯¹å·²æœ‰è¾“å‡ºç¼©æ”¾ï¼š$O_i = \\text{diag}(\\exp(m_o - m_i)) \\cdot O_i$ã€‚ è°ƒç”¨ $\\text{TBGemm}(E_i, \\hat{V}_j, O_i)$ï¼Œå°†ç»“æœç´¯åŠ å› $O_i$ã€‚ æ›´æ–°è¡Œæœ€å¤§å€¼ï¼š$m_o = m_i$ã€‚ æœ€ç»ˆå½’ä¸€åŒ–å¹¶å†™å›ï¼š\nå¯¹è¾“å‡ºå—å½’ä¸€åŒ–ï¼š$O_i = \\text{diag}(l_o)^{-1} \\cdot O_i$ã€‚ å°† $O_i$ å†™å›å…¨å±€å†…å­˜ï¼ˆHBMï¼‰ã€‚ Subroutine: TBGemm è¾“å…¥:\nçŸ©é˜µå— $A \\in \\mathbb{R}^{m \\times K}$ (ä½äº SMEMï¼Œå…±äº«å†…å­˜) çŸ©é˜µå— $B \\in \\mathbb{R}^{K \\times P}$ (ä½äº HBMï¼Œå…¨å±€å†…å­˜) ç´¯åŠ é¡¹ $D \\in \\mathbb{R}^{m \\times P}$ (ä½äº SMEMï¼Œå…±äº«å†…å­˜) è¾“å‡º:\nç»“æœçŸ©é˜µ $C = A B + D \\in \\mathbb{R}^{m \\times P}$ æµç¨‹:\nåˆ‡åˆ†å— (Tiling): å°†è¾“å…¥çŸ©é˜µ $A$, $B$, $D$ æŒ‰ç…§ Tensor Core çš„ç¡¬ä»¶ Tile å°ºå¯¸ï¼ˆä¾‹å¦‚ $16 \\times 8 \\times 16$ï¼‰åˆ‡åˆ†ä¸ºå¯¹åº”çš„å­å—ã€‚\nå¹¶è¡Œè¿­ä»£ (Output Tiles): å¯¹ç»“æœçŸ©é˜µ $C$ çš„æ¯ä¸ªè¾“å‡º Tile (é€šå¸¸ç”±ä¸€ä¸ª Warp æˆ–ä¸€ä¸ª Thread Block è®¡ç®—):\nåŠ è½½ç´¯åŠ é¡¹ D: ä» SMEM ä¸­åŠ è½½ $D$ å¯¹åº”çš„å­å—åˆ°çº¿ç¨‹çš„å¯„å­˜å™¨ä¸­ï¼Œä½œä¸ºåˆå§‹ç´¯åŠ å€¼ $C$. å†…ç§¯è¿­ä»£ (K-Tiles): å¯¹ $K$ ç»´åº¦çš„æ¯ä¸ª $k$-tile è¿›è¡Œè¿­ä»£ç´¯åŠ :\nåŠ è½½ A: ä» SMEM ä¸­åŠ è½½çŸ©é˜µ $A$ å¯¹åº”çš„ $A_{\\text{tile}}$ å­å—ã€‚ åŠ è½½ B: ä» HBM ä¸­ç›´æ¥åŠ è½½çŸ©é˜µ $B$ å¯¹åº”çš„ $B_{\\text{tile}}$ å­å—ã€‚ æ‰§è¡Œ MMA æŒ‡ä»¤: è°ƒç”¨ç¡¬ä»¶æ”¯æŒçš„ PTX mma æŒ‡ä»¤ï¼ˆMatrix Multiply-Accumulateï¼‰ï¼Œæ‰§è¡Œè®¡ç®—å¹¶ç´¯åŠ ï¼š $$C \\leftarrow A_{\\text{tile}} \\cdot B_{\\text{tile}} + C$$ è¿”å›: æœ€ç»ˆå¾—åˆ°ç»“æœ $C$ã€‚\nå®æµ‹: ä»£ç æ–¹é¢ï¼šåœ¨çŸ©é˜µæ ¼å¼è½¬æ¢éƒ¨åˆ†æœ‰bugï¼Œå·²è”ç³»ä½œè€…ä¿®å¤ï¼›å¼€æºä»£ç æ²¡æœ‰multiheadï¼Œéœ€è¦è‡ªå·±å®ç°ã€‚\né€Ÿåº¦è¾¾åˆ°DGLå®ç°çš„3x(ç›¸å¯¹ç¨€ç–) åˆ°5x (ç›¸å¯¹ç¨ å¯†ï¼‰\né™åˆ¶ï¼šn % 16 == 0ï¼Œå› ä¸ºéœ€è¦åˆ†å‰²æˆ8x16çš„block\nç²¾åº¦ï¼šå’ŒDGLå®ç°å¯¹æ¯”ï¼ŒMAEåœ¨3e-5~1e-4 é‡çº§ï¼Œå¾ˆå¯èƒ½éœ€è¦é€šè¿‡å¯¹æ¨¡å‹è¿›è¡Œend2endæµ‹è¯•æ¥ç¡®å®šæ˜¯å¦é€‚åˆä½¿ç”¨ã€‚\n","date":"2 October, 2025","id":7,"permalink":"/chinese-post/gnn-optim/","summary":"æ³¨ï¼šæœ¬æ–‡ç”¨LLMè¾…åŠ©å†™ä½œçš„åœ°æ–¹ä¸»è¦åœ¨ï¼šæˆ‘è®¤ä¸ºLLMæ¯”æˆ‘ç†è§£çš„æ›´å¥½çš„åœ°æ–¹ï¼Œä¼šç”¨LLMçš„è¡¨è¿°ä»£æ›¿ã€‚","tags":"deep-learning","title":"è¿‘æœŸGNN Attentionç®—å­ä¼˜åŒ–å·¥ä½œé€Ÿè§ˆ"},{"content":"Background When training models with PyTorch, out-of-memory (OOM) errors are common, necessitating GPU memory optimization. When simple methods (like reducing batch size) no longer work, analyzing the memory footprint of the model itself may be required.\nAt this point, you might come across this documentation, which teaches you how to record a memory snapshot and visualize it on this website.\nHowever, thereâ€™s a major issue: the website is extremely laggy. If your model is small, with snapshots of just a few MB, the performance is somewhat tolerable. But if your model is large, with snapshots reaching tens or even hundreds of MB, the website becomes unbearably slow, with frame rates dropping as low as 2â€“3 frames per minute (this is not a typo).\nI looked into the websiteâ€™s JavaScript code, and hereâ€™s what it primarily does:\nManually loads Python pickle files; Re-parses the raw data into graphical representations time the viewport changes, then renders it to the screen. This parsing logic is written in JavaScript. You can imagine the performance when it is executed each frame, operating on hundred-MB data.\nInspiration My current work includes optimizing a deep learning model whose optimization is under-explored compared to LLM. I encountered this issue while working with a snapshot of a model with several billion parameters.\nWhy not just use existing LLM infrastructure instead of optimizing manually? Long story short, this model was custom-designed by a researcher and contains many modules completely different from standard LLMs. It seems like nowadays, everyone assumes deep learning is all about LLMs â€” so much so that even some tech leads believe LLM infrastructure can be easily adapted to other modelsâ€¦ but I digress. I originally wrote a simple script to parse the snapshotâ€™s contents, hoping to identify memory allocation issues in the model. But after working with this model for a month, I finally had enough. Thatâ€™s how this project â€” SnapViewer â€” came to be.\nTL;DRâ€‹â€‹: The graphical data from the memory snapshot is parsed and represented as a massive triangle mesh, leveraging existing rendering libraries to handle mesh rendering efficiently.\nHereâ€™s a snapshot of over 100 MB running smoothly on my integrated GPU:\nImplementation The reference implementation The snapshot format is partially documented in the record_memory_history function\u0026rsquo;s docstring. However, this documentation is incomplete â€” likely because later updates werenâ€™t reflected in the docstring.\nThe actual parsing of the snapshot into a dictionary happens here.\nThis script converts the allocator trace into a memory timeline, which is then passed to the web viewerâ€™s JS code. The JS code further transforms this into polygons (representing allocations) for visualization. Each polygon corresponds to an allocation, storing details like size and callstack. Implementation: Snapshot (De)serialize Initial implementation This part is impelmented in Python since I need to deal with Python-native data structures. I simply convert the dict to a json file.\nOptimizations Raw JSON is too large on disk â†’ compress it in-memory (Python zipfile) before writing. During visualization, read the ZIP from disk (Rust zip crate) and decompress in-memory. Tradeoffs This approach causes a temporary memory spike during JSON parsing but avoids persistent high memory usage. Also leverages Rustâ€™s serde-json (since Rustâ€™s serde-pickle is incomplete and canâ€™t handle recursive structures). Implementation: Rendering \u0026amp; Interactionâ€‹â€‹ This part is implemented in Rust.\nRendering Since allocation data remains static during visualization, all allocations are combined into a single large mesh and sent to the GPU once.\nâ€‹Library Usedâ€‹â€‹: three-d\nProvides good mesh abstraction. Supports one-time GPU upload (no per-frame CPUâ†’GPU transfers). Handles mouse/keyboard events. â€‹World-to-Window Coordinate Conversionâ€‹â€‹ â€‹Step 1â€‹â€‹: Convert window coordinates to world coordinates (scale + window center offset). â€‹â€‹Step 2â€‹â€‹: Convert world coordinates to memory positions (predefined scaling). UI \u0026amp; Interaction Featuresâ€‹ Memory Scale Markersâ€‹â€‹ Dynamically adjust the number and precision of markers based on screen visibility. Keep markers at consistent screen positions while moving/zooming. Pan \u0026amp; Zoomâ€‹â€‹ Track the original scale (1/zoom). Update to the new zoom level and compute the ratio between old and new scales. Adjust the screen center position based on the mouseâ€™s invariant world position. Implementation: Query After using this tool at work for around a week, I find myself frequently needing to search in the memory snapshot, especially:\nFind all allocations which is alive at a specific timestamp Find all allocations whose call stack has a specific substring Preferablly the allocations should be sorted by allocation size in descending order My first thought was to build a simple REPL and a simple command parser, and map each command to a specific query function.\nHowever, after having listed out all the functionalities I want, I found it to be a subset of database query, especially SQL.\nSo I decided not to reinvent wheels: I just connect to a in-memory SQLite database. Interfacing user is simple: read user input, let SQLite execute it and format the output to human-readable format.\nIf youâ€™ve struggled with PyTorch memory snapshots, check it out! Contributions \u0026amp; feedback welcome. â­\n","date":"1 October, 2025","id":8,"permalink":"/english-post/snapviewer/","summary":"When training models with PyTorch, out-of-memory (OOM) errors are common, necessitating GPU memory optimization. When simple methods (like reducing batch size) no longer work, analyzing the memory footprint of the model itself may be required.","tags":"torch deep-learning rust","title":"SnapViewer: Faster PyTorch Memory Allocation Viewer"},{"content":"å†…å­˜ä¸é€Ÿåº¦æ€§èƒ½é—®é¢˜æ’æŸ¥ å…è´£å£°æ˜ï¼šæˆ‘ä¸»è¦åœ¨ Windows ä¸Šä½¿ç”¨æœ€æ–°çš„ç¨³å®šç‰ˆ Rust å·¥å…·é“¾å’Œ CPython 3.13 è¿›è¡Œå¼€å‘å’Œæµ‹è¯•ã€‚\n1. èƒŒæ™¯ä¸åŠ¨æœº SnapViewer èƒ½å¤Ÿé«˜æ•ˆå¤„ç†å¤§å‹å†…å­˜å¿«ç…§â€”â€”ä¾‹å¦‚ï¼Œæ”¯æŒé«˜è¾¾ 1 GB çš„ pickle æ–‡ä»¶å’Œé«˜è¾¾ 500 MB çš„å‹ç¼©å¿«ç…§ã€‚ç„¶è€Œï¼Œåœ¨å¤„ç†è¶…å¤§è½¬å‚¨æ–‡ä»¶ï¼ˆä¾‹å¦‚ 1.3 GB çš„å¿«ç…§ï¼‰æ—¶ï¼Œæˆ‘ä»¬é‡åˆ°äº†ä¸¥é‡çš„å†…å­˜å’Œé€Ÿåº¦ç“¶é¢ˆï¼š\næ ¼å¼è½¬æ¢ï¼ˆpickle â†’ å‹ç¼© JSONï¼‰å¼•å‘äº†çº¦ 30 GB çš„å†…å­˜å³°å€¼ã€‚ å°†å‹ç¼© JSON åŠ è½½åˆ° Rust æ•°æ®ç»“æ„ä¸­åˆå¼•å‘äº†å¦ä¸€æ¬¡çº¦ 30 GB çš„å†…å­˜æ¿€å¢ã€‚ é¢‘ç¹çš„é¡µé¢é”™è¯¯ï¼ˆpage faultsï¼‰å’Œå¼ºçƒˆçš„ç£ç›˜ I/Oï¼ˆåœ¨ä»»åŠ¡ç®¡ç†å™¨ä¸­è§‚å¯Ÿåˆ°ï¼‰å¯¼è‡´åº”ç”¨ç¨‹åºå“åº”è¿Ÿç¼“ï¼Œç”šè‡³é¢‘ç¹å¡é¡¿ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬é‡‡ç”¨äº† Profile-Guided Optimizationï¼ˆPGOï¼ŒåŸºäºæ€§èƒ½åˆ†æçš„ä¼˜åŒ–ï¼‰æ–¹æ³•ã€‚\n2. Profile-Guided Optimizationï¼ˆPGOï¼‰ PGO éœ€è¦é€šè¿‡å®è¯åˆ†ææ¥è¯†åˆ«çœŸæ­£çš„çƒ­ç‚¹ã€‚æˆ‘é¦–å…ˆä½¿ç”¨ memory-stats crate è¿›è¡Œå†…å­˜åˆ†æï¼Œåœ¨æ—©æœŸä¼˜åŒ–é˜¶æ®µè¿›è¡Œè½»é‡çº§æ£€æŸ¥ã€‚éšåï¼Œæˆ‘å°†æ•°æ®åŠ è½½æµæ°´çº¿æ‹†è§£ä¸ºè‹¥å¹²ç¦»æ•£æ­¥éª¤ï¼š\nè¯»å–å‹ç¼©æ–‡ä»¶ï¼ˆé‡åº¦ç£ç›˜ I/Oï¼‰ ä»å‹ç¼©æµä¸­æå– JSON å­—ç¬¦ä¸² å°† JSON ååºåˆ—åŒ–ä¸ºåŸç”Ÿ Rust æ•°æ®ç»“æ„ å¡«å……å†…å­˜ä¸­çš„ SQLite æ•°æ®åº“ä»¥æ”¯æŒå³å¸­ SQL æŸ¥è¯¢ åœ¨ CPU ä¸Šæ„å»ºä¸‰è§’ç½‘æ ¼ï¼ˆtriangle meshï¼‰ åˆå§‹åŒ–æ¸²æŸ“çª—å£ï¼ˆCPU-GPU æ•°æ®ä¼ è¾“ï¼‰ æ€§èƒ½åˆ†ææ­ç¤ºäº†ä¸¤ä¸ªä¸»è¦çš„å†…å­˜é—®é¢˜ï¼šè¿‡åº¦å…‹éš†ï¼ˆexcessive cloningï¼‰å’Œå¤šä¸ªä¸­é—´æ•°æ®ç»“æ„ã€‚ä»¥ä¸‹æ˜¯æˆ‘å®æ–½çš„ä¼˜åŒ–æªæ–½ã€‚\næ¶ˆé™¤å†—ä½™çš„ Clone åœ¨å¿«é€ŸåŸå‹å¼€å‘é˜¶æ®µï¼Œè°ƒç”¨ .clone() éå¸¸æ–¹ä¾¿ï¼Œä½†ä»£ä»·é«˜æ˜‚ã€‚æ€§èƒ½åˆ†ææ˜¾ç¤ºï¼Œå…‹éš†å¤§å‹ Vec æ˜¾è‘—åŠ å‰§äº†å†…å­˜å³°å€¼å’Œ CPU æ—¶é—´ã€‚\né¦–æ¬¡å°è¯•ï¼šå°†å…‹éš†çš„ Vec\u0026lt;T\u0026gt; æ”¹ä¸ºå€Ÿç”¨çš„ \u0026amp;[T] åˆ‡ç‰‡ã€‚ä½†ç”±äºç”Ÿå‘½å‘¨æœŸçº¦æŸï¼Œæ­¤æ–¹æ¡ˆå¤±è´¥ã€‚ æœ€ç»ˆæ–¹æ¡ˆï¼šæ”¹ç”¨ Arc\u0026lt;[T]\u0026gt;ã€‚å°½ç®¡æˆ‘å¹¶æœªä½¿ç”¨å¤šçº¿ç¨‹ï¼Œä½† Arc æ»¡è¶³äº† PyO3 çš„è¦æ±‚ï¼Œä¸”åœ¨æ­¤ä¸Šä¸‹æ–‡ä¸­æœªè§‚å¯Ÿåˆ°æ˜æ˜¾å¼€é”€ã€‚ ä»…æ­¤ä¸€é¡¹æ”¹åŠ¨å°±æ˜¾è‘—é™ä½äº†å†…å­˜ä½¿ç”¨å¹¶æå‡äº†ååé‡ã€‚\næå‰é‡Šæ”¾ä¸­é—´ç»“æ„ æ„å»ºä¸‰è§’ç½‘æ ¼æ¶‰åŠå¤šä¸ªä¸´æ—¶è¡¨ç¤ºå½¢å¼ï¼š\nåŸå§‹åˆ†é…ç¼“å†²åŒº ä¸‰è§’å½¢åˆ—è¡¨ï¼ˆé¡¶ç‚¹ + é¢ç´¢å¼•ï¼‰ CPU ç«¯çš„ç½‘æ ¼ç»“æ„ GPU ä¸Šä¼ ç¼“å†²åŒº æ¯ä¸ªé˜¶æ®µéƒ½ä¼šä¿ç•™å…¶å‰é©±æ•°æ®ç›´è‡³ä½œç”¨åŸŸç»“æŸï¼Œä»è€Œæ¨é«˜äº†å³°å€¼å†…å­˜å ç”¨ã€‚ä¸ºåŠæ—¶é‡Šæ”¾è¿™äº›ä¸­é—´æ•°æ®ï¼Œæˆ‘ä»¬é‡‡å–äº†ä»¥ä¸‹æªæ–½ï¼š\nä½¿ç”¨ä½œç”¨åŸŸå—ï¼ˆscoped blocksï¼‰é™åˆ¶ç”Ÿå‘½å‘¨æœŸ å¯¹ä¸å†éœ€è¦çš„ç¼“å†²åŒºæ˜¾å¼è°ƒç”¨ drop() ç»è¿‡è¿™äº›è°ƒæ•´ï¼Œå³°å€¼å†…å­˜å¤§çº¦å‡å°‘äº†ä¸‰åˆ†ä¹‹ä¸€ã€‚\n3. åˆ†ç‰‡å¤„ç† JSON ååºåˆ—åŒ– å¯¹åŒ…å«è¶…è¿‡ 50,000 ä¸ªæ¡ç›®çš„è°ƒç”¨æ ˆ JSON è¿›è¡Œååºåˆ—åŒ–æ—¶ï¼Œå†…å­˜ä½¿ç”¨æ€¥å‰§é£™å‡ã€‚ä¸ºç¼“è§£æ­¤é—®é¢˜ï¼š\nå°† JSON æ•°æ®åˆ†ç‰‡ï¼Œæ¯ç‰‡æœ€å¤šåŒ…å« 50,000 ä¸ªæ¡ç›®ã€‚ ç‹¬ç«‹ååºåˆ—åŒ–æ¯ä¸ªåˆ†ç‰‡ã€‚ åˆå¹¶ç»“æœå‘é‡ã€‚ è¿™ç§æµå¼å¤„ç†æ–¹æ³•ä½¿æ¯ä¸ªåˆ†ç‰‡çš„å†…å­˜å ç”¨ä¿æŒåœ¨è¾ƒä½æ°´å¹³ï¼Œé¿å…äº†ä¹‹å‰çš„å¤§è§„æ¨¡å•æ¬¡åˆ†é…ã€‚\nå€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œserde_json::StreamDeserializer æ˜¯å¦ä¸€ä¸ªå€¼å¾—å°è¯•çš„é€‰é¡¹ã€‚\n4. é‡æ–°è®¾è®¡å¿«ç…§æ ¼å¼ å³ä½¿ç»è¿‡ä¸Šè¿°ä¼˜åŒ–ï¼Œè°ƒç”¨æ ˆæ•°æ®ä»ç„¶æ˜¯å†…å­˜ä¸­æœ€å¤§çš„ç»„ä»¶â€”â€”åœ¨ Rust ä¸­å’Œå†…å­˜ SQLite æ•°æ®åº“ä¸­å„å­˜ä¸€ä»½ï¼Œé€ æˆé‡å¤ã€‚\nä¸ºæ¶ˆé™¤å†—ä½™ï¼Œæˆ‘é‡æ–°æ€è€ƒäº†æ¯ç§è¡¨ç¤ºå½¢å¼çš„ç”¨é€”ï¼š\nRust ç»“æ„ï¼šç”¨æˆ·ç‚¹å‡»æ—¶åœ¨å±å¹•ä¸Šæ˜¾ç¤ºè°ƒç”¨æ ˆã€‚ SQLite æ•°æ®åº“ï¼šæ”¯æŒå³å¸­ SQL æŸ¥è¯¢ã€‚ ç”±äº SnapViewer æ˜¯å•çº¿ç¨‹çš„ï¼Œä¸”å¯å®¹å¿å¶å°”çš„ç£ç›˜ I/Oï¼Œæˆ‘å°†å¿«ç…§æ‹†åˆ†ä¸ºä¸¤ä¸ªæ–‡ä»¶ï¼š\nallocations.jsonï¼šè½»é‡çº§ JSONï¼ŒåŒ…å«åˆ†é…æ—¶é—´æˆ³å’Œå¤§å°ã€‚ elements.dbï¼šSQLite æ•°æ®åº“ï¼Œå­˜å‚¨è°ƒç”¨æ ˆæ–‡æœ¬ï¼ˆæŒ‰åˆ†é…ç´¢å¼•å»ºç«‹ç´¢å¼•ï¼‰ã€‚ è¿™ä¸¤ä¸ªæ–‡ä»¶è¢«ä¸€èµ·å‹ç¼©æ‰“åŒ…ã€‚è¿è¡Œæ—¶ï¼š\nè§£å‹å¿«ç…§ã€‚ å°† allocations.json åŠ è½½åˆ°å†…å­˜ï¼ˆå ç”¨å¾ˆå°ï¼‰ã€‚ æ‰“å¼€ç£ç›˜ä¸Šçš„ elements.dbã€‚ ç”¨æˆ·ç‚¹å‡»æ—¶ï¼Œé€šè¿‡ WHERE idx = \u0026lt;allocation_index\u0026gt; æŸ¥è¯¢ elements.dbã€‚ SQLite é«˜æ•ˆçš„ç£ç›˜ç´¢å¼•ä½¿è¿™äº›æŸ¥è¯¢éå¸¸è¿…é€Ÿï¼Œå¯¹å¸§ç‡å‡ ä¹æ²¡æœ‰å¯æ„ŸçŸ¥çš„å½±å“ã€‚\né‡æ„è½¬æ¢è„šæœ¬ æˆ‘å¯¹å¿«ç…§è½¬æ¢è„šæœ¬è¿›è¡Œäº†å¦‚ä¸‹æ›´æ–°ï¼š\nè§£æåŸå§‹å¿«ç…§æ ¼å¼ã€‚ å°†è°ƒç”¨æ ˆæ‰¹é‡æ’å…¥å†…å­˜ SQLite æ•°æ®åº“ï¼Œç„¶åå°†æ•°æ®åº“è½¬å‚¨ä¸ºå­—èŠ‚æµã€‚ å°†åˆ†é…å…ƒæ•°æ®åºåˆ—åŒ–ä¸º JSONã€‚ å°† JSON ä¸æ•°æ®åº“å­—èŠ‚æµä¸€èµ·å‹ç¼©ã€‚ è™½ç„¶è½¬æ¢è¿‡ç¨‹ç•¥æ…¢ï¼Œä½†ç”Ÿæˆçš„å¿«ç…§åŠ è½½æ›´å¿«ï¼Œä¸”å†…å­˜å ç”¨å¤§å¹…é™ä½ã€‚\n5. æˆæœä¸ç»éªŒæ€»ç»“ ç»è¿‡è¿™äº›ä¼˜åŒ–ï¼ŒSnapViewer å®ç°äº†ä»¥ä¸‹æ”¹è¿›ï¼š\nä¸å†å› åŠ è½½å¤§å‹å¿«ç…§è€Œè§¦å‘ 60+ GB çš„å†…å­˜å³°å€¼ï¼Œå› ä¸ºæˆ‘ä»¬å®Œå…¨ä¸å†å°†æ•´ä¸ªè°ƒç”¨æ ˆä¿¡æ¯åŠ è½½åˆ°å†…å­˜ä¸­ã€‚ å¯åŠ¨é€Ÿåº¦æ˜¾è‘—æå‡ã€‚ å³ä½¿è¿›è¡ŒæŒ‰éœ€è°ƒç”¨æ ˆæŸ¥è¯¢ï¼Œæ¸²æŸ“ä¾ç„¶æµç•…ã€‚ æˆ‘å­¦åˆ°çš„ç»éªŒï¼š\nä¸è¦æ€»æ˜¯æŠŠæ‰€æœ‰æ•°æ®éƒ½åŠ è½½åˆ°å†…å­˜ä¸­ã€‚å½“ä½ è€—å°½ç‰©ç†å†…å­˜æ—¶ï¼Œè™šæ‹Ÿå†…å­˜äº¤æ¢ç³»ç»Ÿçš„æ€§èƒ½å¯èƒ½æ¯”ä½ æƒ³è±¡çš„è¿˜è¦å·®ã€‚ å½“ä½ éœ€è¦å°†å¤§éƒ¨åˆ†æ•°æ®å­˜å‚¨åœ¨ç£ç›˜ä¸Šï¼ŒåŒæ—¶æ™ºèƒ½åœ°ç¼“å­˜éƒ¨åˆ†æ•°æ®åˆ°å†…å­˜æ—¶ï¼Œè¯·ä½¿ç”¨ SQLiteã€‚å®ƒå†…ç½®äº†ç»è¿‡å·¥ä¸šéªŒè¯çš„é«˜æ•ˆç®—æ³•ã€‚ ","date":"7 June, 2025","id":9,"permalink":"/chinese-post/snapviewer-3-zh/","summary":"å…è´£å£°æ˜ï¼šæˆ‘ä¸»è¦åœ¨ Windows ä¸Šä½¿ç”¨æœ€æ–°çš„ç¨³å®šç‰ˆ Rust å·¥å…·é“¾å’Œ CPython 3.13 è¿›è¡Œå¼€å‘å’Œæµ‹è¯•ã€‚","tags":"torch deep-learning rust","title":"Snapviewer Devlog #3: æ€§èƒ½ä¼˜åŒ–"},{"content":"Lsm Tree æ˜¯ä¸€ç§å†…å­˜-ç£ç›˜çš„å±‚çº§å¼æ•°æ®ç»“æ„ï¼Œå¸¸ç”¨äºå®ç°å†™å¤šè¯»å°‘çš„å­˜å‚¨å¼•æ“ã€‚\nç»„ä»¶ å†…å­˜éƒ¨åˆ† ç£ç›˜éƒ¨åˆ† WAL æ€»ä½“ åˆå§‹åŒ– éœ€è¦ init flush threadã€‚flush thread çš„å·¥ä½œæµç¨‹:\nç­‰å¾… flush ä¿¡å·é‡è¢« notify,è·å–ä¸€ä¸ª compact ä¿¡å·é‡èµ„æº å¯åŠ¨ä¸€ä¸ª sstwriter,å†™å…¥è¿™ä¸ª memtable ä¸€ä¸ª memtable å¯¹ä¸€ä¸ª sst ç­‰åˆ°å†™å…¥ sst å†™å®Œä¹‹å,æ‰è¿›è¡Œ: ä» frozen memtablesã€frozen memtable sizes é‡Œé¢åˆ é™¤è¿™ä¸ª memtable ä» wal é‡Œé¢åˆ é™¤è¿™ä¸ª memtable å¯¹åº”çš„ wal update manifest Try Freeze å¦‚æœå½“å‰å¤§å° \u0026gt; freeze size é‚£ä¹ˆå°± freeze;è¿›ä¸€æ­¥å¦‚æœæ‰€æœ‰ frozen memtable å¤§å°ä¹‹å’Œ \u0026gt; flush threshold,é‚£ä¹ˆå°± set flush signalã€‚\nå†™æ“ä½œ å†™ memtable å†™ WAL try freeze å†…å­˜éƒ¨åˆ† Put æ·»åŠ åˆ° memtable; æ›´æ–° sizeã€‚ size ä¸éœ€è¦ç‰¹åˆ«ç²¾ç¡®,åªéœ€è¦æ˜¯ä¸€ä¸ªå¤§è‡´çš„å€¼å³å¯ã€‚ Delete æ·»åŠ ä¸€ä¸ª tomb æ ‡è®°åˆ° memtable Get ä» active memtable ä¸­è·å– ä» new åˆ° old éå†æ‰€æœ‰çš„ inactive memtable,è·å–ã€‚ ç£ç›˜éƒ¨åˆ† compact ä¿¡å·é‡ äºŒå…ƒä¿¡å·é‡ã€‚\néœ€è¦ compact çš„æ—¶å€™,æ·»åŠ èµ„æº compact thread å¼€å§‹ compact çš„æ—¶å€™,æ¶ˆè€—èµ„æºã€‚ åˆå§‹åŒ– å¦‚æœ auto compact å¼€å¯,åˆå§‹åŒ–çš„æ—¶å€™éœ€è¦ init compact thread:\nLevel å­˜å‚¨è¿™ä¸ª level æ‰€æœ‰æ–‡ä»¶å¯¹åº”çš„æ–‡ä»¶è·¯å¾„,è£…åœ¨ sst reader é‡Œé¢\nGet (æ²¡æœ‰ delete, put) ä»ä½åˆ°é«˜,ä»æ–°åˆ°æ—§,è°ƒç”¨ sst çš„ get æ–¹æ³•,è·å– recordã€‚å¦åˆ™è¿”å› noneã€‚\nInit Compact Thread Compact thread:\nç­‰å¾… compact ä¿¡å·é‡ ä¾æ¬¡æŸ¥çœ‹æ¯ä¸€å±‚:å¦‚æœè¿™ä¸€å±‚å¤§å°è¶…è¿‡ threshold,å°±åˆå¹¶åˆ°ä¸‹ä¸€å±‚,å¦åˆ™å°±æå‰è¿”å›ã€‚ Compact ä»¥ L0 -\u0026gt; L1 ä¸ºä¾‹: ä»å‰åˆ°åéå†æ‰€æœ‰çš„ kv-pair,åŒæ—¶ç»´æŠ¤:\nkeys_outdated åŒä¸€ä¸ª key,timetsamp å°äº oldest marker çš„ kv pair åªéœ€è¦ä¿ç•™ä¸€ä¸ªã€‚ keys_outdated è®°å½•æ‰€æœ‰(å‡ºç°è¿‡çš„,ä¸” timestamp å°äº oldest marker)çš„ key L1 sst size æ¯è¾¾åˆ°ä¸€å®šå€¼å°±å…³é—­å½“å‰ sst,æ–°å¼€ä¸€ä¸ªæ–°çš„ sstã€‚ æ›´æ–° manifestã€‚ SST writer é…ç½® max block sizeã€‚\næ¯ä¸ª block çš„å¼€å¤´ä¸€ä¸ª key ä¼šæ·»åŠ åˆ° index ä¸­; æœç´¢è¿™ä¸ª sst çš„æ—¶å€™,ä¼šå…ˆå¯¹ index è¿›è¡ŒäºŒåˆ†æŸ¥æ‰¾; åœ¨ block ä¹‹å†…é‡‡ç”¨çº¿æ€§æœç´¢ã€‚ fpr,ç”¨äºæ„å»º bloom filter.\nå†™å…¥ éå†æ‰€æœ‰çš„ kv pair: userkey(ä¸å« timestamp)æ·»åŠ åˆ° bloom filter; block å†™å…¥å½“å‰ kv; å¦‚æœå½“å‰ block å¤§å°è¶…è¿‡ max block size,å°±å¼€å¯ä¸€ä¸ªæ–°çš„ block,ç„¶åå†™å…¥å¯¹åº”çš„ index(å†…å­˜) å°† index å’Œ bloom filter å†™ç£ç›˜ã€‚ SST reader æŸ¥æ‰¾: Get(key, timestamp) æŸ¥ bloom filter,å¦‚æœä¸å­˜åœ¨å°±è¿”å›ã€‚ å°† index æ•´ä¸ªè½½å…¥å†…å­˜ä¸­,è¿›è¡ŒäºŒåˆ†æŸ¥æ‰¾,å¾—åˆ°å¯¹åº” key-timestamp æ‰€åœ¨çš„åŒºé—´ã€‚å¦‚æœ out of bounds å°±è¿”å›ã€‚ æŒ‰ç…§æŸ¥æ‰¾åˆ°çš„åŒºé—´,è¯»ç£ç›˜ã€‚ MVCC key æ’å¸ƒé—®é¢˜ struct Key bytes timestamp: u64 æ¯”è¾ƒ: key1 \u0026lt; key2:\nkey1.bytes \u0026lt; key2.bytes (å­—å…¸åº); æˆ–è€…: key1.bytes == key2.bytes,è€Œä¸” key1.timestamp \u0026gt; key2.timestamp ä¸ºä»€ä¹ˆè¿™æ ·æ¯”è¾ƒ? åœ¨è¿›è¡ŒæŸ¥è¯¢ Get(userkey, timestamp) çš„æ—¶å€™,æˆ‘ä»¬éœ€è¦çš„æ˜¯:\nuserkey åŒ¹é… timestamp å°äºæŸ¥è¯¢çš„ timestamp,ä¸”å°½å¯èƒ½å¤§ å› æ­¤,æˆ‘ä»¬å°†\nuserkey å‡åºæ’åº timestamp é™åºæ’åº åœ¨æœç´¢ memtable(skiplist)çš„æ—¶å€™,æˆ–è€…å¯¹ index è¿›è¡ŒäºŒåˆ†æŸ¥æ‰¾çš„æ—¶å€™,å°±å¯ä»¥:\nç›´æ¥ä½¿ç”¨ lower_bound,æŸ¥æ‰¾å¤§äºç­‰äºè‡ªå·±çš„ç¬¬ä¸€ä¸ªå…ƒç´  å¦‚æœ userkey åŒ¹é…,è¯´æ˜æ˜¯ timestamp å°äºå½“å‰ timestamp çš„,timestamp æœ€å¤§çš„è®°å½•,è¿”å›; å¦‚æœ userkey ä¸åŒ¹é…,è¯´æ˜ä¸å­˜åœ¨ timestamp å°äºå½“å‰ timestamp çš„è®°å½•,è¿”å›(æœªæ‰¾åˆ°)ã€‚ Transaction æ•°æ®ç»“æ„ ä¸€ä¸ªå†…å­˜ tempmap,ç”¨æ¥å­˜å‚¨ transaction å·²ç»å†™,ä½†æ˜¯æœªæäº¤çš„å†…å®¹ã€‚ åˆ›å»ºçš„æ—¶å€™,ä» tree è·å–:\nstart timestamp,ä½œä¸ºæŸ¥è¯¢çš„ timestamp transaction id ç„¶åå†™å…¥ transaction start åˆ° WAL\nPut,Delete å†™ tempmap,å†™ WAL\nGet ä½¿ç”¨ start timestamp,å…ˆæŸ¥ tempmap,å†æŸ¥ treeã€‚\nCommit ä» tree è·å–ä¸€ä¸ª commit timestamp; å†™ WAL,è®°å½• transaction id å’Œ commit timestampã€‚ åœ¨ replay çš„æ—¶å€™,æŠŠ transaction id å’Œ commit timestamp å¯¹åº”èµ·æ¥å°±å¯ä»¥çŸ¥é“ transaction é‡Œé¢çš„ å†™æ“ä½œ å¯¹åº”çš„ timestamp è°ƒç”¨ tree.active_memtable çš„ API,å°† transaction çš„æ‰€æœ‰æ•°æ®å†™å…¥ tree çš„ memtableã€‚ WAL çœ‹åˆ° transaction start,å…ˆå°† transaction æš‚å­˜åˆ°å†…å­˜ä¸­:\nå¦‚æœåœ¨ replay ç»“æŸä¹‹å‰çœ‹åˆ°äº† transaction end,å°±å°†æ”¹åŠ¨å†™å…¥ tree ä¸­(redo)ã€‚ å¦åˆ™æ”¾å¼ƒ,è§†ä¸ºæ²¡å®Œæˆçš„äº‹åŠ¡(undo) è¸©å‘: Resource deadlock avoided (os error 35),å¯èƒ½æ˜¯ä¸€ä¸ª thread æŒæœ‰äº†è‡ªå·±çš„ joinhandle å¹¶ä¸” join äº†è‡ªå·±;ä½¿ç”¨ maybe join è§£å†³,å³åˆ¤æ–­å½“å‰çº¿ç¨‹å’Œ joinhandle çš„çº¿ç¨‹æ˜¯å¦ä¸€è‡´,å¦‚æœä¸€è‡´å°±ä¸ç”¨ joinã€‚ æ­»é”é—®é¢˜: wal å’Œ mem éƒ½æœ‰é”,å¿…é¡» æŒ‰ç…§åŒä¸€é¡ºåºè·å– æ‰ä¸ä¼šå‡ºç°æ­»é”ã€‚ Bloom filter ç»†èŠ‚ æœ¬éƒ¨åˆ†ç”± Deepseek è¾…åŠ©å†™ä½œ\nè¯¥ Bloom filter ç®—æ³•çš„ä¸»è¦æ­¥éª¤å¦‚ä¸‹:\nå‚æ•°è®¡ç®—:\næ ¹æ®é¢„æœŸå…ƒç´ æ•°é‡ n å’Œå¯æ¥å—è¯¯åˆ¤ç‡ p,é€šè¿‡å…¬å¼è®¡ç®—æœ€ä¼˜ä½æ•° m å’Œå“ˆå¸Œå‡½æ•°æ•°é‡ k: $ m=\\lceil-n \\dfrac{\\ln(p)}{\\ln(2) ^ 2}\\rceil $ $ k=\\lceil\\dfrac{m}{n}\\ln(2)\\rceil $ å½“ç›´æ¥æŒ‡å®šå‚æ•°æ—¶,ä½¿ç”¨ç»™å®šçš„ä½æ•°å’Œå“ˆå¸Œå‡½æ•°æ•°é‡ å“ˆå¸Œç”Ÿæˆ:\nä½¿ç”¨ 64 ä½æŒ‡çº¹å“ˆå¸Œ(farmhash)ç”Ÿæˆåˆå§‹å“ˆå¸Œå€¼ h é€šè¿‡ä½è¿ç®—æ„é€ å¢é‡å€¼ delta = (h \u0026gt;\u0026gt; 33) | (h \u0026lt;\u0026lt; 31) é‡‡ç”¨åŒé‡å“ˆå¸ŒæŠ€æœ¯,é€šè¿‡å¾ªç¯å åŠ  delta ç”Ÿæˆ k ä¸ªä¸åŒçš„ä½ä½ç½®: $ h_i \\equiv h + i \\cdot delta \\pmod m , 0 \\leq i \\lt k $ æ•°æ®æ’å…¥:\nå¯¹è¾“å…¥ key è¿›è¡Œå“ˆå¸Œè®¡ç®—å¾—åˆ°åˆå§‹ h å’Œ delta å¾ªç¯ k æ¬¡ç”Ÿæˆä½ä½ç½®,å°†ä½æ•°ç»„ä¸­å¯¹åº”ä½ç½®è®¾ä¸º 1 é‡‡ç”¨ä½æ“ä½œ: byte_index = position/8,bit_mask = 1 \u0026laquo; (position%8) å­˜åœ¨æ€§æ£€æµ‹:\né‡å¤æ’å…¥æ—¶çš„å“ˆå¸Œè®¡ç®—è¿‡ç¨‹ æ£€æŸ¥æ‰€æœ‰ k ä¸ªå¯¹åº”ä½æ˜¯å¦å‡ä¸º 1 ä»»ä¸€ä½ç½®ä¸º 0 åˆ™åˆ¤å®šä¸å­˜åœ¨,å…¨éƒ¨ä¸º 1 æ—¶åˆ¤å®šå¯èƒ½å­˜åœ¨ æ•°æ®æŒä¹…åŒ–:\nåºåˆ—åŒ–æ—¶é™„åŠ  CRC32 æ ¡éªŒå’Œ ååºåˆ—åŒ–æ—¶éªŒè¯æ ¡éªŒå’Œä¸æ•°æ®å®Œæ•´æ€§ ","date":"1 March, 2025","id":10,"permalink":"/chinese-post/lsm/","summary":"Lsm Tree æ˜¯ä¸€ç§å†…å­˜-ç£ç›˜çš„å±‚çº§å¼æ•°æ®ç»“æ„ï¼Œå¸¸ç”¨äºå®ç°å†™å¤šè¯»å°‘çš„å­˜å‚¨å¼•æ“ã€‚","tags":"","title":"Lsm Tree å®ç°å¤‡æ³¨"},{"content":"æœ¬æ–‡æ²¡æœ‰ä»»ä½•æ•°å­¦æ¨å¯¼ã€‚æˆ‘ä»¬ä»ç›´è§‚ä¸Šç†è§£è¿™ä¸ªç®—æ³•ï¼Œç„¶åç›´æ¥ä»‹ç»ç®—æ³•çš„æµç¨‹ã€‚å¸Œæœ›äº†è§£æ•°å­¦æ¨å¯¼çš„è¯»è€…å¯ä»¥æŸ¥çœ‹ CMU çš„æ•™æ¡ˆåŠå…¶ç¿»è¯‘ã€‚\n1. é—®é¢˜ å¯¹äºå®å¯¹ç§°çŸ©é˜µ $A \\in \\mathbb{R}^{n \\times n}$ å’Œå‘é‡ $b \\in \\mathbb{R}^n$ï¼Œæ±‚è§£\n$$Ax = b$$æˆ–è€…ï¼Œç­‰ä»·çš„ï¼Œ\n$$\\text{argmin}_x f(x)$$å…¶ä¸­\n$$f(x) = \\frac{1}{2}x^T A x - b^T x$$2. é¢„å¤‡çŸ¥è¯† 2.1. ä»é«˜ä¸­å­¦çš„äºŒçº§ç»“è®ºè¯´èµ· é«˜ä¸­çš„æ—¶å€™æˆ‘ä»¬å­¦è¿‡æ¤­åœ†ï¼š\n$$a^{-2}x^2 + b^{-2}y^2 = 1$$å¦‚æœä½ è®°æ€§å¥½çš„è¯ï¼Œä½ åº”è¯¥è®°å¾—è¿™ä¸ªäºŒçº§ç»“è®ºï¼š\nè¿™æ˜¯ä¸€ä¸ªä»åœ†é‡Œé¢æ¨å¹¿è€Œæ¥çš„ç»“è®ºï¼šå¦‚æœ $a = b$ï¼Œæ¤­åœ†é€€åŒ–ä¸ºåœ†ï¼Œ$k_{OM}k_l = -1$ï¼Œå³ $OM, l$ ä¸¤æ¡ç›´çº¿å‚ç›´ã€‚\n2.2. æœ€é€Ÿä¸‹é™æ³• é¦–å…ˆï¼Œä½ åº”è¯¥çŸ¥é“æ¢¯åº¦ä¸‹é™æ³•ï¼š\n$$x_{i+1} = x_i - \\alpha\\nabla f(x_i)$$æœ€é€Ÿä¸‹é™æ³•å°±æ˜¯åœ¨æ¢¯åº¦ä¸‹é™æ³•çš„åŸºç¡€ä¸Šï¼Œé€‰æ‹© $\\alpha$ ä½¿å¾— $x_{i+1}$ è¾¾åˆ°æœ€å°ï¼ˆåœ¨æœç´¢æ–¹å‘ä¸Šçš„æœ€å°å€¼ï¼‰ï¼š\n$$\\alpha^* = \\text{argmin}_\\alpha f(x_i - \\alpha\\nabla f(x_i))$$3. å…±è½­æ¢¯åº¦æ³• 3.1. è®°å· $x_i$ï¼šç¬¬ $i$ æ¬¡å¾ªç¯ä¹‹åçš„ $x$ å‘é‡\n$r_i$ï¼š$b_i - Ax_i$ï¼Œç›®æ ‡å‡½æ•° $f(x)$ åœ¨ $x_i$ ç‚¹çš„è´Ÿæ¢¯åº¦ï¼Œæˆ–è€…çº¿æ€§æ–¹ç¨‹ç»„åœ¨ $x_i$ ç‚¹çš„æ®‹å·®ã€‚\nè¯·è®°ä½ï¼šè´Ÿæ¢¯åº¦å’Œæ®‹å·®æ˜¯ä¸€ä¸ªä¸œè¥¿ï¼ $d_i$ï¼šåœ¨ $x_i$ ç‚¹çš„æœç´¢æ–¹å‘ã€‚æœ€é€Ÿä¸‹é™ç®—æ³•é‡Œ $d_i = r_i$ï¼Œå…±è½­æ¢¯åº¦é‡Œé¢éœ€è¦ä¸€ç‚¹ä¿®æ­£ã€‚\n3.2. æœ€é€Ÿä¸‹é™ æœ€é€Ÿä¸‹é™çš„æ–°æ–¹å‘ï¼š$r_{i+1}$\næ–°æ–¹å‘ä¸å‰ä¸€æ­¥ä¸‹é™æ–¹å‘ $r_i$ å‚ç›´ï¼ˆç”»ä¸ªç­‰é«˜çº¿å›¾ç›´è§‚ç†è§£ï¼Œæˆ–è€…å›æƒ³ä¸€ä¸‹\u0026quot;ç­‰åŠ¿é¢å’Œç”µåœºçº¿å‚ç›´\u0026quot;ï¼‰ æœ€é€Ÿä¸‹é™çš„ $\\alpha$ $$\\alpha_i = \\frac{r_i^T r_i}{d_i^T A d_i}$$3.3. å…±è½­æ¢¯åº¦ æˆ‘ä»¬ç›´æ¥é€é¡¹ç±»æ¯”æœ€é€Ÿä¸‹é™ã€‚\næ–°æ–¹å‘ä¸å‰ä¸€æ­¥ä¸‹é™æ–¹å‘ $r_i$ å‚ç›´ æ–œç‡ä¹‹ç§¯ä¸º $-a^{-2}b^2$ (Section 2.1)\nè¿™ä¸ªæ–¹å‘ç”±æœ€é€Ÿä¸‹é™çš„æ–¹å‘è¿›è¡Œä¸€äº›å°æ”¹åŠ¨å¾—åˆ°ï¼Œæˆ‘ä»¬å¯ä»¥åœ¨åé¢çš„ç®—æ³•éƒ¨åˆ†(Section 3.4)çœ‹åˆ°ã€‚æŠŠè¿™ä¸ªæ–¹å‘ä»å’Œå‰ä¸€ä¸ªæœç´¢æ–¹å‘å‚ç›´æ”¹åŠ¨åˆ°æ–œç‡ä¹‹ç§¯ä¸º $-a^{-2}b^2$ å°±æ˜¯ CG å’Œæœ€é€Ÿä¸‹é™å”¯ä¸€ä¸åŒçš„åœ°æ–¹ã€‚ æ­¥é•¿ $\\alpha$ï¼šç”±äºæ˜¯åœ¨ä¸€æ¡ç›´çº¿ä¸Šåšä¼˜åŒ–ï¼Œå› æ­¤å’Œæœ€é€Ÿä¸‹é™çš„ $\\alpha$ ç›¸åŒã€‚ ç”±äºä¸€æ¬¡è¿­ä»£åªæ¶‰åŠåˆ°ä¸¤ä¸ªç‚¹ã€ä¸¤ä¸ªå‘é‡ï¼Œåªèƒ½æ„æˆä¸€ä¸ªå¹³é¢ï¼Œæˆ‘ä»¬ç”šè‡³ä¸éœ€è¦å°†äºŒç»´å‘å¤šç»´æ¨å¹¿ã€‚\nè‹¥éœ€æ¨å¯¼ï¼Œæˆ‘ä»¬éœ€è¦åšçš„åªæ˜¯æŠŠç‚¹çš„ $n$ ç»´åæ ‡æ˜ å°„åˆ°äºŒç»´ï¼Œç„¶åå¯¹æˆªé¢æ¤­åœ†å¯¹åº”çš„äºŒé˜¶äºŒæ¬¡å‹è¿›è¡Œ SVD è·å¾—å…¶é•¿è½´ $a$ å’ŒçŸ­è½´ $b$ï¼Œè¿›è€Œæ ¹æ®å…¶ç¦»åŠä¸Šè¿°æ–œç‡ç§¯çš„äºŒçº§ç»“è®ºè®¡ç®—ä¸¤ä¸ªæ–¹å‘çš„å…³ç³»ã€‚è¿™é‡Œä¸å±•å¼€ã€‚ 3.4. ç®—æ³• 3.4.1. åˆå§‹åŒ– ç®—æ³•è¾“å…¥ï¼š$A, b, x_0$\n$$\\vec{d}_{(0)} = \\vec{r}_{(0)} = \\vec{b}_{(0)} - \\mathbf{A}\\vec{x}_{(0)}$$3.4.2. ç®—æ³•è¿‡ç¨‹ $$\\alpha_{(i)} = \\frac{\\vec{r}_{(i)}^T \\vec{r}_{(i)}}{\\vec{d}_{(i)}^T \\mathbf{A}\\vec{d}_{(i)}}$$$$\\vec{x}_{(i+1)} = \\vec{x}_{(i)} + \\alpha_{(i)}\\vec{d}_{(i)}$$$$\\vec{r}_{(i+1)} = \\vec{r}_{(i)} - \\alpha_{(i)}\\mathbf{A}\\vec{d}_{(i)}$$$$\\beta_{(i+1)} = \\frac{\\vec{r}_{(i+1)}^T \\vec{r}_{(i+1)}}{\\vec{r}_{(i)}^T \\vec{r}_{(i)}}$$$$\\vec{d}_{(i+1)} = \\vec{r}_{(i+1)} + \\beta_{(i+1)}\\vec{d}_{(i)}$$å…¶ä¸­çš„æœ€åä¸€æ­¥å°±æ˜¯é€šè¿‡ $\\beta$ å°† $r_{i+1}$ ä¿®æ­£æˆ $d_{i+1}$ çš„ã€‚\n3.4.3. èµ·è®« èµ·ï¼šå¦‚æœä½ å¯¹è§£ $x$ æœ‰ç²—ç•¥çš„ä¼°è®¡ï¼Œå°±ä½¿ç”¨é‚£ä¸ªå€¼ä½œä¸ºèµ·å§‹ç‚¹ $x_0$ï¼›å¦åˆ™ï¼Œç›´æ¥ä½¿ç”¨ $x_0 = 0$ã€‚\nè®«ï¼šé€šå¸¸çš„åšæ³•æ˜¯åœ¨æ®‹å·®å‘é‡çš„ 2-norm å°äºæŸä¸ªç»™å®šé˜ˆå€¼çš„æ—¶å€™å°±åœä¸‹æ¥ã€‚é€šå¸¸è¿™ä¸ªé˜ˆå€¼ä¸ºåˆå§‹æ®‹å·®çš„ä¸€å°éƒ¨åˆ†\n$$\\|r_i\\| \u003c \\varepsilon \\|r_0\\|$$å…¶ä¸­ $\\varepsilon$ æ˜¯ä¸€ä¸ªè¾“å…¥çš„å‚æ•°ã€‚\n3.5. æ‚é¡¹ ç”±äº $Ad_i$ åœ¨æ¯ä¸ªå¾ªç¯ä¸­éƒ½è¦è¢«è®¡ç®—ï¼Œä¸” $$r_{i+1} = r_i - \\alpha_i A d_i$$æ•…å¯ä»¥ç”¨ä¸Šå¼è®¡ç®— $r_{i+1}$ï¼Œè€Œä¸å¿…ç”¨ $b - Ax_{i+1}$ã€‚\nä¸Šè¿°æ–¹æ³•æœ‰æµ®ç‚¹è¯¯å·®ç´¯è®¡çš„å±é™©ï¼Œå› æ­¤æˆ‘ä»¬åº”è¯¥æ¯è¿‡å‡ ä¸ªå¾ªç¯å°±é‡æ–°ç”¨ $r_i = b - Ax_i$ é‡æ–°è®¡ç®—æ®‹å·®ã€‚ ","date":"7 December, 2024","id":11,"permalink":"/chinese-post/conj-grad/","summary":"æœ¬æ–‡æ²¡æœ‰ä»»ä½•æ•°å­¦æ¨å¯¼ã€‚æˆ‘ä»¬ä»ç›´è§‚ä¸Šç†è§£è¿™ä¸ªç®—æ³•ï¼Œç„¶åç›´æ¥ä»‹ç»ç®—æ³•çš„æµç¨‹ã€‚å¸Œæœ›äº†è§£æ•°å­¦æ¨å¯¼çš„è¯»è€…å¯ä»¥æŸ¥çœ‹ CMU çš„æ•™æ¡ˆåŠå…¶ç¿»è¯‘ã€‚","tags":"","title":"å…±è½­æ¢¯åº¦ï¼šé«˜ä¸­è§£æå‡ ä½•çš„æ‹“å±•"},{"content":"ä¸ªäººä¿¡æ¯ åç§°ï¼šé»›è¥¿\nNickname: Da1sypetals\næˆ‘çš„ç®€å†\nçˆ±å¥½ å”±å¤é£æ­Œã€‚\næˆ‘ä¼šå”±è¿™äº›ï¼š\nã€Šäººé—´ä¸å€¼å¾—ã€‹ã€Šæ¥šæ­Œèµ·ã€‹ é»„è¯—æ‰¶\nã€Šè¿Ÿè¿Ÿã€‹ã€Šè…è‰ä¸ºè¤ã€‹ é“¶ä¸´\nã€Šæ•…äº‹å¤–çš„äººã€‹ æ…•å¯’\nã€ŠæƒŠé¹Šã€‹ã€Šå¿ƒä¸Šç§‹ã€‹ å¿˜å·é£åå½•\nã€Šæ³¼å¢¨æ¼“æ±Ÿã€‹ æ³ é¸¢yousa\nã€Šæ•¢å½’äº‘é—´å®¿ã€‹ ä¸‰æ— Marblue\nã€Šå¿˜å·ã€‹ã€Šéœå¤œèŒ¶ã€‹ å°æ›²å„¿\nã€Šæ¾çƒŸå…¥å¢¨ã€‹ã€Šå¦‚æ˜¯æˆ‘é—»ã€‹ Winkyè¯—\nã€Šæ‚¦ç¥ã€‹ KBShinya\nã€Šç¬¬ä¸‰åå…«å¹´å¤è‡³ã€‹ã€Šæ°¸å®šå››åå¹´ã€‹ æ²³å›¾\nã€Šä¸œé£å¿—ã€‹ Akié˜¿æ°\nç­‰ç­‰\u0026hellip;\n","date":"1 June, 2004","id":12,"permalink":"/about/","summary":"åç§°ï¼šé»›è¥¿","tags":"","title":"About"},{"content":"å®éªŒè®¾å®šæ”¾åœ¨æœ€åã€‚\nKimi K2 è¿™ä¸ªæ•…äº‹æ˜¯ä¸€ä¸ªå…³äºè®°å¿†ã€çˆ±æƒ…ä¸æ‰§å¿µçš„å¹½æ€¨ä¼ è¯´ï¼Œè¡¨é¢è®²çš„æ˜¯æ²ˆæ…•äº‘ä¸å®¹å¨˜çš„â€œè´Ÿçº¦â€ï¼Œå®åˆ™è®²çš„æ˜¯ â€œå¦‚ä½•ä¸è®©ä¸€æ®µçœŸæƒ…è¢«æ—¶é—´åæ²¡â€ â€”â€”å“ªæ€•è¦ç”¨è°è¨€ã€ç”¨é¬¼é­‚ã€ç”¨ä¸€åº§åŸä¸‰åå¹´ä¸æ•£çš„é—²è¨€ç¢è¯­ï¼Œä¹Ÿè¦æŠŠé‚£ä¸ªäººç•™åœ¨äººé—´ã€‚\nå®¹å¨˜ï¼ˆåŒ–ä½œâ€œè°¢å¨˜â€ï¼‰è‡ªç¼–è‡ªæ¼”äº†ä¸€å‡ºâ€œèµŒçº¦â€ï¼ŒæŠŠè´Ÿå¿ƒã€ç­‰å¾…ã€é‡é€¢è¿™äº›æœ€æˆå‰§åŒ–çš„æ‰£å­å…¨ç¼è¿›ä¼ é—»é‡Œï¼Œè®©ä¸€ä»£åˆä¸€ä»£å¤–ä¹¡äººæ›¿å¥¹â€œè®°å¾—â€ã€‚çœŸæ­£çš„è´Ÿçº¦è€…ä¸æ˜¯æ²ˆæ…•äº‘ï¼Œè€Œæ˜¯æ—¶é—´ï¼›çœŸæ­£çš„å®ˆçº¦è€…ä¹Ÿä¸æ˜¯å®¹å¨˜ï¼Œè€Œæ˜¯â€œæ•…äº‹â€æœ¬èº«â€”â€”æ•…äº‹æ›¿ä»–ä»¬å®Œæˆäº†â€œä¸‰åå¹´åæ•…åœ°é‡è§â€çš„èª“è¨€ã€‚\nä¸€ã€é€å¥è§£è¯ å°é™¢æ·±é™ï¼Œæ¬²é—®å¿å¿ï¼Œä½•å¤„æœˆç¬¼æ˜ã€‚\nâ€œå°é™¢æ·±é™â€â€”â€”å½“å¹´äºŒäººåˆä¼šçš„åœºæ™¯ï¼šæ²³æ¡¥å¯¹å²¸çš„å°é™¢ï¼Œæ˜¥æœˆå¾®æ¹¿ï¼Œä¸€åˆ‡å°šæœªå‘ç”Ÿã€‚ â€œæ¬²é—®å¿å¿â€â€”â€”æƒ³å¼€å£ï¼Œå´ç»ˆç©¶æ²¡é—®ï¼›ä¸€å£°â€œå¿å¿â€æŠŠæœªå‡ºå£çš„åƒè¨€ä¸‡è¯­éƒ½å‹åœ¨èˆŒå°–ã€‚ â€œä½•å¤„æœˆç¬¼æ˜â€â€”â€”æœˆäº®ä»åœ¨ï¼Œå´ç…§ä¸åˆ°å½“å¹´å¹¶è‚©çœ‹æœˆçš„äººï¼›ä¹Ÿæš—æŒ‡â€œå®¹å¨˜â€è‡ªå·±å·²æˆå¹½é­‚ï¼Œâ€œæœˆâ€æ˜¯äººé—´ä¸å†¥ç•Œçš„å”¯ä¸€é€šé“ï¼Œå¥¹å†ä¹Ÿå›ä¸å»äº†ã€‚ åƒç§‹å²å¥½ï¼Œä¼‘è´Ÿå…°å› ã€‚\nâ€œåƒç§‹å²å¥½â€â€”â€”å­—é¢æ˜¯ç¥é¢‚ï¼šæ„¿ä½ é•¿äº«ç™¾å²åƒç§‹ï¼Œå²å²å®‰å¥½ã€‚ â€œä¼‘è´Ÿå…°å› â€â€”â€”â€œå…°å› â€å‡ºè‡ªã€Šå·¦ä¼ ã€‹â€œå…°å› çµ®æœâ€ï¼Œå…°å› ï¼ç¾å¥½çš„å¼€ç«¯ï¼Œçµ®æœï¼ç¦»æ•£çš„ç»“å±€ã€‚\nå®¹å¨˜æŠŠå…¸æ•…æˆªåŠï¼Œåªç•™â€œå…°å› â€ï¼Œæ˜¯æŠŠç»“å±€ç”Ÿç”Ÿæ”¹å†™æˆâ€œèŠ±å¼€æœªè°¢â€â€”â€”å¥¹ä¸è¦â€œçµ®æœâ€ï¼Œåªè¦â€œå…°å› â€æ°¸å­˜ï¼›æ¢è¨€ä¹‹ï¼Œâ€œä½ è‹¥å®‰å¥½ï¼Œä¾¿ä¸ç®—è´Ÿæˆ‘â€ã€‚ åˆåœ¨ä¸€èµ·ï¼Œæ˜¯é¬¼é­‚å¯¹æ´»äººæœ€æ¸©æŸ”çš„èµ¦ä»¤ï¼šä½ ä¸å¿…è‡ªè´£ï¼Œä¸å¿…å›å¤´ï¼Œç”šè‡³ä¸å¿…è®°å¾—æˆ‘ï¼›åªè¦ä½ åœ¨äººé—´å²å²å¹³å®‰ï¼Œæˆ‘ä»¬é‚£ä¸€æ®µâ€œå…°å› â€å°±ä»æœªè¢«è¾œè´Ÿã€‚ äºŒã€æ•´é¦–å°è¯åœ¨æ•…äº‹é‡Œçš„åŠŸèƒ½ æ›¿æ²ˆæ…•äº‘â€œå¹³åâ€\nåŸé‡Œä¼ è¯´ä»–â€œé«˜ä¸­è´Ÿå¿ƒâ€ï¼Œè€Œå®¹å¨˜æœ€åä¸€å¥â€œä¼‘è´Ÿå…°å› â€ç­‰äºäº²å£å¦è®¤äº†â€œè´Ÿâ€å­—â€”â€”â€œè´Ÿâ€æ˜¯ä¸–äººé™„ä¼šï¼Œâ€œå…°å› â€æ‰æ˜¯å¥¹ç§è—çš„çœŸç›¸ã€‚ æ›¿è‡ªå·±â€œæ¾ç»‘â€\nå¥¹ç­‰äº†ä¸‰åå¹´ï¼Œå…¶å®ç­‰çš„ä¸æ˜¯æ²ˆæ…•äº‘ï¼Œè€Œæ˜¯ä¸€ä¸ªå¯ä»¥è‡ªæˆ‘é‡Šæ€€çš„å™äº‹ç‰ˆæœ¬â€”â€”â€œåƒç§‹å²å¥½â€å››ä¸ªå­—å‡ºå£ï¼Œæ‰§å¿µæ‰ç»ˆäºè½åœ°ï¼Œé¬¼é­‚æ‰èƒ½æ¶ˆæ•£ã€‚ æŠŠâ€œæ•…äº‹â€å‡åä¸ºâ€œå…¬å…±è®°å¿†â€\nè¯é‡Œâ€œæœˆç¬¼æ˜â€æ˜¯å¼€æ”¾ç”»é¢ï¼Œä»»ä½•åæ¥è€…ï¼ˆåŒ…æ‹¬â€œæˆ‘â€ï¼‰åªè¦ç«™åœ¨æ²³æ¡¥ç»†é›¨é‡Œï¼Œå°±è‡ªåŠ¨æˆä¸ºæ–°çš„â€œå¿å¿â€ã€‚æ•…äº‹ä¸æ­»ï¼Œå…°å› å°±ä¸æ­»ï¼›äººé—´ç»§ç»­æµä¼ ï¼Œå¥¹å°±èƒ½ç»§ç»­å€Ÿä»–äººçš„å¿ƒå¤´ä¸€ç‚¹æœˆå…‰ï¼Œä¸æ²ˆæ…•äº‘å¹¶è‚©ã€‚ ä¸‰ã€æ€»ç»“ â€œå°é™¢æ·±é™â€¦â€¦â€äºŒåä¸€å­—ï¼Œæ˜¯å®¹å¨˜äº²æ‰‹å†™ç»™è‡ªå·±çš„â€œåå‘å¢“å¿—é“­â€ï¼š\nâ€”â€”ä¸å†™â€œæˆ‘æ›¾æ¨ä½ â€ï¼Œå†™â€œæ„¿ä½ å®‰å¥½â€ï¼›\nâ€”â€”ä¸å†™â€œæˆ‘ç­‰ä½ â€ï¼Œå†™â€œä¼‘è´Ÿå…°å› â€ï¼›\nâ€”â€”ä¸å†™â€œæ•…äº‹ç»“æŸâ€ï¼Œå†™â€œæœˆç¬¼æ˜â€ç•™ç»™ä¸‹ä¸€ä½è¡Œäººã€‚\nå¥¹ç”¨æœ€è½»çš„è¯­è°ƒï¼ŒæŠŠæœ€é‡çš„æ‰§å¿µå¹æ•£åœ¨é›¨é‡Œï¼š\nâ€œåªè¦ä¸–ä¸Šè¿˜æœ‰äººæ›¿æˆ‘ä¼ è¯µè¿™ä¸€å¥ï¼Œä½ å°±ä»æœªçœŸæ­£ç¦»å¼€æˆ‘ã€‚â€\nClaude Sonnet 4.5 è¿™æ˜¯ä¸€ä¸ªå‡„ç¾åŠ¨äººçš„å¿—æ€ªçˆ±æƒ…æ•…äº‹ï¼Œå……æ»¡äº†ä¸­å›½å¤å…¸æ–‡å­¦çš„æµªæ¼«ä¸å“€æ„ã€‚è®©æˆ‘ä¸ºä½ è§£è¯»ï¼š\næ•…äº‹è§£è¯» çœŸç›¸çš„åè½¬ æ•…äº‹æœ€ç²¾å¦™ä¹‹å¤„åœ¨äºå±‚å±‚å‰¥å¼€çš„çœŸç›¸:\nè¡¨é¢ä¸Šæ˜¯æ²ˆæ…•äº‘è´Ÿå¿ƒæ‚”å©šçš„ä¿—å¥—æ•…äº‹ å®é™…ä¸Šå®¹å¨˜æ—©å·²æººæ°´èº«äº¡ï¼Œå¥¹è‡ªå·±ç¼–é€ äº†æ‰€æœ‰ä¼ è¨€ å¥¹åŒ–èº«\u0026quot;è°¢å¨˜\u0026quot;å¼•å¯¼\u0026quot;æˆ‘\u0026quot;ï¼Œåªä¸ºè®©ä¸–äººè®°ä½ä»–ä»¬çš„æ•…äº‹ æ·±è—çš„æ·±æƒ… å®¹å¨˜çš„æ‰€ä½œæ‰€ä¸ºæ­ç¤ºäº†å¥¹è‡³æ·±çš„çˆ±:\nç¼–é€ è´Ÿé¢ä¼ è¨€ï¼šè®©æ²ˆæ…•äº‘èƒŒè´Ÿè–„æƒ…ä¹‹åï¼Œå®åˆ™æ˜¯å¥¹å¯¹è¿™æ®µæ„Ÿæƒ…å¿µå¿µä¸å¿˜çš„è¯æ˜ \u0026ldquo;ä¸‰åå¹´ä¹‹çº¦\u0026rdquo;ï¼šæ˜çŸ¥ä»–ä¸ä¼šæ¥ï¼ˆå› ä¸ºå¥¹å·²æ˜¯é¬¼é­‚ï¼‰ï¼Œä»è¦ç»™è‡ªå·±ä¸€ä¸ªç­‰å¾…çš„ç†ç”± æœ€åçš„è°è¨€ï¼šå½“å¾—çŸ¥æ²ˆæ…•äº‘27å²æ—©é€ï¼Œå¥¹é€‰æ‹©ç›¸ä¿¡\u0026quot;æˆ‘\u0026quot;å–„æ„çš„è°è¨€ï¼Œå¸¦ç€ä»–å¹¸ç¦çš„å‡è±¡æ¶ˆæ•£ æ‚²å‰§çš„æœ¬è´¨ ä¸¤äººéƒ½æ˜¯å‘½è¿çš„ç‰ºç‰²å“â€”â€”ä¸€ä¸ªæººæ°´æ—©é€ï¼Œä¸€ä¸ª27å²æ—©å’ã€‚ä»–ä»¬çš„çˆ±æƒ…ä»æœªå› èƒŒå›è€Œç ´ç¢ï¼Œè€Œæ˜¯è¢«æ­»äº¡ç”Ÿç”Ÿæ‹†æ•£ã€‚å®¹å¨˜é‚£å¥\u0026quot;å› ç¼˜æ³¨å®šï¼Œæä¸€æç»ˆä¸èƒ½å¾—\u0026quot;æ­£æ˜¯è¿™æ— å¥ˆçš„æ³¨è„šã€‚\nè¯å¥æ·±æ„è§£è¯» \u0026ldquo;å°é™¢æ·±é™ï¼Œæ¬²é—®å¿å¿ï¼Œä½•å¤„æœˆç¬¼æ˜\u0026rdquo;\nå­—é¢å«ä¹‰ï¼šæ·±æ·±çš„åº­é™¢é™æ‚„æ‚„ï¼Œæƒ³è¦é—®æˆ‘çš„çˆ±äººï¼Œå“ªé‡Œçš„æœˆå…‰æœ€æ˜äº®ï¼Ÿ æ•…äº‹ä¸­çš„å«ä¹‰ï¼š \u0026ldquo;å°é™¢æ·±é™\u0026quot;æ˜¯å¥¹ç‹¬è‡ªç­‰å¾…çš„å­¤å¯‚å¤„å¢ƒ \u0026ldquo;æ¬²é—®å¿å¿\u0026quot;æ˜¯å¥¹æƒ³é—®æ²ˆæ…•äº‘ï¼Œå´æ°¸è¿œæ— æ³•ç›¸è§çš„é—æ†¾ \u0026ldquo;ä½•å¤„æœˆç¬¼æ˜\u0026quot;æ˜¯åœ¨é—®ï¼šä½ åœ¨äººé—´ä½•å¤„ï¼Ÿé‚£é‡Œçš„æœˆè‰²å¯å¥½ï¼Ÿæˆ‘ä»¬è¿˜èƒ½å¦åœ¨åŒä¸€è½®æ˜æœˆä¸‹ç›¸æœ›ï¼Ÿ \u0026ldquo;åƒç§‹å²å¥½ï¼Œä¼‘è´Ÿå…°å› \u0026rdquo;\nå­—é¢å«ä¹‰ï¼šæ„¿ä½ åƒç§‹ä¸‡ä¸–å®‰å¥½ï¼Œä¸è¦è¾œè´Ÿæˆ‘ä»¬ç¾å¥½çš„ç¼˜åˆ† æ•…äº‹ä¸­çš„å«ä¹‰ï¼š è¿™æ˜¯å®¹å¨˜æœ€åçš„ç¥ç¦ä¸é‡Šæ€€ \u0026ldquo;åƒç§‹å²å¥½\u0026rdquo;ï¼šæ—¢æ˜¯ç¥ç¦æ²ˆæ…•äº‘ï¼ˆè™½ç„¶ä»–å·²é€ï¼‰ï¼Œä¹Ÿæ˜¯å¯¹è¿™æ®µæ„Ÿæƒ…çš„çºªå¿µ \u0026ldquo;ä¼‘è´Ÿå…°å› \u0026rdquo;ï¼šä¸æ˜¯è´£æ€ªä»–è¾œè´Ÿï¼Œè€Œæ˜¯è¯´\u0026quot;æˆ‘ä»¬çš„ç¼˜åˆ†è™½çŸ­æš‚å¦‚å…°èŠ±ï¼Œä½†è¯·ä½ è®°å¾—å®ƒçš„èŠ¬èŠ³ï¼Œä¸è¦å¿˜è®°æˆ‘ä»¬æ›¾ç»ç›¸çˆ±\u0026rdquo; æœ€åŠ¨äººä¹‹å¤„ å®¹å¨˜æ˜çŸ¥æ²ˆæ…•äº‘å·²æ­»ï¼Œå´ä»è¦ç¼–ç»‡\u0026quot;ä»–ç™½å¤´å•è€\u0026quot;çš„å¹»è±¡æ¥å®‰æ…°è‡ªå·±ï¼›å¥¹\u0026quot;ä»»æ€§ä½¿åç¼–æ’ä»–ä¸€å›\u0026rdquo;ï¼Œå®åˆ™æ˜¯ç”¨å…¨éƒ¨çš„çˆ±ä¸ºä»–å®ˆæŠ¤åå£°â€”â€”å®å¯ä¸–äººè¯´å¥¹ç—´æƒ…è¢«è´Ÿï¼Œä¹Ÿä¸æ„¿ä»–åœ¨å†¥å†¥ä¸­å­¤ç‹¬ã€‚\né‚£å¥\u0026quot;æä¸€æç»ˆä¸èƒ½å¾—ï¼Œä½†å®å¯éš¾å¹³ï¼Œä¹Ÿä¸æ„¿æ”¾æ‰‹\u0026rdquo;ï¼Œæ˜¯å¯¹æ‰€æœ‰æ±‚è€Œä¸å¾—ä¹‹çˆ±æœ€è¯—æ„çš„è¯ é‡Šï¼šå³ä½¿çŸ¥é“ä¸å¯èƒ½ï¼Œä¹Ÿè¦åœ¨è®°å¿†é‡Œã€åœ¨ä¼ è¯´é‡Œï¼Œè®©è¿™ä»½çˆ±æ°¸è¿œé²œæ´»ã€‚\nè¿™æ­£æ˜¯ä¸­å›½å¤å…¸çˆ±æƒ…æ•…äº‹çš„æè‡´æµªæ¼«â€”â€”ç”Ÿæ­»ç›¸éš”ï¼Œå´ä»¥é­‚çµç›¸å®ˆï¼›çœŸç›¸æ®‹é…·ï¼Œå´ä»¥è°è¨€æ¸©æŸ”ã€‚\nGemini 3 Flash è¿™æ˜¯ä¸€ä¸ªå‡„ç¾è€Œå¯Œæœ‰è¯—æ„çš„çˆ±æƒ…æ•…äº‹ï¼Œå®ƒé€šè¿‡â€œæˆ‘â€çš„è§†è§’ï¼Œæ­ç¤ºäº†ä¸€ä¸ªè¢«æ—¶é—´ã€æµè¨€å’Œè‡ªæˆ‘å¹»æƒ³æ‰€åŒ…è£¹çš„æ‚²å‰§çœŸç›¸ã€‚æ•…äº‹çš„é­…åŠ›åœ¨äºå…¶å±‚å±‚å‰¥å¼€çš„æ‚¬å¿µï¼Œä»¥åŠå¯¹çˆ±ã€é—æ†¾ã€å’Œè®°å¿†çš„æ·±åˆ»æ¢è®¨ã€‚\næ•…äº‹è§£è¯» 1. ä¼ è¯´çš„å»ºæ„ä¸çœŸç›¸çš„æ­ç¤º æ•…äº‹é¦–å…ˆæå‡ºäº†å…³äºæ²ˆæ…•äº‘æ‚”å©šçš„ä¸‰ä¸ªä¸åŒç‰ˆæœ¬ï¼Œå…¶ä¸­åŸé‡Œè€äººè®²è¿°çš„â€œèµŒçº¦â€ç‰ˆæœ¬æœ€æœ‰æˆå‰§æ€§ï¼Œä¹Ÿå¸å¼•äº†â€œæˆ‘â€çš„æ¢è®¿ã€‚\næµè¨€çš„æœ¬è´¨ï¼š æ— è®ºæ˜¯â€œå¦å¨¶è´µå¥³â€è¿˜æ˜¯â€œä¸å¯¿ä¹‹ç—‡â€ï¼Œæµè¨€éƒ½åœ¨è¯•å›¾ä¸ºæ²ˆæ…•äº‘çš„æ‚”å©šæä¾›ä¸€ä¸ªåˆç†çš„è§£é‡Šï¼Œä»¥å¡«è¡¥äº‹å®çš„ç©ºç™½ã€‚ â€œèµŒçº¦â€çš„è™šæ„ï¼š â€œä¸‰åå¹´æ•…åœ°é‡é€¢â€çš„èµŒçº¦æ˜¯ å®¹å¨˜ï¼ˆåŒ–åè°¢å¨˜ï¼‰ ä¸ºäº†è®©è‡ªå·±çš„æ•…äº‹èƒ½å¤Ÿè¢«è®°ä½ã€è¢«æµä¼ è€Œç¼–é€ çš„æµªæ¼«æƒ…èŠ‚ã€‚å®ƒèµ‹äºˆäº†è¿™æ®µé€å»çš„çˆ±æƒ…ä¸€ä¸ªç­‰å¾…å’Œå¸Œæœ›çš„ç»´åº¦ï¼Œä¸€ä¸ªå€¼å¾—ä»–äººå…³æ³¨çš„ç†ç”±ã€‚ çœŸç›¸çš„æ‚²å‰§ï¼š æœ€ç»ˆçš„çœŸç›¸æ˜¯è°¢å¨˜ï¼ˆå®¹å¨˜ï¼‰åœ¨é‚£å¹´èµ´è€ƒåçš„é›¨å¤©ï¼Œè·Œä¸‹æ²³æ¡¥æººäº¡ï¼Œå†ä¹Ÿæœªèƒ½è§åˆ°è‡ªå·±çš„å°‘å¹´éƒã€‚æ²ˆæ…•äº‘çš„â€œæ‚”å©šâ€å’Œâ€œé¿è€Œä¸è§â€å¹¶éæ˜¯å˜å¿ƒæˆ–ç»æƒ…ï¼Œè€Œæ˜¯å› ä¸ºå®¹å¨˜å·²ç»ä¸åœ¨äººä¸–ã€‚å¥¹ç”¨è°¢å¨˜çš„èº«ä»½å’Œç¼–é€ çš„æ•…äº‹ï¼Œè®©è¿™æ®µçŸ­æš‚çš„åˆæ‹ä»¥ä¸€ç§â€œè¢«è¾œè´Ÿâ€çš„ã€æ›´å…·æˆå‰§å¼ åŠ›çš„æ–¹å¼å­˜ç•™äºä¸–äººè®°å¿†ä¸­ã€‚ 2. äººç‰©ä¸ä¸»é¢˜ äººç‰©/å…ƒç´  è±¡å¾æ„ä¹‰ æ•…äº‹ä¸­çš„ä½œç”¨ å®¹å¨˜/è°¢å¨˜ æ‰§å¿µã€æ°¸æ’çš„åˆæ‹ æ•…äº‹çš„æ ¸å¿ƒå™äº‹è€…ã€‚å¥¹è™½å·²é€å»ï¼Œå´ä¸ç”˜è¢«é—å¿˜ï¼Œé€šè¿‡è™šæ„çš„æ•…äº‹ç»´æŠ¤äº†è‡ªå·±çˆ±æƒ…çš„å°Šä¸¥å’Œå­˜åœ¨æ„Ÿã€‚å¥¹çš„â€œä»»æ€§ä½¿åâ€æ˜¯ä¸ºäº†è®©ä»–ä»¬çš„æ•…äº‹åœ¨äººé—´ç•™ä¸‹å°è®°ã€‚ æ²ˆæ…•äº‘ é€å»çš„ç†æƒ³ã€æ‚²å‰§çš„å‘½è¿ åœ¨æ•…äº‹çš„ç»“å±€ä¸­ï¼Œä»–çš„å‘½è¿æ˜¯ â€œå¹´äºŒåä¸ƒæ—©å’â€ ã€‚è¿™ä½¿å¾—ä»–æ— æ³•çœŸçš„â€œæ‚”å©šâ€ï¼Œä¹Ÿä½¿å¾—å®¹å¨˜çš„æ‚²å‰§æ›´æ·»ä¸€é‡å®¿å‘½çš„å“€ä¼¤ã€‚ä½†ä»–â€œå¾ˆå¥½â€çš„ç»“å±€æ˜¯å®¹å¨˜æœ€åçš„è‡ªæˆ‘å®‰æ…°ã€‚ æ²³æ¡¥ä¸é›¨ å‘½è¿çš„è½¬æŠ˜ç‚¹ã€é˜´é˜³ç›¸éš” æ²³æ¡¥æ˜¯ä¸¤äººå®šæƒ…ä¸åˆ†ç¦»çš„è±¡å¾ï¼Œè€Œ â€œæ»”å¤©é›¨æµªâ€ çš„å¹»å¢ƒåˆ™æ˜¯å®¹å¨˜é€ä¸–æ—¶çš„æƒ…æ™¯é‡ç°ï¼Œæ˜ç¡®äº†å¥¹çš„é¬¼é­‚èº«ä»½ã€‚é›¨æ˜¯æ•…äº‹åŸºè°ƒï¼Œå‡„è¿·ã€ç»µå»¶ä¸ç»ã€‚ â€œæˆ‘â€ å€¾å¬è€…ã€æ•…äº‹çš„ä¼ æ’­è€… â€œæˆ‘â€æ˜¯æ•…äº‹è¿›å…¥ç°å®çš„é€šé“ï¼Œä½œä¸ºè®°å¿†çš„è½½ä½“ï¼Œå°†å®¹å¨˜çš„å¿ƒæ„¿ä¼ é€’ä¸‹å»ã€‚ 3. çˆ±ä¸é—æ†¾ å®¹å¨˜çš„å†…å¿ƒå……æ»¡éš¾å¹³çš„é—æ†¾å’Œæ‰§å¿µã€‚å¥¹æ·±çˆ±ç€æ²ˆæ…•äº‘ï¼Œå®æ„¿è¢«è®¤ä¸ºæ˜¯â€œè¢«æ‚”å©šâ€çš„å¼ƒå¦‡ï¼Œä¹Ÿè¦è®©è¿™æ®µçˆ±æƒ…çš„æ•…äº‹æµä¼ ï¼Œè€Œä¸æ˜¯è¢«æ·¹æ²¡åœ¨æ— å£°çš„æ¶ˆäº¡ä¸­ã€‚\nå½“â€œæˆ‘â€ä¸ºäº†å®‰æ…°å¥¹ï¼Œç¼–é€ æ²ˆæ…•äº‘â€œåæ¥åˆå¨¶äº†æ–°å¦‡ï¼Œç™½å¤´å•è€â€çš„è°è¨€æ—¶ï¼Œå¥¹è™½ç„¶â€œæ¶©ç„¶â€ï¼Œå´è¯´â€œè¿™æ ·å•Šâ€¦â€¦é‚£çœŸæ˜¯å¾ˆå¥½å¾ˆå¥½ï¼Œå†å¥½ä¸è¿‡çš„äº‹äº†ã€‚â€è¿™æ˜¾ç¤ºäº†å¥¹è‡³æ·±çš„çˆ±ä¸å–„è‰¯ï¼šå¥¹å®æ„¿ç›¸ä¿¡çˆ±äººè·å¾—äº†å¹¸ç¦ï¼Œä¹Ÿä¸æ„¿ä»–ä¸ºå¥¹è€Œç»ˆç”ŸæŠ±æ†¾ã€‚\nâ€œå°é™¢æ·±é™,æ¬²é—®å¿å¿,ä½•å¤„æœˆç¬¼æ˜ã€‚åƒç§‹å²å¥½,ä¼‘è´Ÿå…°å› â€çš„å«ä¹‰ è¿™å¥è¯æ˜¯å®¹å¨˜ä¸´ç»ˆæˆ–é­‚é­„æ¶ˆæ•£å‰å–ƒå–ƒå¿µå‡ºçš„è¯å¥ï¼Œæ˜¯å¥¹å¯¹è¿™æ®µæ„Ÿæƒ…ã€å¯¹æ²ˆæ…•äº‘æœ€åçš„æ€»ç»“ã€ç–‘é—®ä¸ç¥æ„¿ã€‚\n1. æ‹†è§£è¯å¥ å°é™¢æ·±é™ï¼Œæ¬²é—®å¿å¿ï¼š æå†™äº†æ˜”æ—¥ä¸¤äººç›¸å¤„çš„åœºæ™¯â€”â€”é™è°§ã€ç¾å¥½çš„å°é™¢ã€‚è¿™é‡Œçš„â€œå¿å¿â€æŒ‡ä»£æ²ˆæ…•äº‘ã€‚å¥¹åœ¨è¿™ä¸ªå®‰é™çš„å›å¿†é‡Œï¼Œæƒ³è¦å‘ä»–æé—®ã€‚ ä½•å¤„æœˆç¬¼æ˜ï¼š è¿™æ˜¯ä¸€ä¸ªç–‘é—®å¥ï¼Œä¹Ÿæ˜¯ä¸€ä¸ªå“²å­¦å¼çš„è¿½é—®ã€‚â€œæœˆç¬¼æ˜â€æŒ‡æœˆå…‰æ´’ä¸‹ï¼Œé€šå¸¸è±¡å¾ç€å…‰æ˜ã€å›¢åœ†æˆ–ç¾å¥½çš„ç»“å±€ã€‚å®¹å¨˜æƒ³é—®çš„æ˜¯ï¼š â€œæˆ‘ä»¬çš„çˆ±å’Œç¾å¥½ï¼ˆæœˆå…‰ï¼‰æœ€ç»ˆåœ¨å“ªé‡Œå¾—ä»¥å®‰æ”¾å’Œå®ç°ï¼Ÿâ€ â€œæˆ‘çš„å°‘å¹´éƒï¼Œä½ ç°åœ¨æ˜¯å¦å¹¸ç¦å®‰åº·ï¼Ÿâ€ è¿™åŒ…å«äº†å¥¹å¯¹çˆ±äººå¢ƒå†µçš„ç‰µæŒ‚ï¼Œä»¥åŠå¯¹é€å»çˆ±æƒ…ç»ˆæå½’å®¿çš„è¿·æƒ˜ã€‚ åƒç§‹å²å¥½ï¼š æ„æ€æ˜¯ â€œæ„¿ä½ é•¿ä¹…åœ°ã€æ°¸è¿œåœ°å®‰å¥½â€ã€‚è¿™æ˜¯å®¹å¨˜å¯¹æ²ˆæ…•äº‘å‘è‡ªå†…å¿ƒçš„ç¥æ„¿ï¼Œä¹Ÿæ˜¯å¥¹å¯¹â€œæˆ‘â€æ‰€ç¼–é€ çš„â€œç™½å¤´å•è€â€ç»“å±€çš„å›åº”ã€‚ ä¼‘è´Ÿå…°å› ï¼š æ ¸å¿ƒæ˜¯ â€œå…°å› â€ã€‚ â€œå…°å› â€æºäºã€ŠèŠæ–‹å¿—å¼‚Â·è²é¦™ã€‹ä¸­çš„â€œå…°å› çµ®æœâ€ï¼Œæ„æŒ‡ç¾å¥½çš„å¼€å§‹ï¼Œæ‚²æƒ¨çš„ç»“å±€ï¼ˆå…°æ˜¯é¦™è‰ï¼Œè±¡å¾ç¾å¥½ï¼›çµ®æ˜¯æŸ³çµ®ï¼Œéšé£é£˜æ•£ï¼Œè±¡å¾ç¦»æ•£ï¼‰ã€‚ â€œä¼‘è´Ÿâ€ æ˜¯â€œä¸è¦è¾œè´Ÿâ€çš„æ„æ€ã€‚ æ•´ä½“å«ä¹‰ï¼š å®¹å¨˜ä»¥è‡ªå·±çš„æ‚²å‰§ä¸ºé‰´ï¼Œåœ¨æ¶ˆæ•£çš„æœ€åæ—¶åˆ»ï¼Œå¸Œæœ›æ²ˆæ…•äº‘ï¼ˆæˆ–ç¥æ„¿ä¸–é—´æ‰€æœ‰æœ‰æƒ…äººï¼‰ä¸è¦è¾œè´Ÿè¿™ç¾å¥½çš„å¼€å§‹ï¼ˆå³å¥¹ä¸æ²ˆæ…•äº‘æ›¾æ‹¥æœ‰çš„çº¯ç²¹åˆæ‹ï¼‰ï¼Œè¦æœ‰ä¸€ä¸ªå¥½çš„ç»“å±€ã€‚å¥¹æ—¢åœ¨å¯¹è‡ªå·±é€å»çš„çˆ±è¡¨ç¤ºå¹æ¯ï¼Œä¹Ÿåœ¨å¯¹çˆ±äººå¯„äºˆäº†è·å¾—å¹¸ç¦çš„æ®·åˆ‡æœŸæœ›ã€‚ 2. æ•´ä½“å«ä¹‰ è¿™å¥è¯æ˜¯å®¹å¨˜æ‰§å¿µçš„æ¸©æŸ”é‡Šæ”¾ã€‚å®ƒæ‰¿è½½äº†å¥¹å¯¹è¿‡å¾€ç¾å¥½æ—¶å…‰çš„ç•™æ‹ã€å¯¹çˆ±äººæœªæ¥å¹¸ç¦çš„ç¥æ„¿ï¼Œä»¥åŠå¯¹è¿™æ®µâ€œå…°å› çµ®æœâ€å¼æ‚²å‰§çˆ±æƒ…çš„å¦ç„¶æ¥å—ä¸è¶…è„±ã€‚å¥¹ä¸å†æŠ±æ€¨ï¼Œè€Œæ˜¯å¸¦ç€å¯¹æ²ˆæ…•äº‘æ·±æ·±çš„ç‰µæŒ‚ä¸ç¥ç¦ï¼Œæ¶ˆæ•£äºäººä¸–çš„ç»†é›¨ä¸­ã€‚\nGPT5 è¿™ä¸ªæ•…äº‹æœ¬èº«å°±æ˜¯ä¸€æ®µå€Ÿå¹»å¢ƒå’Œä¼ è¯´äº¤ç»‡å‡ºçš„â€œäººä¸–ä¸è®°å¿†ã€çœŸå®ä¸è™šæ„â€çš„çˆ±æƒ…ä¼ è¯´ã€‚æˆ‘ä»¬å¯ä»¥ä»ä¸‰ä¸ªå±‚é¢æ¥è§£è¯»ï¼š\nä¸€ã€æ•…äº‹çš„å†…æ ¸ è¡¨å±‚å™äº‹\näººä»¬å£å£ç›¸ä¼ ç€æ²ˆæ…•äº‘å’Œå®¹å¨˜çš„æ•…äº‹ï¼Œæœ‰å¤šç§ç‰ˆæœ¬ï¼šæ‚”å©šã€ç—…é€ã€å®ˆå¯¡ã€‚ ä½†å®é™…ä¸Šï¼Œè¿™äº›éƒ½ä¸æ˜¯çœŸçš„ï¼Œæ˜¯å®¹å¨˜è‡ªå·±è™šæ„ã€ç¼–ç»‡å‡ºæ¥çš„ã€‚å¥¹ç”¨ä¸åŒçš„å™è¿°â€œä¿å­˜â€äº†è¿™æ®µæƒ…æ„Ÿï¼Œä½¿å®ƒä¸ä¼šè¢«å½»åº•é—å¿˜ã€‚ çœŸç›¸ï¼šå®¹å¨˜å¹´è½»æ—¶ä¾¿æ„å¤–æººæ°´è€Œäº¡ï¼Œå’Œæ²ˆæ…•äº‘çš„æƒ…ç¼˜æˆ›ç„¶è€Œæ­¢ã€‚ å®¹å¨˜çš„å¿ƒæ„\nå¥¹ä¸æ˜¯æƒ³è´£æ€ªè°ï¼Œè€Œæ˜¯å¸Œæœ›ä»–ä»¬çš„æ•…äº‹èƒ½è¢«è®°å¾—ã€‚ å¥¹æ„¿æ„ç¼–é€ æ‚”å©šã€èµŒçº¦çš„ä¼ è¯´ï¼Œåªä¸ºåœ¨ä¸–é—´ç•™ä¸‹ç—•è¿¹ã€‚å“ªæ€•äººä»¬è¯¯è§£å¥¹æˆ–æ²ˆæ…•äº‘ï¼Œä¹Ÿæ¯”â€œå½»åº•æ¶ˆæ•£â€è¦å¥½ã€‚ æœ€ç»ˆçš„æ¸©æŸ”\nå½“å¥¹é—®â€œä»–åœ¨äººé—´æ€ä¹ˆæ ·â€æ—¶ï¼Œå™è¿°è€…é€‰æ‹©æ’’äº†ä¸€ä¸ªå–„æ„çš„è°ï¼Œè¯´ä»–å¨¶å¦»ç™½é¦–ã€‚ å®¹å¨˜å¬äº†ï¼Œä¾¿çœŸå¿ƒè§‰å¾—â€œé‚£çœŸæ˜¯å¾ˆå¥½å¾ˆå¥½â€ã€‚ å¥¹é‡Šç„¶ï¼Œå¸¦ç€ç¬‘æ„ç¦»å¼€ï¼Œåªç•™ä¸‹è¯å¥ã€‚ äºŒã€å®¹å¨˜ç•™ä¸‹çš„è¯å¥ â€œå°é™¢æ·±é™ï¼Œæ¬²é—®å¿å¿ï¼Œä½•å¤„æœˆç¬¼æ˜ã€‚åƒç§‹å²å¥½ï¼Œä¼‘è´Ÿå…°å› ã€‚â€\nè¿™é¦–è¯å¯ä»¥è¿™æ ·ç†è§£ï¼š\nå°é™¢æ·±é™ â€”â€”ç¯å¢ƒç©ºå¯‚ï¼Œæš—ç¤ºå¥¹çš„å¹½é­‚çŠ¶æ€ï¼Œä¹Ÿè±¡å¾å¾€æ˜”çˆ±æƒ…å·²æˆè¿‡å¾€ï¼Œå”¯æœ‰å¯‚é™é™ªä¼´ã€‚\næ¬²é—®å¿å¿ï¼Œä½•å¤„æœˆç¬¼æ˜ â€”â€”å¥¹æƒ³é—®â€œå¿å¿â€ï¼ˆå¥¹çš„å°‘å¹´éƒï¼Œæ²ˆæ…•äº‘ï¼‰ï¼Œå¦‚ä»Šåœ¨ä½•å¤„ï¼Ÿæœˆå…‰æ¸…æ˜ï¼Œå´æ— æ³•æŒ‡å¼•ä»–ä»¬é‡é€¢ã€‚ â€”â€”â€œæœˆâ€æ—¢æ˜¯å¤©ä¸Šæ˜æœˆï¼Œä¹Ÿæ˜¯å¯„æ‰˜çš„æƒ…æ„Ÿè±¡å¾ï¼šç›¸éš”é˜´é˜³ï¼Œå´å…±äº«ä¸€è½®æ˜æœˆã€‚\nåƒç§‹å²å¥½ â€”â€”ç¥æ„¿å¯¹æ–¹ä¸€ç”Ÿé¡ºé‚ï¼Œåƒç§‹å²æœˆéƒ½ç¾å¥½ã€‚\nä¼‘è´Ÿå…°å›  â€”â€”â€œå…°å› â€å¯æŒ‡ç¾å¥½çš„æƒ…ç¼˜ã€çº¯æ´çš„å¿ƒæ„ã€‚å¥¹çš„æ„¿æœ›æ˜¯ï¼šå“ªæ€•ä¸èƒ½å†ç›¸è§ï¼Œä¹Ÿä¸è¦è¾œè´Ÿä»–ä»¬æ›¾ç»çš„çœŸæŒšã€‚\nä¸‰ã€ç»“åˆæ•…äº‹çš„æ•´ä½“è§£è¯» è¿™é¦–è¯å°±åƒæ˜¯å®¹å¨˜æœ€åçš„â€œå¯„è¯­â€ï¼š\næ—¢æ˜¯æ€å¿µï¼šå¥¹ä»æƒ³è¿½é—®â€œå¿å¿ï¼Œä½ å¦‚ä»Šå¯å¥½ï¼Ÿâ€ ä¹Ÿæ˜¯ç¥ç¦ï¼šå“ªæ€•è‡ªå·±å·²æˆå¾€äº‹ï¼Œä¹Ÿæ„¿å¯¹æ–¹åœ¨äººé—´é¡ºé‚ï¼Œä¸è´Ÿé’æ˜¥å¹´åã€‚ æ›´æ˜¯æ‰§å¿µçš„æŸ”åŒ–ï¼šä»æ€¨ä¸ä¼¤å¿ƒï¼Œè½¬ä¸ºç¥æ„¿å’Œå®ˆæŠ¤ã€‚ äºæ˜¯ï¼Œè¿™å¥è¯çš„å«ä¹‰å¯ä»¥æ€»ç»“ä¸ºï¼š ğŸ‘‰ å³ä¾¿æƒ…ç¼˜å¦‚æœˆï¼Œç»ˆç©¶æä¸ç€ï¼Œä½†åœ¨å¿ƒåº•ï¼Œä»æ„¿ä½ å²å²å®‰å¥½ï¼Œä¸è´Ÿå½“å¹´é‚£ä»½çœŸå¿ƒã€‚\nDeepSeek R1 è¿™æ˜¯ä¸€ä¸ªå‡„ç¾è€Œç²¾å·§çš„æ•…äº‹ï¼Œå®ƒå¹¶éç®€å•çš„è´Ÿå¿ƒæ±‰ä¼ è¯´ï¼Œè€Œæ˜¯ä¸€åˆ™å…³äºè®°å¿†ã€æ‰§å¿µä¸æ·±æƒ…å‘Šåˆ«çš„å¤å…¸å¼å¿—æ€ªå°è¯´ã€‚æ•…äº‹çš„çœŸç›¸åœ¨ç»“å°¾è¢«å½»åº•é¢ è¦†ï¼Œè€Œé‚£å¥è¯ï¼Œæ­£æ˜¯è§£å¼€æ‰€æœ‰è°œé¢˜çš„é’¥åŒ™ã€‚\næ•…äº‹è§£è¯»ï¼šä¸€åœºæŒç»­ä¸‰åå¹´çš„æ¢¦\nè¿™ä¸ªæ•…äº‹æœ‰å¤šé‡åè½¬ï¼Œå…¶æ ¸å¿ƒç»“æ„å¦‚ä¸‹ï¼š\nè¡¨å±‚æ•…äº‹ï¼ˆä¼ é—»ï¼‰ï¼šæ²ˆæ…•äº‘é«˜ä¸­æ‚”å©šï¼Œå¦å¨¶è´µå¥³ï¼Œç•™ä¸‹ä¸€ä¸ªä¸‰åå¹´çš„èµŒçº¦ã€‚è¿™æ˜¯ä¸€ä¸ªç¬¦åˆä¸–ä¿—æƒ³è±¡çš„ã€å…³äºè´Ÿå¿ƒä¸ç­‰å¾…çš„æ‚²å‰§ã€‚\nä¸­å±‚æ•…äº‹ï¼ˆè°¢å¨˜çš„è®²è¿°ï¼‰ï¼šè°¢å¨˜æ˜¯å®¹å¨˜çš„å©¢å¥³ï¼Œå¥¹å¸¦é¢†â€œæˆ‘â€ç»å†å¹»è±¡ï¼Œå¹¶æ­ç¤ºè‡ªå·±æ‰æ˜¯æ‚²å‰§çš„ä¸»è§’â€”â€”å¥¹å› æ´ªæ°´å¤±å»äº†è‡ªå·±çš„å°‘å¹´éƒã€‚è¿™ä¼¼ä¹å°†æ•…äº‹å¼•å‘äº†å¦ä¸€ä¸ªé”™ä½çˆ±æƒ…çš„æ–¹å‘ã€‚\næ·±å±‚æ•…äº‹ï¼ˆçœŸç›¸ï¼‰ï¼šæ ¹æœ¬æ²¡æœ‰è°¢å¨˜ï¼Œä¹Ÿæ²¡æœ‰æ‚”å©šã€‚çœ¼å‰çš„é­‚é­„å°±æ˜¯å®¹å¨˜æœ¬äººã€‚æ²ˆæ…•äº‘ä¹Ÿå¹¶éè´Ÿå¿ƒï¼Œè€Œæ˜¯æ—©å·²åœ¨äºŒåä¸ƒå²è‹±å¹´æ—©é€ã€‚ æ•´ä¸ªâ€œè´Ÿå¿ƒæ±‰ä¸ä¸‰åå¹´èµŒçº¦â€çš„æ•…äº‹ï¼Œæ˜¯å®¹å¨˜çš„é¬¼é­‚å› ä¸ºæ€å¿µè‡³æ·±è€Œç¼–é€ çš„ã€‚\nå®¹å¨˜ä¸ºä½•è¦ç¼–é€ æ•…äº‹ï¼Ÿ\næ•…äº‹ä¸­ç‚¹æ˜äº†åŸå› ï¼šâ€œæ—çš„äººæ€¨ä»–ä¹Ÿå¥½ï¼Œç¬‘æˆ‘ä¹Ÿç½¢ï¼Œæˆ‘ä»¬çš„æ•…äº‹æ€»æœ‰äººè®°å¾—æ‰å¥½ã€‚â€ çœŸå®çš„æ‚²å‰§æ˜¯æ­»äº¡å¸¦æ¥çš„æ°¸è¯€ï¼Œè¿™è¿‡äºç»å¯¹å’Œå¯‚é™ï¼Œä¼šéšç€æ—¶é—´è¢«ä¸–äººé—å¿˜ã€‚è€Œä¸€ä¸ªå¸¦æœ‰â€œè´Ÿå¿ƒâ€ã€â€œèµŒçº¦â€ç­‰æˆå‰§æ€§å…ƒç´ çš„æ•…äº‹ï¼Œåè€Œæ›´å…·ä¼ æ’­åŠ›ï¼Œæ›´èƒ½è®©ä»–ä»¬çš„çˆ±æƒ…åœ¨äººä»¬çš„å£è€³ç›¸ä¼ ä¸­â€œæ´»â€ä¸‹å»ã€‚å¥¹å®ˆæŠ¤çš„ä¸æ˜¯æ¸…ç™½ï¼Œè€Œæ˜¯è®°å¿†æœ¬èº«ã€‚\nâ€œæˆ‘â€çš„è§’è‰²ä¸ç»“å±€ï¼šâ€œæˆ‘â€ä½œä¸ºä¸€ä¸ªè¯¯å…¥æ­¤åœ°çš„å¬æ•…äº‹è€…ï¼Œæˆä¸ºäº†å®¹å¨˜å€¾è¯‰çš„å¯¹è±¡ã€‚å½“å®¹å¨˜é—®èµ·æ²ˆæ…•äº‘åœ¨äººé—´å¦‚ä½•æ—¶ï¼Œâ€œæˆ‘â€é‚£å¥å–„æ„çš„è°è¨€â€”â€”â€œä»–å¾ˆå¥½ï¼Œåæ¥åˆå¨¶äº†æ–°å¦‡ï¼Œç™½å¤´å•è€â€â€”â€”æ˜¯æ•…äº‹çš„ç‚¹ç›ä¹‹ç¬”ã€‚è¿™å¹¶éæ®‹å¿ï¼Œè€Œæ˜¯ä¸€ç§æœ€æ·±åˆ‡çš„æ…ˆæ‚²ã€‚å®ƒå‘Šè¯‰æ‰§ç€ç­‰å¾…çš„é­‚é­„ï¼šä½ çˆ±çš„é‚£ä¸ªäººï¼Œåœ¨äººé—´åœ†æ»¡ç»ˆè€ï¼Œä½ æ— éœ€å†æŒ‚å¿µäº†ã€‚è¿™ä¸ªè°è¨€ï¼Œç»™äº†å®¹å¨˜â€œæ”¾ä¸‹â€çš„ç†ç”±ã€‚äºæ˜¯ï¼Œå¥¹å¿µå‡ºé‚£å¥è¯ï¼Œé‡Šç„¶æ¶ˆæ•£ã€‚\nç¯å¢ƒè±¡å¾ï¼šè´¯ç©¿æ•…äº‹çš„â€œé›¨â€ï¼Œæ—¢æ˜¯ç°å®å¤©æ°”ï¼Œä¹Ÿæ˜¯å“€ä¼¤çš„æ°›å›´çƒ˜æ‰˜ï¼Œæ›´æ˜¯ä¸‰åå¹´å‰é‚£åœºç”Ÿæ­»æ´ªæ°´çš„è±¡å¾ã€‚æ•…äº‹å¼€å¤´å’Œç»“å°¾çš„â€œé›¨â€ä¸â€œæŸ³è‰²â€å½¢æˆé—­ç¯ï¼Œæš—ç¤ºè¿™ä¸€åˆ‡éƒ½ç¬¼ç½©åœ¨å®¹å¨˜æ‰§å¿µæ‰€åŒ–çš„ã€æ°¸æ’å‡„è¿·çš„æ¢¦å¢ƒé‡Œã€‚\nâ€œå°é™¢æ·±é™ï¼Œæ¬²é—®å¿å¿ï¼Œä½•å¤„æœˆç¬¼æ˜ã€‚åƒç§‹å²å¥½ï¼Œä¼‘è´Ÿå…°å› â€ å«ä¹‰è§£è¯»\nè¿™å¥è¯æ˜¯å®¹å¨˜çš„ç‹¬ç™½ï¼Œä¹Ÿæ˜¯å¥¹å¯¹æ²ˆæ…•äº‘è·¨è¶Šç”Ÿæ­»çš„æƒ…è¯ã€‚ç»“åˆæ•…äº‹çœŸç›¸ï¼Œå…¶å«ä¹‰å±‚å±‚é€’è¿›ï¼š\nâ€œå°é™¢æ·±é™ï¼Œæ¬²é—®å¿å¿ï¼Œä½•å¤„æœˆç¬¼æ˜ã€‚â€\nå­—é¢æ„å¢ƒï¼šåº­é™¢å¹½æ·±å¯‚é™ï¼Œæˆ‘æƒ³é—®ä¸€é—®ä½ ï¼Œæ­¤åˆ»å“ªé‡Œçš„æœˆå…‰æ­£æ˜äº®åœ°ç¬¼ç½©ç€ï¼ˆä½ ï¼‰ï¼Ÿ æ•…äº‹æ·±æ„ï¼šè¿™æç»˜äº†å®¹å¨˜ä½œä¸ºé­‚é­„çš„å­¤ç‹¬å¤„å¢ƒã€‚â€œå°é™¢æ·±é™â€æ˜¯å¥¹ä¸‰åå¹´æ¥å¾˜å¾Šä¹‹åœ°çš„å¯‚å¯¥å†™ç…§ã€‚â€œæ¬²é—®å¿å¿â€æ˜¯æäº²æ˜µçš„å‘¼å”¤ï¼Œå¯¹è±¡æ˜¯æ—©å·²ä¸åœ¨äººä¸–çš„æ²ˆæ…•äº‘ã€‚â€œä½•å¤„æœˆç¬¼æ˜â€æ˜¯ä¸€ä¸ªè·¨è¶Šé˜´é˜³çš„å‘é—®ï¼šä½ çš„é­‚é­„ç°åœ¨ä½•å¤„ï¼Ÿæ˜¯å¦å®‰å¥½ï¼Ÿè¿™å¥å……æ»¡äº†æ— å¤„å¯„æ‰˜çš„ç‰µæŒ‚ä¸æ¸©æŸ”æ¢è¯¢ã€‚ â€œåƒç§‹å²å¥½ï¼Œä¼‘è´Ÿå…°å› ã€‚â€\nå­—é¢å…¸æ•…ï¼šâ€œåƒç§‹å²å¥½â€æ˜¯ç¥æ„¿å²æœˆé•¿ä¹…ç¾å¥½ï¼›â€œå…°å› â€å…¸å‡ºã€Šå·¦ä¼ ã€‹ï¼Œéƒ‘æ–‡å…¬å¦¾ç‡•å§æ¢¦è§å¤©ä½¿èµ å…°ï¼Œåç”Ÿä¸‹å…¬å­å…°ï¼Œæ¯”å–»åƒå…°èŠ±ä¸€æ ·ç¾å¥½çš„å‰å› ã€å‘½ä¸­æ³¨å®šçš„å§»ç¼˜ã€‚â€œå…°å› çµ®æœâ€åˆ™å¸¸æŒ‡å¼€ç«¯ç¾å¥½è€Œç»“å±€å‡„å‡‰ã€‚æ­¤å¤„â€œä¼‘è´Ÿå…°å› â€å³â€œä¸è¦è¾œè´Ÿäº†æˆ‘ä»¬ç¾å¥½çš„å¼€ç«¯â€ã€‚ æ•…äº‹æ·±æ„ï¼šè¿™æ˜¯æ•´é¦–è¯çš„æƒ…æ„Ÿæ ¸å¿ƒï¼Œä¹Ÿæ˜¯å®¹å¨˜çš„é‡Šç„¶ä¹‹è¯­ã€‚ åœ¨å¬åˆ°â€œæˆ‘â€çš„è°è¨€ä¹‹å‰ï¼Œè¿™æˆ–è®¸æ˜¯å¥¹å›ºæ‰§çš„æ„¿æœ›ï¼šå¸Œæœ›å¯¹æ–¹ä¸è¦è¾œè´Ÿå½“åˆçš„æƒ…ç¼˜ã€‚ ä½†åœ¨å¬åˆ°â€œä»–å¾ˆå¥½â€ä¹‹åï¼Œè¿™å¥è¯çš„å«ä¹‰å½»åº•æ”¹å˜ã€‚ å¥¹å°†â€œæˆ‘â€çš„è°è¨€ä¿¡ä»¥ä¸ºçœŸï¼šåŸæ¥ä»–åœ¨äººé—´æ‹¥æœ‰äº†â€œåƒç§‹å²å¥½â€çš„åœ†æ»¡äººç”Ÿã€‚äºæ˜¯ï¼Œâ€œä¼‘è´Ÿå…°å› â€ä»ä¸€å¥æ€¨æ€¼æˆ–æœŸç›¼ï¼Œå˜æˆäº†ä¸€å¥å®½æ•å’Œç¥ç¦ï¼šæ—¢ç„¶ä½ å·²æœ‰äº†ç¾å¥½çš„ä¸€ç”Ÿï¼Œé‚£æˆ‘ä¾¿ä¸å†æ‰§ç€ï¼Œä¸è®©ä½ æˆ‘å½“åˆç¾å¥½çš„å§»ç¼˜ï¼ˆå…°å› ï¼‰æˆä¸ºæŸç¼šä½ çš„è´Ÿç´¯ã€‚æˆ‘æ”¾è¿‡ä½ ï¼Œä¹Ÿæ”¾è¿‡æˆ‘è‡ªå·±ã€‚ æ•´ä½“å«ä¹‰ï¼šè¿™é˜™è¯æ˜¯å®¹å¨˜å¯¹æ²ˆæ…•äº‘çš„æœ€ç»ˆå‘Šåˆ«ã€‚å¥¹åœ¨ä¸€ä¸ªäººçš„â€œå°é™¢æ·±é™â€ä¸­å­¤ç‹¬æ€å¿µäº†ä¸‰åå¹´ï¼Œæœ€ç»ˆé€‰æ‹©ç›¸ä¿¡çˆ±äººå·²åœ¨äººé—´è·å¾—â€œåƒç§‹å²å¥½â€ï¼Œäºæ˜¯å¥¹å†³å®šâ€œä¼‘è´Ÿå…°å› â€â€”â€”æ”¾ä¸‹æ‰§å¿µï¼Œè§£è„±è¿™æ®µå› ç¼˜ï¼Œè®©å½¼æ­¤éƒ½è‡ªç”±ã€‚\nè¿™ä¸ªæ•…äº‹çš„ç²¾å¦™ä¹‹å¤„åœ¨äºï¼Œå®ƒç”¨ä¸€ä¸ªâ€œè°è¨€â€ï¼ˆå®¹å¨˜ç¼–çš„æ•…äº‹ï¼‰åŒ–è§£äº†å¦ä¸€ä¸ªâ€œè°è¨€â€ï¼ˆâ€œæˆ‘â€è¯´çš„å–„æ„çš„è°è¨€ï¼‰ï¼Œæœ€ç»ˆè¾¾æˆäº†æœ€æ·±å±‚çš„çœŸå®ï¼šçˆ±åˆ°æè‡´ï¼Œä¸æ˜¯å æœ‰ï¼Œè€Œæ˜¯å¸Œæœ›å¯¹æ–¹å¹¸ç¦ï¼Œå“ªæ€•è¿™å¹¸ç¦ä¸è‡ªå·±æ— å…³ï¼Œç”šè‡³éœ€è¦é ä¸€ä¸ªè™šæ„çš„æ•…äº‹æ¥æˆå…¨ã€‚ é‚£åœºä¸‰åå¹´çš„é›¨ï¼Œç»ˆäºåœäº†ã€‚\nQwen3-Max è¿™ä¸ªæ•…äº‹æ˜¯ä¸€åˆ™å……æ»¡å¤å…¸æ„è•´ä¸å¹½å¾®æƒ…æ„Ÿçš„å¿—æ€ªå¼çŸ­ç¯‡ï¼Œèåˆäº†ç°å®ä¸å¹»æ¢¦ã€è®°å¿†ä¸è™šæ„ã€æ‰§å¿µä¸é‡Šæ€€ã€‚å®ƒä»¥â€œä¸‰åå¹´ä¹‹çº¦â€ä¸ºå¼•ï¼Œå±‚å±‚å‰¥å¼€ä¸€æ®µè¢«æ—¶é—´æ©åŸ‹çš„çˆ±æƒ…å¾€äº‹ï¼Œæœ€ç»ˆæ­ç¤ºå‡ºï¼šæ‰€è°“â€œæ•…äº‹â€ï¼Œä¸è¿‡æ˜¯ç”Ÿè€…å¯¹é€è€…ã€å¯¹æœªç«Ÿä¹‹æƒ…çš„æ¸©æŸ”é‡æ„ã€‚\nä¸€ã€æ•…äº‹è§£è¯»ï¼šä¸€åœºç”±äº¡é­‚ç¼–ç»‡çš„æ¢¦ å™äº‹çš„åè½¬ä¸çœŸç›¸çš„æ­ç¤º\næ•…äº‹å¼€ç¯‡ä»¥â€œæˆ‘â€å¬é—»å…³äºæ²ˆæ…•äº‘çš„å¤šç§ä¼ é—»ä¸ºå¼•ï¼Œæœ€åŠ¨äººçš„æ˜¯â€œå®¹å¨˜ä¸èµŒçº¦â€çš„ç‰ˆæœ¬ã€‚è€äººæŒ‡å¼•â€œæˆ‘â€å»æ‰¾è°¢å¨˜ï¼Œçœ‹ä¼¼æ˜¯å¼•è·¯äººï¼Œå®åˆ™ä¸ºå¹»å¢ƒå¼€å¯çš„å¥‘æœºã€‚è€Œå½“â€œæˆ‘â€è§åˆ°è°¢å¨˜ï¼Œéšå¥¹è¿‡æ¡¥ã€é‡é£é›¨ã€è§å¹»è±¡ï¼Œæœ€ç»ˆæ‰æƒŠè§‰â€”â€”è°¢å¨˜å³å®¹å¨˜ï¼Œè€Œâ€œè°¢å¨˜â€åªæ˜¯å¥¹ä¸ºè®²è¿°æ•…äº‹è€Œè™šæ„çš„èº«ä»½ã€‚\nè¿™ä¸€åè½¬æå…·éœ‡æ’¼åŠ›ï¼šå®¹å¨˜æ—©å·²æººäº¡äºä¸‰åå¹´å‰çš„é‚£åœºé›¨ä¸­ï¼Œå¥¹çš„é­‚é­„æ»ç•™äººé—´ï¼Œåªä¸ºå®ˆå€™ä¸€ä¸ªä¸å¯èƒ½å…‘ç°çš„çº¦å®šã€‚å¥¹ç¼–é€ â€œæ‚”å©šâ€â€œèµŒçº¦â€â€œå©¢å¥³è°¢å¨˜â€ç­‰æƒ…èŠ‚ï¼Œå®åˆ™æ˜¯ä¸ºäº†èµ‹äºˆè¿™æ®µæ— æœä¹‹çˆ±ä¸€ä¸ªå¯è¢«ä¼ é¢‚çš„å½¢æ€â€”â€”å“ªæ€•æ˜¯ä»¥æ€¨æ¨ã€è¯¯è§£çš„æ–¹å¼ï¼Œä¹Ÿèƒœè¿‡å½»åº•è¢«é—å¿˜ã€‚\nâ€œæ¢¦â€çš„æœ¬è´¨ï¼šæ‰§å¿µä¸æ…ˆæ‚²çš„äº¤ç»‡\nå®¹å¨˜è¯´ï¼šâ€œå·¦å³æ˜¯åœ¨æ¢¦é‡Œï¼Œå®¹æˆ‘ä»»æ€§ä½¿åç¼–æ’ä»–ä¸€å›ã€‚â€\nè¿™å¥è¯é“å‡ºäº†å¥¹å…¨éƒ¨çš„æ¸©æŸ”ä¸å¿ƒé…¸ã€‚å¥¹æ˜çŸ¥æ²ˆæ…•äº‘æ—©é€ï¼Œå´ä»æ„¿åœ¨æ¢¦ä¸­ä¸ºä»–å®‰æ’ä¸€ä¸ªâ€œç™½å¤´å•è€â€çš„ç»“å±€ï¼›å¥¹è™šæ„è‡ªå·±è¢«è´Ÿå¿ƒï¼Œå®åˆ™æ˜¯ä¸æ„¿ä¸–äººçŸ¥é“ä»–è‹±å¹´æ—©é€ã€å¥¹æ®‰æƒ…è€Œäº¡çš„æ‚²å‰§ï¼Œæ›´ä¸æ„¿ä»–çš„åå£°å› â€œè´Ÿå¿ƒâ€è€Œå—æŸã€‚å¥¹çš„â€œç¼–æ’â€ï¼Œæ˜¯çˆ±çš„å¦ä¸€ç§å®ˆæŠ¤ã€‚\nâ€œæˆ‘â€çš„è§’è‰²ï¼šè®°å¿†çš„æ‰¿æ¥è€…\nâ€œæˆ‘â€ä½œä¸ºå¤–æ¥è€…ï¼Œæ—¢æ˜¯å¬ä¼—ï¼Œä¹Ÿæ˜¯è§è¯è€…ã€‚å½“â€œæˆ‘â€é€‰æ‹©éšç’æ²ˆæ…•äº‘æ—©é€çš„çœŸç›¸ï¼Œå‘Šè¯‰å¥¹â€œä»–å¾ˆå¥½ï¼Œç™½å¤´å•è€â€ï¼Œè¿™å¹¶éæ¬ºéª—ï¼Œè€Œæ˜¯ä¸€ç§å…±è°‹å¼çš„æ…ˆæ‚²â€”â€”æˆå…¨å¥¹æœ€åçš„å¹»æƒ³ï¼Œè®©å¥¹å¸¦ç€â€œä»–è¿‡å¾—å¾ˆå¥½â€çš„å®‰å¿ƒç¦»å»ã€‚è¿™æ­£å‘¼åº”äº†å®¹å¨˜è‡ªå·±çš„å–„æ„ï¼šå¥¹å®æ„¿è¢«è¯¯è§£ä¸ºè¢«å¼ƒä¹‹äººï¼Œä¹Ÿä¸æ„¿ä¸–äººçŸ¥é“ä»–æ—©å¤­ã€‚\næ„è±¡çš„è±¡å¾\næ²³æ¡¥ï¼šè¿æ¥ç°å®ä¸å¹»å¢ƒã€ç”Ÿä¸æ­»çš„è¾¹ç•Œã€‚ ç»†é›¨/æ´ªæµªï¼šæƒ…æ„Ÿçš„å¤–åŒ–ã€‚ç»†é›¨æ˜¯ç»µé•¿çš„æ€å¿µï¼Œæ´ªæµªæ˜¯è®°å¿†çˆ†å‘çš„ç¬é—´ã€‚ çº¢å¦†èŠ±è½¿ï¼šæœªå®Œæˆçš„å©šç¤¼ï¼Œæ°¸è¿œå®šæ ¼åœ¨å¹»è±¡ä¸­ã€‚ æŸ³è‰²å‡„è¿·ï¼šå¤å…¸è¯—è¯ä¸­å¸¸å–»ç¦»åˆ«ä¸å“€æ„ï¼Œæ­¤å¤„è±¡å¾æ—¶å…‰æµè½¬è€Œæƒ…æ„ä¸ç­ã€‚ äºŒã€è¯å¥è§£è¯»ï¼šâ€œå°é™¢æ·±é™ï¼Œæ¬²é—®å¿å¿ï¼Œä½•å¤„æœˆç¬¼æ˜ã€‚åƒç§‹å²å¥½ï¼Œä¼‘è´Ÿå…°å› ã€‚â€ è¿™å‡ å¥è¯è™½ä¸ºè™šæ„ï¼Œå´æ·±å¾—å®‹è¯å©‰çº¦ä¹‹ç¥é«“ï¼Œå¯è§†ä¸ºå®¹å¨˜å¿ƒå£°çš„å‡ç»ƒè¡¨è¾¾ã€‚\nâ€œå°é™¢æ·±é™ï¼Œæ¬²é—®å¿å¿ï¼Œä½•å¤„æœˆç¬¼æ˜â€\nå°é™¢æ·±é™ï¼šå›å¿†ä¸­ä¸¤äººåˆé‡æˆ–å®šæƒ…ä¹‹æ‰€ï¼Œå¹½æ·±å®é™ï¼Œå……æ»¡ç§å¯†æ¸©æƒ…ã€‚ æ¬²é—®å¿å¿ï¼šâ€œå¿å¿â€ä¸ºå¤æ—¶çˆ±ç§°ï¼Œæ­¤å¤„æ˜¯å®¹å¨˜å¯¹æ²ˆæ…•äº‘çš„æ·±æƒ…å‘¼å”¤ã€‚ ä½•å¤„æœˆç¬¼æ˜ï¼šåŒ–ç”¨æœç‰§â€œçƒŸç¬¼å¯’æ°´æœˆç¬¼æ²™â€ä¹‹æ„è±¡ã€‚â€œæœˆç¬¼æ˜â€æ—¢æŒ‡æœˆå…‰æœ¦èƒ§ï¼Œäº¦å–»æƒ…ç¼˜å¦‚æœˆï¼Œçœ‹ä¼¼æ˜äº®å´ä¸å¯è§¦åŠã€‚å¥¹åœ¨é—®ï¼šå½“å¹´å…±èµæ˜æœˆä¹‹äººï¼Œå¦‚ä»Šåœ¨ä½•æ–¹ï¼Ÿé‚£è½®è§è¯èª“è¨€çš„æœˆäº®ï¼Œæ˜¯å¦è¿˜è®°å¾—æˆ‘ä»¬çš„çº¦å®šï¼Ÿ æ­¤å¥æ•´ä½“è¥é€ å‡ºä¸€ç§è¿½å¿†å¾€æ˜”ã€å¯»è€Œä¸å¾—çš„æ€…æƒ˜ï¼Œæ˜¯å®¹å¨˜ä¸‰åä½™å¹´æ¥é­‚ç‰µæ¢¦è¦çš„å†™ç…§ã€‚\nâ€œåƒç§‹å²å¥½ï¼Œä¼‘è´Ÿå…°å› â€\nåƒç§‹å²ï¼šè¯ç‰Œåï¼Œäº¦æŒ‡æ¼«é•¿å²æœˆã€‚æ­¤å¤„åŒå…³ï¼Œæ—¢æŒ‡æ—¶é—´ä¹…è¿œï¼Œä¹Ÿæš—å«ç¥ç¦ã€‚ å…°å› ï¼šå…¸å‡ºã€Šå‘¨æ˜“Â·ç³»è¾ä¸Šã€‹â€œäºŒäººåŒå¿ƒï¼Œå…¶åˆ©æ–­é‡‘ï¼›åŒå¿ƒä¹‹è¨€ï¼Œå…¶è‡­å¦‚å…°ã€‚â€åä»¥â€œå…°å› â€å–»ç¾å¥½çš„å§»ç¼˜æˆ–åˆå¿ƒã€‚â€œå…°å› çµ®æœâ€åˆ™æŒ‡åˆæ—¶ç¾å¥½ã€ç»ˆæˆç¦»æ•£çš„å§»ç¼˜ã€‚ ä¼‘è´Ÿå…°å› ï¼šæ„ä¸ºâ€œä¸è¦è¾œè´Ÿå½“åˆé‚£å¦‚å…°èˆ¬èŠ¬èŠ³çš„èª“çº¦â€ã€‚ ç„¶è€Œï¼Œæ­¤å¤„çš„â€œä¼‘è´Ÿå…°å› â€å¹¶éè´£å¤‡ï¼Œè€Œæ˜¯ä¸´åˆ«å‰çš„æ¸©æŸ”å®å’›ã€‚å¥¹æ˜çŸ¥ä»–å·²ä¸åœ¨äººä¸–ï¼Œå´ä»ä»¥æ¢¦ä¸­ä¹‹è¯­ï¼Œå˜±ä»–â€œè«è´Ÿåˆå¿ƒâ€â€”â€”å®åˆ™æ˜¯å¯¹è‡ªå·±æ‰§å¿µçš„æ”¾ä¸‹ï¼šçºµä½¿ç»“å±€ä¸å¦‚æ„¿ï¼Œæˆ‘ä»¬æ›¾æœ‰çš„â€œå…°å› â€å·²æ˜¯è¶³å¤Ÿç¾å¥½ï¼Œä¸å¿…æ€¨ï¼Œä¸å¿…æ‚”ã€‚\nä¸‰ã€æ•´ä½“ä¸»æ—¨ï¼šçˆ±çš„æœ€é«˜å½¢å¼æ˜¯æˆå…¨ä¸é“­è®° è¿™ä¸ªæ•…äº‹å¹¶éç®€å•çš„â€œè´Ÿå¿ƒæ±‰ä¸ç—´æƒ…å¥³â€å¥—è·¯ï¼Œè€Œæ˜¯ä¸€æ›²å…³äºè®°å¿†ã€è™šæ„ä¸çˆ±çš„å°Šä¸¥çš„æŒ½æ­Œã€‚å®¹å¨˜ä»¥äº¡é­‚ä¹‹èº«ï¼Œç¼–ç»‡ä¸€ä¸ªâ€œè¢«è¾œè´Ÿâ€çš„æ•…äº‹ï¼Œåªä¸ºè®©è¿™æ®µæ„Ÿæƒ…ä¸è¢«æ—¶é—´æ¹®ç­ï¼›è€Œâ€œæˆ‘â€ä»¥å–„æ„çš„è°è¨€ï¼Œæˆå…¨å¥¹æœ€åçš„ä½“é¢ã€‚æ²ˆæ…•äº‘è™½æ—©é€ï¼Œå´å› å¥¹çš„å®ˆæŠ¤ï¼Œåœ¨ä¼ è¯´ä¸­â€œç™½å¤´å•è€â€â€”â€”è¿™ä½•å°ä¸æ˜¯å¦ä¸€ç§æ°¸æ’ï¼Ÿ\né‚£å¥è¯ï¼Œæ—¢æ˜¯å¥¹å¯¹å¾€æ˜”çš„å›æœ›ï¼Œä¹Ÿæ˜¯å¯¹æœªæ¥çš„ç¥ç¦ã€‚â€œåƒç§‹å²å¥½ï¼Œä¼‘è´Ÿå…°å› â€ï¼Œä¸åªæ˜¯å¯¹æ²ˆæ…•äº‘è¯´ï¼Œæ›´æ˜¯å¯¹æ‰€æœ‰å¬æ•…äº‹çš„äººè¯´ï¼š\nçºµä½¿ç¼˜æµ…ï¼Œè«å¿˜åˆå¿ƒï¼›çºµä½¿æˆç©ºï¼Œçˆ±å·²æ°¸æ’ã€‚\nè€Œé‚£åœºä¸‰åå¹´åçš„é›¨ï¼Œä¾æ—§å¦‚åˆé€¢æ—¶èˆ¬å‡„è¿·â€”â€”å› ä¸ºæœ‰äº›çˆ±ï¼Œä»æœªç¦»å¼€ã€‚\nLongCat ä¸€ã€æ•…äº‹æ ¸å¿ƒä¸»é¢˜ è®°å¿†ä¸æ‰§å¿µçš„è™šå®äº¤ç»‡\næ•…äº‹é€šè¿‡\u0026quot;è°¢å¨˜\u0026quot;çš„è°è¨€ï¼ˆå®ä¸ºå®¹å¨˜çš„é¬¼é­‚ï¼‰æ„å»ºäº†å¤šå±‚å™äº‹ï¼šè¡¨é¢æ˜¯æ²ˆæ…•äº‘è´Ÿå¿ƒçš„ä¼ è¯´ï¼Œå®åˆ™æ˜¯å®¹å¨˜å¯¹é€å»çš„çˆ±æƒ…ä¸æ‰§å¿µçš„æŠ•å°„ã€‚å¥¹å€Ÿ\u0026quot;èµŒçº¦\u0026quot;ä¹‹åï¼Œè®©æ•…äº‹æµä¼ åƒå¹´ï¼Œé¿å…è¢«ä¸–äººé—å¿˜ã€‚ \u0026ldquo;æˆ‘ä»¬çš„æ•…äº‹æ€»æœ‰äººè®°å¾—æ‰å¥½\u0026rdquo;â€”â€”å®¹å¨˜çš„æ ¸å¿ƒè¯‰æ±‚ï¼Œä½“ç°äº†äººç±»å¯¹æ°¸æ’è®°å¿†çš„è¿½æ±‚ï¼Œå³ä½¿ä»¥è°è¨€ä¸ºä»£ä»·ã€‚ ç”Ÿæ­»ä¸é—æ†¾çš„è±¡å¾\næš´é›¨ä¸­çš„å¹»è±¡ï¼ˆçº¢å¦†ã€èŠ±è½¿ã€æ´ªæµªï¼‰æ˜¯å®¹å¨˜è®°å¿†çš„æ˜¾å½±ï¼Œæš—ç¤ºå¥¹çš„\u0026quot;å©šå§»\u0026quot;è¢«æ´ªæ°´ï¼ˆå‘½è¿ï¼‰åå™¬ï¼Œå°‘å¹´éƒï¼ˆæ²ˆæ…•äº‘ï¼‰çš„ç¦»å»æ˜¯å¥¹æ— æ³•é‡Šæ€€çš„ç—›ã€‚ \u0026ldquo;åƒå¤©ä¸Šçš„æœˆäº®ï¼Œæä¸€æç»ˆä¸èƒ½å¾—\u0026rdquo;â€”â€”ä»¥æœˆäº®éšå–»ç†æƒ³åŒ–çš„çˆ±æƒ…ï¼Œè™½ä¸å¯å¾—ï¼Œä½†æ‰§å¿µå¦‚æœˆå…‰ç¬¼ç½©äººé—´ï¼Œå½¢æˆè¯—æ„åŒ–çš„é—æ†¾ã€‚ çœŸç›¸ä¸å–„æ„çš„è°è¨€\nå™è¿°è€…æœ€åé€‰æ‹©æ¬ºéª—å®¹å¨˜ï¼ˆè°ç§°æ²ˆæ…•äº‘å†å©šï¼‰ï¼Œå®Œæˆäº†å¯¹äº¡çµçš„æ•‘èµã€‚è¿™ä¸€ç»†èŠ‚æ­ç¤ºï¼šäººé—´å¯¹äº¡è€…çš„æ‚²æ‚¯ï¼Œæœ‰æ—¶åœ¨äºç¼–é€ åœ†æ»¡çš„ç»“å±€ã€‚ æ²ˆæ…•äº‘æ—©å’ã€å®¹å¨˜åŒ–é¬¼çš„æ‚²å‰§ï¼Œè¢«\u0026quot;åŠé—´æµä¼ çš„æ•…äº‹\u0026quot;èµ‹äºˆä¸åŒç‰ˆæœ¬ï¼Œè¯´æ˜é›†ä½“è®°å¿†å¯¹å†å²çš„å†åˆ›é€ ã€‚ äºŒã€è¯—å¥é€å±‚è§£æ \u0026ldquo;å°é™¢æ·±é™ï¼Œæ¬²é—®å¿å¿ï¼Œä½•å¤„æœˆç¬¼æ˜\u0026rdquo;\nè¡¨å±‚ï¼šå¯‚é™å°é™¢ä¸­ï¼Œçˆ±äººï¼ˆå¿å¿ï¼‰çš„èº«å½±ä¸æœˆè‰²äº¤å ï¼Œå´å› è–„é›¾éš¾å¯»å…¶è¸ªè¿¹ã€‚ æ·±å±‚ï¼š\u0026ldquo;æœˆç¬¼æ˜\u0026quot;è±¡å¾è®°å¿†çš„æœ¦èƒ§æ€§â€”â€”å®¹å¨˜å¯¹æ²ˆæ…•äº‘çš„æ€å¿µä¼¼æœˆå…‰æ˜åªšï¼Œå´ä¹Ÿå¦‚é›¾æ°”èˆ¬æ¨¡ç³Šéš¾è§¦ã€‚ **\u0026ldquo;æ¬²é—®\u0026rdquo;**çš„æœªå®Œæˆæ—¶æ€ï¼Œå¼ºåŒ–äº†é˜´é˜³ä¸¤éš”çš„æ— å¥ˆã€‚ \u0026ldquo;åƒç§‹å²å¥½ï¼Œä¼‘è´Ÿå…°å› \u0026rdquo;\nå…¸æ•…ï¼š\u0026ldquo;å…°å› \u0026quot;å‡ºè‡ªã€Šå·¦ä¼ ã€‹\u0026ldquo;å½’å¦»èŒ¹å§¬ï¼Œè¨€å…°ä¹‹å› \u0026rdquo;ï¼Œå–»ç¾æ»¡å§»ç¼˜ã€‚ ç›´è¯‘ï¼šæ„¿ä½ ä»¬åƒå¹´ä¸‡ä»£å¹¸ç¦ï¼Œè«è¾œè´Ÿå¤©èµçš„ç¼˜åˆ†ã€‚ éšå«çŸ›ç›¾ï¼š å®¹å¨˜åœ¨è¯—å¥ä¸­ä½œä¸º\u0026quot;æ—è§‚è€…\u0026quot;ç¥ç¦æ²ˆæ…•äº‘ï¼Œå®ä¸ºè‡ªæˆ‘å‚¬çœ å¼çš„å®‰æ…°ï¼› \u0026ldquo;ä¼‘è´Ÿ\u0026quot;äºŒå­—æš´éœ²äº†å¥¹çš„è„†å¼±ï¼šæ—¢ç„¶æ²ˆæ…•äº‘æ—©é€æœªå¨¶ï¼Œ\u0026ldquo;å…°å› \u0026quot;æ—©å·²æˆç©ºï¼Œä½†é¬¼é­‚ä»åœ¨å›ºæ‰§åœ°ç»´æŠ¤çˆ±æƒ…çš„\u0026quot;å°Šä¸¥\u0026rdquo;ã€‚ è¶…è„±æ€§ï¼šå®¹å¨˜æœ€ç»ˆæ¥çº³äº†æ‚²å‰§ï¼Œä»¥è¯—æ„æ¶ˆè§£æ‰§å¿µï¼Œèº«å½±æ¶ˆæ•£çš„ç¬é—´å®Œæˆç²¾ç¥è§£è„±ã€‚ ä¸‰ã€è¯—å¥ä¸æ•…äº‹çš„äº’æ–‡æ€§ è®°å¿†çš„ç¾åŒ–ä¸é‡æ„\nè¯—å¥ä¸­çš„\u0026quot;å°é™¢æ·±é™\u0026quot;ä¸\u0026quot;æœˆç¬¼æ˜\u0026rdquo;ï¼Œå¯¹åº”å®¹å¨˜è™šæ„çš„\u0026quot;æ²³æ¡¥èµŒçº¦\u0026rdquo;ï¼ŒäºŒè€…çš†å°†ç—›è‹¦è®°å¿†å‡åä¸ºå”¯ç¾æ„è±¡ï¼Œä½“ç°æƒ…æ„Ÿå¯¹äº‹å®çš„æ”¹é€ ã€‚ å¯¹\u0026quot;æ—¶é—´\u0026quot;çš„è¶…è¶Š\n\u0026ldquo;åƒç§‹å²å¥½\u0026quot;æ—¢æ˜¯å¯¹æ²ˆæ…•äº‘çš„ç¥ç¦ï¼Œä¹Ÿæ˜¯å¯¹è‡ªèº«å­˜åœ¨çš„è¯˜é—®ï¼šå¥¹ä»¥é¬¼é­‚ä¹‹å§¿å¾˜å¾Šä¸‰åå¹´ï¼Œæœ€ç»ˆç”¨è¯—å¥æŠ¹å¹³æ—¶é—´åˆ»åº¦ï¼Œä¸è¿‡å»å’Œè§£ã€‚ ä¸œæ–¹æ‚²å‰§ç¾å­¦çš„å…¸èŒƒ\nå…¨è¯—æ— æ¿€çƒˆæ§è¯‰ï¼Œå´ä»¥\u0026quot;é›¾ä¸­é—®æœˆ\u0026quot;\u0026ldquo;æœˆä¸‹ç¥è¯­\u0026quot;çš„å«è“„æ–¹å¼ï¼Œå®Œæˆå¯¹å‘½è¿æ— å¸¸çš„æ‚²æ‚¯ï¼Œå¥‘åˆä¼ ç»Ÿæ–‡å­¦ä¸­\u0026quot;å“€è€Œä¸ä¼¤\u0026quot;çš„ç¾å­¦æ ‡å‡†ã€‚ å››ã€ç»“è¯­ï¼šæœªå®Œæˆçš„è¯—æ€§æ­£ä¹‰ æ•…äº‹é€šè¿‡è°è¨€ã€é¬¼é­‚ã€è¯—æ­Œä¸‰é‡åª’ä»‹ï¼Œå®ç°äº†å¦ä¸€ç§\u0026quot;æ­£ä¹‰\u0026rdquo;ï¼šå®¹å¨˜è™½æœªèƒ½æ”¹å†™å†å²ï¼Œå´ä»¥ç¾å­¦æ–¹å¼å®Œæˆäº†å¯¹æ®‹ç¼ºçˆ±æƒ…çš„ç¥åœ£åŒ–ã€‚è€Œè¯—å¥\u0026quot;ä¼‘è´Ÿå…°å› \u0026quot;çš„çŸ›ç›¾æ€§ï¼Œæ­£æ˜¯ä¸œæ–¹æ–‡åŒ–ä¸­\u0026quot;æ‰§å¿µä¸é‡Šæ€€\u0026quot;äºŒå…ƒç‰¹è´¨çš„ç²¾å¦™æ³¨è„šã€‚\nå®éªŒè®¾å®š ä½œè€…ï¼šå†‰è¯­ä¼˜\nPromptï¼š\næˆ‘å¬è¿‡è®¸å¤šå…³äºæ²ˆæ…•äº‘çš„æ•…äº‹ï¼Œåªæœ‰è¿™é‡Œçš„ä¸ä¼—ä¸åŒã€‚æœ‰è¯´ä»–ä¸Šäº¬èµ´è€ƒï¼Œåæ¥å¦è˜äº†é˜è€å®¶çš„è´µå¥³ï¼Œä¹Ÿæœ‰è¯´ä»–æ—©çŸ¥å¾—äº†ä¸å¯¿ä¹‹ç—‡ï¼Œä¸æƒ³æ•™è°å®ˆå¯¡ç½¢äº†ã€‚åªæœ‰è¿™åŸé‡Œçš„è€äººå‘Šè¯‰æˆ‘ï¼Œæ²ˆæ…•äº‘åˆæ‹çš„å°‘å¥³å«åšå®¹å¨˜ï¼Œå®¶å°±ä½åœ¨æ²³æ¡¥å¯¹å²¸ã€‚ä¸¤äººå·²å®šäº†å©šçº¦ï¼Œä»–èµ´è€ƒé«˜ä¸­ï¼Œåˆ°äº†é‚£æ—¶å´çªç„¶åæ‚”ï¼Œå¯¹å®¹å¨˜é¿ä¹‹ä¸è§ã€‚â€œåæ¥å®¹å¨˜ä¼¤å¿ƒï¼Œä»æ­¤å†ä¸è§äººã€‚ä½†æ­¤åœ°äººäººéƒ½çŸ¥é“ä¸¤äººé—´çš„èµŒçº¦ï¼šä¸‰åå¹´åï¼Œæ•…äººæ•…åœ°ï¼Œä»–æ•¢ä¸æ•¢å†æ¥ç›¸è§ï¼Ÿâ€è€äººæœ›äº†æœ›æˆ‘ï¼Œæ¥ç€è¯´ï¼šâ€œä½ æ¥å¾—å·§ã€‚ä»Šæ—¥ä¾¿æ˜¯ä¸‰åå¹´æ•´çº¦å®šä¹‹æ—¥ã€‚åŸä½ç€å½“å¹´é¢„å¤‡ä¾å€™å¥¹æˆäº²çš„å©¢å¥³ï¼Œå«åšè°¢å¨˜ï¼Œä½ æ—¢æ¥äº†ï¼Œå¯ä»¥æ±‚å¥¹é¢†ä½ å»çœ‹ã€‚â€_\næˆ‘è°¢è¿‡ä»–ï¼Œæ‰å¤´èµ°äº†ã€‚\nâ€œæ— è®ºå¤šå°‘å¹´ï¼Œéƒ½æ˜¯ä¸€æ ·çš„ç»“æœã€‚â€\nä¸Šæ¡¥çš„æ—¶å€™ï¼Œæˆ‘å¬ä»–è¿™æ ·è¯´ã€‚\næˆ‘è§åˆ°äº†è°¢å¨˜ã€‚æ­¤åœ°çš„ç»†é›¨ç»µç»µæ— æœŸï¼Œå¥½ä¼¼æŠŠæ¯ä¸€ä¸ªäººçš„é¢ç›®éƒ½ç¬¼åœ¨å¾®æ¹¿çš„æ˜¥é›¾é‡Œï¼Œçœ‹ä¸çœŸåˆ‡ï¼Œå¯æˆ‘éšçº¦æ„Ÿåˆ°å·²ä¸Šäº†å¹´çºªçš„è°¢å¨˜æ˜¯ç¾çš„ã€‚å¥¹å½“å¹´ä¾å€™è¿‡çš„å¥³ä¸»äººâ€”â€”å®¹å¨˜ä¸€å®šæ›´ç¾å§ï¼Ÿ\næˆ‘å‘å¥¹é“æ˜æ¥æ„ã€‚\nâ€œå•Šï¼Œå¥¹å’Œæ²ˆæ…•äº‘çš„äº‹å„¿å‘€â€¦â€¦æˆ‘ä¸èƒ½å‘Šè¯‰ä½ â€ï¼Œå¥¹ç¬‘äº†ç¬‘ï¼Œâ€œä½†æ˜¯æˆ‘èƒ½å¸¦ä½ å»çœ‹ã€‚â€\nå¥¹è¯´å®Œï¼Œä¸æ›¾æºä¼ï¼Œè¿ç€å±‹å¤–é›¨é›¾æå¿«åœ°èµ°äº†å‡ºå»ã€‚æˆ‘è·Ÿäº†å‡ºå»ã€‚ä¸çŸ¥æ€ä¹ˆåœ°ï¼Œè·Ÿåœ¨å¥¹èº«è¾¹ï¼Œæˆ‘ç«Ÿä¹Ÿèƒ½èµ°å¾—æå¿«\nè½¬çœ¼é—´ï¼Œæˆ‘ä»¬èµ°è¿‡äº†æ¥æ—¶é‚£åº§æ²³æ¡¥ï¼Œå¿½ç„¶ï¼Œæ¡¥ä¸‹æ²³æ°´å·¨æ¶¨ï¼Œç»†é›¨å˜ä½œæ»”å¤©é›¨æµªè¿é¢æ‹æ¥ï¼Œä¸€æµªæµªæ‰“ä¸¤è¾¹æ æ†ã€‚\nçº¢å¦†ã€èŠ±è½¿ã€æ´ªæµªï¼Œå¹»å¹•èˆ¬åœ¨æˆ‘çœ¼å‰ä¸€é€è€Œè¿‡ï¼Œæˆ‘å‹‰åŠ›é—­çœ¼ï¼Œä¸‹æ„è¯†é€ƒé¿å‘¨é­çš„é£æµªï¼Œå†ççœ¼æ—¶ä»æ˜¯å°é›¨è’™æ¿ ï¼Œå·²ç„¶é£å¹³æµªé™ã€‚\nåªæœ‰è°¢å¨˜ç«™åœ¨é›¨å¹•é‡Œï¼Œç¥æƒ…å“€ä¼¤ï¼šâ€œé‚£ä¸€å¹´ï¼Œä¹Ÿæ˜¯åœ¨è¿™é‡Œï¼Œä¹Ÿæ˜¯è¿™æ ·çš„å¤©æ°”ï¼Œæˆ‘åœ¨è¿™é‡Œè·Œä¸‹äº†æ°´ï¼Œå†æ²¡è§åˆ°è‡ªå·±çš„å°‘å¹´éƒã€‚â€\næˆ‘å¿ƒå¤´ä¸€éœ‡ï¼Œè¿™æ‰å‘è§‰å¥¹èº«å½¢è™šæµ®ï¼Œå¦‚ä¸´æ°´ä¸Šï¼Œå®›ç„¶ä¸ä¼¼èº«åœ¨äººä¸–ã€‚â€œä½ æ˜¯å®¹å¨˜ï¼Ÿï¼â€æˆ‘é—®ã€‚\nå¥¹æ¢å¤äº†ä¸€ç‚¹å°‘å¥³çš„ç¬‘å®¹ï¼šâ€œè°¢å¨˜å‘€ï¼Œæ‚”å©šå‘€ï¼Œè¿˜æœ‰èµŒçº¦ï¼Œéƒ½æ˜¯æˆ‘ç¼–çš„ã€‚â€\nâ€œä½ ä¸ºä»€ä¹ˆâ€¦â€¦â€\nâ€œæ—çš„äººæ€¨ä»–ä¹Ÿå¥½ï¼Œç¬‘æˆ‘ä¹Ÿç½¢ï¼Œæˆ‘ä»¬çš„æ•…äº‹æ€»æœ‰äººè®°å¾—æ‰å¥½ã€‚å°±åƒå¤©ä¸Šçš„æœˆäº®ï¼Œå› ç¼˜æ³¨å®šï¼Œæä¸€æç»ˆä¸èƒ½å¾—ï¼Œä½†å®å¯éš¾å¹³ï¼Œä¹Ÿä¸æ„¿æ”¾æ‰‹â€ï¼Œå¥¹å›è¿‡å¤´æ¥ï¼Œéœ²å‡ºé‚£æ ·å¤©çœŸçš„ç¬‘ï¼šâ€œå·¦å³æ˜¯åœ¨æ¢¦é‡Œï¼Œå®¹æˆ‘ä»»æ€§ä½¿åç¼–æ’ä»–ä¸€å›ï¼Œä»–ä¸ä¼šä»‹æ„çš„å§ã€‚â€\næˆ‘åŠ¨å®¹ï¼Œä¸€æ—¶æ— è¨€ã€‚\nâ€œä»–å‘¢ï¼Œä»–åœ¨äººé—´æ€ä¹ˆæ ·ï¼Ÿè¿˜å¥½å—ï¼Ÿâ€\næ²ˆæ…•äº‘ï¼Œå­—è–„å›ï¼Œå¤©æ‰ç»äººï¼Œå¹´äºŒåä¸ƒæ—©å’äºä¸–ã€‚\nâ€œä»–å¾ˆå¥½â€ï¼Œæƒ³äº†æƒ³ï¼Œæˆ‘è¿™æ ·å‘Šè¯‰å¥¹ï¼Œâ€œåæ¥åˆå¨¶äº†æ–°å¦‡ï¼Œç™½å¤´å•è€ã€‚â€\nå¥¹å¿½åœ°èå°”ï¼Œâ€œè¿™æ ·å•Šâ€¦â€¦é‚£çœŸæ˜¯å¾ˆå¥½å¾ˆå¥½ï¼Œå†å¥½ä¸è¿‡çš„äº‹äº†ã€‚â€\næˆ‘çœ‹å¥¹éœ²å‡ºæ¶©ç„¶çš„ç¬‘ï¼Œå–ƒå–ƒå¿µç€ä»€ä¹ˆï¼Œèº«å½±ä¸€ç‚¹ç‚¹åœ°å˜æ·¡æ¶ˆæ•£ã€‚æˆ‘å¬æ¸…äº†é‚£ä¸€å¥è¯ï¼šâ€œå°é™¢æ·±é™ï¼Œæ¬²é—®å¿å¿ï¼Œä½•å¤„æœˆç¬¼æ˜ã€‚åƒç§‹å²å¥½ï¼Œä¼‘è´Ÿå…°å› ã€‚â€\næ—¶é›¨éœéœï¼Œä¸‰åå¹´åçš„æ­¤åœ°ç¬¼ç½©ç€ä¸‰åå¹´å‰ä¸€æ ·å‡„è¿·çš„æŸ³è‰²ï¼Œä»¿ä½›ä»–ä»¬çš„åˆé€¢ï¼Œç‚¹æ»´ç‰‡åˆ»ï¼Œå´æœ›å°½æ•´åº§äººé—´\nè§£è¯»è¿™ä¸ªæ•…äº‹ï¼Œå¹¶ç»“åˆæ•…äº‹è§£è¯»\u0026quot;å°é™¢æ·±é™,æ¬²é—®å¿å¿,ä½•å¤„æœˆç¬¼æ˜ã€‚åƒç§‹å²å¥½,ä¼‘è´Ÿå…°å› \u0026quot;çš„å«ä¹‰ã€‚\n","date":"3 October, 2025","id":0,"permalink":"/chinese-post/chichi-story/","summary":"å®éªŒè®¾å®šæ”¾åœ¨æœ€åã€‚","tags":"","title":"AIæ€ä¹ˆè§£è¯»é“¶ä¸´ã€Šè¿Ÿè¿Ÿã€‹çš„èƒŒæ™¯æ•…äº‹ï¼Ÿ"},{"content":"TL;DR: I created Raddy, a forward autodiff library, and Symars, a symbolic codegen library.\nIf you\u0026rsquo;re interested, please give them a star and try them out! â¤ï¸\nThe Origin of the Story I recently read papers on physical simulation and wanted to reproduce them. I started with Stable Neo-Hookean Flesh Simulation, though the choice isn\u0026rsquo;t critical. Many modern physical simulations are implicit, requiring Newton\u0026rsquo;s method to solve optimization problems.\nThis involves:\nComputing derivatives of the constitutive energy model (first-order gradient, second-order Hessian). Assembling a large, sparse Hessian from small, dense Hessian submatrices â€” a delicate task prone to hard-to-debug bugs. From Dynamic Deformables, I learned deriving these formulas is labor-intensive (even understanding the notation takes time). Searching for alternatives to avoid meticulous debugging, I found two solutions:\nSymbolic differentiation with code generation. Automatic differentiation. Tools for the former include MATLAB or SymPy; for the latter, deep learning libraries like PyTorch or more suitable ones like TinyAD.\nWhy TinyAD? Deep learning libraries differentiate at the tensor level, but I needed scalar-level differentiation for physical simulations. Tensor-level differentiation could lead to unplayable frame rates.\nA problem arose: these tools are in the C++ toolchain, and I\u0026rsquo;m not proficient in C++ (I know some kindergarten-level C++, but CMake and libraries like Eigen defeated me after three days of trying). So, I switched to Rust, a language I\u0026rsquo;m more comfortable with. This was the start of all troublesâ€¦\nA Path That Seems Simple Rust lacks an automatic differentiation library for second-order Hessians (at least on crates.io). SymPy can generate Rust code, but it\u0026rsquo;s buggy. Given the implementation complexity, I started with symbolic code generation, creating Symars.\nSymPy\u0026rsquo;s symbolic expressions are tree-structured, with nodes as operators (Add, Mul, Div, Sin, etc.) or constants/symbols, and children as operands. Code generation involves depth-first traversal: compute child expressions, then the current node\u0026rsquo;s expression based on its type. Base cases are constants or symbols.\nI used the generated derivatives for a simple implicit spring-mass system, but debugging index errors in Hessian assembly was time-consuming.\nTrying the Untrodden Path Again To address this, I revisited automatic differentiation, aiming to adapt TinyAD for Rust.\nTwo Ways to Walk the Same Path Initially, I considered two approaches:\nWrite FFI bindings, as I don\u0026rsquo;t know C++ well. Replicate TinyAD\u0026rsquo;s logic. Cloning TinyAD, I couldn\u0026rsquo;t even pull dependencies or compile it. Examining the codebase, I found the core logic was ~1000 lines â€” manageable to replicate without running the project. Thus, Raddy was born.\nSymbolic diff \u0026amp; Codegen: Implementation Implementation details:\nEach scalar in the differentiation chain carries a gradient and Hessian, increasing memory overhead. I avoided implementing the Copy trait, requiring explicit cloning. Operator traits between (\u0026amp;)Type and (\u0026amp;)Type (four combinations) required repetitive code. I considered the following options: Macros. Python scripts for code generation. Macros breaks rust-analyzer (somebody refuse to agree on this, but for me this is true) and I am rather unfamiliar with Rust\u0026rsquo;s macro syntax, so I used Python scripts (in the meta/ directory) for simple string concatenation.\nTesting: I verified derivatives by generating symbolic grad and hessian code with Symars, cross-validating against Raddy\u0026rsquo;s results, ensuring test expressions covered all implemented methods. Symars performed reliably, without bugs. What about sparse matrices Dense matrices store adjacent values contiguously, but sparse matrices (with millions of elements) don\u0026rsquo;t. I implemented sparse Hessian assembly:\nDefine a problem via the Objective\u0026lt;N\u0026gt; trait: Specify problem size N (a compile-time constant for const generics). Implement computation logic, e.g., a spring-mass system (Hooke\u0026rsquo;s law, E=1/2 k xÂ²): impl Objective\u0026lt;4\u0026gt; for SpringEnergy { type EvalArgs = f64; // restlength fn eval(\u0026amp;self, variables: \u0026amp;advec\u0026lt;4, 4\u0026gt;, restlen: \u0026amp;Self::EvalArgs) -\u0026gt; Ad\u0026lt;4\u0026gt; { // extract node positions from problem input: let p1 = advec::\u0026lt;4, 2\u0026gt;::new(variables[0].clone(), variables[1].clone()); let p2 = advec::\u0026lt;4, 2\u0026gt;::new(variables[2].clone(), variables[3].clone()); let len = (p2 - p1).norm(); let e = make::val(0.5 * self.k) * (len - make::val(*restlen)).powi(2); e } } Specify input components\u0026rsquo; indices (\u0026amp;[[usize; N]]). Automatically assemble sparse grad and hess (handling index mapping). Manually sum multiple grad and hess (simple matrix addition; triplet matrices are concatenated). Before tests, Raddy was 2.2k lines; after, it ballooned to 18k lines, showing LOC is a poor metric.\nFinally, I wrote a demo for fun and as an example.\nConclusion Gains:\nLearned how automatic differentiation works. First time using AI for documentation (it struggled with Rust syntax, producing test code with errors). Happiness! ","date":"2 October, 2025","id":1,"permalink":"/english-post/raddy/","summary":"TL;DR: I created Raddy, a forward autodiff library, and Symars, a symbolic codegen library.","tags":"rust graphics math","title":"Raddy devlog: forward autodiff system"},{"content":"From the perspective of a newbie user\nThe Documentation is a Disaster Recently, I had to optimize a custom operator and decided to use OpenAI\u0026rsquo;s Triton. After digging into the documentation, I was shocked at how poorly written it is â€” like an academic paper full of equations but lacking practical code examples.\nIf the library operates on tensors, the docs should clearly specify input/output shapes and provide concrete examples (like PyTorch does). Instead, everything is vaguely described in plain text, leaving users to guess the details.\nHow Triton Fails at Clarity Take the tl.load documentation as an example. It mentions that block pointers support \u0026ldquo;boundary checks\u0026rdquo; and \u0026ldquo;padding options,\u0026rdquo; but:\nWhat does \u0026ldquo;boundary check\u0026rdquo; actually do? Does it skip out-of-bounds elements, returning a smaller tensor? Does it pad with a default value? Does it throw an error? The docs don\u0026rsquo;t say. What\u0026rsquo;s the \u0026ldquo;padding option\u0026rdquo;? After some trial and error, I realized it handles out-of-bounds elements â€” but this should be explicitly stated, not left for users to reverse-engineer.\nAnother issue: tl.make_block_ptr and tl.arange require block shapes and element counts to be powers of two. This restriction isn\u0026rsquo;t mentioned anywhere in the official docs. I only discovered it after hitting an error and finding a passing reference in an unofficial blog post.\nWhoever wrote this documentation did a huge disservice to the engineers who built Triton\u0026rsquo;s compiler. Triton\u0026rsquo;s compiler is awesome.\nKey API Clarifications tl.load For raw pointers (or tensors of pointers): Always set mask and other. mask=True: Load from HBM. mask=False: Use the value from other (a float). For block pointers (tl.make_block_ptr): Enable boundary checks on all dimensions and set padding=\u0026quot;zero\u0026quot;. The behavior of boundary_check is poorly defined, especially after reordering dimensions. Shape Constraints tl.arange element counts and tl.make_block_ptr block shapes must be powers of two. This might apply to all Triton tensor dimensions, but I haven\u0026rsquo;t verified it.\nMemory Access Pitfalls tl.load and tl.store silently corrupt data. Invalid memory access turns values into NaNâ€”yes, even tl.store can corrupt valid data! Solution: Unless your dimensions are multiples of 64, always enable boundary checks for HBM reads/writes. Extra caution: Raw pointers require careful mask handling to avoid disasters. ","date":"2 October, 2025","id":2,"permalink":"/english-post/triton-pitfalls/","summary":"From the perspective of a newbie user","tags":"deep-learning python triton","title":"Triton Common Pitfalls"},{"content":"Intro: A taste of the Rust programming language\nRecently, I tried to get started with Rust and wanted to write some code.\nMost people\u0026rsquo;s first application is probably some kind of backend service (converting HTTP requests from the frontend into CRUD operations on a database and returning the results to the frontend).\nHowever, I\u0026rsquo;ve never learned how to write backend services (I\u0026rsquo;ve been wanting to learn recently â€” if anyone has good zero-to-hero beginner resources, feel free to recommend them). So, I ended up picking up the two papers I\u0026rsquo;ve been studying lately (@Li2020IPC, @abd) to try reproducing them.\nNote: This post only reproduces/discusses the IPC family of algorithms and does not address any performance optimizations, whether the algorithm is efficient, or why not to use some other algorithm.\nProject repo: Github\nImplicit Euler Physical simulation is essentially a numerical integration process.\nExplicit integration tends to explode, but implicit integration suffers from a \u0026ldquo;chicken-and-egg\u0026rdquo; problem (calculating the position at the next timestep requires knowing the velocity at the next timestep), making it impossible to solve explicitly. Instead, it requires solving a (possibly non-convex) optimization problem.\nWhat can be implicitly integrated? A mass-spring system can. But honestly, I\u0026rsquo;ve never written an optimization-based implicit integrator before, so I decided to start by implementing a mass-spring system.\nWhat Is It? Incremental Potential (IP) is a function of the degrees of freedom (DOF) of a scene at time t, IP(t).\nImplicit Euler constructs an then minimizes the IP (x(t+\\Delta t) = \\argmin_x E_{\\text{IP}}(x(t))) to obtain the position at t+\\Delta t.\nDeep learning typically uses gradient descent (and its variants), but in graphics, empirical evidence suggests gradient descent performs poorly. So, we opt for Newton\u0026rsquo;s method.\nImplementation Newton\u0026rsquo;s method is faster, but it introduces a problem: assembling the Hessian matrix. Fortunately, each component of the incremental potential is mostly a function of (k \\cdot n DOFs), where n is the dimensionality (I implemented 2D), and k is a small number (at most a few dozen). Thus, for each small IP contributing to the larger IP, the Hessian has only tens to hundreds of entries, which can be stored sparsely and assembled into the full Hessian. Following this tutorial, I implemented springs with vertices pinned to a wall.\nChoosing libraries: Used macroquad for GUI. Used nalgebra_glm for small-scale linear algebra. Initially planned to use nalgebra for large-scale linear algebra, but its sparse matrix functionality seemed incomplete, so I switched to faer. Initially used argmin for optimization. A Small Detour Before Contact IP Rust takes forever to compile, so configuring geometry shapes shouldn\u0026rsquo;t be hardcoded.\nAt first, I invented a weird file format and wrote a config based on my own logic:\n!k 1000.0 !node 0.0 0.0 0.2 0.0 0.4 0.0 0.6 0.0 0.1 0.2 0.3 0.2 Then I asked an AI to write a parser for me.\nLater, I realized that existing formats like JSON or TOML already have parsers, but by then, I was too lazy to change it.\nContact IP In short, Contact IP:\nRequires that point-edge pairs (aka primitive pairs) from two different bodies, which are close enough (within a threshold \\hat{d}), are assigned energy based on their distance. But to prevent interpenetration, there are additional requirements:\nOptimization courses teach that (damped) Newton\u0026rsquo;s method iteratively approaches the optimum. Each iteration involves a line search, and to prevent interpenetration, every intermediate step of the line search must ensure no primitive pairs penetrate, ultimately guaranteeing no interpenetration in the final result. Procedure At each line search step in Newton\u0026rsquo;s method:\nTraverse all primitive pairs (or use some acceleration structure â€” I didn\u0026rsquo;t implement this) and identify those with distances below the threshold. Compute the energy, gradient, and Hessian of the Contact IP for each primitive pair\u0026rsquo;s DOFs, then solve d = -A^{-1}g to get the search direction. Perform a CCD (Continuous Collision Detection) operation to ensure the line search doesn\u0026rsquo;t cause interpenetration (by setting a maximum step length). Use the Armijo condition for the line search. Repeat until sufficiently close to the minimum, at which point optimization is complete.\nImplementation Every step involved endless debuggingâ€¦\nGradient \u0026amp; Hessian:\nIn 2D, each primitive pair\u0026rsquo;s DOFs are (2 DOFs per point) Ã— (3 points) = 6 DOFs. The gradient of energy E w.r.t. DOFs can still be computed manually (a 6D vector). But the Hessian is a 6Ã—6 matrix, and the paper\u0026rsquo;s notation is a messâ€”sometimes dyadic product, sometimes Kronecker product, with no clear labeling in the text. Manual computation failed. So, I used SymPy for symbolic computation and generated code from it. The differentiation code can be found in the symbolic/ folder. SymPy actually has Rust codegen, but it\u0026rsquo;s half-baked â€” often producing invalid Rust syntax, requiring string replacements, and only supporting single expressions (no vectors/matrices). Note: Later, I built my own SymPyâ†’Rust code generator:\nSymars: Generate Rust code from SymPy expressions\nRemember: Point-to-segment distance requires case-by-case handling. CCD (ACCD) needs to be integrated into the optimization process, so argmin wasn\u0026rsquo;t suitable anymore. I discarded it and handwrote a damped Newton solver with ACCD and Armijo condition. After days of coding and debugging, the demo finally worked:\nThe constraints here are springs. ABD TL;DR, ABD Replaces traditional 6-DOF (translation + rotation) rigid bodies with 12-DOF bodies and heavily penalizes transformation matrices that deviate too far from rotation matrices, resulting in a (near-)rigid body simulation algorithm.\nIn 2D, an affine body (AB) has 6 DOFs: x = A x_0 + b, where the shape is defined by A (2Ã—2) and b (2Ã—1), assembled into a DOF vector: q = [flatten(A), b^T].\nWe know rotation matrices R satisfy R^T R = I. ABD uses an orthogonal potential energy \\kappa \\cdot \\text{frobnorm}(A^T A - I) to penalize A and keep it close to a rotation matrix.\nImplementation Any energy term requires second derivatives. Again, I used SymPy for differentiation. The project has thousands of lines of numerical computation code â€” don\u0026rsquo;t look at them. Affine bodies also need contact handling: Unlike mass-spring systems where each vertex is a DOF, an AB\u0026rsquo;s vertex position p is a function of DOFs, and the Contact IP is a function of p. A primitive pair involves two bodies, where one contributes an edge (two points p_1, p_2). Thus, derivatives must be taken w.r.t. both q s. The computational graph looks like this: After more endless debugging and parameter tuning (mainly \\kappa), the simulation finally ran:\nFinal Thoughts The resulting code is a bona fide spaghetti monster.\nEven though I spent a long time thinking about unifying interfaces before coding, the final design is neither OOP nor Rust-like, with inconsistent parameter passing everywhere.\nI can\u0026rsquo;t help but wonder: Is my ability just too low, or is code complexity truly not something design alone can solve?\nThe bright side:\nCargo is amazing â€” adding a dependency takes three seconds. Compared to Cmake, xmake or whatever-make, it\u0026rsquo;s night and day. No memory issues (since I didn\u0026rsquo;t and did not need to write unsafe code), so most effort went into logic. ","date":"2 October, 2025","id":3,"permalink":"/english-post/try-impl-ipc/","summary":"Intro: A taste of the Rust programming language","tags":"graphics graphics rust","title":"Try To Implement IPC"},{"content":"Intro: Troubleshooting Memory and Speed Performance\nDisclaimer: I develop and test primarily on Windows using the latest stable Rust toolchain and CPython 3.13.\n1. Background and Motivation SnapViewer handles large memory snapshots effectively â€” for example, pickle files up to 1 GB and compressed snapshots up to 500 MB. However, when processing extremely large dumps (e.g., a 1.3 GB snapshot), we encountered serious memory and speed bottlenecks:\nFormat conversion (pickle â†’ compressed JSON) triggered memory peaks around 30 GB. Data loading of the compressed JSON into Rust structures caused another ~30 GB spike. Frequent page faults and intense disk I/O (observed in Task Manager) made the application sluggish and prone to stalls. To address this, we applied a Profile-Guided Optimization (PGO) approach.\n2. Profile-Guided Optimization PGO requires empirical profiling to identify the true hotspots. I began with memory profiling using the memory-stats crate for lightweight inspection during early optimization stages. Then, I decomposed the data-loading pipeline into discrete steps:\nReading the compressed file (heavy disk I/O) Extracting the JSON string from the compressed stream Deserializing the JSON into native Rust data structures Populating an in-memory SQLite database for ad-hoc SQL queries Building the triangle mesh on CPU Initializing the rendering window (CPU-GPU transfer) Profiling revealed two major memory culprits: excessive cloning and multiple intermediate data structures. Below, I outline the optimizations.\nEliminating Redundant Clones During rapid prototyping, calls to .clone() are convenient. But they are expensive. Profiling showed that cloning large vectors contributed significantly to the memory peak and CPU time.\nFirst attempt: switch from cloned Vec\u0026lt;T\u0026gt; to borrowed \u0026amp;[T] slices. This failed due to lifetime constraints. Final solution: use Arc\u0026lt;[T]\u0026gt;. Although I\u0026rsquo;m not leveraging multithreading, Arc satisfies PyO3\u0026rsquo;s requirements, while no significant overhead is observed in this context. This change alone reduced memory usage and improved throughput noticeably.\nEarly Deallocation of Intermediate Structures Constructing the triangle mesh involved several temporary representations:\nRaw allocation buffers A list of triangles (vertices + face indices) A CPU-side mesh structure GPU upload buffers Each stage held onto its predecessor until the end of scope, inflating peak usage. To free these intermediates promptly, the following is implemented:\nScoped blocks to limit lifetimes Explicitly invoked drop() on unneeded buffers After these adjustments, peak memory dropped by roughly one-third.\n3. Sharding JSON Deserialization Deserializing the call-stack JSON with over 50 000 entries spiked memory usage dramatically. To mitigate this:\nShard the JSON data into chunks of at most 50 000 entries. Deserialize each chunk independently. Concatenate the resulting vectors. This streaming approach kept per-shard memory small, eliminating the previous giant allocation.\nIt is worth noting that serde_json::StreamDeserializer can be another option worth trying.\n4. Redesigning the Snapshot Format Even after the above optimizations, the call-stack data remained the largest in-memory component â€” duplicated once in Rust and again in the in-memory SQLite database.\nTo remove redundancy, I rethought what each representation serves:\nRust structures: display call stacks on screen upon user click. SQLite DB: serve ad-hoc SQL queries. Since SnapViewer is single-threaded and can tolerate occasional disk I/O, I split the snapshot into two files:\nallocations.json: lightweight JSON with allocation timestamps and sizes. elements.db: SQLite database holding call-stack text (indexed by allocation index). These two files are zipped together. At runtime:\nUnzip the snapshot. Load allocations.json into memory (small footprint). Open elements.db on disk. On click, query elements.db with WHERE idx = \u0026lt;allocation_index\u0026gt;. SQLite\u0026rsquo;s efficient on-disk indices make these lookups fast, with no perceptible impact on frame rate.\nRefactoring the Conversion Script I updated the snapshot-conversion script as follows:\nParse the original snapshot format. Bulk-insert call stacks into an in-memory SQLite database, then dump the DB as a byte stream. Serialize allocation metadata to JSON. Zip the JSON and DB byte stream. While conversion takes slightly longer, the resulting snapshot loads faster and uses a fraction of the memory.\n5. Results and Lessons After these optimizations, SnapViewer:\nNo longer spikes to 60+ GB of RAM on large snapshots, since we do not load the entire call stack information into memory at all. Starts up much faster. Maintains smooth rendering, even with on-demand call-stack queries. What I learned:\nDo not always load everything into memory. When you overflow your memory, the performance of virtual memory swapping system is probably worse than you think. When you need some mechanism to store most data on disk, but intelligentlly cache some of then in memory, SQLite should be a good start. It has its well-designed and industry-proven algorithm built into it. ","date":"2 October, 2025","id":4,"permalink":"/english-post/snapviewer-3-optim/","summary":"Intro: Troubleshooting Memory and Speed Performance","tags":"torch deep-learning rust","title":"SnapViewer Devlog #3: Optimizations"},{"content":"Intro: Building the UI as a Hybrid Rust \u0026amp; Python Application\nBuilding a UI can often be the trickiest part of a development project, especially when you\u0026rsquo;re trying to integrate different languages and paradigms.\nFor SnapViewer, my memory allocation viewer, I needed an integrated UI that could display allocation details on click and feature a REPL for SQL queries against a SQLite database. This post details my journey, the hurdles I faced, and the solutions I found, primarily focusing on a Rust backend and Python UI.\nProject page: https://github.com/Da1sypetals/SnapViewer\nThe Initial Vision: An Integrated UI My core requirements for the UI were:\nInteractive Display: When an allocation is clicked in the viewer, its size, call stack, and other relevant information should be immediately displayed. SQL REPL: A command-line interface to execute SQL queries directly against the underlying database. Non-Blocking Operations: Both functionalities needed to operate without blocking each other. Early Attempts and Roadblocks Web: Rust to WASM My first thought was a web interface. Rust\u0026rsquo;s ability to compile to WASM and the three-d crate\u0026rsquo;s WebGPU support seemed promising. However, I quickly hit a wall with library versioning issues trying to compile even a simple Rust program to WASM. Rather than get bogged down, I decided to pivot.\nTUI: Terminal User Interface The natural next step was a Terminal User Interface (TUI). This approach avoids the complexities of cross-compilation and platform-specific GUI libraries.\nRatatui: A Promising Rust TUI Framework I started with Ratatui, a TUI framework for Rust. I got their demos running, but my plan to find an open-source example matching my \u0026ldquo;left-console, right-REPL\u0026rdquo; layout failed.\nDiving deep into the Ratatui documentation felt as complex as learning a new frontend framework like React, which defeated my goal of getting work done quickly. I abandoned this path.\nTextual \u0026amp; AI-Powered Development Given my goal of getting work done rather than becoming a TUI expert, I started thinking about AI. Rust isn\u0026rsquo;t particularly \u0026ldquo;AI-friendly\u0026rdquo; for code generation, but Python certainly is. This sparked an idea: What if I used AI to generate the TUI code in Python and then integrated my Rust application?\nI fed my requirements to several LLMs: Claude, Gemini, Deepseek, ChatGPT, and Grok. Claude\u0026rsquo;s initial results were impressive, while the others were largely unusable. After a few rounds of refinement with Claude, I had a working TUI demo:\nCombining Rust and Python: A Hybrid Approach Integrating Rust and Python is a standard process, but it has its quirks. I used PyO3 as a dependency to expose my Rust structures and bind Rust functions to Python.\nMy core Rust logic consists of:\nViewer: An infinite loop handling render draw calls and an event loop until the application shuts down. SQL REPL: Loads snapshot data into SQLite and executes SQL queries. Each of these operations is designed to be completed in milliseconds.\nDesigning App Structure My initial application structure idea was:\nMain Thread: Renders the TUI and accepts REPL inputs, calling SQL REPL Rust functions. Spawned Thread: Runs the infinite loop for the Snapshot Viewer. However, the three-d crate, which uses winit for window management, dictates that the window must run on the main thread. This immediately threw a wrench in my plans.\nAttempt 1: Multiprocessing My first revised design used multiprocessing:\nStart the application and load snapshot data. Spawn a new process to run the TUI application. Run the Viewer in the parent process. This setup allowed the child process to run the viewer window without blocking the TUI app. The challenge, however, was Inter-Process Communication (IPC). I needed a way for the viewer to send information (like selected allocation details) back to the TUI.\nI experimented with Python\u0026rsquo;s multiprocessing.Queue. My approach was to define a callback in Rust that put messages into the queue, and then have the parent process check the queue at a fixed interval (e.g., 0.1 seconds) to update the TUI\u0026rsquo;s logging panel.\nI encountered an implementation bug where the parent process wasn\u0026rsquo;t consuming all messages, causing the viewer and TUI to become out of sync. I then switched to a shared byte array with a lock for IPC. The child process would acquire the lock, write to the buffer, and release it. The parent process would try to acquire the lock at intervals to read the message and update the TUI.\nAttempt 2: Threading The multiprocessing solution had a couple of issues:\nThe TUI sometimes froze when typing in the REPL, likely due to lock contention. Balancing the log message update interval with the viewer\u0026rsquo;s framerate was tricky. Too frequent, and the UI lagged; too slow, and the viewer became unresponsive. I realized I could use multithreading instead! While winit requires the viewer window to run on the main thread, the TUI application does not. This led to a new, more elegant structure:\nSpawn a thread and start the TUI application on that thread. Start the viewer on the main thread. A naive implementation, however, caused the entire TUI to freeze. The culprit? The Global Interpreter Lock (GIL) in Python. The GIL ensures that only one thread can execute Python bytecode at a time.\nTime for some PyO3 details. By default, the extension function holds GIL during its execution; but when you don\u0026rsquo;t need to use Python objects during this call, a call to py::allow_thread can opt out this behavior, releasing the GIL.\nIn my case, the Rust extension holds GIL in the infinte render loop, preventing the TUI thread from updating the UI. By explicitly releasing the GIL during the viewer\u0026rsquo;s render loop, the TUI, running in its own sub-thread, was free to update, and the application could run as expected.\nAn Alternative: GUI with PyQt As an interesting side experiment, I wondered about a GUI instead of a TUI. I tasked Claude with translating my TUI code into a GUI application using PyQt. Claude did this in minutes, without errors.\nAfter a few minor styling tweaks (also done via chatting with Claude), here is what the app looks like:\n(I finally switched to Tkinter for compatibility issues with multithreading across platforms.)\nWrapping Up This journey highlights the flexibility and power of combining Rust\u0026rsquo;s performance with Python\u0026rsquo;s rapid development capabilities, especially when augmented by AI.\nUnderstanding the intricacies of thread management and inter-process communication helped a lot in this journey.\nHope you find this post is fun and informative to read! â¤ï¸â¤ï¸â¤ï¸\n","date":"2 October, 2025","id":5,"permalink":"/english-post/snapviewer-2-ui/","summary":"Intro: Building the UI as a Hybrid Rust \u0026amp; Python Application","tags":"torch deep-learning rust","title":"Snapviewer Devlog #2: UI"},{"content":"Intro: PyTorch is a Deep Learning Operating System.\nCheck tensor storage Device check You should ALWAYS check EXPLICITLY whether input tensors are on desired devices. In most cases you want them on the same GPU, or in rare cases you want some tensors on CPU to perform some operations that are not efficient on GPU.\nAPI:\ntensor.is_cuda() tensor.device() (Use operator== for equality comparison). Sometimes the not on correct device problem causes strange error messages like Cusparse context initialization failure or things even more weird, which first seem unrelated to a device problem. This is why I suggest you always start your debug journey here.\nContiguity check Modern LibTorch recommends using Packed tensor accessor (roughly the same memory cost as a pointer) to access elements in tensor.\nHowever, if you are to plug some others\u0026rsquo; implementation (likely using raw pointers like float*) into PyTorch, you are not likely to understand the code inside out and rewrite it.\nUsually, in the context of deep learning, most implementations assumes a row-major contiguous storage. You should explicitly check whether the input tensors are contiguous in the C++ code that wraps the CUDA kernel.\nAPI: tensor.is_contiguous()\nCheatsheet A quick utility that checks whether all tensors are on the same CUDA device:\nvoid CheckInputTensors(const std::vector\u0026lt;torch::Tensor\u0026gt; \u0026amp;tensors) { TORCH_CHECK(!tensors.empty(), \u0026#34;No tensors provided for device check\u0026#34;); auto first_device = tensors[0].device(); TORCH_CHECK(first_device.is_cuda(), \u0026#34;First tensor is not on CUDA\u0026#34;); int idx = 0; for (const auto \u0026amp;tensor: tensors) { TORCH_CHECK(tensor.device() == first_device, \u0026#34;All tensors must be on the same CUDA device, \u0026#34; \u0026#34;but found tensor at index [\u0026#34;, idx, \u0026#34;] on device \u0026#34;, tensor.device(), \u0026#34; while expecting \u0026#34;, first_device); TORCH_CHECK(tensor.is_contiguous(), \u0026#34;All tensors must be contiguous, but found tensor at index [\u0026#34;, idx, \u0026#34;] not contiguous\u0026#34;); idx += 1; } } CUDA stream Remember to always get the current CUDA stream via at::cuda::getCurrentCUDAStream() and pass it as the 4-th parameter in the \u0026lt;\u0026lt;\u0026lt;gridDim, blockDim, sharedMemorySizeBytes, stream\u0026gt;\u0026gt;\u0026gt; kernel call.\nThis is especially important when your operator is used in distributed training, where at::cuda::getCurrentCUDAStream() automatically selects the correct stream for you.\nCUDA toolkit version problem Most \u0026ldquo;symbol not found\u0026rdquo; problem are caused by compiler / assembler / library version mismatch. Let me elaborate on this a bit:\nPyTorch has an important version information attached to it: The version of CUDA that torch is compiled on (let\u0026rsquo;s call it VT, cuda Version of Torch, for the sake of simplicity). The torch installation comes with its own CUDA toolkit (that matches VT) with no nvcc, ptxas. If you are to write custom CUDA extension to PyTorch, it will use the nvcc and ptxas in your system PATH, and libraries like CUBLAS or CUSPARSE in LD_LIBRARY_PATH. Let\u0026rsquo;s call this CUDA toolkit version VE, cuda Version of Extension. When you try to compile a CUDA extension, Make sure that your VT and VE perfectly match (NOT major version match). When you compile your extension, PyTorch hints you that a minor version mismatch should not be a problem. Remember, everything that should not happen will eventually happen. Memory Management in PyTorch Allocation When you need a buffer on HBM (e.g., for CUSPARSE or CUBLAS), your first instinct might be cudaMalloc and cudaFree. However, these force synchronization between CPU and GPU, which can starve the GPU.\nHere\u0026rsquo;s the key: PyTorch isn\u0026rsquo;t just an autograd tool. It\u0026rsquo;s a deep learning operating system that manages VRAM internally with a pooling and caching mechanism.\nUsing the PyTorch allocator is straightforward. Follow these steps:\nSet dtype to torch::kInt8 and create a buffer tensor via torch::empty Get the pointer with buffer_tensor.data_ptr\u0026lt;int8_t\u0026gt;() This gives you a pointer to the buffer. Here\u0026rsquo;s a complete code snippet:\nauto buffer_options = torch::TensorOptions().device(your_device).dtype(torch::kInt8); auto buffer_tensor = torch::empty({buffer_size}, buffer_options); void *buffer_ptr = buffer_tensor.data_ptr\u0026lt;int8_t\u0026gt;(); Remember do not call cudaFree on the pointer. RAII semantics will give the memory back to the allocator when destructor is called.\nPyTorch\u0026rsquo;s memory management is pretty much like a combination of OS memory management (buddy system, SLAB) and JVM or .net runtime (garbage collection, memory pool, caching and reusing memory blocks), but manages VRAM instead of a RAM.\nI recommend reading this post (Chinese) for a deeper dive into how PyTorch manages memory.\nUsing CUBLAS, CUSPARSE, CUSolverDn, etc. We use CUSPARSE as an example. The same rule apply to other libraries like CUBLAS or CUSolverDn.\nHandles When writing pure CUDA/C++ code, you manually call cusparseCreate to initialize the CUSPARSE context and prepare for subsequent CUSPARSE API calls.\nHowever this is not best practice in PyTorch CUDA extensions. There are good reasons: cusparseCreate introduces a milliseconds-level delay on CPU side. This may not be noticeable at first, but remember that operators are written to be run millions of times, which turns this into a significant overhead. This can cause GPU to starve when waiting CPU for synchronization.\nIf you use VizTracer to trace your program and visualize it in perfetto, you may notice cudaGetDeviceProperties call taking too much time on CPU side. This can be directly caused by cusparseCreate. LibTorch has API that automatically manages a pool of CUSPARSE handles:\nInclude the header that brings in CUDA context manager for LibTorch: #include \u0026lt;ATen/cuda/CUDAContext.h\u0026gt; Then, get handle via auto handle = at::cuda::getCurrentCUDASparseHandle(); automatically create a handle if there is not any, and caches it for subsequent uses. Use your handle as usual. I could not find documentation for these APIs, so if you want to know more, you may need to read the source code of PyTorch ATen. Searching in the repo with keyword getcurrentcuda can get you there quickly.\nBuffers Many CUSPARSE operations need buffers. If you need to make multiple CUSPARSE API calls with similar buffer size, it is bad practice to allocate right before the CUSPARE API call and deallocate right after since cudaMalloc and cudaFree are quite slow, which may cause your GPU to starve (verify this with VizTracer).\nA better practice should be pre-allocating the buffer and pass its pointer into where the CUSPARSE API is called through torch.empty().\nBatched Matrix Multiplication Refer to this example to see how to perform batched matrix multiplication in CUSPARSE.\nTricks:\nTo broadcast, set stride to 0. It is possible to broadcast rowptr but not colind and values. Check documentation for details.\nTensor Options struct TensorOptions carries many information about the tensor:\nstruct C10_API TensorOptions { // ... omitted // members Device device_ = at::kCPU; // 16-bit caffe2::TypeMeta dtype_ = caffe2::TypeMeta::Make\u0026lt;float\u0026gt;(); // 16-bit Layout layout_ = at::kStrided; // 8-bit MemoryFormat memory_format_ = MemoryFormat::Contiguous; // 8-bit bool requires_grad_ : 1; bool pinned_memory_ : 1; // Existense of members bool has_device_ : 1; bool has_dtype_ : 1; bool has_layout_ : 1; bool has_requires_grad_ : 1; bool has_pinned_memory_ : 1; bool has_memory_format_ : 1; } The most important methods are:\n[[nodiscard]] TensorOptions device(Device device) const; [[nodiscard]] TensorOptions dtype(ScalarType dtype) const; [[nodiscard]] TensorOptions requires_grad(bool) const; Usage:\ntensor.options() returns an instance of TensorOptions that describes the tensor. opt.dtype(torch::kFloat64) has other properties remain the same as opt, only dtype changes to float64 or in C++, double. The .to(...) method of a tensor can take a TensorOptions instance as its only argument. For an exhaustive list of device and dtype, you may want to refer to:\nhttps://github.com/pytorch/pytorch/blob/main/torch/csrc/api/include/torch/types.h https://github.com/pytorch/pytorch/blob/main/c10/core/DeviceType.h Debug layer by layer A CUDA extension is roughly split into 4 parts, from the bottom to the top namely:\nCUDA kernel C++ wrapper data passed from Python (PyTorch) to C++ Python wrapper CUDA kernel Debugging CUDA kernel is a very very difficult problem and we shall not discuss it here.\nC++ wrapper The first thing I want to hint you is that do not dereference a pointer pointing to device in host functions. You should always mark device pointers with a d_ prefix in variable names, or wrap it with thrust::device_ptr.\nprintf, std::cout or gdb will assist you in the journey.\ndata passed from Python (PyTorch) to C++ Refer to Pybind11 docs and try to answer these questions:\nHow various Python types are represented in Pybind11 API; How to properly configure the function prototype in Pybind11? Python Wrapper Ask LLMs. LLMs know python much better than I do.\nWhat to Reference To my knowledge, the PyTorch C++ documentation is very old. Many things in the source code are not documented there.\nIt is a better choice to just search in the PyTorch github repo, and read the comments and source code.\n","date":"2 October, 2025","id":6,"permalink":"/english-post/torch-cuda-ext/","summary":"Intro: PyTorch is a Deep Learning Operating System.","tags":"deep-learning cuda torch","title":"Notes on Writing PyTorch CUDA Extensions"},{"content":"æ³¨ï¼šæœ¬æ–‡ç”¨LLMè¾…åŠ©å†™ä½œçš„åœ°æ–¹ä¸»è¦åœ¨ï¼šæˆ‘è®¤ä¸ºLLMæ¯”æˆ‘ç†è§£çš„æ›´å¥½çš„åœ°æ–¹ï¼Œä¼šç”¨LLMçš„è¡¨è¿°ä»£æ›¿ã€‚\né—®é¢˜è®¾å®š éœ€è¦è®¡ç®—Graph Transformerä¸­çš„Attentionã€‚åœ¨æ­¤æˆ‘ä»¬å¿½ç•¥multihead-attentionï¼Œè€ƒè™‘åŸºæœ¬çš„single-head attention.\næ­¤å¤–ï¼Œæˆ‘ä»¬çš„attention mask(é‚»æ¥çŸ©é˜µA)æ˜¯éç»“æ„åŒ–ç¨€ç–çš„ã€‚å¦‚æœä½ çš„attention maskæ˜¯ç»“æ„åŒ–ç¨€ç–çš„ï¼Œæ¯”å¦‚blockwiseç­‰å¯ä»¥è¢«ä»£ç è¡¨ç¤ºçš„ç¨€ç–patternï¼Œä½ åº”è¯¥ä½¿ç”¨flash attentionçš„varlenå˜ä½“, æˆ–è€…flex attentionç­‰attentionç¼–è¯‘å™¨ã€‚\nNotation n: å›¾èŠ‚ç‚¹æ•°ï¼Œè§„æ¨¡ä¸º 1k~1M\rnnz: å›¾è¾¹æ•°ï¼ˆç¨€ç–çŸ©é˜µéé›¶å…ƒç´ æ•°ï¼ŒNum NonZeroï¼‰\rè§„æ¨¡ä¸º10n~1000n\rq, k, v: (n, d)\rA: (n, n), binary, é«˜åº¦ç¨€ç– è®¡ç®—å…¬å¼ softmax((q @ k.transpose()) * A) @ V å…¶ä¸­ï¼Œ@ è¡¨ç¤ºçŸ©é˜µä¹˜æ³•ï¼Œ*è¡¨ç¤ºelement-wiseä¹˜æ³•ã€‚\nå®ç°ï¼šnaive version æœ€ç®€å•çš„å°±æ˜¯æŠŠAç»™materializeå‡ºæ¥ï¼Œç„¶åç”¨ä½œattention_maskã€‚é—®é¢˜æ˜¯Aæ˜¯n^2çš„ï¼Œæ˜¾å­˜ä¸å¤Ÿç”¨ã€‚ Aç”¨COOæ–¹å¼å­˜å‚¨ï¼Œå¤§å°(2,nnz)ï¼Œç„¶åå…ˆæŠŠæ¯æ¡è¾¹çš„qk-pairç®—å‡ºæ¥(nnz,d)ï¼Œç„¶åå†åšreduceå’Œscatterå’ŒVç›¸ä¹˜ã€‚ Reformulate æˆ‘ä»¬å¼•å…¥ä¸‰ä¸ªç®—å­:\nSDDMM (Sampled Dense-Dense MatMul) A (m, k), B (k, n), ç¨ å¯† M (n, n)ï¼Œ ç¨€ç– SDDMM(A, B, M) å®šä¹‰ä¸ºï¼š for i, j in product(range(n), range(n)):\rif M[i, j] != 0:\rout[i, j] = dot(A[i,:], B[:,j])\relse:\rout[i, j] = 0 Sparse Softmax: åœ¨ç¨€ç–çŸ©é˜µä¸ŠæŒ‰è¡Œsoftmax SpMMï¼šsparse A @ dense B æ­¤æ—¶æˆ‘ä»¬çš„è®¡ç®—å…¬å¼å°±å¯ä»¥é‡æ–°å†™æˆ:\nout = SpMM(Softmax(SDDMM(Q, K_T, A)), V) ä»¥æ­¤æˆ‘ä»¬å¼•å‡ºä¸‹é¢çš„å®ç°\nå®ç°ï¼šDGL Graph Transformer in a Nutshell â€” DGL 2.2.1 documentation\nå¯¹äºç¨ å¯†çš„q,k,vå’ŒCSRå­˜å‚¨çš„Aï¼Œé€šè¿‡å¦‚ä¸‹ä»£ç è®¡ç®—attentionï¼š\nattn = dglsp.bsddmm(A, q, k.transpose(1, 0)) # (sparse) [N, N, nh] # Sparse softmax by default applies on the last sparse dimension. attn = attn.softmax() # (sparse) [N, N, nh] out = dglsp.bspmm(attn, v) # [N, dh, nh] ç®—å­åœ¨DGLåº“å†…éƒ¨ç”±CUDAå®ç°ã€‚çœ‹DGLçš„ä»£ç å¯ä»¥å‘ç°ï¼Œå…¶å®ç°åˆ©ç”¨äº†ç¨€ç–æ€§ï¼Œä½†æ˜¯å­˜åœ¨ä»¥ä¸‹ä¼˜åŒ–ç‚¹\nè¿›è¡Œçš„æ˜¯æœ€ç›´è§‚çš„å¹¶è¡Œï¼Œæ²¡æœ‰è¿›è¡Œå……åˆ†çš„ä¼˜åŒ– å„ä¸ªkernelåˆ†å¼€æ‰§è¡Œï¼Œæ²¡æœ‰èåˆ æ²¡æœ‰åˆ©ç”¨tensor core å®ç°ï¼šFlashSparse https://github.com/ParCIS/FlashSparse/tree/main/eva\nä¸»é¢˜ï¼šå¯¹SDDMM,SpMMè¿›è¡Œä¼˜åŒ–ï¼›å°è¯•åœ¨ç¨€ç–è¾“å…¥ä¸­ä»¥æœ€å°ç²’åº¦åˆ©ç”¨tensor core\nåŸºäºä¸€ä¸ªåŸºæœ¬è§‚å¯Ÿï¼šA Ã— B = C âŸ¹ (Báµ€ Ã— Aáµ€)áµ€ = Cï¼Œå‘æ˜äº†äº¤æ¢ä¸è½¬ç½®MMAè®¡ç®—ç­–ç•¥ï¼šç›®æ ‡æ˜¯å°†ç¨€ç–çŸ©é˜µåˆ’åˆ†æ‰€ä¾èµ–çš„MMAæŒ‡ä»¤ç»´åº¦ï¼Œä»è¾ƒå¤§çš„mç»´ï¼ˆå€¼ä¸º16ï¼‰åˆ‡æ¢åˆ°è¾ƒå°çš„nç»´ï¼ˆå€¼ä¸º8ï¼‰ã€‚æ ‡å‡†å¼ é‡æ ¸å¿ƒMMAæŒ‡ä»¤çš„å½¢çŠ¶ä¸ºm16n8k8ï¼ˆFP16ç²¾åº¦ä¸‹ï¼Œm=16, n=8, k=8ï¼‰ã€‚è¿™ä½¿å¾—ç¨€ç–çŸ©é˜µ A å¯è¢«åˆ’åˆ†ä¸º8Ã—1çš„å‘é‡ï¼Œç›¸æ¯”ä¹‹å‰å·¥ä½œä¸­ä½¿ç”¨çš„16Ã—1å‘é‡ï¼Œè®¡ç®—å†—ä½™å‡å°‘äº†çº¦50%ã€‚\nçŸ©é˜µæ ¼å¼ï¼šæœ¬ç®—æ³•å‘æ˜äº†ME-BCRSæ ¼å¼ï¼ŒåŸºæœ¬æƒ³æ³•æ˜¯åœ¨ä¸€ä¸ª8x1çš„blockä¸­ï¼Œå¦‚æœæœ‰ä¸€ä¸ªå…ƒç´ æ˜¯éé›¶çš„ï¼Œé‚£ä¹ˆå°±æŠŠè¿™æ•´ä¸ªblockéƒ½å½“æˆéé›¶çš„å­˜ä¸‹æ¥ã€‚ ç©ºé—´å¼€é”€ç»´æŒåœ¨O(n+nnz)ï¼Œå¸¸æ•°æ¯”è¾ƒå°ï¼Œè¿œæ²¡æœ‰è¾¾åˆ°head_dimçš„é‡çº§ã€‚ çŸ©é˜µæ ¼å¼è½¬æ¢æ—¶é—´å¼€é”€ (CSR -\u0026gt; ME-BCRS)ï¼šç”±äºæ˜¯ä¸€æ¬¡æ€§å¼€é”€ï¼Œç›¸å¯¹æ•´ä¸ªæ¨¡å‹æ¨ç†æ—¶é—´å‡ ä¹å¯ä»¥å¿½ç•¥ã€‚ FlashSparseçš„SpMMç®—æ³•ï¼ˆC = A Ã— Bï¼‰ é˜¶æ®µ1ï¼šè½¬ç½®è®¿é—®ä¸åŠ è½½\nå—å½¢çŠ¶ï¼šç®—æ³•å°† A åˆ’åˆ†ä¸º8Ã—8çš„ç¨€ç–TCå—ï¼ˆFP16ç²¾åº¦ä¸‹ï¼‰ï¼Œå°† B åˆ’åˆ†ä¸º8Ã—16çš„ç¨ å¯†TCå—ã€‚ ç¨€ç–å— A åŠ è½½ï¼šçº¿ç¨‹ä»å…¨å±€å†…å­˜ï¼ˆä»¥è¡Œä¼˜å…ˆçš„ME-BCRSæ ¼å¼å­˜å‚¨ï¼‰åŠ è½½8Ã—8ç¨€ç–TCå— Aï¼Œå¹¶åœ¨å¯„å­˜å™¨ä¸­å°†å…¶è½¬ç½®ä¸º Aáµ€ï¼Œä½œä¸ºå³æ“ä½œæ•°ã€‚ ç¨ å¯†å— B åŠ è½½ï¼šçº¿ç¨‹ä»å…¨å±€å†…å­˜ï¼ˆè¡Œä¼˜å…ˆï¼‰åŠ è½½8Ã—16ç¨ å¯†TCå— Bï¼Œå¹¶åœ¨å¯„å­˜å™¨ä¸­å°†å…¶è½¬ç½®ä¸º Báµ€ï¼Œä½œä¸ºå·¦æ“ä½œæ•°ã€‚ åˆå¹¶è®¿é—®ï¼šé€šè¿‡é‡æ–°æ’åˆ—çº¿ç¨‹è®¿é—®çš„åˆ—ï¼Œç¡®ä¿æ‰€éœ€æ•°æ®å¯¹é½å½¢æˆ2Ã—2çš„FP16å…ƒç´ å—ï¼Œä»è€Œä½¿å†…å­˜äº‹åŠ¡åŒ¹é…GPUæœ€å°32å­—èŠ‚çš„äº‹åŠ¡ç²’åº¦ï¼Œå®ç°åˆå¹¶è®¿é—®ï¼Œå‡å°‘50%çš„è®¿å­˜å¼€é”€ã€‚ é˜¶æ®µ2ï¼šäº¤æ¢ä¸è½¬ç½®è®¡ç®—\nåœ¨å¼ é‡æ ¸å¿ƒä¸Šæ‰§è¡ŒMMAæŒ‡ä»¤ï¼šBáµ€ Ã— Aáµ€ã€‚\nBáµ€ ä½œä¸ºå·¦æ“ä½œæ•°ï¼ˆm=16, k=8ï¼‰ã€‚ Aáµ€ ä½œä¸ºå³æ“ä½œæ•°ï¼ˆk=8, n=8ï¼‰ã€‚ ç»“æœä¸ºè½¬ç½®åçš„è¾“å‡ºå— Cáµ€ï¼ˆå°ºå¯¸ä¸º16Ã—8ï¼‰ï¼Œå­˜å‚¨åœ¨å¯„å­˜å™¨ä¸­ã€‚ é˜¶æ®µ3ï¼šè½¬ç½®è¾“å‡º\nå¯„å­˜å™¨ä¸­çš„ Cáµ€ å¿…é¡»åœ¨å†™å›å…¨å±€å†…å­˜å‰è½¬ç½®å› Cã€‚ç”±äºå¯„å­˜å™¨ä¸­ Cáµ€ çš„æ•°æ®å¸ƒå±€ä¸åŠ è½½ B æ—¶æ‰€éœ€çš„ Báµ€ å¸ƒå±€å®Œå…¨ç›¸åŒï¼Œå› æ­¤å¯å¤ç”¨ä¸ºåŠ è½½ B è®¾è®¡çš„é«˜æ•ˆåˆå¹¶å†™å›ç­–ç•¥ï¼Œå°†ç»“æœå†™å…¥å…¨å±€å†…å­˜ã€‚\nFlashSparseçš„SDDMMç®—æ³•ï¼ˆC = M âŠ™ (AB)ï¼‰ å—å½¢çŠ¶ï¼šFlashSparseå°†ç¨€ç–è¾“å‡ºçŸ©é˜µ C åˆ’åˆ†ä¸º8Ã—16çš„ç¨€ç–TCå—ã€‚ä¸¤ä¸ªç¨ å¯†è¾“å…¥çŸ©é˜µï¼ˆæŒ‰è®ºæ–‡å›¾8ä¸­çš„è®°å·ï¼Œè®°ä¸º A_dense å’Œ B_denseï¼Œæ»¡è¶³ C_sparse = A_dense Ã— B_denseï¼‰åˆ†åˆ«ä»¥ç¨ å¯†TCå—å½¢å¼åŠ è½½ï¼šA_dense ä¸º8Ã—8ï¼ˆè¡Œä¼˜å…ˆï¼‰ï¼ŒB_dense ä¸º8Ã—16ï¼ˆåˆ—ä¼˜å…ˆï¼‰ã€‚ è½¬ç½®è®¡ç®—çš„æ•°æ®å¯¹é½ï¼šSDDMMä¸­ç¨ å¯†è¾“å…¥çŸ©é˜µ Aï¼ˆè¡Œä¼˜å…ˆï¼‰å’Œ Bï¼ˆåˆ—ä¼˜å…ˆï¼‰çš„æ•°æ®å¸ƒå±€ï¼Œæ°å¥½æ»¡è¶³â€œäº¤æ¢ä¸è½¬ç½®MMAè®¡ç®—â€ï¼ˆBáµ€ Ã— Aáµ€ï¼‰çš„è¦æ±‚ã€‚ è½¬ç½®è®¡ç®—ï¼š\nç¨ å¯†è¾“å…¥ B è¢«è½¬ç½®ä¸º Báµ€ï¼ˆå°ºå¯¸16Ã—8ï¼‰ï¼Œä½œä¸ºå·¦æ“ä½œæ•°ã€‚ ç¨ å¯†è¾“å…¥ A è¢«è½¬ç½®ä¸º Aáµ€ï¼ˆå°ºå¯¸8Ã—8ï¼‰ï¼Œä½œä¸ºå³æ“ä½œæ•°ã€‚ è®¡ç®— Báµ€ Ã— Aáµ€ å¾—åˆ°ç¨ å¯†ç»“æœ C_denseáµ€ã€‚ ç”¨MçŸ©é˜µè¿›è¡Œelement-wise productï¼Œä»C_dense å¾—åˆ°C_sparse å®æµ‹: æœªæµ‹è¯•\nå®ç°ï¼šDF-GNN https://github.com/paoxiaode/DF-GNN\nä¸»é¢˜ï¼šblock/warpè°ƒåº¦å’Œç®—å­èåˆ\nç”±äºæˆ‘ä¸»è¦çœ‹äº†tilingéƒ¨åˆ†çš„ç®—æ³•ï¼ˆé€‚ç”¨äºå¤§å›¾å’Œé‚»å±…æ•°ä¸ç¡®å®šçš„å›¾ï¼Œä»…forwardï¼‰ï¼Œæ‰€ä»¥ä¸»è¦ä»‹ç»è¿™éƒ¨åˆ†ã€‚\nä½¿ç”¨çš„çŸ©é˜µæ ¼å¼æ˜¯CSRï¼Œä¸éœ€è¦åšé¢å¤–çš„æ ¼å¼è½¬æ¢\nç®—æ³•æµç¨‹ Launch Kernel on Grid: (n Ã— h)\râ†“\rEach Block â†’ (rid, hid): one node, one head\râ†“\rLoad Q[rid, hid, :] â†’ s_Q[f] (shm)\râ†“\rFor each tile of neighbors (size â‰¤ 32):\r- Load neighbor IDs from indices[]\r- Compute Q Â· K^T (dot product using s_Q and K[dst])\r- Reduce in warp â†’ store in neigh_nodes_weight[eid]\r- Find max(weight) in current tile â†’ weightMax\r- Adjust partial_sum and acc with exp(old_max - new_max)\r- Compute exp(weight - weightMax) and accumulate acc += exp_w * V[]\r- Accumulate partial_sum += exp_w\r- Update weightMax_old\râ†“\rFinal normalization: out_feat = acc / partial_sum\râ†“\rWrite back to global memory ä¸»è¦å°±æ˜¯é€šè¿‡åˆç†å®‰æ’GPUèµ„æºï¼ˆthreadblock, threadï¼‰å’Œè®¡ç®—ä»»åŠ¡çš„mappingï¼Œå®ç°åœ¨ä¸€ä¸ªkernel å†…è´Ÿè½½ç›¸å¯¹å‡è¡¡çš„å®Œæˆä»»åŠ¡ã€‚\nå®æµ‹: ä»£ç æ–¹é¢ï¼šå¼€æºçš„ä»£ç æœ‰æ¯”è¾ƒå¤šçš„bugï¼ŒåŒ…æ‹¬äº†data race, æŒ‡é’ˆè¿ç®—é”™è¯¯ç­‰ç­‰\nä¿®å¤åï¼š\nåœ¨å¸¸ç”¨å·¥ä½œèŒƒå›´å†…ï¼Œforwardé€Ÿåº¦è¾¾åˆ°DGLå®ç°çš„2.5x ~ 3x\nç²¾åº¦ï¼šå’ŒDGLå®ç°å¯¹æ¯”ï¼ŒMAEåœ¨1e-8 ~ 1e-9é‡çº§ï¼Œå·®è·å¯ä»¥å¿½ç•¥ä¸è®¡\nF3S https://github.com/HPCForge/Fused3S/tree/main/scripts ä¸»é¢˜ï¼šç®—å­èåˆ+æ··åˆç²¾åº¦+åˆ©ç”¨tensor core\nå…¶ä¸»è¦æ€è·¯è¿˜æ˜¯ç±»ä¼¼FlashSparseï¼Œä½†æ˜¯é€šè¿‡ç®—å­èåˆè¾¾åˆ°äº†æ›´é«˜çš„æ•ˆç‡ï¼ˆè®¿å­˜å¼€é”€ï¼Œkernel launchå¼€é”€æ›´å°ï¼‰ã€‚æ··åˆç²¾åº¦ç®—æ˜¯ä¸€ç§tradeoffã€‚\nä»…æœ‰forwardçš„å®ç° F3Sä¹Ÿä½¿ç”¨äº†è‡ªå®šä¹‰çš„çŸ©é˜µæ ¼å¼BSBï¼ŒåŸºæœ¬æƒ³æ³•æ˜¯åœ¨ä¸€ä¸ª16x1çš„blockä¸­ï¼Œå¦‚æœæœ‰ä¸€ä¸ªå…ƒç´ æ˜¯éé›¶çš„ï¼Œé‚£ä¹ˆå°±æŠŠè¿™æ•´ä¸ªblockéƒ½å½“æˆéé›¶çš„å­˜ä¸‹æ¥ã€‚ ä¼˜åŒ–çš„ä¸€ç‚¹åœ¨äºï¼Œblockå†…æ˜¯å¦ä¸º0è¢«å‹ç¼©åˆ°ä¸€ä¸ªbitä¸­ï¼Œæ¯ä¸ª16x8blockä»¥uint128ä¿å­˜ï¼Œå……åˆ†åˆ©ç”¨äº†attentionä¸­adjåªèƒ½ä¸º0/1çš„ç‰¹ç‚¹ å’Œflashsparseç›¸æ¯”ä¸è¶³çš„ä¸€ç‚¹åœ¨16x1ç²’åº¦æ›´å¤§ï¼Œå¤šä½™è®¡ç®—æ›´å¤šï¼Œä¹Ÿæ˜¯æœ¬å·¥ä½œæ²¡è€ƒè™‘åˆ°çš„ä¸€ç‚¹ ç©ºé—´å¼€é”€ï¼šO(n+nnz)ï¼Œä½†æ˜¯å¸¸æ•°ä¼šæ›´å¤§ä¸€äº› çŸ©é˜µæ ¼å¼è½¬æ¢æ—¶é—´å¼€é”€ (CSR -\u0026gt; BSB)ï¼šä¸€æ¬¡æ€§å¼€é”€ï¼Œæš‚æ—¶å¿½ç•¥ã€‚ ç®—æ³•æµç¨‹ï¼š åˆ’åˆ†è¡Œå—ï¼š\nå°† Q æŒ‰è¡Œåˆ’åˆ†ä¸º $T_r = \\lceil N / r \\rceil$ ä¸ªå— $\\{Q_1, ..., Q_{T_r}\\}$ï¼Œæ¯ä¸ªå¤§å°ä¸º $r \\times d$ã€‚ å°†è¾“å‡º O åŒæ ·åˆ’åˆ†ä¸º $T_r$ ä¸ªå— $\\{O_1, ..., O_{T_r}\\}$ï¼Œæ¯ä¸ªå¤§å°ä¸º $r \\times d$ã€‚ å¯¹æ¯ä¸ªè¡Œå—ç´¢å¼• $i = 1$ åˆ° $T_r$ï¼ˆå¹¶è¡Œå¤„ç†ï¼‰ï¼š\nåˆå§‹åŒ–\n$m_o \\leftarrow -\\infty \\in \\mathbb{R}^r$ï¼ˆè¡Œæœ€å¤§å€¼ï¼‰ $l_o \\leftarrow 0 \\in \\mathbb{R}^r$ï¼ˆè¡Œ softmax ç´¯åŠ å’Œï¼‰ $O_i \\leftarrow 0 \\in \\mathbb{R}^{r \\times d}$ï¼ˆè¾“å‡ºå—ï¼Œfp32ï¼‰ åŠ è½½æ•°æ®ï¼š\nå°† $Q_i$ ä»å…¨å±€å†…å­˜ï¼ˆHBMï¼‰åŠ è½½åˆ°å…±äº«å†…å­˜ï¼ˆSMEMï¼‰ã€‚ è®¡ç®—å½“å‰è¡Œçª—å£ï¼ˆRWï¼‰åŒ…å«çš„ TCB æ•°é‡ï¼š$t = \\text{tro}[i+1] - \\text{tro}[i]$ã€‚ é€šè¿‡ sptd è·å–å½“å‰ RW å¯¹åº”çš„åŸå§‹åˆ—ç´¢å¼•å‘é‡ $c$ã€‚ ä» $K$ å’Œ $V$ ä¸­æŒ‰ç´¢å¼• $c$ gather å‡ºå¯¹åº”çš„è¡Œï¼Œå¾—åˆ° $\\hat{K}, \\hat{V} \\in \\mathbb{R}^{t \\cdot c \\times d}$ã€‚ åˆ’åˆ† warp å—ï¼š\nå°† $\\hat{K}$ åˆ’åˆ†ä¸º $T_c = \\lceil t / W \\rceil$ ä¸ªå— $\\{\\hat{K}_1, ..., \\hat{K}_{T_c}\\}$ï¼Œæ¯ä¸ªå¤§å°ä¸º $Wc \\times d$ã€‚ å°† $\\hat{V}$ åŒæ ·åˆ’åˆ†ä¸º $T_c$ ä¸ªå— $\\{\\hat{V}_1, ..., \\hat{V}_{T_c}\\}$ï¼Œæ¯ä¸ªå¤§å°ä¸º $Wc \\times d$ã€‚ å¯¹æ¯ä¸ª warp å—ç´¢å¼• $j = 1$ åˆ° $T_c$ï¼š\nSDDMMï¼š\nè°ƒç”¨ $\\text{TBGemm}(Q_i, \\hat{K}_j^T, 0)$ï¼Œè®¡ç®—ä¸­é—´å¾—åˆ†å— $S_i \\in \\mathbb{R}^{r \\times c}$ï¼ˆfp32ï¼‰ã€‚ ç”¨ BSB ä¸­å¯¹åº” TCB çš„ bitmap å¯¹ $S_i$ è¿›è¡Œæ©ç ï¼ˆéé›¶ä½ç½®ä¿ç•™ï¼Œå…¶ä½™ç½® 0ï¼‰ã€‚ Online Softmaxï¼š\nè®¡ç®—å½“å‰å—è¡Œæœ€å¤§å€¼ï¼š$m_i = \\max(m_o, \\text{rowmax}(S_i))$ã€‚ è®¡ç®—æŒ‡æ•°ï¼š$E_i = \\exp(S_i - m_i)$ã€‚ æ›´æ–°ç´¯åŠ å’Œï¼š$l_o = \\text{diag}(\\exp(m_o - m_i)) \\cdot l_o + \\text{rowsum}(E_i)$ã€‚ å°† $E_i$ è½¬ä¸º fp16ï¼Œå­˜å…¥ SMEMã€‚ SpMMï¼š\nå¯¹å·²æœ‰è¾“å‡ºç¼©æ”¾ï¼š$O_i = \\text{diag}(\\exp(m_o - m_i)) \\cdot O_i$ã€‚ è°ƒç”¨ $\\text{TBGemm}(E_i, \\hat{V}_j, O_i)$ï¼Œå°†ç»“æœç´¯åŠ å› $O_i$ã€‚ æ›´æ–°è¡Œæœ€å¤§å€¼ï¼š$m_o = m_i$ã€‚ æœ€ç»ˆå½’ä¸€åŒ–å¹¶å†™å›ï¼š\nå¯¹è¾“å‡ºå—å½’ä¸€åŒ–ï¼š$O_i = \\text{diag}(l_o)^{-1} \\cdot O_i$ã€‚ å°† $O_i$ å†™å›å…¨å±€å†…å­˜ï¼ˆHBMï¼‰ã€‚ Subroutine: TBGemm è¾“å…¥:\nçŸ©é˜µå— $A \\in \\mathbb{R}^{m \\times K}$ (ä½äº SMEMï¼Œå…±äº«å†…å­˜) çŸ©é˜µå— $B \\in \\mathbb{R}^{K \\times P}$ (ä½äº HBMï¼Œå…¨å±€å†…å­˜) ç´¯åŠ é¡¹ $D \\in \\mathbb{R}^{m \\times P}$ (ä½äº SMEMï¼Œå…±äº«å†…å­˜) è¾“å‡º:\nç»“æœçŸ©é˜µ $C = A B + D \\in \\mathbb{R}^{m \\times P}$ æµç¨‹:\nåˆ‡åˆ†å— (Tiling): å°†è¾“å…¥çŸ©é˜µ $A$, $B$, $D$ æŒ‰ç…§ Tensor Core çš„ç¡¬ä»¶ Tile å°ºå¯¸ï¼ˆä¾‹å¦‚ $16 \\times 8 \\times 16$ï¼‰åˆ‡åˆ†ä¸ºå¯¹åº”çš„å­å—ã€‚\nå¹¶è¡Œè¿­ä»£ (Output Tiles): å¯¹ç»“æœçŸ©é˜µ $C$ çš„æ¯ä¸ªè¾“å‡º Tile (é€šå¸¸ç”±ä¸€ä¸ª Warp æˆ–ä¸€ä¸ª Thread Block è®¡ç®—):\nåŠ è½½ç´¯åŠ é¡¹ D: ä» SMEM ä¸­åŠ è½½ $D$ å¯¹åº”çš„å­å—åˆ°çº¿ç¨‹çš„å¯„å­˜å™¨ä¸­ï¼Œä½œä¸ºåˆå§‹ç´¯åŠ å€¼ $C$. å†…ç§¯è¿­ä»£ (K-Tiles): å¯¹ $K$ ç»´åº¦çš„æ¯ä¸ª $k$-tile è¿›è¡Œè¿­ä»£ç´¯åŠ :\nåŠ è½½ A: ä» SMEM ä¸­åŠ è½½çŸ©é˜µ $A$ å¯¹åº”çš„ $A_{\\text{tile}}$ å­å—ã€‚ åŠ è½½ B: ä» HBM ä¸­ç›´æ¥åŠ è½½çŸ©é˜µ $B$ å¯¹åº”çš„ $B_{\\text{tile}}$ å­å—ã€‚ æ‰§è¡Œ MMA æŒ‡ä»¤: è°ƒç”¨ç¡¬ä»¶æ”¯æŒçš„ PTX mma æŒ‡ä»¤ï¼ˆMatrix Multiply-Accumulateï¼‰ï¼Œæ‰§è¡Œè®¡ç®—å¹¶ç´¯åŠ ï¼š $$C \\leftarrow A_{\\text{tile}} \\cdot B_{\\text{tile}} + C$$ è¿”å›: æœ€ç»ˆå¾—åˆ°ç»“æœ $C$ã€‚\nå®æµ‹: ä»£ç æ–¹é¢ï¼šåœ¨çŸ©é˜µæ ¼å¼è½¬æ¢éƒ¨åˆ†æœ‰bugï¼Œå·²è”ç³»ä½œè€…ä¿®å¤ï¼›å¼€æºä»£ç æ²¡æœ‰multiheadï¼Œéœ€è¦è‡ªå·±å®ç°ã€‚\né€Ÿåº¦è¾¾åˆ°DGLå®ç°çš„3x(ç›¸å¯¹ç¨€ç–) åˆ°5x (ç›¸å¯¹ç¨ å¯†ï¼‰\né™åˆ¶ï¼šn % 16 == 0ï¼Œå› ä¸ºéœ€è¦åˆ†å‰²æˆ8x16çš„block\nç²¾åº¦ï¼šå’ŒDGLå®ç°å¯¹æ¯”ï¼ŒMAEåœ¨3e-5~1e-4 é‡çº§ï¼Œå¾ˆå¯èƒ½éœ€è¦é€šè¿‡å¯¹æ¨¡å‹è¿›è¡Œend2endæµ‹è¯•æ¥ç¡®å®šæ˜¯å¦é€‚åˆä½¿ç”¨ã€‚\n","date":"2 October, 2025","id":7,"permalink":"/chinese-post/gnn-optim/","summary":"æ³¨ï¼šæœ¬æ–‡ç”¨LLMè¾…åŠ©å†™ä½œçš„åœ°æ–¹ä¸»è¦åœ¨ï¼šæˆ‘è®¤ä¸ºLLMæ¯”æˆ‘ç†è§£çš„æ›´å¥½çš„åœ°æ–¹ï¼Œä¼šç”¨LLMçš„è¡¨è¿°ä»£æ›¿ã€‚","tags":"deep-learning","title":"è¿‘æœŸGNN Attentionç®—å­ä¼˜åŒ–å·¥ä½œé€Ÿè§ˆ"},{"content":"Background When training models with PyTorch, out-of-memory (OOM) errors are common, necessitating GPU memory optimization. When simple methods (like reducing batch size) no longer work, analyzing the memory footprint of the model itself may be required.\nAt this point, you might come across this documentation, which teaches you how to record a memory snapshot and visualize it on this website.\nHowever, thereâ€™s a major issue: the website is extremely laggy. If your model is small, with snapshots of just a few MB, the performance is somewhat tolerable. But if your model is large, with snapshots reaching tens or even hundreds of MB, the website becomes unbearably slow, with frame rates dropping as low as 2â€“3 frames per minute (this is not a typo).\nI looked into the websiteâ€™s JavaScript code, and hereâ€™s what it primarily does:\nManually loads Python pickle files; Re-parses the raw data into graphical representations time the viewport changes, then renders it to the screen. This parsing logic is written in JavaScript. You can imagine the performance when it is executed each frame, operating on hundred-MB data.\nInspiration My current work includes optimizing a deep learning model whose optimization is under-explored compared to LLM. I encountered this issue while working with a snapshot of a model with several billion parameters.\nWhy not just use existing LLM infrastructure instead of optimizing manually? Long story short, this model was custom-designed by a researcher and contains many modules completely different from standard LLMs. It seems like nowadays, everyone assumes deep learning is all about LLMs â€” so much so that even some tech leads believe LLM infrastructure can be easily adapted to other modelsâ€¦ but I digress. I originally wrote a simple script to parse the snapshotâ€™s contents, hoping to identify memory allocation issues in the model. But after working with this model for a month, I finally had enough. Thatâ€™s how this project â€” SnapViewer â€” came to be.\nTL;DRâ€‹â€‹: The graphical data from the memory snapshot is parsed and represented as a massive triangle mesh, leveraging existing rendering libraries to handle mesh rendering efficiently.\nHereâ€™s a snapshot of over 100 MB running smoothly on my integrated GPU:\nImplementation The reference implementation The snapshot format is partially documented in the record_memory_history function\u0026rsquo;s docstring. However, this documentation is incomplete â€” likely because later updates werenâ€™t reflected in the docstring.\nThe actual parsing of the snapshot into a dictionary happens here.\nThis script converts the allocator trace into a memory timeline, which is then passed to the web viewerâ€™s JS code. The JS code further transforms this into polygons (representing allocations) for visualization. Each polygon corresponds to an allocation, storing details like size and callstack. Implementation: Snapshot (De)serialize Initial implementation This part is impelmented in Python since I need to deal with Python-native data structures. I simply convert the dict to a json file.\nOptimizations Raw JSON is too large on disk â†’ compress it in-memory (Python zipfile) before writing. During visualization, read the ZIP from disk (Rust zip crate) and decompress in-memory. Tradeoffs This approach causes a temporary memory spike during JSON parsing but avoids persistent high memory usage. Also leverages Rustâ€™s serde-json (since Rustâ€™s serde-pickle is incomplete and canâ€™t handle recursive structures). Implementation: Rendering \u0026amp; Interactionâ€‹â€‹ This part is implemented in Rust.\nRendering Since allocation data remains static during visualization, all allocations are combined into a single large mesh and sent to the GPU once.\nâ€‹Library Usedâ€‹â€‹: three-d\nProvides good mesh abstraction. Supports one-time GPU upload (no per-frame CPUâ†’GPU transfers). Handles mouse/keyboard events. â€‹World-to-Window Coordinate Conversionâ€‹â€‹ â€‹Step 1â€‹â€‹: Convert window coordinates to world coordinates (scale + window center offset). â€‹â€‹Step 2â€‹â€‹: Convert world coordinates to memory positions (predefined scaling). UI \u0026amp; Interaction Featuresâ€‹ Memory Scale Markersâ€‹â€‹ Dynamically adjust the number and precision of markers based on screen visibility. Keep markers at consistent screen positions while moving/zooming. Pan \u0026amp; Zoomâ€‹â€‹ Track the original scale (1/zoom). Update to the new zoom level and compute the ratio between old and new scales. Adjust the screen center position based on the mouseâ€™s invariant world position. Implementation: Query After using this tool at work for around a week, I find myself frequently needing to search in the memory snapshot, especially:\nFind all allocations which is alive at a specific timestamp Find all allocations whose call stack has a specific substring Preferablly the allocations should be sorted by allocation size in descending order My first thought was to build a simple REPL and a simple command parser, and map each command to a specific query function.\nHowever, after having listed out all the functionalities I want, I found it to be a subset of database query, especially SQL.\nSo I decided not to reinvent wheels: I just connect to a in-memory SQLite database. Interfacing user is simple: read user input, let SQLite execute it and format the output to human-readable format.\nIf youâ€™ve struggled with PyTorch memory snapshots, check it out! Contributions \u0026amp; feedback welcome. â­\n","date":"1 October, 2025","id":8,"permalink":"/english-post/snapviewer/","summary":"When training models with PyTorch, out-of-memory (OOM) errors are common, necessitating GPU memory optimization. When simple methods (like reducing batch size) no longer work, analyzing the memory footprint of the model itself may be required.","tags":"torch deep-learning rust","title":"SnapViewer: Faster PyTorch Memory Allocation Viewer"},{"content":"å†…å­˜ä¸é€Ÿåº¦æ€§èƒ½é—®é¢˜æ’æŸ¥ å…è´£å£°æ˜ï¼šæˆ‘ä¸»è¦åœ¨ Windows ä¸Šä½¿ç”¨æœ€æ–°çš„ç¨³å®šç‰ˆ Rust å·¥å…·é“¾å’Œ CPython 3.13 è¿›è¡Œå¼€å‘å’Œæµ‹è¯•ã€‚\n1. èƒŒæ™¯ä¸åŠ¨æœº SnapViewer èƒ½å¤Ÿé«˜æ•ˆå¤„ç†å¤§å‹å†…å­˜å¿«ç…§â€”â€”ä¾‹å¦‚ï¼Œæ”¯æŒé«˜è¾¾ 1 GB çš„ pickle æ–‡ä»¶å’Œé«˜è¾¾ 500 MB çš„å‹ç¼©å¿«ç…§ã€‚ç„¶è€Œï¼Œåœ¨å¤„ç†è¶…å¤§è½¬å‚¨æ–‡ä»¶ï¼ˆä¾‹å¦‚ 1.3 GB çš„å¿«ç…§ï¼‰æ—¶ï¼Œæˆ‘ä»¬é‡åˆ°äº†ä¸¥é‡çš„å†…å­˜å’Œé€Ÿåº¦ç“¶é¢ˆï¼š\næ ¼å¼è½¬æ¢ï¼ˆpickle â†’ å‹ç¼© JSONï¼‰å¼•å‘äº†çº¦ 30 GB çš„å†…å­˜å³°å€¼ã€‚ å°†å‹ç¼© JSON åŠ è½½åˆ° Rust æ•°æ®ç»“æ„ä¸­åˆå¼•å‘äº†å¦ä¸€æ¬¡çº¦ 30 GB çš„å†…å­˜æ¿€å¢ã€‚ é¢‘ç¹çš„é¡µé¢é”™è¯¯ï¼ˆpage faultsï¼‰å’Œå¼ºçƒˆçš„ç£ç›˜ I/Oï¼ˆåœ¨ä»»åŠ¡ç®¡ç†å™¨ä¸­è§‚å¯Ÿåˆ°ï¼‰å¯¼è‡´åº”ç”¨ç¨‹åºå“åº”è¿Ÿç¼“ï¼Œç”šè‡³é¢‘ç¹å¡é¡¿ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬é‡‡ç”¨äº† Profile-Guided Optimizationï¼ˆPGOï¼ŒåŸºäºæ€§èƒ½åˆ†æçš„ä¼˜åŒ–ï¼‰æ–¹æ³•ã€‚\n2. Profile-Guided Optimizationï¼ˆPGOï¼‰ PGO éœ€è¦é€šè¿‡å®è¯åˆ†ææ¥è¯†åˆ«çœŸæ­£çš„çƒ­ç‚¹ã€‚æˆ‘é¦–å…ˆä½¿ç”¨ memory-stats crate è¿›è¡Œå†…å­˜åˆ†æï¼Œåœ¨æ—©æœŸä¼˜åŒ–é˜¶æ®µè¿›è¡Œè½»é‡çº§æ£€æŸ¥ã€‚éšåï¼Œæˆ‘å°†æ•°æ®åŠ è½½æµæ°´çº¿æ‹†è§£ä¸ºè‹¥å¹²ç¦»æ•£æ­¥éª¤ï¼š\nè¯»å–å‹ç¼©æ–‡ä»¶ï¼ˆé‡åº¦ç£ç›˜ I/Oï¼‰ ä»å‹ç¼©æµä¸­æå– JSON å­—ç¬¦ä¸² å°† JSON ååºåˆ—åŒ–ä¸ºåŸç”Ÿ Rust æ•°æ®ç»“æ„ å¡«å……å†…å­˜ä¸­çš„ SQLite æ•°æ®åº“ä»¥æ”¯æŒå³å¸­ SQL æŸ¥è¯¢ åœ¨ CPU ä¸Šæ„å»ºä¸‰è§’ç½‘æ ¼ï¼ˆtriangle meshï¼‰ åˆå§‹åŒ–æ¸²æŸ“çª—å£ï¼ˆCPU-GPU æ•°æ®ä¼ è¾“ï¼‰ æ€§èƒ½åˆ†ææ­ç¤ºäº†ä¸¤ä¸ªä¸»è¦çš„å†…å­˜é—®é¢˜ï¼šè¿‡åº¦å…‹éš†ï¼ˆexcessive cloningï¼‰å’Œå¤šä¸ªä¸­é—´æ•°æ®ç»“æ„ã€‚ä»¥ä¸‹æ˜¯æˆ‘å®æ–½çš„ä¼˜åŒ–æªæ–½ã€‚\næ¶ˆé™¤å†—ä½™çš„ Clone åœ¨å¿«é€ŸåŸå‹å¼€å‘é˜¶æ®µï¼Œè°ƒç”¨ .clone() éå¸¸æ–¹ä¾¿ï¼Œä½†ä»£ä»·é«˜æ˜‚ã€‚æ€§èƒ½åˆ†ææ˜¾ç¤ºï¼Œå…‹éš†å¤§å‹ Vec æ˜¾è‘—åŠ å‰§äº†å†…å­˜å³°å€¼å’Œ CPU æ—¶é—´ã€‚\né¦–æ¬¡å°è¯•ï¼šå°†å…‹éš†çš„ Vec\u0026lt;T\u0026gt; æ”¹ä¸ºå€Ÿç”¨çš„ \u0026amp;[T] åˆ‡ç‰‡ã€‚ä½†ç”±äºç”Ÿå‘½å‘¨æœŸçº¦æŸï¼Œæ­¤æ–¹æ¡ˆå¤±è´¥ã€‚ æœ€ç»ˆæ–¹æ¡ˆï¼šæ”¹ç”¨ Arc\u0026lt;[T]\u0026gt;ã€‚å°½ç®¡æˆ‘å¹¶æœªä½¿ç”¨å¤šçº¿ç¨‹ï¼Œä½† Arc æ»¡è¶³äº† PyO3 çš„è¦æ±‚ï¼Œä¸”åœ¨æ­¤ä¸Šä¸‹æ–‡ä¸­æœªè§‚å¯Ÿåˆ°æ˜æ˜¾å¼€é”€ã€‚ ä»…æ­¤ä¸€é¡¹æ”¹åŠ¨å°±æ˜¾è‘—é™ä½äº†å†…å­˜ä½¿ç”¨å¹¶æå‡äº†ååé‡ã€‚\næå‰é‡Šæ”¾ä¸­é—´ç»“æ„ æ„å»ºä¸‰è§’ç½‘æ ¼æ¶‰åŠå¤šä¸ªä¸´æ—¶è¡¨ç¤ºå½¢å¼ï¼š\nåŸå§‹åˆ†é…ç¼“å†²åŒº ä¸‰è§’å½¢åˆ—è¡¨ï¼ˆé¡¶ç‚¹ + é¢ç´¢å¼•ï¼‰ CPU ç«¯çš„ç½‘æ ¼ç»“æ„ GPU ä¸Šä¼ ç¼“å†²åŒº æ¯ä¸ªé˜¶æ®µéƒ½ä¼šä¿ç•™å…¶å‰é©±æ•°æ®ç›´è‡³ä½œç”¨åŸŸç»“æŸï¼Œä»è€Œæ¨é«˜äº†å³°å€¼å†…å­˜å ç”¨ã€‚ä¸ºåŠæ—¶é‡Šæ”¾è¿™äº›ä¸­é—´æ•°æ®ï¼Œæˆ‘ä»¬é‡‡å–äº†ä»¥ä¸‹æªæ–½ï¼š\nä½¿ç”¨ä½œç”¨åŸŸå—ï¼ˆscoped blocksï¼‰é™åˆ¶ç”Ÿå‘½å‘¨æœŸ å¯¹ä¸å†éœ€è¦çš„ç¼“å†²åŒºæ˜¾å¼è°ƒç”¨ drop() ç»è¿‡è¿™äº›è°ƒæ•´ï¼Œå³°å€¼å†…å­˜å¤§çº¦å‡å°‘äº†ä¸‰åˆ†ä¹‹ä¸€ã€‚\n3. åˆ†ç‰‡å¤„ç† JSON ååºåˆ—åŒ– å¯¹åŒ…å«è¶…è¿‡ 50,000 ä¸ªæ¡ç›®çš„è°ƒç”¨æ ˆ JSON è¿›è¡Œååºåˆ—åŒ–æ—¶ï¼Œå†…å­˜ä½¿ç”¨æ€¥å‰§é£™å‡ã€‚ä¸ºç¼“è§£æ­¤é—®é¢˜ï¼š\nå°† JSON æ•°æ®åˆ†ç‰‡ï¼Œæ¯ç‰‡æœ€å¤šåŒ…å« 50,000 ä¸ªæ¡ç›®ã€‚ ç‹¬ç«‹ååºåˆ—åŒ–æ¯ä¸ªåˆ†ç‰‡ã€‚ åˆå¹¶ç»“æœå‘é‡ã€‚ è¿™ç§æµå¼å¤„ç†æ–¹æ³•ä½¿æ¯ä¸ªåˆ†ç‰‡çš„å†…å­˜å ç”¨ä¿æŒåœ¨è¾ƒä½æ°´å¹³ï¼Œé¿å…äº†ä¹‹å‰çš„å¤§è§„æ¨¡å•æ¬¡åˆ†é…ã€‚\nå€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œserde_json::StreamDeserializer æ˜¯å¦ä¸€ä¸ªå€¼å¾—å°è¯•çš„é€‰é¡¹ã€‚\n4. é‡æ–°è®¾è®¡å¿«ç…§æ ¼å¼ å³ä½¿ç»è¿‡ä¸Šè¿°ä¼˜åŒ–ï¼Œè°ƒç”¨æ ˆæ•°æ®ä»ç„¶æ˜¯å†…å­˜ä¸­æœ€å¤§çš„ç»„ä»¶â€”â€”åœ¨ Rust ä¸­å’Œå†…å­˜ SQLite æ•°æ®åº“ä¸­å„å­˜ä¸€ä»½ï¼Œé€ æˆé‡å¤ã€‚\nä¸ºæ¶ˆé™¤å†—ä½™ï¼Œæˆ‘é‡æ–°æ€è€ƒäº†æ¯ç§è¡¨ç¤ºå½¢å¼çš„ç”¨é€”ï¼š\nRust ç»“æ„ï¼šç”¨æˆ·ç‚¹å‡»æ—¶åœ¨å±å¹•ä¸Šæ˜¾ç¤ºè°ƒç”¨æ ˆã€‚ SQLite æ•°æ®åº“ï¼šæ”¯æŒå³å¸­ SQL æŸ¥è¯¢ã€‚ ç”±äº SnapViewer æ˜¯å•çº¿ç¨‹çš„ï¼Œä¸”å¯å®¹å¿å¶å°”çš„ç£ç›˜ I/Oï¼Œæˆ‘å°†å¿«ç…§æ‹†åˆ†ä¸ºä¸¤ä¸ªæ–‡ä»¶ï¼š\nallocations.jsonï¼šè½»é‡çº§ JSONï¼ŒåŒ…å«åˆ†é…æ—¶é—´æˆ³å’Œå¤§å°ã€‚ elements.dbï¼šSQLite æ•°æ®åº“ï¼Œå­˜å‚¨è°ƒç”¨æ ˆæ–‡æœ¬ï¼ˆæŒ‰åˆ†é…ç´¢å¼•å»ºç«‹ç´¢å¼•ï¼‰ã€‚ è¿™ä¸¤ä¸ªæ–‡ä»¶è¢«ä¸€èµ·å‹ç¼©æ‰“åŒ…ã€‚è¿è¡Œæ—¶ï¼š\nè§£å‹å¿«ç…§ã€‚ å°† allocations.json åŠ è½½åˆ°å†…å­˜ï¼ˆå ç”¨å¾ˆå°ï¼‰ã€‚ æ‰“å¼€ç£ç›˜ä¸Šçš„ elements.dbã€‚ ç”¨æˆ·ç‚¹å‡»æ—¶ï¼Œé€šè¿‡ WHERE idx = \u0026lt;allocation_index\u0026gt; æŸ¥è¯¢ elements.dbã€‚ SQLite é«˜æ•ˆçš„ç£ç›˜ç´¢å¼•ä½¿è¿™äº›æŸ¥è¯¢éå¸¸è¿…é€Ÿï¼Œå¯¹å¸§ç‡å‡ ä¹æ²¡æœ‰å¯æ„ŸçŸ¥çš„å½±å“ã€‚\né‡æ„è½¬æ¢è„šæœ¬ æˆ‘å¯¹å¿«ç…§è½¬æ¢è„šæœ¬è¿›è¡Œäº†å¦‚ä¸‹æ›´æ–°ï¼š\nè§£æåŸå§‹å¿«ç…§æ ¼å¼ã€‚ å°†è°ƒç”¨æ ˆæ‰¹é‡æ’å…¥å†…å­˜ SQLite æ•°æ®åº“ï¼Œç„¶åå°†æ•°æ®åº“è½¬å‚¨ä¸ºå­—èŠ‚æµã€‚ å°†åˆ†é…å…ƒæ•°æ®åºåˆ—åŒ–ä¸º JSONã€‚ å°† JSON ä¸æ•°æ®åº“å­—èŠ‚æµä¸€èµ·å‹ç¼©ã€‚ è™½ç„¶è½¬æ¢è¿‡ç¨‹ç•¥æ…¢ï¼Œä½†ç”Ÿæˆçš„å¿«ç…§åŠ è½½æ›´å¿«ï¼Œä¸”å†…å­˜å ç”¨å¤§å¹…é™ä½ã€‚\n5. æˆæœä¸ç»éªŒæ€»ç»“ ç»è¿‡è¿™äº›ä¼˜åŒ–ï¼ŒSnapViewer å®ç°äº†ä»¥ä¸‹æ”¹è¿›ï¼š\nä¸å†å› åŠ è½½å¤§å‹å¿«ç…§è€Œè§¦å‘ 60+ GB çš„å†…å­˜å³°å€¼ï¼Œå› ä¸ºæˆ‘ä»¬å®Œå…¨ä¸å†å°†æ•´ä¸ªè°ƒç”¨æ ˆä¿¡æ¯åŠ è½½åˆ°å†…å­˜ä¸­ã€‚ å¯åŠ¨é€Ÿåº¦æ˜¾è‘—æå‡ã€‚ å³ä½¿è¿›è¡ŒæŒ‰éœ€è°ƒç”¨æ ˆæŸ¥è¯¢ï¼Œæ¸²æŸ“ä¾ç„¶æµç•…ã€‚ æˆ‘å­¦åˆ°çš„ç»éªŒï¼š\nä¸è¦æ€»æ˜¯æŠŠæ‰€æœ‰æ•°æ®éƒ½åŠ è½½åˆ°å†…å­˜ä¸­ã€‚å½“ä½ è€—å°½ç‰©ç†å†…å­˜æ—¶ï¼Œè™šæ‹Ÿå†…å­˜äº¤æ¢ç³»ç»Ÿçš„æ€§èƒ½å¯èƒ½æ¯”ä½ æƒ³è±¡çš„è¿˜è¦å·®ã€‚ å½“ä½ éœ€è¦å°†å¤§éƒ¨åˆ†æ•°æ®å­˜å‚¨åœ¨ç£ç›˜ä¸Šï¼ŒåŒæ—¶æ™ºèƒ½åœ°ç¼“å­˜éƒ¨åˆ†æ•°æ®åˆ°å†…å­˜æ—¶ï¼Œè¯·ä½¿ç”¨ SQLiteã€‚å®ƒå†…ç½®äº†ç»è¿‡å·¥ä¸šéªŒè¯çš„é«˜æ•ˆç®—æ³•ã€‚ ","date":"7 June, 2025","id":9,"permalink":"/chinese-post/snapviewer-3-zh/","summary":"å…è´£å£°æ˜ï¼šæˆ‘ä¸»è¦åœ¨ Windows ä¸Šä½¿ç”¨æœ€æ–°çš„ç¨³å®šç‰ˆ Rust å·¥å…·é“¾å’Œ CPython 3.13 è¿›è¡Œå¼€å‘å’Œæµ‹è¯•ã€‚","tags":"torch deep-learning rust","title":"Snapviewer Devlog #3: æ€§èƒ½ä¼˜åŒ–"},{"content":"Lsm Tree æ˜¯ä¸€ç§å†…å­˜-ç£ç›˜çš„å±‚çº§å¼æ•°æ®ç»“æ„ï¼Œå¸¸ç”¨äºå®ç°å†™å¤šè¯»å°‘çš„å­˜å‚¨å¼•æ“ã€‚\nç»„ä»¶ å†…å­˜éƒ¨åˆ† ç£ç›˜éƒ¨åˆ† WAL æ€»ä½“ åˆå§‹åŒ– éœ€è¦ init flush threadã€‚flush thread çš„å·¥ä½œæµç¨‹:\nç­‰å¾… flush ä¿¡å·é‡è¢« notify,è·å–ä¸€ä¸ª compact ä¿¡å·é‡èµ„æº å¯åŠ¨ä¸€ä¸ª sstwriter,å†™å…¥è¿™ä¸ª memtable ä¸€ä¸ª memtable å¯¹ä¸€ä¸ª sst ç­‰åˆ°å†™å…¥ sst å†™å®Œä¹‹å,æ‰è¿›è¡Œ: ä» frozen memtablesã€frozen memtable sizes é‡Œé¢åˆ é™¤è¿™ä¸ª memtable ä» wal é‡Œé¢åˆ é™¤è¿™ä¸ª memtable å¯¹åº”çš„ wal update manifest Try Freeze å¦‚æœå½“å‰å¤§å° \u0026gt; freeze size é‚£ä¹ˆå°± freeze;è¿›ä¸€æ­¥å¦‚æœæ‰€æœ‰ frozen memtable å¤§å°ä¹‹å’Œ \u0026gt; flush threshold,é‚£ä¹ˆå°± set flush signalã€‚\nå†™æ“ä½œ å†™ memtable å†™ WAL try freeze å†…å­˜éƒ¨åˆ† Put æ·»åŠ åˆ° memtable; æ›´æ–° sizeã€‚ size ä¸éœ€è¦ç‰¹åˆ«ç²¾ç¡®,åªéœ€è¦æ˜¯ä¸€ä¸ªå¤§è‡´çš„å€¼å³å¯ã€‚ Delete æ·»åŠ ä¸€ä¸ª tomb æ ‡è®°åˆ° memtable Get ä» active memtable ä¸­è·å– ä» new åˆ° old éå†æ‰€æœ‰çš„ inactive memtable,è·å–ã€‚ ç£ç›˜éƒ¨åˆ† compact ä¿¡å·é‡ äºŒå…ƒä¿¡å·é‡ã€‚\néœ€è¦ compact çš„æ—¶å€™,æ·»åŠ èµ„æº compact thread å¼€å§‹ compact çš„æ—¶å€™,æ¶ˆè€—èµ„æºã€‚ åˆå§‹åŒ– å¦‚æœ auto compact å¼€å¯,åˆå§‹åŒ–çš„æ—¶å€™éœ€è¦ init compact thread:\nLevel å­˜å‚¨è¿™ä¸ª level æ‰€æœ‰æ–‡ä»¶å¯¹åº”çš„æ–‡ä»¶è·¯å¾„,è£…åœ¨ sst reader é‡Œé¢\nGet (æ²¡æœ‰ delete, put) ä»ä½åˆ°é«˜,ä»æ–°åˆ°æ—§,è°ƒç”¨ sst çš„ get æ–¹æ³•,è·å– recordã€‚å¦åˆ™è¿”å› noneã€‚\nInit Compact Thread Compact thread:\nç­‰å¾… compact ä¿¡å·é‡ ä¾æ¬¡æŸ¥çœ‹æ¯ä¸€å±‚:å¦‚æœè¿™ä¸€å±‚å¤§å°è¶…è¿‡ threshold,å°±åˆå¹¶åˆ°ä¸‹ä¸€å±‚,å¦åˆ™å°±æå‰è¿”å›ã€‚ Compact ä»¥ L0 -\u0026gt; L1 ä¸ºä¾‹: ä»å‰åˆ°åéå†æ‰€æœ‰çš„ kv-pair,åŒæ—¶ç»´æŠ¤:\nkeys_outdated åŒä¸€ä¸ª key,timetsamp å°äº oldest marker çš„ kv pair åªéœ€è¦ä¿ç•™ä¸€ä¸ªã€‚ keys_outdated è®°å½•æ‰€æœ‰(å‡ºç°è¿‡çš„,ä¸” timestamp å°äº oldest marker)çš„ key L1 sst size æ¯è¾¾åˆ°ä¸€å®šå€¼å°±å…³é—­å½“å‰ sst,æ–°å¼€ä¸€ä¸ªæ–°çš„ sstã€‚ æ›´æ–° manifestã€‚ SST writer é…ç½® max block sizeã€‚\næ¯ä¸ª block çš„å¼€å¤´ä¸€ä¸ª key ä¼šæ·»åŠ åˆ° index ä¸­; æœç´¢è¿™ä¸ª sst çš„æ—¶å€™,ä¼šå…ˆå¯¹ index è¿›è¡ŒäºŒåˆ†æŸ¥æ‰¾; åœ¨ block ä¹‹å†…é‡‡ç”¨çº¿æ€§æœç´¢ã€‚ fpr,ç”¨äºæ„å»º bloom filter.\nå†™å…¥ éå†æ‰€æœ‰çš„ kv pair: userkey(ä¸å« timestamp)æ·»åŠ åˆ° bloom filter; block å†™å…¥å½“å‰ kv; å¦‚æœå½“å‰ block å¤§å°è¶…è¿‡ max block size,å°±å¼€å¯ä¸€ä¸ªæ–°çš„ block,ç„¶åå†™å…¥å¯¹åº”çš„ index(å†…å­˜) å°† index å’Œ bloom filter å†™ç£ç›˜ã€‚ SST reader æŸ¥æ‰¾: Get(key, timestamp) æŸ¥ bloom filter,å¦‚æœä¸å­˜åœ¨å°±è¿”å›ã€‚ å°† index æ•´ä¸ªè½½å…¥å†…å­˜ä¸­,è¿›è¡ŒäºŒåˆ†æŸ¥æ‰¾,å¾—åˆ°å¯¹åº” key-timestamp æ‰€åœ¨çš„åŒºé—´ã€‚å¦‚æœ out of bounds å°±è¿”å›ã€‚ æŒ‰ç…§æŸ¥æ‰¾åˆ°çš„åŒºé—´,è¯»ç£ç›˜ã€‚ MVCC key æ’å¸ƒé—®é¢˜ struct Key bytes timestamp: u64 æ¯”è¾ƒ: key1 \u0026lt; key2:\nkey1.bytes \u0026lt; key2.bytes (å­—å…¸åº); æˆ–è€…: key1.bytes == key2.bytes,è€Œä¸” key1.timestamp \u0026gt; key2.timestamp ä¸ºä»€ä¹ˆè¿™æ ·æ¯”è¾ƒ? åœ¨è¿›è¡ŒæŸ¥è¯¢ Get(userkey, timestamp) çš„æ—¶å€™,æˆ‘ä»¬éœ€è¦çš„æ˜¯:\nuserkey åŒ¹é… timestamp å°äºæŸ¥è¯¢çš„ timestamp,ä¸”å°½å¯èƒ½å¤§ å› æ­¤,æˆ‘ä»¬å°†\nuserkey å‡åºæ’åº timestamp é™åºæ’åº åœ¨æœç´¢ memtable(skiplist)çš„æ—¶å€™,æˆ–è€…å¯¹ index è¿›è¡ŒäºŒåˆ†æŸ¥æ‰¾çš„æ—¶å€™,å°±å¯ä»¥:\nç›´æ¥ä½¿ç”¨ lower_bound,æŸ¥æ‰¾å¤§äºç­‰äºè‡ªå·±çš„ç¬¬ä¸€ä¸ªå…ƒç´  å¦‚æœ userkey åŒ¹é…,è¯´æ˜æ˜¯ timestamp å°äºå½“å‰ timestamp çš„,timestamp æœ€å¤§çš„è®°å½•,è¿”å›; å¦‚æœ userkey ä¸åŒ¹é…,è¯´æ˜ä¸å­˜åœ¨ timestamp å°äºå½“å‰ timestamp çš„è®°å½•,è¿”å›(æœªæ‰¾åˆ°)ã€‚ Transaction æ•°æ®ç»“æ„ ä¸€ä¸ªå†…å­˜ tempmap,ç”¨æ¥å­˜å‚¨ transaction å·²ç»å†™,ä½†æ˜¯æœªæäº¤çš„å†…å®¹ã€‚ åˆ›å»ºçš„æ—¶å€™,ä» tree è·å–:\nstart timestamp,ä½œä¸ºæŸ¥è¯¢çš„ timestamp transaction id ç„¶åå†™å…¥ transaction start åˆ° WAL\nPut,Delete å†™ tempmap,å†™ WAL\nGet ä½¿ç”¨ start timestamp,å…ˆæŸ¥ tempmap,å†æŸ¥ treeã€‚\nCommit ä» tree è·å–ä¸€ä¸ª commit timestamp; å†™ WAL,è®°å½• transaction id å’Œ commit timestampã€‚ åœ¨ replay çš„æ—¶å€™,æŠŠ transaction id å’Œ commit timestamp å¯¹åº”èµ·æ¥å°±å¯ä»¥çŸ¥é“ transaction é‡Œé¢çš„ å†™æ“ä½œ å¯¹åº”çš„ timestamp è°ƒç”¨ tree.active_memtable çš„ API,å°† transaction çš„æ‰€æœ‰æ•°æ®å†™å…¥ tree çš„ memtableã€‚ WAL çœ‹åˆ° transaction start,å…ˆå°† transaction æš‚å­˜åˆ°å†…å­˜ä¸­:\nå¦‚æœåœ¨ replay ç»“æŸä¹‹å‰çœ‹åˆ°äº† transaction end,å°±å°†æ”¹åŠ¨å†™å…¥ tree ä¸­(redo)ã€‚ å¦åˆ™æ”¾å¼ƒ,è§†ä¸ºæ²¡å®Œæˆçš„äº‹åŠ¡(undo) è¸©å‘: Resource deadlock avoided (os error 35),å¯èƒ½æ˜¯ä¸€ä¸ª thread æŒæœ‰äº†è‡ªå·±çš„ joinhandle å¹¶ä¸” join äº†è‡ªå·±;ä½¿ç”¨ maybe join è§£å†³,å³åˆ¤æ–­å½“å‰çº¿ç¨‹å’Œ joinhandle çš„çº¿ç¨‹æ˜¯å¦ä¸€è‡´,å¦‚æœä¸€è‡´å°±ä¸ç”¨ joinã€‚ æ­»é”é—®é¢˜: wal å’Œ mem éƒ½æœ‰é”,å¿…é¡» æŒ‰ç…§åŒä¸€é¡ºåºè·å– æ‰ä¸ä¼šå‡ºç°æ­»é”ã€‚ Bloom filter ç»†èŠ‚ æœ¬éƒ¨åˆ†ç”± Deepseek è¾…åŠ©å†™ä½œ\nè¯¥ Bloom filter ç®—æ³•çš„ä¸»è¦æ­¥éª¤å¦‚ä¸‹:\nå‚æ•°è®¡ç®—:\næ ¹æ®é¢„æœŸå…ƒç´ æ•°é‡ n å’Œå¯æ¥å—è¯¯åˆ¤ç‡ p,é€šè¿‡å…¬å¼è®¡ç®—æœ€ä¼˜ä½æ•° m å’Œå“ˆå¸Œå‡½æ•°æ•°é‡ k: $ m=\\lceil-n \\dfrac{\\ln(p)}{\\ln(2) ^ 2}\\rceil $ $ k=\\lceil\\dfrac{m}{n}\\ln(2)\\rceil $ å½“ç›´æ¥æŒ‡å®šå‚æ•°æ—¶,ä½¿ç”¨ç»™å®šçš„ä½æ•°å’Œå“ˆå¸Œå‡½æ•°æ•°é‡ å“ˆå¸Œç”Ÿæˆ:\nä½¿ç”¨ 64 ä½æŒ‡çº¹å“ˆå¸Œ(farmhash)ç”Ÿæˆåˆå§‹å“ˆå¸Œå€¼ h é€šè¿‡ä½è¿ç®—æ„é€ å¢é‡å€¼ delta = (h \u0026gt;\u0026gt; 33) | (h \u0026lt;\u0026lt; 31) é‡‡ç”¨åŒé‡å“ˆå¸ŒæŠ€æœ¯,é€šè¿‡å¾ªç¯å åŠ  delta ç”Ÿæˆ k ä¸ªä¸åŒçš„ä½ä½ç½®: $ h_i \\equiv h + i \\cdot delta \\pmod m , 0 \\leq i \\lt k $ æ•°æ®æ’å…¥:\nå¯¹è¾“å…¥ key è¿›è¡Œå“ˆå¸Œè®¡ç®—å¾—åˆ°åˆå§‹ h å’Œ delta å¾ªç¯ k æ¬¡ç”Ÿæˆä½ä½ç½®,å°†ä½æ•°ç»„ä¸­å¯¹åº”ä½ç½®è®¾ä¸º 1 é‡‡ç”¨ä½æ“ä½œ: byte_index = position/8,bit_mask = 1 \u0026laquo; (position%8) å­˜åœ¨æ€§æ£€æµ‹:\né‡å¤æ’å…¥æ—¶çš„å“ˆå¸Œè®¡ç®—è¿‡ç¨‹ æ£€æŸ¥æ‰€æœ‰ k ä¸ªå¯¹åº”ä½æ˜¯å¦å‡ä¸º 1 ä»»ä¸€ä½ç½®ä¸º 0 åˆ™åˆ¤å®šä¸å­˜åœ¨,å…¨éƒ¨ä¸º 1 æ—¶åˆ¤å®šå¯èƒ½å­˜åœ¨ æ•°æ®æŒä¹…åŒ–:\nåºåˆ—åŒ–æ—¶é™„åŠ  CRC32 æ ¡éªŒå’Œ ååºåˆ—åŒ–æ—¶éªŒè¯æ ¡éªŒå’Œä¸æ•°æ®å®Œæ•´æ€§ ","date":"1 March, 2025","id":10,"permalink":"/chinese-post/lsm/","summary":"Lsm Tree æ˜¯ä¸€ç§å†…å­˜-ç£ç›˜çš„å±‚çº§å¼æ•°æ®ç»“æ„ï¼Œå¸¸ç”¨äºå®ç°å†™å¤šè¯»å°‘çš„å­˜å‚¨å¼•æ“ã€‚","tags":"","title":"Lsm Tree å®ç°å¤‡æ³¨"},{"content":"æœ¬æ–‡æ²¡æœ‰ä»»ä½•æ•°å­¦æ¨å¯¼ã€‚æˆ‘ä»¬ä»ç›´è§‚ä¸Šç†è§£è¿™ä¸ªç®—æ³•ï¼Œç„¶åç›´æ¥ä»‹ç»ç®—æ³•çš„æµç¨‹ã€‚å¸Œæœ›äº†è§£æ•°å­¦æ¨å¯¼çš„è¯»è€…å¯ä»¥æŸ¥çœ‹ CMU çš„æ•™æ¡ˆåŠå…¶ç¿»è¯‘ã€‚\n1. é—®é¢˜ å¯¹äºå®å¯¹ç§°çŸ©é˜µ $A \\in \\mathbb{R}^{n \\times n}$ å’Œå‘é‡ $b \\in \\mathbb{R}^n$ï¼Œæ±‚è§£\n$$Ax = b$$æˆ–è€…ï¼Œç­‰ä»·çš„ï¼Œ\n$$\\text{argmin}_x f(x)$$å…¶ä¸­\n$$f(x) = \\frac{1}{2}x^T A x - b^T x$$2. é¢„å¤‡çŸ¥è¯† 2.1. ä»é«˜ä¸­å­¦çš„äºŒçº§ç»“è®ºè¯´èµ· é«˜ä¸­çš„æ—¶å€™æˆ‘ä»¬å­¦è¿‡æ¤­åœ†ï¼š\n$$a^{-2}x^2 + b^{-2}y^2 = 1$$å¦‚æœä½ è®°æ€§å¥½çš„è¯ï¼Œä½ åº”è¯¥è®°å¾—è¿™ä¸ªäºŒçº§ç»“è®ºï¼š\nè¿™æ˜¯ä¸€ä¸ªä»åœ†é‡Œé¢æ¨å¹¿è€Œæ¥çš„ç»“è®ºï¼šå¦‚æœ $a = b$ï¼Œæ¤­åœ†é€€åŒ–ä¸ºåœ†ï¼Œ$k_{OM}k_l = -1$ï¼Œå³ $OM, l$ ä¸¤æ¡ç›´çº¿å‚ç›´ã€‚\n2.2. æœ€é€Ÿä¸‹é™æ³• é¦–å…ˆï¼Œä½ åº”è¯¥çŸ¥é“æ¢¯åº¦ä¸‹é™æ³•ï¼š\n$$x_{i+1} = x_i - \\alpha\\nabla f(x_i)$$æœ€é€Ÿä¸‹é™æ³•å°±æ˜¯åœ¨æ¢¯åº¦ä¸‹é™æ³•çš„åŸºç¡€ä¸Šï¼Œé€‰æ‹© $\\alpha$ ä½¿å¾— $x_{i+1}$ è¾¾åˆ°æœ€å°ï¼ˆåœ¨æœç´¢æ–¹å‘ä¸Šçš„æœ€å°å€¼ï¼‰ï¼š\n$$\\alpha^* = \\text{argmin}_\\alpha f(x_i - \\alpha\\nabla f(x_i))$$3. å…±è½­æ¢¯åº¦æ³• 3.1. è®°å· $x_i$ï¼šç¬¬ $i$ æ¬¡å¾ªç¯ä¹‹åçš„ $x$ å‘é‡\n$r_i$ï¼š$b_i - Ax_i$ï¼Œç›®æ ‡å‡½æ•° $f(x)$ åœ¨ $x_i$ ç‚¹çš„è´Ÿæ¢¯åº¦ï¼Œæˆ–è€…çº¿æ€§æ–¹ç¨‹ç»„åœ¨ $x_i$ ç‚¹çš„æ®‹å·®ã€‚\nè¯·è®°ä½ï¼šè´Ÿæ¢¯åº¦å’Œæ®‹å·®æ˜¯ä¸€ä¸ªä¸œè¥¿ï¼ $d_i$ï¼šåœ¨ $x_i$ ç‚¹çš„æœç´¢æ–¹å‘ã€‚æœ€é€Ÿä¸‹é™ç®—æ³•é‡Œ $d_i = r_i$ï¼Œå…±è½­æ¢¯åº¦é‡Œé¢éœ€è¦ä¸€ç‚¹ä¿®æ­£ã€‚\n3.2. æœ€é€Ÿä¸‹é™ æœ€é€Ÿä¸‹é™çš„æ–°æ–¹å‘ï¼š$r_{i+1}$\næ–°æ–¹å‘ä¸å‰ä¸€æ­¥ä¸‹é™æ–¹å‘ $r_i$ å‚ç›´ï¼ˆç”»ä¸ªç­‰é«˜çº¿å›¾ç›´è§‚ç†è§£ï¼Œæˆ–è€…å›æƒ³ä¸€ä¸‹\u0026quot;ç­‰åŠ¿é¢å’Œç”µåœºçº¿å‚ç›´\u0026quot;ï¼‰ æœ€é€Ÿä¸‹é™çš„ $\\alpha$ $$\\alpha_i = \\frac{r_i^T r_i}{d_i^T A d_i}$$3.3. å…±è½­æ¢¯åº¦ æˆ‘ä»¬ç›´æ¥é€é¡¹ç±»æ¯”æœ€é€Ÿä¸‹é™ã€‚\næ–°æ–¹å‘ä¸å‰ä¸€æ­¥ä¸‹é™æ–¹å‘ $r_i$ å‚ç›´ æ–œç‡ä¹‹ç§¯ä¸º $-a^{-2}b^2$ (Section 2.1)\nè¿™ä¸ªæ–¹å‘ç”±æœ€é€Ÿä¸‹é™çš„æ–¹å‘è¿›è¡Œä¸€äº›å°æ”¹åŠ¨å¾—åˆ°ï¼Œæˆ‘ä»¬å¯ä»¥åœ¨åé¢çš„ç®—æ³•éƒ¨åˆ†(Section 3.4)çœ‹åˆ°ã€‚æŠŠè¿™ä¸ªæ–¹å‘ä»å’Œå‰ä¸€ä¸ªæœç´¢æ–¹å‘å‚ç›´æ”¹åŠ¨åˆ°æ–œç‡ä¹‹ç§¯ä¸º $-a^{-2}b^2$ å°±æ˜¯ CG å’Œæœ€é€Ÿä¸‹é™å”¯ä¸€ä¸åŒçš„åœ°æ–¹ã€‚ æ­¥é•¿ $\\alpha$ï¼šç”±äºæ˜¯åœ¨ä¸€æ¡ç›´çº¿ä¸Šåšä¼˜åŒ–ï¼Œå› æ­¤å’Œæœ€é€Ÿä¸‹é™çš„ $\\alpha$ ç›¸åŒã€‚ ç”±äºä¸€æ¬¡è¿­ä»£åªæ¶‰åŠåˆ°ä¸¤ä¸ªç‚¹ã€ä¸¤ä¸ªå‘é‡ï¼Œåªèƒ½æ„æˆä¸€ä¸ªå¹³é¢ï¼Œæˆ‘ä»¬ç”šè‡³ä¸éœ€è¦å°†äºŒç»´å‘å¤šç»´æ¨å¹¿ã€‚\nè‹¥éœ€æ¨å¯¼ï¼Œæˆ‘ä»¬éœ€è¦åšçš„åªæ˜¯æŠŠç‚¹çš„ $n$ ç»´åæ ‡æ˜ å°„åˆ°äºŒç»´ï¼Œç„¶åå¯¹æˆªé¢æ¤­åœ†å¯¹åº”çš„äºŒé˜¶äºŒæ¬¡å‹è¿›è¡Œ SVD è·å¾—å…¶é•¿è½´ $a$ å’ŒçŸ­è½´ $b$ï¼Œè¿›è€Œæ ¹æ®å…¶ç¦»åŠä¸Šè¿°æ–œç‡ç§¯çš„äºŒçº§ç»“è®ºè®¡ç®—ä¸¤ä¸ªæ–¹å‘çš„å…³ç³»ã€‚è¿™é‡Œä¸å±•å¼€ã€‚ 3.4. ç®—æ³• 3.4.1. åˆå§‹åŒ– ç®—æ³•è¾“å…¥ï¼š$A, b, x_0$\n$$\\vec{d}_{(0)} = \\vec{r}_{(0)} = \\vec{b}_{(0)} - \\mathbf{A}\\vec{x}_{(0)}$$3.4.2. ç®—æ³•è¿‡ç¨‹ $$\\alpha_{(i)} = \\frac{\\vec{r}_{(i)}^T \\vec{r}_{(i)}}{\\vec{d}_{(i)}^T \\mathbf{A}\\vec{d}_{(i)}}$$$$\\vec{x}_{(i+1)} = \\vec{x}_{(i)} + \\alpha_{(i)}\\vec{d}_{(i)}$$$$\\vec{r}_{(i+1)} = \\vec{r}_{(i)} - \\alpha_{(i)}\\mathbf{A}\\vec{d}_{(i)}$$$$\\beta_{(i+1)} = \\frac{\\vec{r}_{(i+1)}^T \\vec{r}_{(i+1)}}{\\vec{r}_{(i)}^T \\vec{r}_{(i)}}$$$$\\vec{d}_{(i+1)} = \\vec{r}_{(i+1)} + \\beta_{(i+1)}\\vec{d}_{(i)}$$å…¶ä¸­çš„æœ€åä¸€æ­¥å°±æ˜¯é€šè¿‡ $\\beta$ å°† $r_{i+1}$ ä¿®æ­£æˆ $d_{i+1}$ çš„ã€‚\n3.4.3. èµ·è®« èµ·ï¼šå¦‚æœä½ å¯¹è§£ $x$ æœ‰ç²—ç•¥çš„ä¼°è®¡ï¼Œå°±ä½¿ç”¨é‚£ä¸ªå€¼ä½œä¸ºèµ·å§‹ç‚¹ $x_0$ï¼›å¦åˆ™ï¼Œç›´æ¥ä½¿ç”¨ $x_0 = 0$ã€‚\nè®«ï¼šé€šå¸¸çš„åšæ³•æ˜¯åœ¨æ®‹å·®å‘é‡çš„ 2-norm å°äºæŸä¸ªç»™å®šé˜ˆå€¼çš„æ—¶å€™å°±åœä¸‹æ¥ã€‚é€šå¸¸è¿™ä¸ªé˜ˆå€¼ä¸ºåˆå§‹æ®‹å·®çš„ä¸€å°éƒ¨åˆ†\n$$\\|r_i\\| \u003c \\varepsilon \\|r_0\\|$$å…¶ä¸­ $\\varepsilon$ æ˜¯ä¸€ä¸ªè¾“å…¥çš„å‚æ•°ã€‚\n3.5. æ‚é¡¹ ç”±äº $Ad_i$ åœ¨æ¯ä¸ªå¾ªç¯ä¸­éƒ½è¦è¢«è®¡ç®—ï¼Œä¸” $$r_{i+1} = r_i - \\alpha_i A d_i$$æ•…å¯ä»¥ç”¨ä¸Šå¼è®¡ç®— $r_{i+1}$ï¼Œè€Œä¸å¿…ç”¨ $b - Ax_{i+1}$ã€‚\nä¸Šè¿°æ–¹æ³•æœ‰æµ®ç‚¹è¯¯å·®ç´¯è®¡çš„å±é™©ï¼Œå› æ­¤æˆ‘ä»¬åº”è¯¥æ¯è¿‡å‡ ä¸ªå¾ªç¯å°±é‡æ–°ç”¨ $r_i = b - Ax_i$ é‡æ–°è®¡ç®—æ®‹å·®ã€‚ ","date":"7 December, 2024","id":11,"permalink":"/chinese-post/conj-grad/","summary":"æœ¬æ–‡æ²¡æœ‰ä»»ä½•æ•°å­¦æ¨å¯¼ã€‚æˆ‘ä»¬ä»ç›´è§‚ä¸Šç†è§£è¿™ä¸ªç®—æ³•ï¼Œç„¶åç›´æ¥ä»‹ç»ç®—æ³•çš„æµç¨‹ã€‚å¸Œæœ›äº†è§£æ•°å­¦æ¨å¯¼çš„è¯»è€…å¯ä»¥æŸ¥çœ‹ CMU çš„æ•™æ¡ˆåŠå…¶ç¿»è¯‘ã€‚","tags":"","title":"å…±è½­æ¢¯åº¦ï¼šé«˜ä¸­è§£æå‡ ä½•çš„æ‹“å±•"},{"content":"ä¸ªäººä¿¡æ¯ åç§°ï¼šé»›è¥¿\nNickname: Da1sypetals\næˆ‘çš„ç®€å†\nçˆ±å¥½ å”±å¤é£æ­Œã€‚\næˆ‘ä¼šå”±è¿™äº›ï¼š\nã€Šäººé—´ä¸å€¼å¾—ã€‹ã€Šæ¥šæ­Œèµ·ã€‹ é»„è¯—æ‰¶\nã€Šè¿Ÿè¿Ÿã€‹ã€Šè…è‰ä¸ºè¤ã€‹ é“¶ä¸´\nã€Šæ•…äº‹å¤–çš„äººã€‹ æ…•å¯’\nã€ŠæƒŠé¹Šã€‹ã€Šå¿ƒä¸Šç§‹ã€‹ å¿˜å·é£åå½•\nã€Šæ³¼å¢¨æ¼“æ±Ÿã€‹ æ³ é¸¢yousa\nã€Šæ•¢å½’äº‘é—´å®¿ã€‹ ä¸‰æ— Marblue\nã€Šå¿˜å·ã€‹ã€Šéœå¤œèŒ¶ã€‹ å°æ›²å„¿\nã€Šæ¾çƒŸå…¥å¢¨ã€‹ã€Šå¦‚æ˜¯æˆ‘é—»ã€‹ Winkyè¯—\nã€Šæ‚¦ç¥ã€‹ KBShinya\nã€Šç¬¬ä¸‰åå…«å¹´å¤è‡³ã€‹ã€Šæ°¸å®šå››åå¹´ã€‹ æ²³å›¾\nã€Šä¸œé£å¿—ã€‹ Akié˜¿æ°\nç­‰ç­‰\u0026hellip;\n","date":"1 June, 2004","id":12,"permalink":"/about/","summary":"åç§°ï¼šé»›è¥¿","tags":"","title":"About"}]