[{"content":"内容来自这里.\n高级 Mini-Batching（Mini-Batching）\n创建 mini-batching 对于让深度学习模型的训练扩展到海量数据至关重要。mini-batch 不会一个接一个地处理样本，而是将一组样本分组到一个统一的表示中，从而可以高效地并行处理。在图像或语言领域，这个过程通常是通过将每个样本重新缩放或 padding 到一组等大小的形状来实现的，然后将样本分组到一个额外的维度中。这个维度的长度等于分组在一个 mini-batch 中的样本数量，通常称为 batch_size。\n由于图是一种最通用的数据结构，可以包含任意数量的节点（nodes）或边（edges），因此上述两种方法要么不可行，要么可能导致大量不必要的内存消耗。在 PyG 中，我们采用另一种方法来实现对大量样本的并行化。在这里，adjacency matrices 以对角线方式堆叠（创建一个包含多个孤立子图的巨大图），并且节点和目标特征（features）简单地沿节点维度进行拼接，即：\n$$ A = \\begin{bmatrix} A_1 \u0026 \u0026 \\\\ \u0026 \\ddots \u0026 \\\\ \u0026 \u0026 A_n \\end{bmatrix}, \\quad X = \\begin{bmatrix} X_1 \\\\ \\vdots \\\\ X_n \\end{bmatrix}, \\quad Y = \\begin{bmatrix} Y_1 \\\\ \\vdots \\\\ Y_n \\end{bmatrix}. $$与其他 batching 过程相比，此过程具有一些关键优势：\n依赖于 message passing scheme 的 GNN operators 不需要修改，因为属于不同图的两个节点之间仍然不能交换消息。 没有计算或内存开销。例如，此 batching 过程完全不需要对节点或边的特征进行任何 padding。请注意，adjacency matrices 没有额外的内存开销，因为它们以稀疏（sparse）方式保存，只包含非零项，即边。 PyG 借助 torch_geometric.loader.DataLoader 类自动将多个图 batch 成一个巨大的图。在内部，DataLoader 只是一个常规的 PyTorch torch.utils.data.DataLoader，它重写了其 collate() 功能，即定义如何将样本列表分组在一起。因此，所有可以传递给 PyTorch DataLoader 的参数也可以传递给 PyG DataLoader，例如 worker 数量 num_workers。\n在其最一般的形式中，PyG DataLoader 会自动将 edge_index tensor 增加到当前处理图之前已聚合（collated）的所有图的累积节点数，并将 edge_index tensors（形状为 [2, num_edges]）在第二个维度上进行拼接。face tensors，即 mesh 中的 face 索引，也是如此。所有其他 tensors 将仅在第一个维度上进行拼接，而不会进一步增加其值。\n然而，存在一些特殊用例（如下所述），用户需要根据自己的需求主动修改此行为。PyG 允许通过重写 torch_geometric.data.Data.__inc__() 和 torch_geometric.data.Data.__cat_dim__() 功能来修改底层的 batching 过程。在没有任何修改的情况下，它们在 Data 类中定义如下：\ndef __inc__(self, key, value, *args, kwargs): if \u0026#39;index\u0026#39; in key: return self.num_nodes else: return 0 def __cat_dim__(self, key, value, *args, kwargs): if \u0026#39;index\u0026#39; in key: return 1 else: return 0 我们可以看到 __inc__() 定义了两个连续图属性之间的增量计数。默认情况下，只要属性名称包含子字符串 index（出于历史原因），PyG 就会将属性增加节点数量 num_nodes，这对于 edge_index 或 node_index 等属性非常方便。但是请注意，这可能会导致属性名称包含子字符串 index 但不应增加的属性出现意外行为。为确保正确，最佳实践是始终仔细检查 batching 的输出。此外，__cat_dim__() 定义了相同属性的图 tensors 应在哪个维度上进行拼接。这两个函数都会为存储在 Data 类中的每个属性调用，并将它们的特定 key 和 value 项作为参数传递。\n接下来，我们将介绍一些可能绝对需要修改 __inc__() 和 __cat_dim__() 的用例。\n图对（Pairs of Graphs） 如果您想在单个 Data object 中存储多个图，例如用于图匹配（graph matching）等应用，则需要确保所有这些图的 batching 行为正确。例如，考虑在 Data 中存储两个图：一个源图 $G_s$ 和一个目标图 $G_t$，例如：\nfrom torch_geometric.data import Data class PairData(Data): pass data = PairData(x_s=x_s, edge_index_s=edge_index_s, # Source graph. x_t=x_t, edge_index_t=edge_index_t) # Target graph. 在这种情况下，edge_index_s 应该增加源图 $G_s$ 中的节点数，例如 x_s.size(0)，而 edge_index_t 应该增加目标图 $G_t$ 中的节点数，例如 x_t.size(0)：\nclass PairData(Data): def __inc__(self, key, value, *args, kwargs): if key == \u0026#39;edge_index_s\u0026#39;: return self.x_s.size(0) if key == \u0026#39;edge_index_t\u0026#39;: return self.x_t.size(0) return super().__inc__(key, value, *args, kwargs) 我们可以通过设置一个简单的测试脚本来测试我们的 PairData batching 行为：\nfrom torch_geometric.loader import DataLoader import torch x_s = torch.randn(5, 16) # 5 nodes. edge_index_s = torch.tensor([ [0, 0, 0, 0], [1, 2, 3, 4], ]) x_t = torch.randn(4, 16) # 4 nodes. edge_index_t = torch.tensor([ [0, 0, 0], [1, 2, 3], ]) data = PairData(x_s=x_s, edge_index_s=edge_index_s, x_t=x_t, edge_index_t=edge_index_t) data_list = [data, data] loader = DataLoader(data_list, batch_size=2) batch = next(iter(loader)) print(batch) # \u0026gt;\u0026gt;\u0026gt; PairDataBatch(x_s=[10, 16], edge_index_s=[2, 8], x_t=[8, 16], edge_index_t=[2, 6]) print(batch.edge_index_s) # \u0026gt;\u0026gt;\u0026gt; tensor([[0, 0, 0, 0, 5, 5, 5, 5], # [1, 2, 3, 4, 6, 7, 8, 9]]) print(batch.edge_index_t) # \u0026gt;\u0026gt;\u0026gt; tensor([[0, 0, 0, 4, 4, 4], # [1, 2, 3, 5, 6, 7]]) 到目前为止一切顺利！即使 $G_s$ 和 $G_t$ 使用不同数量的节点，edge_index_s 和 edge_index_t 也能正确地 batch 到一起。然而，batch 属性（将每个节点映射到其各自的图）丢失了，因为 PyG 无法识别 PairData object 中的实际图。这就是 DataLoader 的 follow_batch 参数发挥作用的地方。在这里，我们可以指定要为哪些属性维护 batch 信息：\nloader = DataLoader(data_list, batch_size=2, follow_batch=[\u0026#39;x_s\u0026#39;, \u0026#39;x_t\u0026#39;]) batch = next(iter(loader)) print(batch) # \u0026gt;\u0026gt;\u0026gt; PairDataBatch(x_s=[10, 16], edge_index_s=[2, 8], x_s_batch=[10], x_t=[8, 16], edge_index_t=[2, 6], x_t_batch=[8]) print(batch.x_s_batch) # \u0026gt;\u0026gt;\u0026gt; tensor([0, 0, 0, 0, 0, 1, 1, 1, 1, 1]) print(batch.x_t_batch) # \u0026gt;\u0026gt;\u0026gt; tensor([0, 0, 0, 0, 1, 1, 1, 1]) 正如所见，follow_batch=['x_s', 'x_t'] 现在成功地为节点特征 x_s 和 x_t 分别创建了分配向量 x_s_batch 和 x_t_batch。现在可以使用这些信息在单个 Batch object 中对多个图执行 reduce 操作，例如 global pooling。\n二分图（Bipartite Graphs） bipartite graph 的 adjacency matrix 定义了两种不同节点类型之间的关系。通常，每种节点类型的节点数量不必匹配，从而导致一个形状为 $A \\in \\{0, 1\\}^{N \\times M}$ 且可能 $N \\ne M$ 的非方阵 adjacency matrix。在 bipartite graphs 的 mini-batching 过程中，edge_index 中边的源节点应以不同于 edge_index 中边的目标节点的方式增加。为了实现这一点，考虑一个介于两种节点类型之间的 bipartite graph，分别具有相应的节点特征 x_s 和 x_t：\nfrom torch_geometric.data import Data class BipartiteData(Data): pass data = BipartiteData(x_s=x_s, x_t=x_t, edge_index=edge_index) 对于 bipartite graphs 中正确的 mini-batching 过程，我们需要告诉 PyG 它应该独立地增加 edge_index 中边的源节点和目标节点：\nclass BipartiteData(Data): def __inc__(self, key, value, *args, kwargs): if key == \u0026#39;edge_index\u0026#39;: return torch.tensor([[self.x_s.size(0)], [self.x_t.size(0)]]) return super().__inc__(key, value, *args, kwargs) 在这里，edge_index[0]（边的源节点）增加了 x_s.size(0)，而 edge_index[1]（边的目标节点）增加了 x_t.size(0)。我们可以再次通过运行一个简单的测试脚本来测试我们的实现：\nfrom torch_geometric.loader import DataLoader import torch x_s = torch.randn(2, 16) # 2 nodes. x_t = torch.randn(3, 16) # 3 nodes. edge_index = torch.tensor([ [0, 0, 1, 1], [0, 1, 1, 2], ]) data = BipartiteData(x_s=x_s, x_t=x_t, edge_index=edge_index) data_list = [data, data] loader = DataLoader(data_list, batch_size=2) batch = next(iter(loader)) print(batch) # \u0026gt;\u0026gt;\u0026gt; BipartiteDataBatch(x_s=[4, 16], x_t=[6, 16], edge_index=[2, 8]) print(batch.edge_index) # \u0026gt;\u0026gt;\u0026gt; tensor([[0, 0, 1, 1, 2, 2, 3, 3], # [0, 1, 1, 2, 3, 4, 4, 5]]) 再次，这正是我们想要的行为！\n沿新维度进行 Batching（Batching Along New Dimensions） 有时，Data object 的属性应该通过获得一个新的 batch dimension 来进行 batching（如经典 mini-batching 中那样），例如对于图级别的属性或目标。具体来说，形状为 [num_features] 的属性列表应作为 [num_examples, num_features] 返回，而不是 [num_examples * num_features]。PyG 通过在 __cat_dim__() 中返回一个 None 的拼接维度来实现这一点：\nfrom torch_geometric.data import Data from torch_geometric.loader import DataLoader class MyData(Data): def __cat_dim__(self, key, value, *args, kwargs): if key == \u0026#39;foo\u0026#39;: return None return super().__cat_dim__(key, value, *args, kwargs) edge_index = torch.tensor([ [0, 1, 1, 2], [1, 0, 2, 1], ]) foo = torch.randn(16) data = MyData(num_nodes=3, edge_index=edge_index, foo=foo) data_list = [data, data] loader = DataLoader(data_list, batch_size=2) batch = next(iter(loader)) print(batch) # \u0026gt;\u0026gt;\u0026gt; MyDataBatch(num_nodes=6, edge_index=[2, 8], foo=[2, 16]) 如预期，batch.foo 现在由两个维度描述：batch dimension 和 feature dimension。\n","date":"16 October, 2025","id":0,"permalink":"/documents/pyg-batching/","summary":"内容来自这里.","tags":"","title":"PyG Batching"},{"content":"矢量图 位图，hires 位图，lowres ","date":"12 October, 2025","id":1,"permalink":"/documents/carrot/","summary":"","tags":"","title":"我的萝卜头像"},{"content":"1. 用默认浏览器打开 2. 按F12，然后把Focus放在html 先按F12，然后按下面的步骤操作\n3. 搜索音频扩展名 先随便点一下里面的代码，然后 Ctrl-F\n搜索.m4a\n找到一个含有.m4a 的链接，然后双击，复制到新的标签页打开。很长一串 4. 下载 ","date":"5 October, 2025","id":2,"permalink":"/documents/quanmin-download/","summary":"","tags":"","title":"全民K歌如何下载歌曲"},{"content":"完整的问题 可以看我和Gemini的对话\n抽象出的问题 假设在mxn的矩阵中全为0，现在进行两个操作：\n以avgdeg/n的概率将矩阵中的值变为1； 如果矩阵中有一列有一个1，那就把这一列都变成1。 现在计算avgdeg\u0026rsquo;为矩阵中1的个数/(mn)，记avgdeg=d, avgdeg\u0026rsquo;=d'\nKimi的回答 我们来逐步分析这个问题，并给出数学推导。\n问题设定 我们有一个 $ m \\times n $ 的矩阵，初始时所有元素为 0。\n进行两个操作：\n随机置 1：以概率 $ \\frac{\\text{avgdeg}}{n} $ 将每个元素独立地变为 1（否则保持 0）。\n记 $ d = \\text{avgdeg} $，所以每个元素变为 1 的概率是 $ p = \\frac{d}{n} $。\n列传播：如果某一列中至少有一个 1，则将该列所有元素都变为 1。\n最终，我们计算新的平均度：\n\\[ d' = \\frac{\\text{矩阵中 1 的总数}}{mn} \\]我们的目标是求 $ d' $ 关于 $ d $ 的表达式，即 $ d' = f(d) $。\n步骤 1：计算某一列在操作 1 后至少有一个 1的概率 在操作 1 后，每个元素独立地以概率 $ p = \\frac{d}{n} $ 变为 1。\n某一列有 $ m $ 个元素，全为 0 的概率是：\n\\[ (1 - p)^m = \\left(1 - \\frac{d}{n}\\right)^m \\]所以，该列至少有一个 1 的概率是：\n\\[ P_{\\text{active}} = 1 - \\left(1 - \\frac{d}{n}\\right)^m \\]步骤 2：操作 2 后，每一列要么全为 1，要么全为 0 因为在操作 2 中，只要某一列有一个 1，整列就变成 1；否则保持全 0。\n所以，最终矩阵中，每一列要么是全 1，要么是全 0。\n步骤 3：计算期望的 1 的总数 每一列以概率 $ P_{\\text{active}} $ 变成全 1（即贡献 $ m $ 个 1），以概率 $ 1 - P_{\\text{active}} $ 保持全 0（即贡献 0 个 1）。\n所以，期望的 1 的总数为：\n\\[ \\mathbb{E}[\\text{total 1s}] = n \\cdot m \\cdot P_{\\text{active}} = mn \\left(1 - \\left(1 - \\frac{d}{n}\\right)^m\\right) \\]步骤 4：计算 $ d' $ \\[ d' = \\frac{\\mathbb{E}[\\text{total 1s}]}{mn} = 1 - \\left(1 - \\frac{d}{n}\\right)^m \\]最终答案 $\\boxed{d' = 1 - \\left(1 - \\frac{d}{n}\\right)^m}$\n这就是 $ d' $ 关于 $ d $ 的显式表达式。\n计算我们所需的结果 $m=8 / m=16$ $d$ 的分布统计量 $\\mu=5.856, \\sigma =0.133$, 这里取 $6$ $n$ 的典型值为 5000~50000 得到结果:\nm=8,n=5000,d\u0026#39;=0.009559776622987126,d\u0026#39;*n=47.798883114935634 m=8,n=50000,d\u0026#39;=0.0009595968967535118,d\u0026#39;*n=47.979844837675586 m=16,n=5000,d\u0026#39;=0.01902816391689277,d\u0026#39;*n=95.14081958446386 m=16,n=50000,d\u0026#39;=0.0019182729673028476,d\u0026#39;*n=95.91364836514238 极限 问题 如果n趋于无穷，nd\u0026rsquo;的极限是多少？m和d保留\nKimi的回答 我们已有\n\\[ d' = 1 - \\left(1 - \\frac{d}{n}\\right)^m. \\]令 $n\\to\\infty$ 而 $m,d$ 固定，考察\n\\[ n d' = n\\left[1 - \\left(1 - \\frac{d}{n}\\right)^m\\right]. \\]利用极限\n\\[ \\lim_{n\\to\\infty} n\\left[1 - \\left(1 - \\frac{d}{n}\\right)^m\\right] = \\lim_{n\\to\\infty} n\\left[1 - \\exp\\left(m\\ln\\!\\Bigl(1 - \\frac{d}{n}\\Bigr)\\right)\\right]. \\]对 $\\ln(1 - x)$ 做泰勒展开：$\\ln(1 - x) = -x - \\frac{x^2}{2} - \\dots$，取首项即可：\n\\[ m\\ln\\!\\Bigl(1 - \\frac{d}{n}\\Bigr) = -\\frac{md}{n} + O\\!\\left(\\frac{1}{n^2}\\right). \\]于是\n\\[ \\exp\\left(m\\ln\\!\\Bigl(1 - \\frac{d}{n}\\Bigr)\\right) = \\exp\\!\\left(-\\frac{md}{n} + O\\!\\left(\\frac{1}{n^2}\\right)\\right) = 1 - \\frac{md}{n} + O\\!\\left(\\frac{1}{n^2}\\right). \\]代回：\n\\[ n d' = n\\left[1 - \\left(1 - \\frac{md}{n} + O\\!\\left(\\frac{1}{n^2}\\right)\\right)\\right] = n\\left[\\frac{md}{n} + O\\!\\left(\\frac{1}{n^2}\\right)\\right] = md + O\\!\\left(\\frac{1}{n}\\right). \\]因此\n\\[ \\boxed{\\lim_{n\\to\\infty} n d' = md}. \\]感悟 这么简单的数学题我居然都要用AI了, 看来上班后数学能力大幅下滑.\n","date":"4 October, 2025","id":3,"permalink":"/posts/interesting-math-gnn-tensor-core/","summary":"可以看我和Gemini的对话","tags":"","title":"一个关于GNN在Tensor Core上的实现的数学问题"},{"content":"Github: https://github.com/spotify/pedalboard\nDocs: https://spotify.github.io/pedalboard/reference/pedalboard.html#pedalboard.LowShelfFilter\nPedalboard API Documentation The pedalboard module provides classes and functions for adding effects to audio. Most classes in this module are subclasses of Plugin, each of which allows applying effects to an audio buffer or stream.\nNote: For audio I/O functionality (i.e.: reading and writing audio files), see the pedalboard.io module.\nThe pedalboard module is named after the concept of a guitar pedalboard, in which musicians will chain various effects pedals together to give them complete control over their sound. The pedalboard module implements this concept with its main Pedalboard class:\nfrom pedalboard import Pedalboard, Chorus, Distortion, Reverb # Create an empty Pedalboard object: my_pedalboard = Pedalboard() # Treat this object like a Python list: my_pedalboard.append(Chorus()) my_pedalboard.append(Distortion()) my_pedalboard.append(Reverb()) # Pass audio through this pedalboard: output_audio = my_pedalboard(input_audio, input_audio_samplerate) Pedalboard objects are lists of zero or more Plugin objects, and Pedalboard objects themselves are subclasses of Plugin - which allows for nesting and composition.\nClasses pedalboard.AudioProcessorParameter A wrapper around various different parameters exposed by VST3Plugin or AudioUnitPlugin instances.\nAudioProcessorParameter objects are rarely used directly, and usually used via their implicit interface:\nmy_plugin = load_plugin(\u0026#34;My Cool Audio Effect.vst3\u0026#34;) # Print all of the parameter names: print(my_plugin.parameters.keys()) # [\u0026#34;mix\u0026#34;, \u0026#34;delay_time_ms\u0026#34;, \u0026#34;foobar\u0026#34;] # Access each parameter as if it were just a Python attribute: my_plugin.mix = 0.5 my_plugin.delay_time_ms = 400 Note: AudioProcessorParameter tries to guess the range of valid parameter values, as well as the type/unit of the parameter, when instantiated. This guess may not always be accurate. Raw control over the underlying parameter’s value can be had by accessing the raw_value attribute, which is always bounded on [0, 1] and is passed directly to the underlying plugin object.\nProperties label: Optional[str] – The units used by this parameter (Hz, dB, etc). May be None if the plugin does not expose units for this parameter or if automatic unit detection fails. units: Optional[str] – Alias for \u0026ldquo;label\u0026rdquo; – the units used by this parameter (Hz, dB, etc). May be None if the plugin does not expose units for this parameter or if automatic unit detection fails. pedalboard.ExternalPlugin A wrapper around a third-party effect plugin.\nDon’t use this directly; use one of pedalboard.VST3Plugin or pedalboard.AudioUnitPlugin instead.\nMethods __call__(*args, **kwargs) – Overloaded function. __call__(self: pedalboard.Plugin, input_array: numpy.ndarray, sample_rate: float, buffer_size: int = 8192, reset: bool = True) -\u0026gt; numpy.ndarray[numpy.float32] – Run an audio or MIDI buffer through this plugin, returning audio. Alias for process(). __call__(self: pedalboard.ExternalPlugin, midi_messages: object, duration: float, sample_rate: float, num_channels: int = 2, buffer_size: int = 8192, reset: bool = True) -\u0026gt; numpy.ndarray[numpy.float32] – Run an audio or MIDI buffer through this plugin, returning audio. Alias for process(). Properties is_effect – True iff this plugin is an audio effect and accepts audio as input. Introduced in v0.7.4. is_instrument – True iff this plugin is not an audio effect and accepts only MIDI input, not audio. Introduced in v0.7.4. Methods process(*args, **kwargs) – Overloaded function. process(self: pedalboard.ExternalPlugin, midi_messages: object, duration: float, sample_rate: float, num_channels: int = 2, buffer_size: int = 8192, reset: bool = True) -\u0026gt; numpy.ndarray[numpy.float32] – Pass a buffer of audio (as a 32- or 64-bit NumPy array) or a list of MIDI messages to this plugin, returning audio. process(self: pedalboard.Plugin, input_array: numpy.ndarray, sample_rate: float, buffer_size: int = 8192, reset: bool = True) -\u0026gt; numpy.ndarray[numpy.float32] – Pass a buffer of audio (as a 32- or 64-bit NumPy array) or a list of MIDI messages to this plugin, returning audio. Note: The process() method can also be used via __call__(); i.e.: just calling this object like a function (my_plugin(...)) will automatically invoke process() with the same arguments.\nreset() -\u0026gt; None – Clear any internal state stored by this plugin (e.g.: reverb tails, delay lines, LFO state, etc). The values of plugin parameters will remain unchanged. pedalboard.Pedalboard(plugins: Optional[List[Plugin]] = None) A container for a series of Plugin objects, to use for processing audio, like a guitar pedalboard.\nPedalboard objects act like regular Python List objects, but come with an additional process() method (also aliased to __call__()), allowing audio to be passed through the entire Pedalboard object for processing:\nmy_pedalboard = Pedalboard() my_pedalboard.append(Reverb()) output_audio = my_pedalboard(input_audio) Warning: Pedalboard objects may only contain effects plugins (i.e.: those for which is_effect is True), and cannot contain instrument plugins (i.e.: those for which is_instrument is True).\nMethods __call__(input_array: numpy.ndarray, sample_rate: float, buffer_size: int = 8192, reset: bool = True) -\u0026gt; numpy.ndarray[numpy.float32] – Run an audio buffer through this plugin. Alias for process(). append(plugin: Plugin) -\u0026gt; None – Append a plugin to the end of this container. insert(index: int, plugin: Plugin) -\u0026gt; None – Insert a plugin at the specified index. process(input_array: numpy.ndarray, sample_rate: float, buffer_size: int = 8192, reset: bool = True) -\u0026gt; numpy.ndarray[numpy.float32] – Run a 32-bit or 64-bit floating point audio buffer through this plugin. remove(plugin: Plugin) -\u0026gt; None – Remove a plugin by its value. reset() -\u0026gt; None – Clear any internal state stored by this plugin (e.g.: reverb tails, delay lines, LFO state, etc). The values of plugin parameters will remain unchanged. Properties is_effect – True iff this plugin is an audio effect and accepts audio as input. Introduced in v0.7.4. is_instrument – True iff this plugin is not an audio effect and accepts only MIDI input, not audio. Introduced in v0.7.4. pedalboard.load_plugin(path_to_plugin_file: str, parameter_values: Dict[str, Union[str, int, float, bool]] = {}, plugin_name: Optional[str] = None, initialization_timeout: float = 10.0) -\u0026gt; ExternalPlugin Load an audio plugin.\nTwo plugin formats are supported:\nVST3® format is supported on macOS, Windows, and Linux Audio Units are supported on macOS Parameters path_to_plugin_file (str) – The path of a VST3® or Audio Unit plugin file or bundle. parameter_values (Dict[str, Union[str, int, float, bool]]) – An optional dictionary of initial values to provide to the plugin after loading. Keys in this dictionary are expected to match the parameter names reported by the plugin, but normalized to strings that can be used as Python identifiers. (These are the same identifiers that are used as keys in the .parameters dictionary of a loaded plugin.) plugin_name (Optional[str]) – An optional plugin name that can be used to load a specific plugin from a multi-plugin package. If a package is loaded but a plugin_name is not provided, an exception will be thrown. initialization_timeout (float) – The number of seconds that Pedalboard will spend trying to load this plugin. Some plugins load resources asynchronously in the background on startup; using larger values for this parameter can give these plugins time to load properly. Introduced in v0.7.6. Returns An instance of pedalboard.VST3Plugin or pedalboard.AudioUnitPlugin.\nThrows ImportError – if the plugin cannot be found or loaded RuntimeError – if the plugin file contains more than one plugin, but no plugin_name was provided pedalboard.Bitcrush A plugin that reduces the signal to a given bit depth, giving the audio a lo-fi, digitized sound. Floating-point bit depths are supported.\nBitcrushing changes the amount of \u0026ldquo;vertical\u0026rdquo; resolution used for an audio signal (i.e.: how many unique values could be used to represent each sample). For an effect that changes the \u0026ldquo;horizontal\u0026rdquo; resolution (i.e.: how many samples are available per second), see pedalboard.Resample.\nProperties bit_depth – The bit depth to quantize the signal to. Must be between 0 and 32 bits. May be an integer, decimal, or floating-point value. Each audio sample will be quantized onto 2 ** bit_depth values. Methods __call__(input_array: numpy.ndarray, sample_rate: float, buffer_size: int = 8192, reset: bool = True) -\u0026gt; numpy.ndarray[numpy.float32] – Run an audio buffer through this plugin. Alias for process(). process(input_array: numpy.ndarray, sample_rate: float, buffer_size: int = 8192, reset: bool = True) -\u0026gt; numpy.ndarray[numpy.float32] – Run a 32-bit or 64-bit floating point audio buffer through this plugin. reset() -\u0026gt; None – Clear any internal state stored by this plugin (e.g.: reverb tails, delay lines, LFO state, etc). The values of plugin parameters will remain unchanged. Properties is_effect – True iff this plugin is an audio effect and accepts audio as input. Introduced in v0.7.4. is_instrument – True iff this plugin is not an audio effect and accepts only MIDI input, not audio. Introduced in v0.7.4. pedalboard.Chain Run zero or more plugins as a plugin. Useful when used with the Mix plugin.\nMethods __call__(input_array: numpy.ndarray, sample_rate: float, buffer_size: int = 8192, reset: bool = True) -\u0026gt; numpy.ndarray[numpy.float32] – Run an audio buffer through this plugin. Alias for process(). append(plugin: Plugin) -\u0026gt; None – Append a plugin to the end of this container. insert(index: int, plugin: Plugin) -\u0026gt; None – Insert a plugin at the specified index. process(input_array: numpy.ndarray, sample_rate: float, buffer_size: int = 8192, reset: bool = True) -\u0026gt; numpy.ndarray[numpy.float32] – Run a 32-bit or 64-bit floating point audio buffer through this plugin. remove(plugin: Plugin) -\u0026gt; None – Remove a plugin by its value. reset() -\u0026gt; None – Clear any internal state stored by this plugin (e.g.: reverb tails, delay lines, LFO state, etc). The values of plugin parameters will remain unchanged. Properties is_effect – True iff this plugin is an audio effect and accepts audio as input. Introduced in v0.7.4. is_instrument – True iff this plugin is not an audio effect and accepts only MIDI input, not audio. Introduced in v0.7.4. pedalboard.Chorus A basic chorus effect.\nThis audio effect can be controlled via the speed and depth of the LFO controlling the frequency response, a mix control, a feedback control, and the centre delay of the modulation.\nNote: To get classic chorus sounds try to use a centre delay time around 7-8 ms with a low feedback volume and a low depth. This effect can also be used as a flanger with a lower centre delay time and a lot of feedback, and as a vibrato effect if the mix value is 1.\nProperties rate_hz – The speed of the chorus effect’s low-frequency oscillator (LFO), in Hertz. This value must be between 0 Hz and 100 Hz. Methods __call__(input_array: numpy.ndarray, sample_rate: float, buffer_size: int = 8192, reset: bool = True) -\u0026gt; numpy.ndarray[numpy.float32] – Run an audio buffer through this plugin. Alias for process(). process(input_array: numpy.ndarray, sample_rate: float, buffer_size: int = 8192, reset: bool = True) -\u0026gt; numpy.ndarray[numpy.float32] – Run a 32-bit or 64-bit floating point audio buffer through this plugin. reset() -\u0026gt; None – Clear any internal state stored by this plugin (e.g.: reverb tails, delay lines, LFO state, etc). The values of plugin parameters will remain unchanged. Properties is_effect – True iff this plugin is an audio effect and accepts audio as input. Introduced in v0.7.4. is_instrument – True iff this plugin is not an audio effect and accepts only MIDI input, not audio. Introduced in v0.7.4. pedalboard.Clipping A distortion plugin that adds hard distortion to the signal by clipping the signal at the provided threshold (in decibels).\nMethods __call__(input_array: numpy.ndarray, sample_rate: float, buffer_size: int = 8192, reset: bool = True) -\u0026gt; numpy.ndarray[numpy.float32] – Run an audio buffer through this plugin. Alias for process(). process(input_array: numpy.ndarray, sample_rate: float, buffer_size: int = 8192, reset: bool = True) -\u0026gt; numpy.ndarray[numpy.float32] – Run a 32-bit or 64-bit floating point audio buffer through this plugin. reset() -\u0026gt; None – Clear any internal state stored by this plugin (e.g.: reverb tails, delay lines, LFO state, etc). The values of plugin parameters will remain unchanged. Properties is_effect – True iff this plugin is an audio effect and accepts audio as input. Introduced in v0.7.4. is_instrument – True iff this plugin is not an audio effect and accepts only MIDI input, not audio. Introduced in v0.7.4. pedalboard.Compressor A dynamic range compressor, used to reduce the volume of loud sounds and \u0026ldquo;compress\u0026rdquo; the loudness of the signal.\nFor a lossy compression algorithm that introduces noise or artifacts, see pedalboard.MP3Compressor or pedalboard.GSMCompressor.\nMethods __call__(input_array: numpy.ndarray, sample_rate: float, buffer_size: int = 8192, reset: bool = True) -\u0026gt; numpy.ndarray[numpy.float32] – Run an audio buffer through this plugin. Alias for process(). process(input_array: numpy.ndarray, sample_rate: float, buffer_size: int = 8192, reset: bool = True) -\u0026gt; numpy.ndarray[numpy.float32] – Run a 32-bit or 64-bit floating point audio buffer through this plugin. reset() -\u0026gt; None – Clear any internal state stored by this plugin (e.g.: reverb tails, delay lines, LFO state, etc). The values of plugin parameters will remain unchanged. Properties is_effect – True iff this plugin is an audio effect and accepts audio as input. Introduced in v0.7.4. is_instrument – True iff this plugin is not an audio effect and accepts only MIDI input, not audio. Introduced in v0.7.4. pedalboard.Convolution An audio convolution, suitable for things like speaker simulation or reverb modeling.\nThe convolution impulse response can be specified either by filename or as a 32-bit floating point NumPy array. If a NumPy array is provided, the sample_rate argument must also be provided to indicate the sample rate of the impulse response.\nSupport for passing NumPy arrays as impulse responses introduced in v0.9.10.\nMethods __call__(input_array: numpy.ndarray, sample_rate: float, buffer_size: int = 8192, reset: bool = True) -\u0026gt; numpy.ndarray[numpy.float32] – Run an audio buffer through this plugin. Alias for process(). process(input_array: numpy.ndarray, sample_rate: float, buffer_size: int = 8192, reset: bool = True) -\u0026gt; numpy.ndarray[numpy.float32] – Run a 32-bit or 64-bit floating point audio buffer through this plugin. reset() -\u0026gt; None – Clear any internal state stored by this plugin (e.g.: reverb tails, delay lines, LFO state, etc). The values of plugin parameters will remain unchanged. Properties is_effect – True iff this plugin is an audio effect and accepts audio as input. Introduced in v0.7.4. is_instrument – True iff this plugin is not an audio effect and accepts only MIDI input, not audio. Introduced in v0.7.4. pedalboard.Delay A digital delay plugin with controllable delay time, feedback percentage, and dry/wet mix.\nMethods __call__(input_array: numpy.ndarray, sample_rate: float, buffer_size: int = 8192, reset: bool = True) -\u0026gt; numpy.ndarray[numpy.float32] – Run an audio buffer through this plugin. Alias for process(). process(input_array: numpy.ndarray, sample_rate: float, buffer_size: int = 8192, reset: bool = True) -\u0026gt; numpy.ndarray[numpy.float32] – Run a 32-bit or 64-bit floating point audio buffer through this plugin. reset() -\u0026gt; None – Clear any internal state stored by this plugin (e.g.: reverb tails, delay lines, LFO state, etc). The values of plugin parameters will remain unchanged. Properties is_effect – True iff this plugin is an audio effect and accepts audio as input. Introduced in v0.7.4. is_instrument – True iff this plugin is not an audio effect and accepts only MIDI input, not audio. Introduced in v0.7.4. pedalboard.Distortion A distortion effect, which applies a non-linear (tanh, or hyperbolic tangent) waveshaping function to apply harmonically pleasing distortion to a signal.\nThis plugin produces a signal that is roughly equivalent to running:\ndef distortion(x): return tanh(x * db_to_gain(drive_db)) Methods __call__(input_array: numpy.ndarray, sample_rate: float, buffer_size: int = 8192, reset: bool = True) -\u0026gt; numpy.ndarray[numpy.float32] – Run an audio buffer through this plugin. Alias for process(). process(input_array: numpy.ndarray, sample_rate: float, buffer_size: int = 8192, reset: bool = True) -\u0026gt; numpy.ndarray[numpy.float32] – Run a 32-bit or 64-bit floating point audio buffer through this plugin. reset() -\u0026gt; None – Clear any internal state stored by this plugin (e.g.: reverb tails, delay lines, LFO state, etc). The values of plugin parameters will remain unchanged. Properties is_effect – True iff this plugin is an audio effect and accepts audio as input. Introduced in v0.7.4. is_instrument – True iff this plugin is not an audio effect and accepts only MIDI input, not audio. Introduced in v0.7.4. pedalboard.ExternalPluginReloadType Indicates the behavior of an external plugin when reset() is called.\nMembers Unknown – The behavior of the plugin is unknown. This will force a full reinstantiation of the plugin every time reset is called. ClearsAudioOnReset – This plugin clears its internal buffers correctly when reset() is called. The plugin will not be reinstantiated when reset is called. PersistsAudioOnReset – This plugin does not clear its internal buffers as expected when reset() is called. This will force a full reinstantiation of the plugin every time reset is called. Properties name pedalboard.GSMFullRateCompressor An audio degradation/compression plugin that applies the GSM \u0026ldquo;Full Rate\u0026rdquo; compression algorithm to emulate the sound of a 2G cellular phone connection. This plugin internally resamples the input audio to a fixed sample rate of 8kHz (required by the GSM Full Rate codec), although the quality of the resampling algorithm can be specified.\nMethods __call__(input_array: numpy.ndarray, sample_rate: float, buffer_size: int = 8192, reset: bool = True) -\u0026gt; numpy.ndarray[numpy.float32] – Run an audio buffer through this plugin. Alias for process(). process(input_array: numpy.ndarray, sample_rate: float, buffer_size: int = 8192, reset: bool = True) -\u0026gt; numpy.ndarray[numpy.float32] – Run a 32-bit or 64-bit floating point audio buffer through this plugin. reset() -\u0026gt; None – Clear any internal state stored by this plugin (e.g.: reverb tails, delay lines, LFO state, etc). The values of plugin parameters will remain unchanged. Properties is_effect – True iff this plugin is an audio effect and accepts audio as input. Introduced in v0.7.4. is_instrument – True iff this plugin is not an audio effect and accepts only MIDI input, not audio. Introduced in v0.7.4. pedalboard.Gain A gain plugin that increases or decreases the volume of a signal by amplifying or attenuating it by the provided value (in decibels). No distortion or other effects are applied.\nThink of this as a volume control.\nMethods __call__(input_array: numpy.ndarray, sample_rate: float, buffer_size: int = 8192, reset: bool = True) -\u0026gt; numpy.ndarray[numpy.float32] – Run an audio buffer through this plugin. Alias for process(). process(input_array: numpy.ndarray, sample_rate: float, buffer_size: int = 8192, reset: bool = True) -\u0026gt; numpy.ndarray[numpy.float32] – Run a 32-bit or 64-bit floating point audio buffer through this plugin. reset() -\u0026gt; None – Clear any internal state stored by this plugin (e.g.: reverb tails, delay lines, LFO state, etc). The values of plugin parameters will remain unchanged. Properties is_effect – True iff this plugin is an audio effect and accepts audio as input. Introduced in v0.7.4. is_instrument – True iff this plugin is not an audio effect and accepts only MIDI input, not audio. Introduced in v0.7.4. pedalboard.HighShelfFilter A high shelf filter plugin with variable Q and gain, as would be used in an equalizer. Frequencies above the cutoff frequency will be boosted (or cut) by the provided gain (in decibels).\nMethods __call__(input_array: numpy.ndarray, sample_rate: float, buffer_size: int = 8192, reset: bool = True) -\u0026gt; numpy.ndarray[numpy.float32] – Run an audio buffer through this plugin. Alias for process(). process(input_array: numpy.ndarray, sample_rate: float, buffer_size: int = 8192, reset: bool = True) -\u0026gt; numpy.ndarray[numpy.float32] – Run a 32-bit or 64-bit floating point audio buffer through this plugin. reset() -\u0026gt; None – Clear any internal state stored by this plugin (e.g.: reverb tails, delay lines, LFO state, etc). The values of plugin parameters will remain unchanged. Properties is_effect – True iff this plugin is an audio effect and accepts audio as input. Introduced in v0.7.4. is_instrument – True iff this plugin is not an audio effect and accepts only MIDI input, not audio. Introduced in v0.7.4. pedalboard.HighpassFilter Apply a first-order high-pass filter with a roll-off of 6dB/octave. The cutoff frequency will be attenuated by -3dB (i.e.: 0.707x as loud, expressed as a gain factor) and lower frequencies will be attenuated by a further 6dB per octave.\nMethods __call__(input_array: numpy.ndarray, sample_rate: float, buffer_size: int = 8192, reset: bool = True) -\u0026gt; numpy.ndarray[numpy.float32] – Run an audio buffer through this plugin. Alias for process(). process(input_array: numpy.ndarray, sample_rate: float, buffer_size: int = 8192, reset: bool = True) -\u0026gt; numpy.ndarray[numpy.float32] – Run a 32-bit or 64-bit floating point audio buffer through this plugin. reset() -\u0026gt; None – Clear any internal state stored by this plugin (e.g.: reverb tails, delay lines, LFO state, etc). The values of plugin parameters will remain unchanged. Properties is_effect – True iff this plugin is an audio effect and accepts audio as input. Introduced in v0.7.4. is_instrument – True iff this plugin is not an audio effect and accepts only MIDI input, not audio. Introduced in v0.7.4. pedalboard.IIRFilter An abstract class that implements various kinds of infinite impulse response (IIR) filter designs. This should not be used directly; use HighShelfFilter, LowShelfFilter, or PeakFilter directly instead.\nMethods __call__(input_array: numpy.ndarray, sample_rate: float, buffer_size: int = 8192, reset: bool = True) -\u0026gt; numpy.ndarray[numpy.float32] – Run an audio buffer through this plugin. Alias for process(). process(input_array: numpy.ndarray, sample_rate: float, buffer_size: int = 8192, reset: bool = True) -\u0026gt; numpy.ndarray[numpy.float32] – Run a 32-bit or 64-bit floating point audio buffer through this plugin. reset() -\u0026gt; None – Clear any internal state stored by this plugin (e.g.: reverb tails, delay lines, LFO state, etc). The values of plugin parameters will remain unchanged. Properties is_effect – True iff this plugin is an audio effect and accepts audio as input. Introduced in v0.7.4. is_instrument – True iff this plugin is not an audio effect and accepts only MIDI input, not audio. Introduced in v0.7.4. pedalboard.Invert Flip the polarity of the signal. This effect is not audible on its own and takes no parameters. This effect is mathematically identical to def invert(x): return -x.\nInverting a signal may be useful to cancel out signals in many cases; for instance, Invert can be used with the Mix plugin to remove the original signal from an effects chain that contains multiple signals.\nMethods __call__(input_array: numpy.ndarray, sample_rate: float, buffer_size: int = 8192, reset: bool = True) -\u0026gt; numpy.ndarray[numpy.float32] – Run an audio buffer through this plugin. Alias for process(). process(input_array: numpy.ndarray, sample_rate: float, buffer_size: int = 8192, reset: bool = True) -\u0026gt; numpy.ndarray[numpy.float32] – Run a 32-bit or 64-bit floating point audio buffer through this plugin. reset() -\u0026gt; None – Clear any internal state stored by this plugin (e.g.: reverb tails, delay lines, LFO state, etc). The values of plugin parameters will remain unchanged. Properties is_effect – True iff this plugin is an audio effect and accepts audio as input. Introduced in v0.7.4. is_instrument – True iff this plugin is not an audio effect and accepts only MIDI input, not audio. Introduced in v0.7.4. pedalboard.LadderFilter A multi-mode audio filter based on the classic Moog synthesizer ladder filter, invented by Dr. Bob Moog in 1968.\nDepending on the filter’s mode, frequencies above, below, or on both sides of the cutoff frequency will be attenuated. Higher values for the resonance parameter may cause peaks in the frequency response around the cutoff frequency.\nClass Mode The type of filter architecture to use.\nMembers LPF12 – A low-pass filter with 12 dB of attenuation per octave above the cutoff frequency. HPF12 – A high-pass filter with 12 dB of attenuation per octave below the cutoff frequency. BPF12 – A band-pass filter with 12 dB of attenuation per octave on both sides of the cutoff frequency. LPF24 – A low-pass filter with 24 dB of attenuation per octave above the cutoff frequency. HPF24 – A high-pass filter with 24 dB of attenuation per octave below the cutoff frequency. BPF24 – A band-pass filter with 24 dB of attenuation per octave on both sides of the cutoff frequency. Properties name Methods __call__(input_array: numpy.ndarray, sample_rate: float, buffer_size: int = 8192, reset: bool = True) -\u0026gt; numpy.ndarray[numpy.float32] – Run an audio buffer through this plugin. Alias for process(). process(input_array: numpy.ndarray, sample_rate: float, buffer_size: int = 8192, reset: bool = True) -\u0026gt; numpy.ndarray[numpy.float32] – Run a 32-bit or 64-bit floating point audio buffer through this plugin. reset() -\u0026gt; None – Clear any internal state stored by this plugin (e.g.: reverb tails, delay lines, LFO state, etc). The values of plugin parameters will remain unchanged. Properties is_effect – True iff this plugin is an audio effect and accepts audio as input. Introduced in v0.7.4. is_instrument – True iff this plugin is not an audio effect and accepts only MIDI input, not audio. Introduced in v0.7.4. pedalboard.Limiter A simple limiter with standard threshold and release time controls, featuring two compressors and a hard clipper at 0 dB.\nMethods __call__(input_array: numpy.ndarray, sample_rate: float, buffer_size: int = 8192, reset: bool = True) -\u0026gt; numpy.ndarray[numpy.float32] – Run an audio buffer through this plugin. Alias for process(). process(input_array: numpy.ndarray, sample_rate: float, buffer_size: int = 8192, reset: bool = True) -\u0026gt; numpy.ndarray[numpy.float32] – Run a 32-bit or 64-bit floating point audio buffer through this plugin. reset() -\u0026gt; None – Clear any internal state stored by this plugin (e.g.: reverb tails, delay lines, LFO state, etc). The values of plugin parameters will remain unchanged. Properties is_effect – True iff this plugin is an audio effect and accepts audio as input. Introduced in v0.7.4. is_instrument – True iff this plugin is not an audio effect and accepts only MIDI input, not audio. Introduced in v0.7.4. pedalboard.LowShelfFilter A low shelf filter with variable Q and gain, as would be used in an equalizer. Frequencies below the cutoff frequency will be boosted (or cut) by the provided gain value.\nMethods __call__(input_array: numpy.ndarray, sample_rate: float, buffer_size: int = 8192, reset: bool = True) -\u0026gt; numpy.ndarray[numpy.float32] – Run an audio buffer through this plugin. Alias for process(). process(input_array: numpy.ndarray, sample_rate: float, buffer_size: int = 8192, reset: bool = True) -\u0026gt; numpy.ndarray[numpy.float32] – Run a 32-bit or 64-bit floating point audio buffer through this plugin. reset() -\u0026gt; None – Clear any internal state stored by this plugin (e.g.: reverb tails, delay lines, LFO state, etc). The values of plugin parameters will remain unchanged. Properties is_effect – True iff this plugin is an audio effect and accepts audio as input. Introduced in v0.7.4. is_instrument – True iff this plugin is not an audio effect and accepts only MIDI input, not audio. Introduced in v0.7.4. pedalboard.LowpassFilter Apply a first-order low-pass filter with a roll-off of 6dB/octave. The cutoff frequency will be attenuated by -3dB (i.e.: 0.707x as loud).\nMethods __call__(input_array: numpy.ndarray, sample_rate: float, buffer_size: int = 8192, reset: bool = True) -\u0026gt; numpy.ndarray[numpy.float32] – Run an audio buffer through this plugin. Alias for process(). process(input_array: numpy.ndarray, sample_rate: float, buffer_size: int = 8192, reset: bool = True) -\u0026gt; numpy.ndarray[numpy.float32] – Run a 32-bit or 64-bit floating point audio buffer through this plugin. reset() -\u0026gt; None – Clear any internal state stored by this plugin (e.g.: reverb tails, delay lines, LFO state, etc). The values of plugin parameters will remain unchanged. Properties is_effect – True iff this plugin is an audio effect and accepts audio as input. Introduced in v0.7.4. is_instrument – True iff this plugin is not an audio effect and accepts only MIDI input, not audio. Introduced in v0.7.4. pedalboard.MP3Compressor An MP3 compressor plugin that runs the LAME MP3 encoder in real-time to add compression artifacts to the audio stream.\nCurrently only supports variable bit-rate mode (VBR) and accepts a floating-point VBR quality value (between 0.0 and 10.0; lower is better).\nNote that the MP3 format only supports 8kHz, 11025Hz, 12kHz, 16kHz, 22050Hz, 24kHz, 32kHz, 44.1kHz, and 48kHz audio; if an unsupported sample rate is provided, an exception will be thrown at processing time.\nMethods __call__(input_array: numpy.ndarray, sample_rate: float, buffer_size: int = 8192, reset: bool = True) -\u0026gt; numpy.ndarray[numpy.float32] – Run an audio buffer through this plugin. Alias for process(). process(input_array: numpy.ndarray, sample_rate: float, buffer_size: int = 8192, reset: bool = True) -\u0026gt; numpy.ndarray[numpy.float32] – Run a 32-bit or 64-bit floating point audio buffer through this plugin. reset() -\u0026gt; None – Clear any internal state stored by this plugin (e.g.: reverb tails, delay lines, LFO state, etc). The values of plugin parameters will remain unchanged. Properties is_effect – True iff this plugin is an audio effect and accepts audio as input. Introduced in v0.7.4. is_instrument – True iff this plugin is not an audio effect and accepts only MIDI input, not audio. Introduced in v0.7.4. pedalboard.Mix A utility plugin that allows running other plugins in parallel. All plugins provided will be mixed equally.\nMethods __call__(input_array: numpy.ndarray, sample_rate: float, buffer_size: int = 8192, reset: bool = True) -\u0026gt; numpy.ndarray[numpy.float32] – Run an audio buffer through this plugin. Alias for process(). append(plugin: Plugin) -\u0026gt; None – Append a plugin to the end of this container. insert(index: int, plugin: Plugin) -\u0026gt; None – Insert a plugin at the specified index. process(input_array: numpy.ndarray, sample_rate: float, buffer_size: int = 8192, reset: bool = True) -\u0026gt; numpy.ndarray[numpy.float32] – Run a 32-bit or 64-bit floating point audio buffer through this plugin. remove(plugin: Plugin) -\u0026gt; None – Remove a plugin by its value. reset() -\u0026gt; None – Clear any internal state stored by this plugin (e.g.: reverb tails, delay lines, LFO state, etc). The values of plugin parameters will remain unchanged. Properties is_effect – True iff this plugin is an audio effect and accepts audio as input. Introduced in v0.7.4. is_instrument – True iff this plugin is not an audio effect and accepts only MIDI input, not audio. Introduced in v0.7.4. pedalboard.NoiseGate A simple noise gate with standard threshold, ratio, attack time and release time controls. Can be used as an expander if the ratio is low.\nMethods __call__(input_array: numpy.ndarray, sample_rate: float, buffer_size: int = 8192, reset: bool = True) -\u0026gt; numpy.ndarray[numpy.float32] – Run an audio buffer through this plugin. Alias for process(). process(input_array: numpy.ndarray, sample_rate: float, buffer_size: int = 8192, reset: bool = True) -\u0026gt; numpy.ndarray[numpy.float32] – Run a 32-bit or 64-bit floating point audio buffer through this plugin. reset() -\u0026gt; None – Clear any internal state stored by this plugin (e.g.: reverb tails, delay lines, LFO state, etc). The values of plugin parameters will remain unchanged. Properties is_effect – True iff this plugin is an audio effect and accepts audio as input. Introduced in v0.7.4. is_instrument – True iff this plugin is not an audio effect and accepts only MIDI input, not audio. Introduced in v0.7.4. pedalboard.PeakFilter A peak (or notch) filter with variable Q and gain, as would be used in an equalizer. Frequencies around the cutoff frequency will be boosted (or cut) by the provided gain value.\nMethods __call__(input_array: numpy.ndarray, sample_rate: float, buffer_size: int = 8192, reset: bool = True) -\u0026gt; numpy.ndarray[numpy.float32] – Run an audio buffer through this plugin. Alias for process(). process(input_array: numpy.ndarray, sample_rate: float, buffer_size: int = 8192, reset: bool = True) -\u0026gt; numpy.ndarray[numpy.float32] – Run a 32-bit or 64-bit floating point audio buffer through this plugin. reset() -\u0026gt; None – Clear any internal state stored by this plugin (e.g.: reverb tails, delay lines, LFO state, etc). The values of plugin parameters will remain unchanged. Properties is_effect – True iff this plugin is an audio effect and accepts audio as input. Introduced in v0.7.4. is_instrument – True iff this plugin is not an audio effect and accepts only MIDI input, not audio. Introduced in v0.7.4. pedalboard.Phaser A 6 stage phaser that modulates first order all-pass filters to create sweeping notches in the magnitude frequency response. This audio effect can be controlled with standard phaser parameters: the speed and depth of the LFO controlling the frequency response, a mix control, a feedback control, and the centre frequency of the modulation.\nMethods __call__(input_array: numpy.ndarray, sample_rate: float, buffer_size: int = 8192, reset: bool = True) -\u0026gt; numpy.ndarray[numpy.float32] – Run an audio buffer through this plugin. Alias for process(). process(input_array: numpy.ndarray, sample_rate: float, buffer_size: int = 8192, reset: bool = True) -\u0026gt; numpy.ndarray[numpy.float32] – Run a 32-bit or 64-bit floating point audio buffer through this plugin. reset() -\u0026gt; None – Clear any internal state stored by this plugin (e.g.: reverb tails, delay lines, LFO state, etc). The values of plugin parameters will remain unchanged. Properties is_effect – True iff this plugin is an audio effect and accepts audio as input. Introduced in v0.7.4. is_instrument – True iff this plugin is not an audio effect and accepts only MIDI input, not audio. Introduced in v0.7.4. pedalboard.PitchShift A pitch shifting effect that can change the pitch of audio without affecting its duration.\nThis effect uses Chris Cannam’s wonderful Rubber Band library audio stretching library.\nMethods __call__(input_array: numpy.ndarray, sample_rate: float, buffer_size: int = 8192, reset: bool = True) -\u0026gt; numpy.ndarray[numpy.float32] – Run an audio buffer through this plugin. Alias for process(). process(input_array: numpy.ndarray, sample_rate: float, buffer_size: int = 8192, reset: bool = True) -\u0026gt; numpy.ndarray[numpy.float32] – Run a 32-bit or 64-bit floating point audio buffer through this plugin. reset() -\u0026gt; None – Clear any internal state stored by this plugin (e.g.: reverb tails, delay lines, LFO state, etc). The values of plugin parameters will remain unchanged. Properties is_effect – True iff this plugin is an audio effect and accepts audio as input. Introduced in v0.7.4. is_instrument – True iff this plugin is not an audio effect and accepts only MIDI input, not audio. Introduced in v0.7.4. pedalboard.Plugin A generic audio processing plugin. Base class of all Pedalboard plugins.\nMethods __call__(input_array: numpy.ndarray, sample_rate: float, buffer_size: int = 8192, reset: bool = True) -\u0026gt; numpy.ndarray[numpy.float32] – Run an audio buffer through this plugin. Alias for process(). process(input_array: numpy.ndarray, sample_rate: float, buffer_size: int = 8192, reset: bool = True) -\u0026gt; numpy.ndarray[numpy.float32] – Run a 32-bit or 64-bit floating point audio buffer through this plugin. reset() -\u0026gt; None – Clear any internal state stored by this plugin (e.g.: reverb tails, delay lines, LFO state, etc). The values of plugin parameters will remain unchanged. Properties is_effect – True iff this plugin is an audio effect and accepts audio as input. Introduced in v0.7.4. is_instrument – True iff this plugin is not an audio effect and accepts only MIDI input, not audio. Introduced in v0.7.4. pedalboard.PluginContainer A generic audio processing plugin that contains zero or more other plugins. Not intended for direct use.\nMethods __call__(input_array: numpy.ndarray, sample_rate: float, buffer_size: int = 8192, reset: bool = True) -\u0026gt; numpy.ndarray[numpy.float32] – Run an audio buffer through this plugin. Alias for process(). append(plugin: Plugin) -\u0026gt; None – Append a plugin to the end of this container. insert(index: int, plugin: Plugin) -\u0026gt; None – Insert a plugin at the specified index. process(input_array: numpy.ndarray, sample_rate: float, buffer_size: int = 8192, reset: bool = True) -\u0026gt; numpy.ndarray[numpy.float32] – Run a 32-bit or 64-bit floating point audio buffer through this plugin. remove(plugin: Plugin) -\u0026gt; None – Remove a plugin by its value. reset() -\u0026gt; None – Clear any internal state stored by this plugin (e.g.: reverb tails, delay lines, LFO state, etc). The values of plugin parameters will remain unchanged. Properties is_effect – True iff this plugin is an audio effect and accepts audio as input. Introduced in v0.7.4. is_instrument – True iff this plugin is not an audio effect and accepts only MIDI input, not audio. Introduced in v0.7.4. pedalboard.Resample A plugin that downsamples the input audio to the given sample rate, then upsamples it back to the original sample rate. Various quality settings will produce audible distortion and aliasing effects.\nClass Quality Indicates which specific resampling algorithm to use.\nResampling algorithms each provide a different tradeoff between speed and quality. Pedalboard provides two different types of resampling algorithms:\nAliasing algorithms, which cause high frequencies to appear as lower frequencies. Non-aliasing algorithms, which filter out high frequencies when downsampling and avoid introducing extra high-frequency content when upsampling. (These algorithms were introduced in Pedalboard v0.9.15.) Aliasing algorithms include:\nZeroOrderHold Linear CatmullRom Lagrange WindowedSinc Non-aliasing algorithms include:\nWindowedSinc256 WindowedSinc128 WindowedSinc64 WindowedSinc32 WindowedSinc16 WindowedSinc8 Choosing an algorithm to use depends on the signal being resampled, the relationship between the source and target sample rates, and the application of the resampled signal.\nIf downsampling by an integer factor (i.e.: from 44.1kHz to 22050Hz, or 48kHz to 24kHz), and if the source signal has no high-frequency content above half of the target sample rate the ZeroOrderHold algorithm will be the fastest by far and will produce no artifacts.\nIn all other cases, any of the numbered WindowedSinc algorithms (i.e.: WindowedSinc256, WindowedSinc64) will produce a clean signal with no artifacts. Higher numbers will produce a cleaner signal with less roll-off of high frequency content near the Nyquist frequency of the new sample rate.\nHowever, depending on your application, the artifacts introduced by each resampling method may be acceptable. Test each method to determine which is the best tradeoff between speed and accuracy for your use case.\nTo provide a good balance between speed and accuracy, WindowedSinc32 is the default from Pedalboard v0.9.15 onwards. (Previously, WindowedSinc was the default.)\nMembers ZeroOrderHold – The lowest quality and fastest resampling method, with lots of audible artifacts. Zero-order hold resampling chooses the next value to use based on the last value, without any interpolation. Think of it like nearest-neighbor resampling. Warning: This algorithm produces aliasing artifacts. Linear – A resampling method slightly less noisy than the simplest method. Linear resampling takes the average of the two nearest values to the desired sample, which is reasonably good for downsampling. Warning: This algorithm produces aliasing artifacts. CatmullRom – A moderately good-sounding resampling method which is fast to run. Slightly slower than Linear resampling, but slightly higher quality. Warning: This algorithm produces aliasing artifacts. Lagrange – A moderately good-sounding resampling method which is slow to run. Slower than CatmullRom resampling, but slightly higher quality. Warning: This algorithm produces aliasing artifacts. WindowedSinc – A very high quality (and the slowest) resampling method, with no audible artifacts when upsampling. This resampler applies a windowed sinc filter design with 100 zero-crossings of the sinc function to approximate an ideal brick-wall low-pass filter. Warning: This algorithm produces aliasing artifacts when downsampling, but not when upsampling. Note: This method was the default in versions of Pedalboard prior to v0.9.15. WindowedSinc256 – The highest possible quality resampling algorithm, with no audible artifacts when upsampling or downsampling. This resampler applies a windowed sinc filter with 256 zero-crossings to approximate an ideal brick-wall low-pass filter. This filter does not produce aliasing artifacts when upsampling or downsampling. Compare this in speed and quality to Resampy’s kaiser_best method. WindowedSinc128 – A very high quality resampling algorithm, with no audible artifacts when upsampling or downsampling. This resampler applies a windowed sinc filter with 128 zero-crossings to approximate an ideal brick-wall low-pass filter. This filter does not produce aliasing artifacts when upsampling or downsampling. This method is roughly as fast as Resampy’s kaiser_fast method, while producing results roughly equal in quality to Resampy’s kaiser_best method. WindowedSinc64 – A very high quality resampling algorithm, with few audible artifacts when upsampling or downsampling. This resampler applies a windowed sinc filter with 64 zero-crossings to approximate an ideal brick-wall low-pass filter. This filter does not produce aliasing artifacts when upsampling or downsampling. This method is (on average) faster than Resampy’s kaiser_fast method, and roughly equal in quality. WindowedSinc32 – A reasonably high quality resampling algorithm, with few audible artifacts when upsampling or downsampling. This resampler applies a windowed sinc filter with 32 zero-crossings to approximate an ideal brick-wall low-pass filter. This filter produces very few aliasing artifacts when upsampling or downsampling. This method is always faster than Resampy’s kaiser_fast method, while being reasonable in quality. Note: This method is the default in Pedalboard v0.9.15 and later. WindowedSinc16 – A medium quality resampling algorithm, with few audible artifacts when upsampling or downsampling. This resampler applies a windowed sinc filter with 16 zero-crossings to approximate an ideal brick-wall low-pass filter. This filter produces some aliasing artifacts when upsampling or downsampling. This method is faster than Resampy’s kaiser_fast method, while being acceptable in quality. WindowedSinc8 – A low quality resampling algorithm, with few audible artifacts when upsampling or downsampling. This resampler applies a windowed sinc filter with 16 zero-crossings to approximate an ideal brick-wall low-pass filter. This filter produces noticeable aliasing artifacts when upsampling or downsampling. This method can be more than 10x faster than Resampy’s kaiser_fast method, and is useful for applications that are tolerant of some resampling artifacts. Properties name Methods __call__(input_array: numpy.ndarray, sample_rate: float, buffer_size: int = 8192, reset: bool = True) -\u0026gt; numpy.ndarray[numpy.float32] – Run an audio buffer through this plugin. Alias for process(). process(input_array: numpy.ndarray, sample_rate: float, buffer_size: int = 8192, reset: bool = True) -\u0026gt; numpy.ndarray[numpy.float32] – Run a 32-bit or 64-bit floating point audio buffer through this plugin. reset() -\u0026gt; None – Clear any internal state stored by this plugin (e.g.: reverb tails, delay lines, LFO state, etc). The values of plugin parameters will remain unchanged. Properties is_effect – True iff this plugin is an audio effect and accepts audio as input. Introduced in v0.7.4. is_instrument – True iff this plugin is not an audio effect and accepts only MIDI input, not audio. Introduced in v0.7.4. quality – The resampling algorithm used to resample the audio. target_sample_rate – The sample rate to resample the input audio to. This value may be a floating-point number, in which case a floating-point sampling rate will be used. Note that the output of this plugin will still be at the original sample rate; this is merely the sample rate used for quality reduction. pedalboard.Reverb A simple reverb effect. Uses a simple stereo reverb algorithm, based on the technique and tunings used in FreeVerb.\nMethods __call__(input_array: numpy.ndarray, sample_rate: float, buffer_size: int = 8192, reset: bool = True) -\u0026gt; numpy.ndarray[numpy.float32] – Run an audio buffer through this plugin. Alias for process(). process(input_array: numpy.ndarray, sample_rate: float, buffer_size: int = 8192, reset: bool = True) -\u0026gt; numpy.ndarray[numpy.float32] – Run a 32-bit or 64-bit floating point audio buffer through this plugin. reset() -\u0026gt; None – Clear any internal state stored by this plugin (e.g.: reverb tails, delay lines, LFO state, etc). The values of plugin parameters will remain unchanged. Properties is_effect – True iff this plugin is an audio effect and accepts audio as input. Introduced in v0.7.4. is_instrument – True iff this plugin is not an audio effect and accepts only MIDI input, not audio. Introduced in v0.7.4. pedalboard.VST3Plugin A wrapper around third-party, audio effect or instrument plugins in Steinberg GmbH’s VST3® format.\nVST3® plugins are supported on macOS, Windows, and Linux. However, VST3® plugin files are not cross-compatible with different operating systems; a platform-specific build of each plugin is required to load that plugin on a given platform. (For example: a Windows VST3 plugin bundle will not load on Linux or macOS.)\nWarning: Some VST3® plugins may throw errors, hang, generate incorrect output, or outright crash if called from background threads. If you find that a VST3® plugin is not working as expected, try calling it from the main thread instead and open a GitHub Issue to track the incompatibility.\nSupport for instrument plugins introduced in v0.7.4.\nSupport for running VST3® plugins on background threads introduced in v0.8.8.\nMethods __call__(*args, **kwargs) – Overloaded function.\n__call__(self: pedalboard.Plugin, input_array: numpy.ndarray, sample_rate: float, buffer_size: int = 8192, reset: bool = True) -\u0026gt; numpy.ndarray[numpy.float32] – Run an audio or MIDI buffer through this plugin, returning audio. Alias for process(). __call__(self: pedalboard.VST3Plugin, midi_messages: object, duration: float, sample_rate: float, num_channels: int = 2, buffer_size: int = 8192, reset: bool = True) -\u0026gt; numpy.ndarray[numpy.float32] – Run an audio or MIDI buffer through this plugin, returning audio. Alias for process(). load_preset(preset_file_path: str) -\u0026gt; None – Load a VST3 preset file in .vstpreset format.\nprocess(*args, **kwargs) – Overloaded function.\nprocess(self: pedalboard.Plugin, input_array: numpy.ndarray, sample_rate: float, buffer_size: int = 8192, reset: bool = True) -\u0026gt; numpy.ndarray[numpy.float32] – Pass a buffer of audio (as a 32- or 64-bit NumPy array) or a list of MIDI messages to this plugin, returning audio. process(self: pedalboard.VST3Plugin, midi_messages: object, duration: float, sample_rate: float, num_channels: int = 2, buffer_size: int = 8192, reset: bool = True) -\u0026gt; numpy.ndarray[numpy.float32] – Pass a buffer of audio (as a 32- or 64-bit NumPy array) or a list of MIDI messages to this plugin, returning audio. reset() -\u0026gt; None – Clear any internal state stored by this plugin (e.g.: reverb tails, delay lines, LFO state, etc). The values of plugin parameters will remain unchanged.\nshow_editor(close_event: object = None) -\u0026gt; None – Show the UI of this plugin as a native window.\nThis method may only be called on the main thread, and will block the main thread until any of the following things happens:\nthe window is closed by clicking the close button the window is closed by pressing the appropriate (OS-specific) keyboard shortcut a KeyboardInterrupt (Ctrl-C) is sent to the program the threading.Event.set() method is called (by another thread) on a provided threading.Event object An example of how to programmatically close an editor window:\nimport pedalboard from threading import Event, Thread plugin = pedalboard.load_plugin(\u0026#34;../path-to-my-plugin-file\u0026#34;) close_window_event = Event() def other_thread(): # do something to determine when to close the window if should_close_window: close_window_event.set() thread = Thread(target=other_thread) thread.start() # This will block until the other thread calls .set(): plugin.show_editor(close_window_event) Properties category – A category that this plugin falls into, such as \u0026ldquo;Dynamics\u0026rdquo;, \u0026ldquo;Reverbs\u0026rdquo;, etc. Introduced in v0.9.4. descriptive_name – A more descriptive name for this plugin. This may be the same as the ‘name’ field, but some plugins may provide an alternative name. Introduced in v0.9.4. has_shared_container – True iff this plugin is part of a multi-plugin container. Introduced in v0.9.4. identifier – A string that can be saved and used to uniquely identify this plugin (and version) again. Introduced in v0.9.4. is_effect – True iff this plugin is an audio effect and accepts audio as input. Introduced in v0.7.4. is_instrument – True iff this plugin identifies itself as an instrument (generator, synthesizer, etc) plugin. Introduced in v0.9.4. manufacturer_name – The name of the manufacturer of this plugin, as reported by the plugin itself. Introduced in v0.9.4. name – The name of this plugin. preset_data – Get or set the current plugin state as bytes in .vstpreset format. Warning: This property can be set to change the plugin’s internal state, but providing invalid data may cause the plugin to crash, taking the entire Python process down with it.\nraw_state – A bytes object representing the plugin’s internal state. For the VST3 format, this is usually an XML-encoded string prefixed with an 8-byte header and suffixed with a single null byte. Warning: This property can be set to change the plugin’s internal state, but providing invalid data may cause the plugin to crash, taking the entire Python process down with it.\nreported_latency_samples – The number of samples of latency (delay) that this plugin reports to introduce into the audio signal due to internal buffering and processing. Pedalboard automatically compensates for this latency during processing, so this property is present for informational purposes. Note that not all plugins correctly report the latency that they introduce, so this value may be inaccurate (especially if the plugin reports 0). Introduced in v0.9.12. version – The version string for this plugin, as reported by the plugin itself. Introduced in v0.9.4. Functions time_stretch def time_stretch( input_audio: numpy.ndarray[numpy.float32], samplerate: float, stretch_factor: Union[float, numpy.ndarray[numpy.float64]] = 1.0, pitch_shift_in_semitones: Union[float, numpy.ndarray[numpy.float64]] = 0.0, high_quality: bool = True, transient_mode: str = \u0026#34;crisp\u0026#34;, transient_detector: str = \u0026#34;compound\u0026#34;, retain_phase_continuity: bool = True, use_long_fft_window: Optional[bool] = None, use_time_domain_smoothing: bool = False, preserve_formants: bool = True, ) -\u0026gt; numpy.ndarray[numpy.float32] Time-stretch (and optionally pitch-shift) a buffer of audio, changing its length.\nUsing a higher stretch_factor will shorten the audio – i.e., a stretch_factor of 2.0 will double the speed of the audio and halve the length of the audio, without changing the pitch of the audio.\nThis function allows for changing the pitch of the audio during the time stretching operation. The stretch_factor and pitch_shift_in_semitones arguments are independent and do not affect each other (i.e.: you can change one, the other, or both without worrying about how they interact).\nBoth stretch_factor and pitch_shift_in_semitones can be either floating-point numbers or NumPy arrays of double-precision floating point numbers. Providing a NumPy array allows the stretch factor and/or pitch shift to vary over the length of the output audio.\nNote: If a NumPy array is provided for stretch_factor or pitch_shift_in_semitones:\nThe length of each array must be the same as the length of the input audio. More frequent changes in the stretch factor or pitch shift will result in slower processing, as the audio will be processed in smaller chunks. Changes to the stretch_factor or pitch_shift_in_semitones more frequent than once every 1,024 samples (23 milliseconds at 44.1kHz) will not have any effect. The additional arguments provided to this function allow for more fine-grained control over the behavior of the time stretcher:\nhigh_quality (the default) enables a higher quality time stretching mode. Set this option to False to use less CPU power. transient_mode controls the behavior of the stretcher around transients (percussive parts of the audio). Valid options are \u0026quot;crisp\u0026quot; (the default), \u0026quot;mixed\u0026quot;, or \u0026quot;smooth\u0026quot;. transient_detector controls which method is used to detect transients in the audio signal. Valid options are \u0026quot;compound\u0026quot; (the default), \u0026quot;percussive\u0026quot;, or \u0026quot;soft\u0026quot;. retain_phase_continuity ensures that the phases of adjacent frequency bins in the audio stream are kept as similar as possible. Set this to False for a softer, phasier sound. use_long_fft_window controls the size of the fast-Fourier transform window used during stretching. The default (None) will result in a window size that varies based on other parameters and should produce better results in most situations. Set this option to True to result in a smoother sound (at the expense of clarity and timing), or False to result in a crisper sound. use_time_domain_smoothing can be enabled to produce a softer sound with audible artifacts around sharp transients. This option mixes well with use_long_fft_window=False. preserve_formants allows shifting the pitch of notes without substantially affecting the pitch profile (formants) of a voice or instrument. Warning: This is a function, not a Plugin instance, and cannot be used in Pedalboard objects, as it changes the duration of the audio stream.\nNote: The ability to pass a NumPy array for stretch_factor and pitch_shift_in_semitones was added in Pedalboard v0.9.8.\n","date":"4 October, 2025","id":4,"permalink":"/documents/pedalboard/","summary":"Github: https://github.com/spotify/pedalboard","tags":"","title":"Pedalboard 文档"},{"content":"TL;DR: I created Raddy, a forward autodiff library, and Symars, a symbolic codegen library.\nIf you\u0026rsquo;re interested, please give them a star and try them out! ❤️\nThe Origin of the Story I recently read papers on physical simulation and wanted to reproduce them. I started with Stable Neo-Hookean Flesh Simulation, though the choice isn\u0026rsquo;t critical. Many modern physical simulations are implicit, requiring Newton\u0026rsquo;s method to solve optimization problems.\nThis involves:\nComputing derivatives of the constitutive energy model (first-order gradient, second-order Hessian). Assembling a large, sparse Hessian from small, dense Hessian submatrices — a delicate task prone to hard-to-debug bugs. From Dynamic Deformables, I learned deriving these formulas is labor-intensive (even understanding the notation takes time). Searching for alternatives to avoid meticulous debugging, I found two solutions:\nSymbolic differentiation with code generation. Automatic differentiation. Tools for the former include MATLAB or SymPy; for the latter, deep learning libraries like PyTorch or more suitable ones like TinyAD.\nWhy TinyAD? Deep learning libraries differentiate at the tensor level, but I needed scalar-level differentiation for physical simulations. Tensor-level differentiation could lead to unplayable frame rates.\nA problem arose: these tools are in the C++ toolchain, and I\u0026rsquo;m not proficient in C++ (I know some kindergarten-level C++, but CMake and libraries like Eigen defeated me after three days of trying). So, I switched to Rust, a language I\u0026rsquo;m more comfortable with. This was the start of all troubles…\nA Path That Seems Simple Rust lacks an automatic differentiation library for second-order Hessians (at least on crates.io). SymPy can generate Rust code, but it\u0026rsquo;s buggy. Given the implementation complexity, I started with symbolic code generation, creating Symars.\nSymPy\u0026rsquo;s symbolic expressions are tree-structured, with nodes as operators (Add, Mul, Div, Sin, etc.) or constants/symbols, and children as operands. Code generation involves depth-first traversal: compute child expressions, then the current node\u0026rsquo;s expression based on its type. Base cases are constants or symbols.\nI used the generated derivatives for a simple implicit spring-mass system, but debugging index errors in Hessian assembly was time-consuming.\nTrying the Untrodden Path Again To address this, I revisited automatic differentiation, aiming to adapt TinyAD for Rust.\nTwo Ways to Walk the Same Path Initially, I considered two approaches:\nWrite FFI bindings, as I don\u0026rsquo;t know C++ well. Replicate TinyAD\u0026rsquo;s logic. Cloning TinyAD, I couldn\u0026rsquo;t even pull dependencies or compile it. Examining the codebase, I found the core logic was ~1000 lines — manageable to replicate without running the project. Thus, Raddy was born.\nSymbolic diff \u0026amp; Codegen: Implementation Implementation details:\nEach scalar in the differentiation chain carries a gradient and Hessian, increasing memory overhead. I avoided implementing the Copy trait, requiring explicit cloning. Operator traits between (\u0026amp;)Type and (\u0026amp;)Type (four combinations) required repetitive code. I considered the following options: Macros. Python scripts for code generation. Macros breaks rust-analyzer (somebody refuse to agree on this, but for me this is true) and I am rather unfamiliar with Rust\u0026rsquo;s macro syntax, so I used Python scripts (in the meta/ directory) for simple string concatenation.\nTesting: I verified derivatives by generating symbolic grad and hessian code with Symars, cross-validating against Raddy\u0026rsquo;s results, ensuring test expressions covered all implemented methods. Symars performed reliably, without bugs. What about sparse matrices Dense matrices store adjacent values contiguously, but sparse matrices (with millions of elements) don\u0026rsquo;t. I implemented sparse Hessian assembly:\nDefine a problem via the Objective\u0026lt;N\u0026gt; trait: Specify problem size N (a compile-time constant for const generics). Implement computation logic, e.g., a spring-mass system (Hooke\u0026rsquo;s law, E=1/2 k x²): impl Objective\u0026lt;4\u0026gt; for SpringEnergy { type EvalArgs = f64; // restlength fn eval(\u0026amp;self, variables: \u0026amp;advec\u0026lt;4, 4\u0026gt;, restlen: \u0026amp;Self::EvalArgs) -\u0026gt; Ad\u0026lt;4\u0026gt; { // extract node positions from problem input: let p1 = advec::\u0026lt;4, 2\u0026gt;::new(variables[0].clone(), variables[1].clone()); let p2 = advec::\u0026lt;4, 2\u0026gt;::new(variables[2].clone(), variables[3].clone()); let len = (p2 - p1).norm(); let e = make::val(0.5 * self.k) * (len - make::val(*restlen)).powi(2); e } } Specify input components\u0026rsquo; indices (\u0026amp;[[usize; N]]). Automatically assemble sparse grad and hess (handling index mapping). Manually sum multiple grad and hess (simple matrix addition; triplet matrices are concatenated). Before tests, Raddy was 2.2k lines; after, it ballooned to 18k lines, showing LOC is a poor metric.\nFinally, I wrote a demo for fun and as an example.\nConclusion Gains:\nLearned how automatic differentiation works. First time using AI for documentation (it struggled with Rust syntax, producing test code with errors). Happiness! ","date":"2 October, 2025","id":5,"permalink":"/english-post/raddy/","summary":"TL;DR: I created Raddy, a forward autodiff library, and Symars, a symbolic codegen library.","tags":"rust graphics math","title":"Raddy devlog: forward autodiff system"},{"content":"From the perspective of a newbie user\nThe Documentation is a Disaster Recently, I had to optimize a custom operator and decided to use OpenAI\u0026rsquo;s Triton. After digging into the documentation, I was shocked at how poorly written it is — like an academic paper full of equations but lacking practical code examples.\nIf the library operates on tensors, the docs should clearly specify input/output shapes and provide concrete examples (like PyTorch does). Instead, everything is vaguely described in plain text, leaving users to guess the details.\nHow Triton Fails at Clarity Take the tl.load documentation as an example. It mentions that block pointers support \u0026ldquo;boundary checks\u0026rdquo; and \u0026ldquo;padding options,\u0026rdquo; but:\nWhat does \u0026ldquo;boundary check\u0026rdquo; actually do? Does it skip out-of-bounds elements, returning a smaller tensor? Does it pad with a default value? Does it throw an error? The docs don\u0026rsquo;t say. What\u0026rsquo;s the \u0026ldquo;padding option\u0026rdquo;? After some trial and error, I realized it handles out-of-bounds elements — but this should be explicitly stated, not left for users to reverse-engineer.\nAnother issue: tl.make_block_ptr and tl.arange require block shapes and element counts to be powers of two. This restriction isn\u0026rsquo;t mentioned anywhere in the official docs. I only discovered it after hitting an error and finding a passing reference in an unofficial blog post.\nWhoever wrote this documentation did a huge disservice to the engineers who built Triton\u0026rsquo;s compiler. Triton\u0026rsquo;s compiler is awesome.\nKey API Clarifications tl.load For raw pointers (or tensors of pointers): Always set mask and other. mask=True: Load from HBM. mask=False: Use the value from other (a float). For block pointers (tl.make_block_ptr): Enable boundary checks on all dimensions and set padding=\u0026quot;zero\u0026quot;. The behavior of boundary_check is poorly defined, especially after reordering dimensions. Shape Constraints tl.arange element counts and tl.make_block_ptr block shapes must be powers of two. This might apply to all Triton tensor dimensions, but I haven\u0026rsquo;t verified it.\nMemory Access Pitfalls tl.load and tl.store silently corrupt data. Invalid memory access turns values into NaN—yes, even tl.store can corrupt valid data! Solution: Unless your dimensions are multiples of 64, always enable boundary checks for HBM reads/writes. Extra caution: Raw pointers require careful mask handling to avoid disasters. ","date":"2 October, 2025","id":6,"permalink":"/english-post/triton-pitfalls/","summary":"From the perspective of a newbie user","tags":"deep-learning triton","title":"Triton Common Pitfalls"},{"content":"Intro: A taste of the Rust programming language\nRecently, I tried to get started with Rust and wanted to write some code.\nMost people\u0026rsquo;s first application is probably some kind of backend service (converting HTTP requests from the frontend into CRUD operations on a database and returning the results to the frontend).\nHowever, I\u0026rsquo;ve never learned how to write backend services (I\u0026rsquo;ve been wanting to learn recently — if anyone has good zero-to-hero beginner resources, feel free to recommend them). So, I ended up picking up the two papers I\u0026rsquo;ve been studying lately (@Li2020IPC, @abd) to try reproducing them.\nNote: This post only reproduces/discusses the IPC family of algorithms and does not address any performance optimizations, whether the algorithm is efficient, or why not to use some other algorithm.\nProject repo: Github\nImplicit Euler Physical simulation is essentially a numerical integration process.\nExplicit integration tends to explode, but implicit integration suffers from a \u0026ldquo;chicken-and-egg\u0026rdquo; problem (calculating the position at the next timestep requires knowing the velocity at the next timestep), making it impossible to solve explicitly. Instead, it requires solving a (possibly non-convex) optimization problem.\nWhat can be implicitly integrated? A mass-spring system can. But honestly, I\u0026rsquo;ve never written an optimization-based implicit integrator before, so I decided to start by implementing a mass-spring system.\nWhat Is It? Incremental Potential (IP) is a function of the degrees of freedom (DOF) of a scene at time t, IP(t).\nImplicit Euler constructs an then minimizes the IP (x(t+\\Delta t) = \\argmin_x E_{\\text{IP}}(x(t))) to obtain the position at t+\\Delta t.\nDeep learning typically uses gradient descent (and its variants), but in graphics, empirical evidence suggests gradient descent performs poorly. So, we opt for Newton\u0026rsquo;s method.\nImplementation Newton\u0026rsquo;s method is faster, but it introduces a problem: assembling the Hessian matrix. Fortunately, each component of the incremental potential is mostly a function of (k \\cdot n DOFs), where n is the dimensionality (I implemented 2D), and k is a small number (at most a few dozen). Thus, for each small IP contributing to the larger IP, the Hessian has only tens to hundreds of entries, which can be stored sparsely and assembled into the full Hessian. Following this tutorial, I implemented springs with vertices pinned to a wall.\nChoosing libraries: Used macroquad for GUI. Used nalgebra_glm for small-scale linear algebra. Initially planned to use nalgebra for large-scale linear algebra, but its sparse matrix functionality seemed incomplete, so I switched to faer. Initially used argmin for optimization. A Small Detour Before Contact IP Rust takes forever to compile, so configuring geometry shapes shouldn\u0026rsquo;t be hardcoded.\nAt first, I invented a weird file format and wrote a config based on my own logic:\n!k 1000.0 !node 0.0 0.0 0.2 0.0 0.4 0.0 0.6 0.0 0.1 0.2 0.3 0.2 Then I asked an AI to write a parser for me.\nLater, I realized that existing formats like JSON or TOML already have parsers, but by then, I was too lazy to change it.\nContact IP In short, Contact IP:\nRequires that point-edge pairs (aka primitive pairs) from two different bodies, which are close enough (within a threshold \\hat{d}), are assigned energy based on their distance. But to prevent interpenetration, there are additional requirements:\nOptimization courses teach that (damped) Newton\u0026rsquo;s method iteratively approaches the optimum. Each iteration involves a line search, and to prevent interpenetration, every intermediate step of the line search must ensure no primitive pairs penetrate, ultimately guaranteeing no interpenetration in the final result. Procedure At each line search step in Newton\u0026rsquo;s method:\nTraverse all primitive pairs (or use some acceleration structure — I didn\u0026rsquo;t implement this) and identify those with distances below the threshold. Compute the energy, gradient, and Hessian of the Contact IP for each primitive pair\u0026rsquo;s DOFs, then solve d = -A^{-1}g to get the search direction. Perform a CCD (Continuous Collision Detection) operation to ensure the line search doesn\u0026rsquo;t cause interpenetration (by setting a maximum step length). Use the Armijo condition for the line search. Repeat until sufficiently close to the minimum, at which point optimization is complete.\nImplementation Every step involved endless debugging…\nGradient \u0026amp; Hessian:\nIn 2D, each primitive pair\u0026rsquo;s DOFs are (2 DOFs per point) × (3 points) = 6 DOFs. The gradient of energy E w.r.t. DOFs can still be computed manually (a 6D vector). But the Hessian is a 6×6 matrix, and the paper\u0026rsquo;s notation is a mess—sometimes dyadic product, sometimes Kronecker product, with no clear labeling in the text. Manual computation failed. So, I used SymPy for symbolic computation and generated code from it. The differentiation code can be found in the symbolic/ folder. SymPy actually has Rust codegen, but it\u0026rsquo;s half-baked — often producing invalid Rust syntax, requiring string replacements, and only supporting single expressions (no vectors/matrices). Note: Later, I built my own SymPy→Rust code generator:\nSymars: Generate Rust code from SymPy expressions\nRemember: Point-to-segment distance requires case-by-case handling. CCD (ACCD) needs to be integrated into the optimization process, so argmin wasn\u0026rsquo;t suitable anymore. I discarded it and handwrote a damped Newton solver with ACCD and Armijo condition. After days of coding and debugging, the demo finally worked:\nThe constraints here are springs. ABD TL;DR, ABD Replaces traditional 6-DOF (translation + rotation) rigid bodies with 12-DOF bodies and heavily penalizes transformation matrices that deviate too far from rotation matrices, resulting in a (near-)rigid body simulation algorithm.\nIn 2D, an affine body (AB) has 6 DOFs: x = A x_0 + b, where the shape is defined by A (2×2) and b (2×1), assembled into a DOF vector: q = [flatten(A), b^T].\nWe know rotation matrices R satisfy R^T R = I. ABD uses an orthogonal potential energy \\kappa \\cdot \\text{frobnorm}(A^T A - I) to penalize A and keep it close to a rotation matrix.\nImplementation Any energy term requires second derivatives. Again, I used SymPy for differentiation. The project has thousands of lines of numerical computation code — don\u0026rsquo;t look at them. Affine bodies also need contact handling: Unlike mass-spring systems where each vertex is a DOF, an AB\u0026rsquo;s vertex position p is a function of DOFs, and the Contact IP is a function of p. A primitive pair involves two bodies, where one contributes an edge (two points p_1, p_2). Thus, derivatives must be taken w.r.t. both q s. The computational graph looks like this: After more endless debugging and parameter tuning (mainly \\kappa), the simulation finally ran:\nFinal Thoughts The resulting code is a bona fide spaghetti monster.\nEven though I spent a long time thinking about unifying interfaces before coding, the final design is neither OOP nor Rust-like, with inconsistent parameter passing everywhere.\nI can\u0026rsquo;t help but wonder: Is my ability just too low, or is code complexity truly not something design alone can solve?\nThe bright side:\nCargo is amazing — adding a dependency takes three seconds. Compared to Cmake, xmake or whatever-make, it\u0026rsquo;s night and day. No memory issues (since I didn\u0026rsquo;t and did not need to write unsafe code), so most effort went into logic. ","date":"2 October, 2025","id":7,"permalink":"/english-post/try-impl-ipc/","summary":"Intro: A taste of the Rust programming language","tags":"graphics graphics rust","title":"Try To Implement IPC"},{"content":"Intro: Troubleshooting Memory and Speed Performance\nDisclaimer: I develop and test primarily on Windows using the latest stable Rust toolchain and CPython 3.13.\n1. Background and Motivation SnapViewer handles large memory snapshots effectively — for example, pickle files up to 1 GB and compressed snapshots up to 500 MB. However, when processing extremely large dumps (e.g., a 1.3 GB snapshot), we encountered serious memory and speed bottlenecks:\nFormat conversion (pickle → compressed JSON) triggered memory peaks around 30 GB. Data loading of the compressed JSON into Rust structures caused another ~30 GB spike. Frequent page faults and intense disk I/O (observed in Task Manager) made the application sluggish and prone to stalls. To address this, we applied a Profile-Guided Optimization (PGO) approach.\n2. Profile-Guided Optimization PGO requires empirical profiling to identify the true hotspots. I began with memory profiling using the memory-stats crate for lightweight inspection during early optimization stages. Then, I decomposed the data-loading pipeline into discrete steps:\nReading the compressed file (heavy disk I/O) Extracting the JSON string from the compressed stream Deserializing the JSON into native Rust data structures Populating an in-memory SQLite database for ad-hoc SQL queries Building the triangle mesh on CPU Initializing the rendering window (CPU-GPU transfer) Profiling revealed two major memory culprits: excessive cloning and multiple intermediate data structures. Below, I outline the optimizations.\nEliminating Redundant Clones During rapid prototyping, calls to .clone() are convenient. But they are expensive. Profiling showed that cloning large vectors contributed significantly to the memory peak and CPU time.\nFirst attempt: switch from cloned Vec\u0026lt;T\u0026gt; to borrowed \u0026amp;[T] slices. This failed due to lifetime constraints. Final solution: use Arc\u0026lt;[T]\u0026gt;. Although I\u0026rsquo;m not leveraging multithreading, Arc satisfies PyO3\u0026rsquo;s requirements, while no significant overhead is observed in this context. This change alone reduced memory usage and improved throughput noticeably.\nEarly Deallocation of Intermediate Structures Constructing the triangle mesh involved several temporary representations:\nRaw allocation buffers A list of triangles (vertices + face indices) A CPU-side mesh structure GPU upload buffers Each stage held onto its predecessor until the end of scope, inflating peak usage. To free these intermediates promptly, the following is implemented:\nScoped blocks to limit lifetimes Explicitly invoked drop() on unneeded buffers After these adjustments, peak memory dropped by roughly one-third.\n3. Sharding JSON Deserialization Deserializing the call-stack JSON with over 50 000 entries spiked memory usage dramatically. To mitigate this:\nShard the JSON data into chunks of at most 50 000 entries. Deserialize each chunk independently. Concatenate the resulting vectors. This streaming approach kept per-shard memory small, eliminating the previous giant allocation.\nIt is worth noting that serde_json::StreamDeserializer can be another option worth trying.\n4. Redesigning the Snapshot Format Even after the above optimizations, the call-stack data remained the largest in-memory component — duplicated once in Rust and again in the in-memory SQLite database.\nTo remove redundancy, I rethought what each representation serves:\nRust structures: display call stacks on screen upon user click. SQLite DB: serve ad-hoc SQL queries. Since SnapViewer is single-threaded and can tolerate occasional disk I/O, I split the snapshot into two files:\nallocations.json: lightweight JSON with allocation timestamps and sizes. elements.db: SQLite database holding call-stack text (indexed by allocation index). These two files are zipped together. At runtime:\nUnzip the snapshot. Load allocations.json into memory (small footprint). Open elements.db on disk. On click, query elements.db with WHERE idx = \u0026lt;allocation_index\u0026gt;. SQLite\u0026rsquo;s efficient on-disk indices make these lookups fast, with no perceptible impact on frame rate.\nRefactoring the Conversion Script I updated the snapshot-conversion script as follows:\nParse the original snapshot format. Bulk-insert call stacks into an in-memory SQLite database, then dump the DB as a byte stream. Serialize allocation metadata to JSON. Zip the JSON and DB byte stream. While conversion takes slightly longer, the resulting snapshot loads faster and uses a fraction of the memory.\n5. Results and Lessons After these optimizations, SnapViewer:\nNo longer spikes to 60+ GB of RAM on large snapshots, since we do not load the entire call stack information into memory at all. Starts up much faster. Maintains smooth rendering, even with on-demand call-stack queries. What I learned:\nDo not always load everything into memory. When you overflow your memory, the performance of virtual memory swapping system is probably worse than you think. When you need some mechanism to store most data on disk, but intelligentlly cache some of then in memory, SQLite should be a good start. It has its well-designed and industry-proven algorithm built into it. ","date":"2 October, 2025","id":8,"permalink":"/english-post/snapviewer-3-optim/","summary":"Intro: Troubleshooting Memory and Speed Performance","tags":"torch deep-learning rust","title":"SnapViewer Devlog #3: Optimizations"},{"content":"Intro: Building the UI as a Hybrid Rust \u0026amp; Python Application\nBuilding a UI can often be the trickiest part of a development project, especially when you\u0026rsquo;re trying to integrate different languages and paradigms.\nFor SnapViewer, my memory allocation viewer, I needed an integrated UI that could display allocation details on click and feature a REPL for SQL queries against a SQLite database. This post details my journey, the hurdles I faced, and the solutions I found, primarily focusing on a Rust backend and Python UI.\nProject page: https://github.com/Da1sypetals/SnapViewer\nThe Initial Vision: An Integrated UI My core requirements for the UI were:\nInteractive Display: When an allocation is clicked in the viewer, its size, call stack, and other relevant information should be immediately displayed. SQL REPL: A command-line interface to execute SQL queries directly against the underlying database. Non-Blocking Operations: Both functionalities needed to operate without blocking each other. Early Attempts and Roadblocks Web: Rust to WASM My first thought was a web interface. Rust\u0026rsquo;s ability to compile to WASM and the three-d crate\u0026rsquo;s WebGPU support seemed promising. However, I quickly hit a wall with library versioning issues trying to compile even a simple Rust program to WASM. Rather than get bogged down, I decided to pivot.\nTUI: Terminal User Interface The natural next step was a Terminal User Interface (TUI). This approach avoids the complexities of cross-compilation and platform-specific GUI libraries.\nRatatui: A Promising Rust TUI Framework I started with Ratatui, a TUI framework for Rust. I got their demos running, but my plan to find an open-source example matching my \u0026ldquo;left-console, right-REPL\u0026rdquo; layout failed.\nDiving deep into the Ratatui documentation felt as complex as learning a new frontend framework like React, which defeated my goal of getting work done quickly. I abandoned this path.\nTextual \u0026amp; AI-Powered Development Given my goal of getting work done rather than becoming a TUI expert, I started thinking about AI. Rust isn\u0026rsquo;t particularly \u0026ldquo;AI-friendly\u0026rdquo; for code generation, but Python certainly is. This sparked an idea: What if I used AI to generate the TUI code in Python and then integrated my Rust application?\nI fed my requirements to several LLMs: Claude, Gemini, Deepseek, ChatGPT, and Grok. Claude\u0026rsquo;s initial results were impressive, while the others were largely unusable. After a few rounds of refinement with Claude, I had a working TUI demo:\nCombining Rust and Python: A Hybrid Approach Integrating Rust and Python is a standard process, but it has its quirks. I used PyO3 as a dependency to expose my Rust structures and bind Rust functions to Python.\nMy core Rust logic consists of:\nViewer: An infinite loop handling render draw calls and an event loop until the application shuts down. SQL REPL: Loads snapshot data into SQLite and executes SQL queries. Each of these operations is designed to be completed in milliseconds.\nDesigning App Structure My initial application structure idea was:\nMain Thread: Renders the TUI and accepts REPL inputs, calling SQL REPL Rust functions. Spawned Thread: Runs the infinite loop for the Snapshot Viewer. However, the three-d crate, which uses winit for window management, dictates that the window must run on the main thread. This immediately threw a wrench in my plans.\nAttempt 1: Multiprocessing My first revised design used multiprocessing:\nStart the application and load snapshot data. Spawn a new process to run the TUI application. Run the Viewer in the parent process. This setup allowed the child process to run the viewer window without blocking the TUI app. The challenge, however, was Inter-Process Communication (IPC). I needed a way for the viewer to send information (like selected allocation details) back to the TUI.\nI experimented with Python\u0026rsquo;s multiprocessing.Queue. My approach was to define a callback in Rust that put messages into the queue, and then have the parent process check the queue at a fixed interval (e.g., 0.1 seconds) to update the TUI\u0026rsquo;s logging panel.\nI encountered an implementation bug where the parent process wasn\u0026rsquo;t consuming all messages, causing the viewer and TUI to become out of sync. I then switched to a shared byte array with a lock for IPC. The child process would acquire the lock, write to the buffer, and release it. The parent process would try to acquire the lock at intervals to read the message and update the TUI.\nAttempt 2: Threading The multiprocessing solution had a couple of issues:\nThe TUI sometimes froze when typing in the REPL, likely due to lock contention. Balancing the log message update interval with the viewer\u0026rsquo;s framerate was tricky. Too frequent, and the UI lagged; too slow, and the viewer became unresponsive. I realized I could use multithreading instead! While winit requires the viewer window to run on the main thread, the TUI application does not. This led to a new, more elegant structure:\nSpawn a thread and start the TUI application on that thread. Start the viewer on the main thread. A naive implementation, however, caused the entire TUI to freeze. The culprit? The Global Interpreter Lock (GIL) in Python. The GIL ensures that only one thread can execute Python bytecode at a time.\nTime for some PyO3 details. By default, the extension function holds GIL during its execution; but when you don\u0026rsquo;t need to use Python objects during this call, a call to py::allow_thread can opt out this behavior, releasing the GIL.\nIn my case, the Rust extension holds GIL in the infinte render loop, preventing the TUI thread from updating the UI. By explicitly releasing the GIL during the viewer\u0026rsquo;s render loop, the TUI, running in its own sub-thread, was free to update, and the application could run as expected.\nAn Alternative: GUI with PyQt As an interesting side experiment, I wondered about a GUI instead of a TUI. I tasked Claude with translating my TUI code into a GUI application using PyQt. Claude did this in minutes, without errors.\nAfter a few minor styling tweaks (also done via chatting with Claude), here is what the app looks like:\n(I finally switched to Tkinter for compatibility issues with multithreading across platforms.)\nWrapping Up This journey highlights the flexibility and power of combining Rust\u0026rsquo;s performance with Python\u0026rsquo;s rapid development capabilities, especially when augmented by AI.\nUnderstanding the intricacies of thread management and inter-process communication helped a lot in this journey.\nHope you find this post is fun and informative to read! ❤️❤️❤️\n","date":"2 October, 2025","id":9,"permalink":"/english-post/snapviewer-2-ui/","summary":"Intro: Building the UI as a Hybrid Rust \u0026amp; Python Application","tags":"torch deep-learning rust","title":"Snapviewer Devlog #2: UI"},{"content":"Intro: PyTorch is a Deep Learning Operating System.\nCheck tensor storage Device check You should ALWAYS check EXPLICITLY whether input tensors are on desired devices. In most cases you want them on the same GPU, or in rare cases you want some tensors on CPU to perform some operations that are not efficient on GPU.\nAPI:\ntensor.is_cuda() tensor.device() (Use operator== for equality comparison). Sometimes the not on correct device problem causes strange error messages like Cusparse context initialization failure or things even more weird, which first seem unrelated to a device problem. This is why I suggest you always start your debug journey here.\nContiguity check Modern LibTorch recommends using Packed tensor accessor (roughly the same memory cost as a pointer) to access elements in tensor.\nHowever, if you are to plug some others\u0026rsquo; implementation (likely using raw pointers like float*) into PyTorch, you are not likely to understand the code inside out and rewrite it.\nUsually, in the context of deep learning, most implementations assumes a row-major contiguous storage. You should explicitly check whether the input tensors are contiguous in the C++ code that wraps the CUDA kernel.\nAPI: tensor.is_contiguous()\nCheatsheet A quick utility that checks whether all tensors are on the same CUDA device:\nvoid CheckInputTensors(const std::vector\u0026lt;torch::Tensor\u0026gt; \u0026amp;tensors) { TORCH_CHECK(!tensors.empty(), \u0026#34;No tensors provided for device check\u0026#34;); auto first_device = tensors[0].device(); TORCH_CHECK(first_device.is_cuda(), \u0026#34;First tensor is not on CUDA\u0026#34;); int idx = 0; for (const auto \u0026amp;tensor: tensors) { TORCH_CHECK(tensor.device() == first_device, \u0026#34;All tensors must be on the same CUDA device, \u0026#34; \u0026#34;but found tensor at index [\u0026#34;, idx, \u0026#34;] on device \u0026#34;, tensor.device(), \u0026#34; while expecting \u0026#34;, first_device); TORCH_CHECK(tensor.is_contiguous(), \u0026#34;All tensors must be contiguous, but found tensor at index [\u0026#34;, idx, \u0026#34;] not contiguous\u0026#34;); idx += 1; } } CUDA stream Remember to always get the current CUDA stream via at::cuda::getCurrentCUDAStream() and pass it as the 4-th parameter in the \u0026lt;\u0026lt;\u0026lt;gridDim, blockDim, sharedMemorySizeBytes, stream\u0026gt;\u0026gt;\u0026gt; kernel call.\nThis is especially important when your operator is used in distributed training, where at::cuda::getCurrentCUDAStream() automatically selects the correct stream for you.\nCUDA toolkit version problem Most \u0026ldquo;symbol not found\u0026rdquo; problem are caused by compiler / assembler / library version mismatch. Let me elaborate on this a bit:\nPyTorch has an important version information attached to it: The version of CUDA that torch is compiled on (let\u0026rsquo;s call it VT, cuda Version of Torch, for the sake of simplicity). The torch installation comes with its own CUDA toolkit (that matches VT) with no nvcc, ptxas. If you are to write custom CUDA extension to PyTorch, it will use the nvcc and ptxas in your system PATH, and libraries like CUBLAS or CUSPARSE in LD_LIBRARY_PATH. Let\u0026rsquo;s call this CUDA toolkit version VE, cuda Version of Extension. When you try to compile a CUDA extension, Make sure that your VT and VE perfectly match (NOT major version match). When you compile your extension, PyTorch hints you that a minor version mismatch should not be a problem. Remember, everything that should not happen will eventually happen. Memory Management in PyTorch Allocation When you need a buffer on HBM (e.g., for CUSPARSE or CUBLAS), your first instinct might be cudaMalloc and cudaFree. However, these force synchronization between CPU and GPU, which can starve the GPU.\nHere\u0026rsquo;s the key: PyTorch isn\u0026rsquo;t just an autograd tool. It\u0026rsquo;s a deep learning operating system that manages VRAM internally with a pooling and caching mechanism.\nUsing the PyTorch allocator is straightforward. Follow these steps:\nSet dtype to torch::kInt8 and create a buffer tensor via torch::empty Get the pointer with buffer_tensor.data_ptr\u0026lt;int8_t\u0026gt;() This gives you a pointer to the buffer. Here\u0026rsquo;s a complete code snippet:\nauto buffer_options = torch::TensorOptions().device(your_device).dtype(torch::kInt8); auto buffer_tensor = torch::empty({buffer_size}, buffer_options); void *buffer_ptr = buffer_tensor.data_ptr\u0026lt;int8_t\u0026gt;(); Remember do not call cudaFree on the pointer. RAII semantics will give the memory back to the allocator when destructor is called.\nPyTorch\u0026rsquo;s memory management is pretty much like a combination of OS memory management (buddy system, SLAB) and JVM or .net runtime (garbage collection, memory pool, caching and reusing memory blocks), but manages VRAM instead of a RAM.\nI recommend reading this post (Chinese) for a deeper dive into how PyTorch manages memory.\nUsing CUBLAS, CUSPARSE, CUSolverDn, etc. We use CUSPARSE as an example. The same rule apply to other libraries like CUBLAS or CUSolverDn.\nHandles When writing pure CUDA/C++ code, you manually call cusparseCreate to initialize the CUSPARSE context and prepare for subsequent CUSPARSE API calls.\nHowever this is not best practice in PyTorch CUDA extensions. There are good reasons: cusparseCreate introduces a milliseconds-level delay on CPU side. This may not be noticeable at first, but remember that operators are written to be run millions of times, which turns this into a significant overhead. This can cause GPU to starve when waiting CPU for synchronization.\nIf you use VizTracer to trace your program and visualize it in perfetto, you may notice cudaGetDeviceProperties call taking too much time on CPU side. This can be directly caused by cusparseCreate. LibTorch has API that automatically manages a pool of CUSPARSE handles:\nInclude the header that brings in CUDA context manager for LibTorch: #include \u0026lt;ATen/cuda/CUDAContext.h\u0026gt; Then, get handle via auto handle = at::cuda::getCurrentCUDASparseHandle(); automatically create a handle if there is not any, and caches it for subsequent uses. Use your handle as usual. I could not find documentation for these APIs, so if you want to know more, you may need to read the source code of PyTorch ATen. Searching in the repo with keyword getcurrentcuda can get you there quickly.\nBuffers Many CUSPARSE operations need buffers. If you need to make multiple CUSPARSE API calls with similar buffer size, it is bad practice to allocate right before the CUSPARE API call and deallocate right after since cudaMalloc and cudaFree are quite slow, which may cause your GPU to starve (verify this with VizTracer).\nA better practice should be pre-allocating the buffer and pass its pointer into where the CUSPARSE API is called through torch.empty().\nBatched Matrix Multiplication Refer to this example to see how to perform batched matrix multiplication in CUSPARSE.\nTricks:\nTo broadcast, set stride to 0. It is possible to broadcast rowptr but not colind and values. Check documentation for details.\nTensor Options struct TensorOptions carries many information about the tensor:\nstruct C10_API TensorOptions { // ... omitted // members Device device_ = at::kCPU; // 16-bit caffe2::TypeMeta dtype_ = caffe2::TypeMeta::Make\u0026lt;float\u0026gt;(); // 16-bit Layout layout_ = at::kStrided; // 8-bit MemoryFormat memory_format_ = MemoryFormat::Contiguous; // 8-bit bool requires_grad_ : 1; bool pinned_memory_ : 1; // Existense of members bool has_device_ : 1; bool has_dtype_ : 1; bool has_layout_ : 1; bool has_requires_grad_ : 1; bool has_pinned_memory_ : 1; bool has_memory_format_ : 1; } The most important methods are:\n[[nodiscard]] TensorOptions device(Device device) const; [[nodiscard]] TensorOptions dtype(ScalarType dtype) const; [[nodiscard]] TensorOptions requires_grad(bool) const; Usage:\ntensor.options() returns an instance of TensorOptions that describes the tensor. opt.dtype(torch::kFloat64) has other properties remain the same as opt, only dtype changes to float64 or in C++, double. The .to(...) method of a tensor can take a TensorOptions instance as its only argument. For an exhaustive list of device and dtype, you may want to refer to:\nhttps://github.com/pytorch/pytorch/blob/main/torch/csrc/api/include/torch/types.h https://github.com/pytorch/pytorch/blob/main/c10/core/DeviceType.h Debug layer by layer A CUDA extension is roughly split into 4 parts, from the bottom to the top namely:\nCUDA kernel C++ wrapper data passed from Python (PyTorch) to C++ Python wrapper CUDA kernel Debugging CUDA kernel is a very very difficult problem and we shall not discuss it here.\nC++ wrapper The first thing I want to hint you is that do not dereference a pointer pointing to device in host functions. You should always mark device pointers with a d_ prefix in variable names, or wrap it with thrust::device_ptr.\nprintf, std::cout or gdb will assist you in the journey.\ndata passed from Python (PyTorch) to C++ Refer to Pybind11 docs and try to answer these questions:\nHow various Python types are represented in Pybind11 API; How to properly configure the function prototype in Pybind11? Python Wrapper Ask LLMs. LLMs know python much better than I do.\nWhat to Reference To my knowledge, the PyTorch C++ documentation is very old. Many things in the source code are not documented there.\nIt is a better choice to just search in the PyTorch github repo, and read the comments and source code.\n","date":"2 October, 2025","id":10,"permalink":"/english-post/torch-cuda-ext/","summary":"Intro: PyTorch is a Deep Learning Operating System.","tags":"deep-learning cuda torch","title":"Notes on Writing PyTorch CUDA Extensions"},{"content":"注：本文用LLM辅助写作的地方主要在：我认为LLM比我理解的更好的地方，会用LLM的表述代替。\n问题设定 需要计算Graph Transformer中的Attention。在此我们忽略multihead-attention，考虑基本的single-head attention.\n此外，我们的attention mask(邻接矩阵A)是非结构化稀疏的。如果你的attention mask是结构化稀疏的，比如blockwise等可以被代码表示的稀疏pattern，你应该使用flash attention的varlen变体, 或者flex attention等attention编译器。\nNotation n: 图节点数，规模为 1k~1M\rnnz: 图边数（稀疏矩阵非零元素数，Num NonZero）\r规模为10n~1000n\rq, k, v: (n, d)\rA: (n, n), binary, 高度稀疏 计算公式 softmax((q @ k.transpose()) * A) @ V 其中，@ 表示矩阵乘法，*表示element-wise乘法。\n实现：naive version 最简单的就是把A给materialize出来，然后用作attention_mask。问题是A是$n^2$的，显存不够用。 A用COO方式存储，大小(2,nnz)，然后先把每条边的qk-pair取出来得到(nnz,d)，然后再做reduce和scatter, 和V相乘。 Reformulate 我们引入三个算子:\nSDDMM (Sampled Dense-Dense MatMul) A (m, k), B (k, n), 稠密 M (n, n)， 稀疏 SDDMM(A, B, M) 定义为： for i, j in product(range(n), range(n)):\rif M[i, j] != 0:\rout[i, j] = dot(A[i,:], B[:,j])\relse:\rout[i, j] = 0 Sparse Softmax: 在稀疏矩阵上按行softmax SpMM：sparse A @ dense B 此时我们的计算公式就可以重新写成:\nout = SpMM(Softmax(SDDMM(Q, K_T, A)), V) 以此我们引出下面的实现\n实现：DGL Graph Transformer in a Nutshell — DGL 2.2.1 documentation\n对于稠密的q,k,v和CSR存储的A，通过如下代码计算attention：\nattn = dglsp.bsddmm(A, q, k.transpose(1, 0)) # (sparse) [N, N, nh] # Sparse softmax by default applies on the last sparse dimension. attn = attn.softmax() # (sparse) [N, N, nh] out = dglsp.bspmm(attn, v) # [N, dh, nh] 算子在DGL库内部由CUDA实现。看DGL的代码可以发现，其实现利用了稀疏性，但是存在以下优化点\n进行的是最直观的并行，没有进行充分的优化 各个kernel分开执行，没有融合 没有利用tensor core 实现：FlashSparse https://github.com/ParCIS/FlashSparse/tree/main/eva\n主题：对SDDMM,SpMM进行优化；尝试在稀疏输入中以最小粒度利用tensor core\n基于一个基本观察：A × B = C ⟹ (Bᵀ × Aᵀ)ᵀ = C，发明了交换与转置MMA计算策略：目标是将稀疏矩阵划分所依赖的MMA指令维度，从较大的m维（值为16）切换到较小的n维（值为8）。标准张量核心MMA指令的形状为m16n8k8（FP16精度下，m=16, n=8, k=8）。这使得稀疏矩阵 A 可被划分为8×1的向量，相比之前工作中使用的16×1向量，计算冗余减少了约50%。\n矩阵格式：本算法发明了ME-BCRS格式，基本想法是在一个8x1的block中，如果有一个元素是非零的，那么就把这整个block都当成非零的存下来。 空间开销维持在O(n+nnz)，常数比较小，远没有达到head_dim的量级。 矩阵格式转换时间开销 (CSR -\u0026gt; ME-BCRS)：由于是一次性开销，相对整个模型推理时间几乎可以忽略。 FlashSparse的SpMM算法（C = A × B） 阶段1：转置访问与加载\n块形状：算法将 A 划分为8×8的稀疏TC块（FP16精度下），将 B 划分为8×16的稠密TC块。 稀疏块 A 加载：线程从全局内存（以行优先的ME-BCRS格式存储）加载8×8稀疏TC块 A，并在寄存器中将其转置为 Aᵀ，作为右操作数。 稠密块 B 加载：线程从全局内存（行优先）加载8×16稠密TC块 B，并在寄存器中将其转置为 Bᵀ，作为左操作数。 合并访问：通过重新排列线程访问的列，确保所需数据对齐形成2×2的FP16元素块，从而使内存事务匹配GPU最小32字节的事务粒度，实现合并访问，减少50%的访存开销。 阶段2：交换与转置计算\n在张量核心上执行MMA指令：Bᵀ × Aᵀ。\nBᵀ 作为左操作数（m=16, k=8）。 Aᵀ 作为右操作数（k=8, n=8）。 结果为转置后的输出块 Cᵀ（尺寸为16×8），存储在寄存器中。 阶段3：转置输出\n寄存器中的 Cᵀ 必须在写回全局内存前转置回 C。由于寄存器中 Cᵀ 的数据布局与加载 B 时所需的 Bᵀ 布局完全相同，因此可复用为加载 B 设计的高效合并写回策略，将结果写入全局内存。\nFlashSparse的SDDMM算法（C = M ⊙ (AB)） 块形状：FlashSparse将稀疏输出矩阵 C 划分为8×16的稀疏TC块。两个稠密输入矩阵（按论文图8中的记号，记为 A_dense 和 B_dense，满足 C_sparse = A_dense × B_dense）分别以稠密TC块形式加载：A_dense 为8×8（行优先），B_dense 为8×16（列优先）。 转置计算的数据对齐：SDDMM中稠密输入矩阵 A（行优先）和 B（列优先）的数据布局，恰好满足“交换与转置MMA计算”（Bᵀ × Aᵀ）的要求。 转置计算：\n稠密输入 B 被转置为 Bᵀ（尺寸16×8），作为左操作数。 稠密输入 A 被转置为 Aᵀ（尺寸8×8），作为右操作数。 计算 Bᵀ × Aᵀ 得到稠密结果 C_denseᵀ。 用M矩阵进行element-wise product，从C_dense 得到C_sparse 实测: 未测试\n实现：DF-GNN https://github.com/paoxiaode/DF-GNN\n主题：block/warp调度和算子融合\n由于我主要看了tiling部分的算法（适用于大图和邻居数不确定的图，仅forward），所以主要介绍这部分。\n使用的矩阵格式是CSR，不需要做额外的格式转换\n算法流程 Launch Kernel on Grid: (n × h)\r↓\rEach Block → (rid, hid): one node, one head\r↓\rLoad Q[rid, hid, :] → s_Q[f] (shm)\r↓\rFor each tile of neighbors (size ≤ 32):\r- Load neighbor IDs from indices[]\r- Compute Q · K^T (dot product using s_Q and K[dst])\r- Reduce in warp → store in neigh_nodes_weight[eid]\r- Find max(weight) in current tile → weightMax\r- Adjust partial_sum and acc with exp(old_max - new_max)\r- Compute exp(weight - weightMax) and accumulate acc += exp_w * V[]\r- Accumulate partial_sum += exp_w\r- Update weightMax_old\r↓\rFinal normalization: out_feat = acc / partial_sum\r↓\rWrite back to global memory 主要就是通过合理安排GPU资源（threadblock, thread）和计算任务的mapping，实现在一个kernel 内负载相对均衡的完成任务。\n实测: 代码方面：开源的代码有比较多的bug，包括了data race, 指针运算错误等等\n修复后：\n在常用工作范围内，forward速度达到DGL实现的2.5x ~ 3x\n精度：和DGL实现对比，MAE在1e-8 ~ 1e-9量级，差距可以忽略不计\nF3S https://github.com/HPCForge/Fused3S/tree/main/scripts 主题：算子融合+混合精度+利用tensor core\n其主要思路还是类似FlashSparse，但是通过算子融合达到了更高的效率（访存开销，kernel launch开销更小）。混合精度算是一种tradeoff。\n仅有forward的实现 F3S也使用了自定义的矩阵格式BSB，基本想法是在一个16x1的block中，如果有一个元素是非零的，那么就把这整个block都当成非零的存下来。 优化的一点在于，block内是否为0被压缩到一个bit中，每个16x8block以uint128保存，充分利用了attention中adj只能为0/1的特点 和flashsparse相比不足的一点在16x1粒度更大，多余计算更多，也是本工作没考虑到的一点 空间开销：O(n+nnz)，但是常数会更大一些 矩阵格式转换时间开销 (CSR -\u0026gt; BSB)：一次性开销，暂时忽略。 算法流程： 划分行块：\n将 Q 按行划分为 $T_r = \\lceil N / r \\rceil$ 个块 $\\{Q_1, ..., Q_{T_r}\\}$，每个大小为 $r \\times d$。 将输出 O 同样划分为 $T_r$ 个块 $\\{O_1, ..., O_{T_r}\\}$，每个大小为 $r \\times d$。 对每个行块索引 $i = 1$ 到 $T_r$（并行处理）：\n初始化\n$m_o \\leftarrow -\\infty \\in \\mathbb{R}^r$（行最大值） $l_o \\leftarrow 0 \\in \\mathbb{R}^r$（行 softmax 累加和） $O_i \\leftarrow 0 \\in \\mathbb{R}^{r \\times d}$（输出块，fp32） 加载数据：\n将 $Q_i$ 从全局内存（HBM）加载到共享内存（SMEM）。 计算当前行窗口（RW）包含的 TCB 数量：$t = \\text{tro}[i+1] - \\text{tro}[i]$。 通过 sptd 获取当前 RW 对应的原始列索引向量 $c$。 从 $K$ 和 $V$ 中按索引 $c$ gather 出对应的行，得到 $\\hat{K}, \\hat{V} \\in \\mathbb{R}^{t \\cdot c \\times d}$。 划分 warp 块：\n将 $\\hat{K}$ 划分为 $T_c = \\lceil t / W \\rceil$ 个块 $\\{\\hat{K}_1, ..., \\hat{K}_{T_c}\\}$，每个大小为 $Wc \\times d$。 将 $\\hat{V}$ 同样划分为 $T_c$ 个块 $\\{\\hat{V}_1, ..., \\hat{V}_{T_c}\\}$，每个大小为 $Wc \\times d$。 对每个 warp 块索引 $j = 1$ 到 $T_c$：\nSDDMM：\n调用 $\\text{TBGemm}(Q_i, \\hat{K}_j^T, 0)$，计算中间得分块 $S_i \\in \\mathbb{R}^{r \\times c}$（fp32）。 用 BSB 中对应 TCB 的 bitmap 对 $S_i$ 进行掩码（非零位置保留，其余置 0）。 Online Softmax：\n计算当前块行最大值：$m_i = \\max(m_o, \\text{rowmax}(S_i))$。 计算指数：$E_i = \\exp(S_i - m_i)$。 更新累加和：$l_o = \\text{diag}(\\exp(m_o - m_i)) \\cdot l_o + \\text{rowsum}(E_i)$。 将 $E_i$ 转为 fp16，存入 SMEM。 SpMM：\n对已有输出缩放：$O_i = \\text{diag}(\\exp(m_o - m_i)) \\cdot O_i$。 调用 $\\text{TBGemm}(E_i, \\hat{V}_j, O_i)$，将结果累加回 $O_i$。 更新行最大值：$m_o = m_i$。 最终归一化并写回：\n对输出块归一化：$O_i = \\text{diag}(l_o)^{-1} \\cdot O_i$。 将 $O_i$ 写回全局内存（HBM）。 Subroutine: TBGemm 输入:\n矩阵块 $A \\in \\mathbb{R}^{m \\times K}$ (位于 SMEM，共享内存) 矩阵块 $B \\in \\mathbb{R}^{K \\times P}$ (位于 HBM，全局内存) 累加项 $D \\in \\mathbb{R}^{m \\times P}$ (位于 SMEM，共享内存) 输出:\n结果矩阵 $C = A B + D \\in \\mathbb{R}^{m \\times P}$ 流程:\n切分块 (Tiling): 将输入矩阵 $A$, $B$, $D$ 按照 Tensor Core 的硬件 Tile 尺寸（例如 $16 \\times 8 \\times 16$）切分为对应的子块。\n并行迭代 (Output Tiles): 对结果矩阵 $C$ 的每个输出 Tile (通常由一个 Warp 或一个 Thread Block 计算):\n加载累加项 D: 从 SMEM 中加载 $D$ 对应的子块到线程的寄存器中，作为初始累加值 $C$. 内积迭代 (K-Tiles): 对 $K$ 维度的每个 $k$-tile 进行迭代累加:\n加载 A: 从 SMEM 中加载矩阵 $A$ 对应的 $A_{\\text{tile}}$ 子块。 加载 B: 从 HBM 中直接加载矩阵 $B$ 对应的 $B_{\\text{tile}}$ 子块。 执行 MMA 指令: 调用硬件支持的 PTX mma 指令（Matrix Multiply-Accumulate），执行计算并累加： $$C \\leftarrow A_{\\text{tile}} \\cdot B_{\\text{tile}} + C$$ 返回: 最终得到结果 $C$。\n实测: 代码方面：在矩阵格式转换部分有bug，已联系作者修复；开源代码没有multihead，需要自己实现。\n速度达到DGL实现的3x(相对稀疏) 到5x (相对稠密）\n限制：n % 16 == 0，因为需要分割成8x16的block\n精度：和DGL实现对比，MAE在3e-5~1e-4 量级，很可能需要通过对模型进行end2end测试来确定是否适合使用。\n","date":"2 October, 2025","id":11,"permalink":"/posts/gnn-optim/","summary":"注：本文用LLM辅助写作的地方主要在：我认为LLM比我理解的更好的地方，会用LLM的表述代替。","tags":"deep-learning cuda","title":"近期GNN Attention算子优化工作速览"},{"content":"Background When training models with PyTorch, out-of-memory (OOM) errors are common, necessitating GPU memory optimization. When simple methods (like reducing batch size) no longer work, analyzing the memory footprint of the model itself may be required.\nAt this point, you might come across this documentation, which teaches you how to record a memory snapshot and visualize it on this website.\nHowever, there’s a major issue: the website is extremely laggy. If your model is small, with snapshots of just a few MB, the performance is somewhat tolerable. But if your model is large, with snapshots reaching tens or even hundreds of MB, the website becomes unbearably slow, with frame rates dropping as low as 2–3 frames per minute (this is not a typo).\nI looked into the website’s JavaScript code, and here’s what it primarily does:\nManually loads Python pickle files; Re-parses the raw data into graphical representations time the viewport changes, then renders it to the screen. This parsing logic is written in JavaScript. You can imagine the performance when it is executed each frame, operating on hundred-MB data.\nInspiration My current work includes optimizing a deep learning model whose optimization is under-explored compared to LLM. I encountered this issue while working with a snapshot of a model with several billion parameters.\nWhy not just use existing LLM infrastructure instead of optimizing manually? Long story short, this model was custom-designed by a researcher and contains many modules completely different from standard LLMs. It seems like nowadays, everyone assumes deep learning is all about LLMs — so much so that even some tech leads believe LLM infrastructure can be easily adapted to other models… but I digress. I originally wrote a simple script to parse the snapshot’s contents, hoping to identify memory allocation issues in the model. But after working with this model for a month, I finally had enough. That’s how this project — SnapViewer — came to be.\nTL;DR​​: The graphical data from the memory snapshot is parsed and represented as a massive triangle mesh, leveraging existing rendering libraries to handle mesh rendering efficiently.\nHere’s a snapshot of over 100 MB running smoothly on my integrated GPU:\nImplementation The reference implementation The snapshot format is partially documented in the record_memory_history function\u0026rsquo;s docstring. However, this documentation is incomplete — likely because later updates weren’t reflected in the docstring.\nThe actual parsing of the snapshot into a dictionary happens here.\nThis script converts the allocator trace into a memory timeline, which is then passed to the web viewer’s JS code. The JS code further transforms this into polygons (representing allocations) for visualization. Each polygon corresponds to an allocation, storing details like size and callstack. Implementation: Snapshot (De)serialize Initial implementation This part is impelmented in Python since I need to deal with Python-native data structures. I simply convert the dict to a json file.\nOptimizations Raw JSON is too large on disk → compress it in-memory (Python zipfile) before writing. During visualization, read the ZIP from disk (Rust zip crate) and decompress in-memory. Tradeoffs This approach causes a temporary memory spike during JSON parsing but avoids persistent high memory usage. Also leverages Rust’s serde-json (since Rust’s serde-pickle is incomplete and can’t handle recursive structures). Implementation: Rendering \u0026amp; Interaction​​ This part is implemented in Rust.\nRendering Since allocation data remains static during visualization, all allocations are combined into a single large mesh and sent to the GPU once.\n​Library Used​​: three-d\nProvides good mesh abstraction. Supports one-time GPU upload (no per-frame CPU→GPU transfers). Handles mouse/keyboard events. ​World-to-Window Coordinate Conversion​​ ​Step 1​​: Convert window coordinates to world coordinates (scale + window center offset). ​​Step 2​​: Convert world coordinates to memory positions (predefined scaling). UI \u0026amp; Interaction Features​ Memory Scale Markers​​ Dynamically adjust the number and precision of markers based on screen visibility. Keep markers at consistent screen positions while moving/zooming. Pan \u0026amp; Zoom​​ Track the original scale (1/zoom). Update to the new zoom level and compute the ratio between old and new scales. Adjust the screen center position based on the mouse’s invariant world position. Implementation: Query After using this tool at work for around a week, I find myself frequently needing to search in the memory snapshot, especially:\nFind all allocations which is alive at a specific timestamp Find all allocations whose call stack has a specific substring Preferablly the allocations should be sorted by allocation size in descending order My first thought was to build a simple REPL and a simple command parser, and map each command to a specific query function.\nHowever, after having listed out all the functionalities I want, I found it to be a subset of database query, especially SQL.\nSo I decided not to reinvent wheels: I just connect to a in-memory SQLite database. Interfacing user is simple: read user input, let SQLite execute it and format the output to human-readable format.\nIf you’ve struggled with PyTorch memory snapshots, check it out! Contributions \u0026amp; feedback welcome. ⭐\n","date":"1 October, 2025","id":12,"permalink":"/english-post/snapviewer/","summary":"When training models with PyTorch, out-of-memory (OOM) errors are common, necessitating GPU memory optimization. When simple methods (like reducing batch size) no longer work, analyzing the memory footprint of the model itself may be required.","tags":"torch deep-learning rust","title":"SnapViewer: Faster PyTorch Memory Allocation Viewer"},{"content":"实验设定放在最后。\n个人评论 不少模型背出了书名《牵丝戏》(未联网), 说明这首歌的知名度确实挺高的. Kimi 继续稳定发挥, 可以说是本土化做的最好的模型之一. 是苏老师魔改的MuonClip发力了, 还是Kimi的数据团队洗的中文数据最好? 这个我就不得而知了. GLM 总是倾向于 详细解释 , 而Kimi更愿意 带着情感和理解重述. Grok的中文理解能力疑似烂得有点离谱，后续使用Grok可能需要尽量用英文沟通. LongCat和Qwen的的哲学含量比较高, 然而我不懂哲学不好评价. 有意思的事他们还一同主动附上了\u0026quot;现代解读\u0026quot;. Claude Sonnet 4.5 这是一个凄美动人的志怪故事，蕴含着深刻的人生哲思。让我为你解析其中的层次：\n故事梗概 雪夜荒寺中，\u0026ldquo;我\u0026quot;遇见一位白发苍苍的傀儡艺人。老翁毕生痴迷傀儡技艺，终身漂泊，唯有一具精美木偶相伴。应邀表演后，老翁却迁怒于木偶，认为是它导致自己穷困潦倒，愤而将其投入火中。火光中，木偶如活人般起身作揖告别，含泪一笑化为灰烬。老翁顿悟，哭喊\u0026quot;暖矣，孤矣\u0026rdquo;。\n深层寓意 1. 艺术与生存的悖论 老翁将一生献给傀儡艺术，却落得贫寒孤苦。这是许多艺术追求者的宿命——精神富足与物质匮乏的尖锐矛盾。他责怪木偶\u0026quot;误\u0026quot;了自己，实际是对命运的质问。\n2. 陪伴与执念的双重性 木偶既是老翁的精神寄托，也是他孤独的见证。\u0026ldquo;居无所行无侣，所伴唯一傀儡木偶\u0026rdquo;——这具木偶填补了他生命的空白，却也映照出他的孤绝。\n3. 木偶显灵的象征 火中木偶\u0026quot;如生人\u0026quot;般作揖告别，这个超自然场景有多重解读：\n艺术赋予的灵性：匠心独运的造物通了人性 情感投射的具现：老翁数十年的情感终于得到回应 诀别的仪式感：一生羁绊在此刻完成了最后的对话 4. \u0026ldquo;暖矣，孤矣\u0026quot;的双关 这四个字是全文的精髓：\n暖矣：身体得到了温暖（火焰），冬衣之忧暂解 孤矣：唯一的伴侣已灭，从此真正形单影只 物质与精神、温度与温情的对立统一 悲剧内核 故事的悲剧性在于：老翁为了眼前的\u0026quot;暖\u0026rdquo;（生存），毁掉了一生的\u0026quot;伴\u0026quot;（意义）。当木偶含泪一笑消失时，他才明白自己失去了什么——不是累赘，而是生命中唯一懂他的\u0026quot;人\u0026quot;。\n这个故事借志怪之笔，写尽了艺术家的执着与困顿，写尽了人在贫寒与孤独中的挣扎，更写出了那种\u0026quot;清醒得太晚\u0026quot;的追悔莫及。\nGrok Grok 三次把 \u0026ldquo;余少\u0026rdquo; 认成了一个人名🤣, 后续内容不堪入目, 这里跳过.\nKimi K2 这是一个寓言式的志怪故事，表面讲“遇鬼”，实则讲人一生的执念、孤独与顿悟。它用极冷的雪夜、极暖的火焰，演了一出“人焚傀儡，傀儡成人”的反向悲剧——不是人抛弃了傀儡，而是傀儡终于挣脱了人。\n逐句拆解 “余少能视鬼，尝于雪夜野寺逢一提傀儡翁……”\n“我”从小能见鬼，雪夜荒寺，撞见一个白发破烂的老木偶师，手里提着一只制作极精、宛如少女、眼角绘泪的木偶。\n——鬼不一定是亡魂，也可能是执念的化身。老翁本身就是“活鬼”，被技艺与孤独啃噬得只剩空壳。\n“翁自述：少时好观牵丝戏……所伴唯一傀儡木偶。”\n老翁一生只做一件事：演傀儡戏。\n“以物象人，自得其乐”——他把人形寄托在木偶里，反而把真人世界过成了空壳。\n“漂泊终生，居无所行无侣”——技艺成了诅咒：越专注，越被常人世界驱逐。\n“演剧于三尺红绵之上……虽妆绘悲容而婉媚绝伦。”\n这是全篇最暖也最幻灭的一幕：\n雪夜、破庙、篝火、红布为台； 老翁用盘铃伴奏，牵丝起舞； 木偶“顾盼神飞”，泪妆却笑，哀极而艳。\n——傀儡比人更像人，因为它被赋予了“戏”的灵魂；而老翁只剩技艺，没有生活。 “曲终，翁抱持木偶……遂忿然投偶入火。”\n戏演完了，老翁突然恨透了自己的命：\n“我穷到买不起冬衣，全因为你！”——他把一生失败归咎于最忠实的伴侣。\n这不是迁怒，而是绝望者不敢恨自己，只能恨镜子。\n“忽见火中木偶婉转而起……一笑迸散，没于篝焰。”\n全篇唯一“鬼证”：木偶在火中起身、作揖、告别、一笑灰飞。\n——它终于成了“人”：会哭、会笑、会拜别；而老翁才露出真正的鬼相——空有人形，无人之心。\n“翁顿悟，掩面嚎啕，曰：暖矣，孤矣。”\n火灭天明，老翁第一次感到温度，却也第一次承认孤独。\n“暖矣”——火给了他片刻体温；\n“孤矣”——烧掉的是傀儡，也是他自己最后的倒影。\n顿悟即崩溃：他亲手杀掉了唯一爱他、陪他、懂他的“人”。\n故事内核 技艺与执念\n老翁把“人”活成了“工具”，把“工具”活成了“人”；当工具终于像人时，人已经不堪为人。\n孤独的双重悲剧\n第一层：世人抛弃他，他只能与木偶相依为命； 第二层：他抛弃木偶，等于亲手处决了世界上最后一个愿意陪伴他的灵魂。 傀儡的复仇\n木偶最后一笑，是宽恕也是永诀：\n“你毁我，我终得自由；你留世，永无归处。” 一句话总结 人把孤独雕成木偶，木偶在火里成了人，人却在火外，永远成了木偶。\nLongCat 这个故事名为《牵丝戏》，通过一个雪夜邂逅、火中诀别的凄美叙事，探讨了执念与自由、热爱与代价、孤独的温暖与冰冷等深刻主题。以下从多个维度解析：\n一、角色与象征 提傀儡翁\n技艺与执念的化身：他以傀儡为业，晚年仍沉浸其中，体现“耽于技”的专注，也暗示艺术或热爱可能成为生命的双刃剑——既赋予意义，也可能成为束缚。 代际困境：鹤发褴褛的形象，暗喻“为艺所困”者的宿命：才华与生存压力间的冲突，社会对边缘手艺人的忽视。 木偶傀儡\n艺术的灵性：木偶“顾盼神飞”“一笑迸散”，象征艺术创作赋予的无生命体以魂魄，也暗示艺术理想被世俗压抑后仍存的孤高。 悲剧性自由：焚毁既是毁灭，也是解脱——木偶以自毁完成对艺术家的终极告别，揭示“执念”只有在牺牲中才能抵达升华。 “我”（余）\n旁观者与共情者：作为目睹全程的第三方，既同情傀儡翁的凄惨，又被迫理解“放下”的必要性，代表局外人对理想主义者的矛盾态度。 二、意象与隐喻 雪夜野寺\n极端封闭的环境，暗示艺术家与社会的割裂，也为后文“火中新生”的极端情感爆发铺垫。 篝火与焚偶\n毁灭与重生：火既是物理毁灭，也是精神解脱。木偶的“肃拜揖别”构成宗教般的仪式感，暗示艺术以自身死亡唤醒创作者对生命的觉悟。 “暖矣，孤矣”\n终极悖论：焚烧木偶取暖，实则是用爱的消亡抵御物质严寒，但灵魂陷入更深的孤独。揭示执着被剥离后的空虚与觉醒。 三、主题探讨 艺术的双刃剑\n傀儡翁的台词“皆傀儡误之”指向艺术家的常见困境：技艺是自我价值的依托，也可能成为逃避现实的牢笼。艺术真正成为生命的一部分，必须超越形式的依恋。 执念的终结\n木偶的“一笑迸散”并非控诉，而是完成艺术家的使命——以己之死点明：“爱”的本质是成全，而非占有。傀儡翁的嚎啕中既有悔恨，也有释然。 孤独的真谛\n故事最后，“暖”来自肉体温度的短暂留存，“孤”则是精神重负的释放。真正的孤独并非无人陪伴，而是曾经燃烧过所有执念后，面对虚无的平静。 四、文化语境 戏曲母题：故事中“盘铃傀儡戏”是中国传统傀儡戏的描写，但情节吸收了志怪文学的“物生灵气”“人鬼情未了”模式，将工匠精神与幽玄意境结合。 道家哲思：结尾与“焚琴煮鹤”“大器免成”的东方哲学呼应——极致的美常因残缺而永恒。 结语：牵丝戏的现代性 故事表面上是一场古典悲剧，实则揭示当代普遍命题：当热爱成为唯一寄托，如何避免被其吞噬？\n傀儡翁的“顿悟”并非超脱，而是背负记忆的重新开始——火中木偶的泪痕与笑容，成为他日后面对现实时最温暖的“冻痕”。真正的勇气，或许是在认清“孤矣”之后，依然能向火光靠近。\nQwen3-Max 这个故事题为《牵丝戏》，是一则充满古典志怪色彩与哲思意味的短篇寓言，融合了《聊斋志异》式的幽玄氛围与庄子式的物我之辩。全文虽短，却层层递进，蕴含多重意蕴，可从以下几个层面进行探讨与解释：\n一、表层叙事：一个雪夜奇遇 故事以第一人称“余”（叙述者）展开：年少能见鬼的“我”，在风雪交加之夜于荒寺偶遇一位白发褴褛的老翁。老翁手持一具制作精巧、神情哀婉如真人的木偶。二人围火夜话，老翁自述一生痴迷傀儡戏，却因此漂泊无依，终至贫寒孤苦。他既爱木偶如命，又怨其误己一生。情绪激荡之下，愤而将木偶投入火中。然木偶竟于火中起身，向翁作揖告别，含笑化为灰烬。老翁顿悟，嚎啕“暖矣，孤矣”。\n这一情节看似奇幻，实则暗藏深意。\n二、核心意象解析 1. 傀儡（木偶）：执念的化身 木偶不仅是老翁的谋生工具，更是他一生情感、理想与孤独的投射。其“绘珠泪盈睫，惹人见怜”，实为老翁内心悲苦的外化。他“以物象人自得其乐”，说明木偶早已超越器物，成为他精神世界的唯一伴侣，甚至是他“自我”的延伸。\n然而，正因这份执念，他拒绝融入世俗生活，甘于漂泊，终致“冬衣难置，一贫至此”。于是他将人生不幸归咎于傀儡——实则是归咎于自己的选择与执迷。\n2. 焚偶：毁灭与解脱的双重仪式 老翁“忿然投偶入火”，表面是泄愤，深层却是对执念的暴力割舍。但木偶并未被动毁灭，反而“婉转而起，肃拜揖别”，以主动的姿态完成告别。这一超现实场景暗示：真正的执念不在木偶，而在人心。木偶本无罪，它只是映照人心的镜子。它的“一笑迸散”，是执念的自我消解，亦是对老翁的慈悲告别。\n3. “暖矣，孤矣”：顿悟的悖论 火燃至天明，老翁嚎啕：“暖矣，孤矣。”此句极富张力：\n“暖矣”：火带来物理温暖，亦象征执念焚尽后的精神释然； “孤矣”：木偶既去，世上再无理解他、陪伴他的存在，孤独赤裸裸地显现。 这并非单纯的悲伤，而是在失去中照见真实——他一生以为傀儡是羁绊，实则是唯一的情感依托；焚偶看似解脱，却暴露了更深的孤独。这种“顿悟”充满存在主义式的悲凉：人终究是孤独的，而我们所依恋之物，或许正是我们对抗虚无的唯一屏障。\n三、哲学与美学意蕴 1. 庄周梦蝶式的物我之辩 故事暗合道家“物我两忘”之思。老翁与木偶，孰为主？孰为客？木偶“姿若生人”，老翁“以物象人”，界限早已模糊。当木偶在火中行礼告别，仿佛它才是有灵的一方，而老翁反成执迷不悟的“傀儡”。这颠覆了主客关系，质问：究竟是人在操纵傀儡，还是执念在操纵人？\n2. “牵丝戏”的隐喻 “牵丝戏”即提线木偶戏，丝线象征命运、欲望或执念。老翁一生被“丝”所牵——对艺术的痴迷、对完美的追求、对世俗的疏离。他以为自己是操偶者，实则自己亦是被无形之丝牵引的傀儡。焚偶，是斩断丝线的尝试，但“孤矣”说明：斩断之后，并非自由，而是直面存在的荒凉。\n3. 悲悯与美的极致 木偶“绘珠泪盈睫”“婉媚绝伦”，其美在于“悲容”中的生命力。它的焚毁不是悲剧的终结，而是美的升华——在毁灭中完成最后一次表演，以“一笑”告别，将悲转化为庄严的仪式。这体现了中国古典美学中“哀而不伤”“以悲为美”的传统。\n四、现代解读：关于执念与存在的寓言 在当代语境下，这个故事可被理解为对“执念”的深刻反思：\n我们是否也如老翁，将某物（事业、爱情、理想、身份）视为生命全部，却在失去时怨其误我？ 当我们试图“焚毁”执念以求解脱，是否反而暴露了内心无法填补的空洞？ 真正的孤独，不是无人相伴，而是意识到：我们所爱之物，或许只是我们自身的倒影。 而木偶的“主动告别”，则提供了一种超越性的可能：执念若能被温柔地放下，而非暴力摧毁，或许能留下一丝暖意，而非只剩孤寒。\n结语 《牵丝戏》以寥寥数百字，构建了一个雪夜、篝火、老翁与木偶的微型宇宙。它既是志怪，又是哲思；既是哀歌，又是顿悟。最终，“暖矣，孤矣”四字，道尽人间执迷与醒悟的永恒张力——我们焚尽所爱以求解脱，却在灰烬中发现，那曾被我们怨恨的，恰是唯一温暖过我们的存在。\nGemini 2.5 Flash 这是一个关于执念、孤独与顿悟的故事，充满了古典的志怪与浪漫色彩。\n主要角色与背景 “余” (叙述者)： 一个能看见鬼魂的人，在雪夜的野寺中与老翁相遇，是故事的见证者。 “提傀儡翁” (老翁)： 一位白发苍苍、衣衫褴褛的傀儡艺人。他的一生都献给了牵丝戏（木偶戏），但最终却因此陷入极度的贫困与孤独。 “木偶”： 老翁唯一的伴侣，制作得极其精美，宛如娇女，绘有珠泪盈睫，是一个寄托了老翁全部心血和情感的艺术品。 情节发展与深层含义 相逢与自述：\n在雪夜的野寺，叙述者与老翁相伴取暖。老翁自述年轻时迷恋牵丝戏，并将此作为终生职业，“以物象人自得其乐”（从木偶身上寄托人的情感和生活乐趣）。 然而，这份执着却导致他**“漂泊终生，居无所行无侣”，唯一的陪伴就是这个木偶。这表明老翁将生命的全部热情和时间都投入到了艺术中，却因此失去了正常的生活和人际关系，最终陷入极度的孤独**。 傀儡戏与情感爆发：\n叙述者请求老翁表演。在**“三尺红绵之上”，木偶被赋予了生命，“顾盼神飞，虽妆绘悲容而婉媚绝伦”。这证明老翁技艺高超，他赋予木偶的不仅是动作，还有深沉的人性与美**。 戏曲结束后，老翁的情绪爆发了。他先是**“稍作欢容”（为自己的艺术成就感到欣慰），但转瞬就被现实的悲苦和愤怒取代。他将自己一生的“落魄”（潦倒）归咎于这个木偶，认为它耗尽了自己的一切，一贫至此，不如烧毁，遂“忿然投偶入火”。这是老翁极度痛苦、怨怼和自我否定的体现。** 木偶的显灵与顿悟：\n最奇特的一幕发生了：叙述者阻止不及，木偶在火中**“婉转而起，肃拜揖别，姿若生人”**。它宛如一个有生命、有灵性的女子，向老翁和世界告别。 木偶的**“一笑迸散，没于篝焰”，象征着“美”的极盛与毁灭**，也暗示木偶承载的不仅是木材，更是老翁的**“精、气、神”**。这个木偶被老翁的艺术和生命力供养，在即将被毁灭时，灵性得以显现。 老翁目睹这一切，“顿悟，掩面嚎啕”。他终于明白，他焚毁的不是一个普通的木偶，而是他艺术的精华、生命的寄托，甚至是他的“伴侣”。 结尾的深沉叹息 “暖矣，孤矣。”\n这是老翁顿悟后最深刻的总结，也是故事的核心主题：\n“暖矣”： 身体因篝火而温暖，更重要的是，内心因看到了木偶的显灵、感受到了它真正的灵性而得到了一瞬间的慰藉或震撼，驱散了贫困和怨怼带来的冰冷。 “孤矣”： 火烧尽了，唯一能伴随他、承载他艺术和情感的“人”（木偶）也彻底消散了。他虽然得到了“暖”，却换来了无可挽回的、绝对的孤独。 这个故事通过一个奇幻的事件，表达了艺术家为追求极致而付出的沉重代价，以及艺术与现实、梦想与生存之间永恒的矛盾。老翁用一生心血供养了一个美丽的“生命”，最后又亲手毁灭了它，在毁灭的瞬间，他才真正理解了自己失去的是什么。\nGLM 4.6 这是一个非常优美而深刻的中文短篇故事，充满了象征意义和情感张力。下面我将为您详细解释这个故事。\n故事梗概 故事讲述了一个能看见鬼魂的“我”（余），在一个风雪交加的夜晚，在一座荒野寺庙里，遇到了一位操纵木偶（傀儡）的老翁。老翁一生漂泊，唯一的伴侣就是他亲手制作、技艺精湛的木偶。在“我”的请求下，老翁表演了一场牵丝傀儡戏，木偶栩栩如生，婉媚绝伦。然而，表演结束后，老翁却将自己一生的贫困潦倒归咎于木偶，一怒之下将它投入火中。就在“我”惊愕之际，那木偶竟在火中站起，向老翁恭敬行礼告别，脸上泪痕宛在，最后带着一个微笑，在火焰中化为灰烬。直到天明，火才熄灭。老翁此刻才幡然醒悟，痛哭道：“暖矣，孤矣。”（暖和了，却也孤独了。）\n分段解析 1. 开篇：相遇与铺垫 “余少能视鬼，尝于雪夜野寺逢一提傀儡翁，鹤发褴褛，唯持一木偶制作极精，宛如娇女，绘珠泪盈睫，惹人见怜。”\n“余少能视鬼”：这是故事的关键设定。它告诉读者，叙述者“我”拥有超自然的能力，能看到常人看不见的东西。这为结尾木偶显灵的情节埋下了伏笔，也让整个故事带上了奇幻色彩。 环境与人物：“雪夜野寺”营造了一个孤寂、寒冷、荒凉的氛围，这与老翁的内心世界和人生境遇相呼应。“鹤发褴褛”直接点出老翁的贫穷与衰老。 木偶的描写：“宛如娇女，绘珠泪盈睫”是点睛之笔。这不仅仅是一个木偶，它被赋予了生命和情感。那“珠泪”暗示了它不只是一个物件，它承载着老翁的心血、情感，甚至可能已经拥有了某种灵性。它“惹人见怜”，也预示了它最终的悲剧命运。 2. 中段：独白与表演 “时云彤雪狂，二人比肩向火，翁自述曰：少时好观牵丝戏\u0026hellip;所伴唯一傀儡木偶。”\n老翁的自白：这部分揭示了老翁的一生。他年轻时热爱傀儡戏，并以此为业，“以物象人自得其乐”。这表明他最初是出于纯粹的热爱，在艺术创作中找到了快乐和自我价值。 人生的悲剧：“奈何漂泊终生，居无所行无侣，所伴唯一傀儡木偶。”这句话道尽了他的辛酸。他将一生奉献给了这门艺术，但艺术却没能给他带来安稳的生活和人类的陪伴。他的世界，只剩下这个木偶。这是一种极致的孤独。 “翁且言且泣\u0026hellip;虽妆绘悲容而婉媚绝伦。”\n请求表演：“我”的“温言释之”和“恳请”代表了外界对他艺术的理解和尊重。这是他长久以来可能从未得到过的认可。 表演的升华：“木偶顾盼神飞，婉媚绝伦”，这时的木偶在老翁的操纵下，达到了艺术的巅峰。它不再是一个死物，而是充满了生命力。这表演是老翁一生技艺的凝结，也是他与木偶之间灵魂的共鸣。**“妆绘悲容”**更是绝妙，它既是木偶的妆容，也是老翁一生的写照，更是整个故事的悲剧底色。 3. 高潮：毁灭与显灵 “曲终，翁抱持木偶，稍作欢容，俄顷恨怒，曰：平生落魄，皆傀儡误之\u0026hellip;遂忿然投偶入火。”\n情感的极端转变：表演的成功带来了短暂的“欢容”，但随即被巨大的“恨怒”所取代。这是一种长期压抑后的爆发。他将自己一生的不幸——贫穷、孤独、漂泊——全部归咎于他最热爱、最依赖的傀儡。这是一种典型的**“迁怒”**，他无法反抗命运，只能摧毁他认为是“祸根”的象征物。他想通过毁灭木偶来结束自己的痛苦和执念。 毁灭的冲动：“不如焚”，烧掉它，或许就能结束这一切寒冷和贫困。这是一种绝望而极端的想法。 “吾止而未及，跌足叹惋。忽见火中木偶婉转而起，肃拜揖别，姿若生人，绘面泪痕宛然，一笑迸散，没于篝焰。火至天明方熄。”\n木偶的“人性”：这是故事的奇幻高潮和情感核心。因为“我”能视鬼，所以“我”看到了这超凡的一幕。木偶的行为充满了人性： “婉转而起，肃拜揖别”：它没有怨恨，反而向它的创造者和毁灭者行了一个恭敬的告别礼。这表明它理解老翁的痛苦，并以一种宽容和尊严的方式接受了自己的命运。 “绘面泪痕宛然”：它确实在流泪，为这段即将终结的关系，为老翁的痛苦，也为自己。 “一笑迸散”：这是最令人心碎的一幕。这个微笑，包含了释然、原谅、解脱，甚至可能是一丝欣慰——它用自己的毁灭，让老翁终于有机会直面自己的内心。它不是被烧死的，而是带着微笑，主动“没于篝焰”，完成了自己的使命。 “火至天明方熄”：这团火不寻常。它燃烧了很久，仿佛在为这段跨越人与物、生与死的情缘举行一场漫长而庄严的告别仪式，直到黎明到来，象征着旧的一切彻底结束，新的一天（新的领悟）即将开始。 4. 结尾：顿悟与悲鸣 “翁顿悟，掩面嚎啕，曰：暖矣，孤矣。”\n“顿悟”：老翁终于明白了。他烧掉的不是一个“误他”的物件，而是他一生唯一的伴侣、他艺术的结晶、他情感的寄托、他灵魂的一部分。他毁灭的，其实是他自己。 “暖矣，孤矣”：这是整个故事的点睛之笔，充满了无尽的悲凉和哲理。 “暖矣”：字面意思是身体暖和了。因为火很大，烧了一夜。但深层含义是，他通过这场毁灭性的行为，终于“烧掉”了自己一生的执念、怨恨和逃避。他不再将责任推给木偶，而是直面了赤裸裸的现实。这种清醒，虽然痛苦，却是一种精神上的“暖”，一种解脱。 “孤矣”：当他意识到木偶的真正价值时，他才发现自己亲手毁灭了它。他曾经“所伴唯一傀儡木偶”，现在，他什么都没有了。世界一片空白，只剩下彻骨的、永恒的孤独。这种孤独，比之前有木偶陪伴时的孤独要深刻和痛苦千万倍。 故事主题与象征意义 艺术与人生的悖论：老翁将一生奉献给艺术（傀儡戏），艺术给了他精神上的“自得其乐”，却也让他陷入了现实生活的“漂泊终生”和“居无所行无侣”。故事探讨了艺术追求与现实生存之间的巨大张力。\n执念与解脱：老翁对傀儡的“耽于”是一种执念，他将所有情感都倾注其上。当他将所有不幸归咎于它并试图毁灭它时，这是一种极端的、试图斩断执念的行为。最终，他确实“解脱”了（暖矣），但代价是失去了执念的对象，陷入了更深的虚无（孤矣）。\n陪伴与孤独：木偶既是老翁对抗孤独的伴侣，也是他孤独的根源。因为它，他无法融入正常社会；没有它，他则一无所有。故事深刻地揭示了人类内心深处对陪伴的渴望，以及失去陪伴后的终极孤独。\n物我合一，人偶同命：老翁和木偶已经超越了创造者与被创造者的关系，达到了“物我合一”的境界。木偶的悲容就是老翁的悲容，木偶的毁灭就是老翁自我毁灭的一部分。木偶在火中的优雅告别，更像是老翁灵魂中美好、宽容那一面的最后一次显现。\n爱与毁灭：老翁对木偶的感情是复杂的，既有深沉的爱（毕生心血），也有扭曲的恨（归咎于它）。这种极致的爱最终以一种毁灭性的方式表达出来，酿成了无法挽回的悲剧。这提醒我们，当爱变得偏执和充满怨恨时，可能会导致毁灭性的后果。\n总结来说，这个故事是一个关于爱、孤独、艺术、执念与失去的悲剧寓言。它通过一个奇幻的情节，探讨了人类内心最深刻的情感困境：我们有时会亲手毁掉自己最珍视的东西，直到失去后才幡然醒悟，但为时已晚，只留下无尽的温暖与彻骨的孤独交织的复杂感受。\nGPT 5 这个故事充满了象征与深刻的情感内涵，结合了孤独、艺术与悲剧的主题。以下是我对这个故事的解析：\n故事背景与人物：\n故事的主角是一位年长的傀儡艺人，他的生活非常孤独，身世贫困，伴随他的一直是他手中的木偶。木偶对他来说不仅是工作工具，还是唯一的“朋友”和“伴侣”。 他描述了自己年轻时的兴趣和技艺，但随着年纪的增长，他逐渐迷失在傀儡艺术的世界中，最终将其作为唯一的寄托和生计方式。 傀儡与孤独：\n傀儡作为故事中的核心元素，象征着人与人之间情感的断裂和孤独感。虽然傀儡非常精致，外表美丽，但它终究只是木头和线绳构成的机械之物，无法给予真实的情感回应。 艺人说到自己漂泊一生，孤身一人，木偶成为他生活中的唯一“伴侣”。他为木偶所迷，甚至将木偶当作替代人类情感的寄托。 艺术与悲剧：\n艺人热衷于制作与操控木偶，他的生活和艺术的激情交织在一起，然而随着时间流逝，生活的艰难让他对这份艺术产生了无奈与愤怒。 当他愤怒与绝望中将木偶投入火中，正是艺术与生活困境的极限体现。木偶的悲情和悲容成为他内心苦闷与绝望的投射。 木偶的复生与启示：\n木偶在火中竟然奇迹般复生，并如人般走向他告别。它似乎带有自我意识，回应了艺人内心的情感——这或许象征着艺术作品的超越性，它能触动人的灵魂，即便在创作背后是孤独和痛苦。 木偶的“死亡”与复生也是对艺人内心的一种反映，可能意味着他对自己艺术的认同与痛苦的纠葛。尽管他认为一切被生活所困，艺术和木偶本身却在某种程度上获得了超越，回归到一种自由、纯净的状态。 结局的象征：\n故事最后，艺人感受到了一种“暖”和“孤”的对比。“暖”可能象征着一种情感的温度、回暖，但紧接着的“孤”则表明，尽管木偶以某种方式展现了生命的象征，艺人依然无法摆脱深深的孤独与人生的无奈。 这是一个关于艺术、孤独和生命意义的反思：艺人虽然通过木偶艺术寻求陪伴与慰藉，但他最终仍然孤独一人，生活的艰难和失落无法通过艺术来完全抚平。 总结来说，故事通过一个傀儡艺人的悲剧人生，探讨了孤独、艺术创作的内心挣扎和对生活的感悟。木偶既是艺人的情感寄托，又是一种象征，它提醒人们，即使在最艰难的时刻，艺术也有可能给予某种慰藉，但生活的真谛与孤独感依然无法逃避。\n实验设定 作者: Vagary\nPrompt:\n余少能视鬼，尝于雪夜野寺逢一提傀儡翁，鹤发褴褛，唯持一木偶制作极精，宛如娇女，绘珠泪盈睫，惹人见怜。　时云彤雪狂，二人比肩向火，翁自述曰：少时好观牵丝戏，耽于盘铃傀儡之技，既年长，其志愈坚，遂以此为业，以物象人自得其乐。奈何漂泊终生，居无所行无侣，所伴唯一傀儡木偶。　翁且言且泣，余温言释之，恳其奏盘铃乐，作牵丝傀儡戏，演剧于三尺红绵之上，度曲咿嘤，木偶顾盼神飞，虽妆绘悲容而婉媚绝伦。曲终，翁抱持木偶，稍作欢容，俄顷恨怒，曰：平生落魄，皆傀儡误之，天寒，冬衣难置，一贫至此，不如焚。遂忿然投偶入火。吾止而未及，跌足叹惋。忽见火中木偶婉转而起，肃拜揖别，姿若生人，绘面泪痕宛然，一笑迸散，没于篝焰。 火至天明方熄。　翁顿悟，掩面嚎啕，曰：暖矣，孤矣。\n探讨并解释这个故事。\n","date":"22 July, 2025","id":13,"permalink":"/posts/story-qiansixi/","summary":"实验设定放在最后。","tags":"","title":"AI怎么解读《牵丝戏》的背景故事？"},{"content":"内存与速度性能问题排查 免责声明：我主要在 Windows 上使用最新的稳定版 Rust 工具链和 CPython 3.13 进行开发和测试。\n1. 背景与动机 SnapViewer 能够高效处理大型内存快照——例如，支持高达 500 MB 的压缩快照。然而，在处理 1.3 GB的snapshot的时，我发现了严重的内存和速度瓶颈：\n格式转换（pickle → 压缩 JSON）引发了约 30 GB 的内存峰值。 将压缩 JSON 加载到 Rust 数据结构中又引发了另一次约 30 GB 的内存激增。 频繁的 page fault 和强烈的磁盘 I/O（在任务管理器中观察到）导致应用程序响应迟缓，甚至频繁卡顿。为了解决这一问题，我们采用了 Profile-Guided Optimization（PGO，基于性能分析的优化）方法。\n2. Profile-Guided Optimization（PGO） PGO 需要通过实证分析来识别真正的热点。我首先使用 memory-stats crate 进行内存分析，在早期优化阶段进行轻量级检查。随后，我将数据加载流水线拆解为若干离散步骤：\n读取压缩文件（重度磁盘 I/O） 从压缩流中提取 JSON 字符串 将 JSON 反序列化为原生 Rust 数据结构 填充内存中的 SQLite 数据库以支持即席 SQL 查询 在 CPU 上构建三角网格（triangle mesh） 初始化渲染窗口（CPU-GPU 数据传输） 性能分析揭示了两个主要的内存问题：过度使用 clone 和多个中间数据结构。以下是我实施的优化措施。\n消除冗余的 Clone 在快速原型开发阶段，调用 .clone() 非常方便，但代价高昂。性能分析显示，克隆大型 Vec 显著加剧了内存峰值和 CPU 时间。\n首次尝试：将对 Vec\u0026lt;T\u0026gt; 的 clone() 改为借用的 \u0026amp;[T] 切片。但由于生命周期约束无法做到. 最终方案：改用 Arc\u0026lt;[T]\u0026gt;。尽管我并未使用多线程，但 Arc 满足了 PyO3 的要求，且在此场景中未观察到明显开销。 仅此一项改动就显著降低了内存使用, 降低了启动耗时。\n提前释放中间结构 构建三角网格涉及多个临时表示形式：\n原始分配缓冲区 三角形列表（顶点 + 面索引） CPU 端的网格结构 GPU 上传缓冲区 每个阶段都会保留其前驱数据直至作用域结束，从而推高了峰值内存占用。为及时释放这些中间数据，我们采取了以下措施：\n使用作用域块（scoped blocks）限制生命周期 对不再需要的缓冲区显式调用 drop() 经过这些调整，峰值内存大约减少了三分之一。\n3. 分片处理 JSON 反序列化 对包含超过 50,000 个条目的调用栈 JSON 进行反序列化时，内存使用急剧飙升。为缓解此问题：\n将 JSON 数据分片，每片最多包含 50,000 个条目。 独立反序列化每个分片。 合并所得到的Vec。 这种流式处理方法使每个分片的内存占用保持在较低水平，避免了之前的大规模单次分配。\n值得注意的是，serde_json::StreamDeserializer 是另一个值得尝试的选项。\n4. 重新设计快照格式 即使经过上述优化，调用栈数据仍然是内存中最大的组件——在 Rust 中和内存 SQLite 数据库中各存一份，造成重复。\n为消除冗余，我重新思考了每种表示形式的用途：\nRust 结构：用户点击时在屏幕上显示调用栈。 SQLite 数据库：支持即席 SQL 查询。 由于 SnapViewer 是单线程的，且可容忍偶尔的磁盘 I/O，我将快照拆分为两个文件：\nallocations.json：轻量级 JSON，包含分配时间戳和大小。 elements.db：SQLite 数据库，存储调用栈文本（按分配索引建立索引）。 这两个文件被一起压缩打包。运行时：\n解压快照。 将 allocations.json 加载到内存（占用很小）。 打开磁盘上的 elements.db。 用户点击时，通过 WHERE idx = \u0026lt;allocation_index\u0026gt; 查询 elements.db。 SQLite 高效的磁盘索引使这些查询非常迅速，对帧率几乎没有可感知的影响。\n重构转换脚本 我对快照转换脚本进行了如下更新：\n解析原始快照格式。 将调用栈批量插入内存 SQLite 数据库，然后将数据库转储为字节流。 将分配元数据序列化为 JSON。 将 JSON 与数据库字节流一起压缩。 虽然转换过程略慢，但生成的快照加载更快，且内存占用大幅降低。\n5. 成果与经验总结 经过这些优化，SnapViewer 实现了以下改进：\n不再因加载大型快照而触发 60+ GB 的内存峰值，因为我们完全不再将整个调用栈信息加载到内存中。 启动速度显著提升。 即使进行按需调用栈查询，渲染依然流畅。 我学到的经验：\n不要总是把所有数据都加载到内存中。当你耗尽物理内存时，虚拟内存交换系统的性能可能比你想象的还要差。 当你需要将大部分数据存储在磁盘上，同时智能地缓存部分数据到内存时，SQLite 是一个好的选择。它内置了经过工业验证的高效算法。 ","date":"7 June, 2025","id":14,"permalink":"/posts/snapviewer-3-zh/","summary":"免责声明：我主要在 Windows 上使用最新的稳定版 Rust 工具链和 CPython 3.13 进行开发和测试。","tags":"torch deep-learning rust","title":"Snapviewer Devlog #3: 性能优化"},{"content":"背景 在使用 PyTorch 训练模型时，内存不足（OOM）错误是很常见的，因此需要对 GPU 内存进行优化。当简单的方法（如减少batch size）不再有效时，就需要分析模型本身的内存占用情况。\n此时，你可能会看到这份文档，它教你如何记录内存快照并在网站上进行可视化。\n但是这里存在一个严重的问题：这个网站性能比较差。\n如果你的模型较小，快照只有几 MB，性能还可以接受。 但是如果你的模型很大，快照达到几十甚至上百 MB，网站就会变得极慢，帧率可能低至每分钟 2-3 帧（非笔误）。 我研究了网站的 JavaScript 代码，其主要功能是：\n手动加载 Python 的 pickle 文件； 每次视口发生变化时重新解析原始数据为图形表示，然后将其渲染到屏幕上。 这些解析逻辑用 JavaScript 编写，你可以想象一下每帧执行这些操作，处理上百 MB 数据要多久.\n灵感 我当前的工作包括优化一个非LLM的深度学习模型。在处理数十亿参数的模型所导出的显存snapshot时，我遇到了这个问题。\n为什么不用现有的 LLM 基础设施而选择手动优化？简单地说，这个模型是研究人员自定义设计的，其中包含许多与标准 LLM 完全不同的模块。现在似乎每个人都认为深度学习就只是关于 LLM——以至于一些技术负责人也认为 LLM 的基础设施可以很容易地适配到其他模型上……不过我有点跑题了。\n最初，我写了一个简单的脚本来解析快照内容，希望能发现模型中的内存分配问题。但是在一个月的工作中，我发现我还是需要一个带有GUI的可视化器, 于是我开发了 SnapViewer.\n简而言之：内存快照的图形数据被解析并呈现为一个巨大的三角形mesh，利用现有的渲染库来高效处理网格渲染。\n下面是一个 100 MB 以上的快照在我的集成显卡上流畅运行的截图：\n实现 参考实现 快照格式在 record_memory_history 函数的docstring中有部分记录。但这份文档并不完整, 可能是后续commit的人懒得更新docstring了.\n实际将快照解析为字典的过程发生在这里：\n该脚本将分配器跟踪转换为内存时间线，然后传递给网页查看器的 JS 代码。 JS 代码进一步将其转换为多边形（表示分配），用于可视化。每个多边形对应一个分配，存储大小和调用栈等细节。 实现：快照 (反)序列化 初始实现 我用 Python 实现这一部分，因为我需要处理 Python 原生数据结构。我只是简单地将字典转换为 JSON 文件。\n优化 原始 JSON 文件太大 → 在写入前进行内存压缩（Python zipfile）。 在可视化过程中，从磁盘读取 ZIP 文件（Rust zip crate），并在内存中解压缩。 权衡 这种方式在 JSON 解析过程中会导致短暂的内存峰值，但避免了持续的高内存使用。 利用 Rust 的 serde-json（因为 Rust 的 serde-pickle 功能不全，不能处理递归结构）。 实现：渲染与交互 这部分用 Rust 实现。\n渲染 由于分配数据在可视化过程中是静态的，所有分配被合并成一个大的三角形mesh，并一次性发送到 GPU。\n使用的库：three-d\n提供良好的网格抽象。 支持一次性上传到 GPU（无需每帧进行 CPU→GPU 传输）。 处理鼠标/键盘事件。 窗口到世界坐标转换 步骤 1：将窗口坐标转换为世界坐标（缩放 + 窗口中心偏移）。 步骤 2：将世界坐标转换为内存位置（预定义的缩放）。 UI \u0026amp; 交互功能 内存刻度标记 根据屏幕可见性动态调整标记的数量和精度。 保持标记在屏幕上的固定位置，即使移动或缩放。 移动 \u0026amp; 缩放 跟踪原始缩放比例（1/zoom）。 更新到新的缩放级别，并计算新旧比例之间的比值。 根据鼠标不变的世界位置，调整屏幕中心位置。 实现：查询 在工作中使用这个工具一周后，我发现自己经常需要搜索内存快照，尤其是：\n找到特定时间戳内所有存活的分配 找到调用栈中包含特定子字符串的所有分配 最好按照分配大小降序排列分配 我最初的想法是构建一个简单的 REPL 和一个简单的命令解析器，将每个命令映射到特定的查询函数。\n然而，在列出所有需要的功能后，我发现这其实是数据库查询的子集，尤其是 SQL。\n因此我决定不再造轮子：我只是连接到一个内存中的 SQLite 数据库。用户交互非常简单：读取用户输入，让 SQLite 执行，并将输出格式化为人可读的格式。\n如果你在使用 PyTorch 内存快照时遇到过困难，来看看吧！欢迎贡献和反馈。 ⭐\n","date":"6 June, 2025","id":15,"permalink":"/posts/snapviewer-zh/","summary":"在使用 PyTorch 训练模型时，内存不足（OOM）错误是很常见的，因此需要对 GPU 内存进行优化。当简单的方法（如减少batch size）不再有效时，就需要分析模型本身的内存占用情况。","tags":"torch deep-learning rust","title":"SnapViewer: 更快的PyTorch显存分配可视化"},{"content":"Lsm Tree 是一种内存-磁盘的层级式数据结构，常用于实现写多读少的存储引擎。\n这是我实现 Lsmkv 的时候记录的备注.\n组件 内存部分 磁盘部分 WAL 总体 初始化 需要 init flush thread。flush thread 的工作流程:\n等待 flush 信号量被 notify,获取一个 compact 信号量资源 启动一个 sstwriter,写入这个 memtable 一个 memtable 对一个 sst 等到写入 sst 写完之后,才进行: 从 frozen memtables、frozen memtable sizes 里面删除这个 memtable 从 wal 里面删除这个 memtable 对应的 wal update manifest Try Freeze 如果当前大小 \u0026gt; freeze size 那么就 freeze;进一步如果所有 frozen memtable 大小之和 \u0026gt; flush threshold,那么就 set flush signal。\n写操作 写 memtable 写 WAL try freeze 内存部分 Put 添加到 memtable; 更新 size。 size 不需要特别精确,只需要是一个大致的值即可。 Delete 添加一个 tomb 标记到 memtable Get 从 active memtable 中获取 从 new 到 old 遍历所有的 inactive memtable,获取。 磁盘部分 compact 信号量 二元信号量。\n需要 compact 的时候,添加资源 compact thread 开始 compact 的时候,消耗资源。 初始化 如果 auto compact 开启,初始化的时候需要 init compact thread:\nLevel 存储这个 level 所有文件对应的文件路径,装在 sst reader 里面\nGet (没有 delete, put) 从低到高,从新到旧,调用 sst 的 get 方法,获取 record。否则返回 none。\nInit Compact Thread Compact thread:\n等待 compact 信号量 依次查看每一层:如果这一层大小超过 threshold,就合并到下一层,否则就提前返回。 Compact 以 L0 -\u0026gt; L1 为例: 从前到后遍历所有的 kv-pair,同时维护:\nkeys_outdated 同一个 key,timetsamp 小于 oldest marker 的 kv pair 只需要保留一个。 keys_outdated 记录所有(出现过的,且 timestamp 小于 oldest marker)的 key L1 sst size 每达到一定值就关闭当前 sst,新开一个新的 sst。 更新 manifest。 SST writer 配置 max block size。\n每个 block 的开头一个 key 会添加到 index 中; 搜索这个 sst 的时候,会先对 index 进行二分查找; 在 block 之内采用线性搜索。 fpr,用于构建 bloom filter.\n写入 遍历所有的 kv pair: userkey(不含 timestamp)添加到 bloom filter; block 写入当前 kv; 如果当前 block 大小超过 max block size,就开启一个新的 block,然后写入对应的 index(内存) 将 index 和 bloom filter 写磁盘。 SST reader 查找: Get(key, timestamp) 查 bloom filter,如果不存在就返回。 将 index 整个载入内存中,进行二分查找,得到对应 key-timestamp 所在的区间。如果 out of bounds 就返回。 按照查找到的区间,读磁盘。 MVCC key 排布问题 struct Key bytes timestamp: u64 比较: key1 \u0026lt; key2:\nkey1.bytes \u0026lt; key2.bytes (字典序); 或者: key1.bytes == key2.bytes,而且 key1.timestamp \u0026gt; key2.timestamp 为什么这样比较? 在进行查询 Get(userkey, timestamp) 的时候,我们需要的是:\nuserkey 匹配 timestamp 小于查询的 timestamp,且尽可能大 因此,我们将\nuserkey 升序排序 timestamp 降序排序 在搜索 memtable(skiplist)的时候,或者对 index 进行二分查找的时候,就可以:\n直接使用 lower_bound,查找大于等于自己的第一个元素 如果 userkey 匹配,说明是 timestamp 小于当前 timestamp 的,timestamp 最大的记录,返回; 如果 userkey 不匹配,说明不存在 timestamp 小于当前 timestamp 的记录,返回(未找到)。 Transaction 数据结构 一个内存 tempmap,用来存储 transaction 已经写,但是未提交的内容。 创建的时候,从 tree 获取:\nstart timestamp,作为查询的 timestamp transaction id 然后写入 transaction start 到 WAL\nPut,Delete 写 tempmap,写 WAL\nGet 使用 start timestamp,先查 tempmap,再查 tree。\nCommit 从 tree 获取一个 commit timestamp; 写 WAL,记录 transaction id 和 commit timestamp。 在 replay 的时候,把 transaction id 和 commit timestamp 对应起来就可以知道 transaction 里面的 写操作 对应的 timestamp 调用 tree.active_memtable 的 API,将 transaction 的所有数据写入 tree 的 memtable。 WAL 看到 transaction start,先将 transaction 暂存到内存中:\n如果在 replay 结束之前看到了 transaction end,就将改动写入 tree 中(redo)。 否则放弃,视为没完成的事务(undo) 踩坑: Resource deadlock avoided (os error 35),可能是一个 thread 持有了自己的 joinhandle 并且 join 了自己;使用 maybe join 解决,即判断当前线程和 joinhandle 的线程是否一致,如果一致就不用 join。 死锁问题: wal 和 mem 都有锁,必须 按照同一顺序获取 才不会出现死锁。 Bloom filter 细节 本部分由 Deepseek 辅助写作\n该 Bloom filter 算法的主要步骤如下:\n参数计算:\n根据预期元素数量 n 和可接受误判率 p,通过公式计算最优位数 m 和哈希函数数量 k: $ m=\\lceil-n \\dfrac{\\ln(p)}{\\ln(2) ^ 2}\\rceil $ $ k=\\lceil\\dfrac{m}{n}\\ln(2)\\rceil $ 当直接指定参数时,使用给定的位数和哈希函数数量 哈希生成:\n使用 64 位指纹哈希(farmhash)生成初始哈希值 h 通过位运算构造增量值 delta = (h \u0026gt;\u0026gt; 33) | (h \u0026lt;\u0026lt; 31) 采用双重哈希技术,通过循环叠加 delta 生成 k 个不同的位位置: $ h_i \\equiv h + i \\cdot delta \\pmod m , 0 \\leq i \\lt k $ 数据插入:\n对输入 key 进行哈希计算得到初始 h 和 delta 循环 k 次生成位位置,将位数组中对应位置设为 1 采用位操作: byte_index = position/8,bit_mask = 1 \u0026laquo; (position%8) 存在性检测:\n重复插入时的哈希计算过程 检查所有 k 个对应位是否均为 1 任一位置为 0 则判定不存在,全部为 1 时判定可能存在 数据持久化:\n序列化时附加 CRC32 校验和 反序列化时验证校验和与数据完整性 ","date":"1 March, 2025","id":16,"permalink":"/posts/lsm/","summary":"Lsm Tree 是一种内存-磁盘的层级式数据结构，常用于实现写多读少的存储引擎。","tags":"database rust","title":"Lsm Tree 实现备注"},{"content":"实验设定放在最后。\nKimi K2 这个故事是一个关于记忆、爱情与执念的幽怨传说，表面讲的是沈慕云与容娘的“负约”，实则讲的是 “如何不让一段真情被时间吞没” ——哪怕要用谎言、用鬼魂、用一座城三十年不散的闲言碎语，也要把那个人留在人间。\n容娘（化作“谢娘”）自编自演了一出“赌约”，把负心、等待、重逢这些最戏剧化的扣子全缝进传闻里，让一代又一代外乡人替她“记得”。真正的负约者不是沈慕云，而是时间；真正的守约者也不是容娘，而是“故事”本身——故事替他们完成了“三十年后故地重见”的誓言。\n一、逐句解词 小院深静，欲问卿卿，何处月笼明。\n“小院深静”——当年二人初会的场景：河桥对岸的小院，春月微湿，一切尚未发生。 “欲问卿卿”——想开口，却终究没问；一声“卿卿”把未出口的千言万语都压在舌尖。 “何处月笼明”——月亮仍在，却照不到当年并肩看月的人；也暗指“容娘”自己已成幽魂，“月”是人间与冥界的唯一通道，她再也回不去了。 千秋岁好，休负兰因。\n“千秋岁好”——字面是祝颂：愿你长享百岁千秋，岁岁安好。 “休负兰因”——“兰因”出自《左传》“兰因絮果”，兰因＝美好的开端，絮果＝离散的结局。\n容娘把典故截半，只留“兰因”，是把结局生生改写成“花开未谢”——她不要“絮果”，只要“兰因”永存；换言之，“你若安好，便不算负我”。 合在一起，是鬼魂对活人最温柔的赦令：你不必自责，不必回头，甚至不必记得我；只要你在人间岁岁平安，我们那一段“兰因”就从未被辜负。 二、整首小词在故事里的功能 替沈慕云“平反”\n城里传说他“高中负心”，而容娘最后一句“休负兰因”等于亲口否认了“负”字——“负”是世人附会，“兰因”才是她私藏的真相。 替自己“松绑”\n她等了三十年，其实等的不是沈慕云，而是一个可以自我释怀的叙事版本——“千秋岁好”四个字出口，执念才终于落地，鬼魂才能消散。 把“故事”升华为“公共记忆”\n词里“月笼明”是开放画面，任何后来者（包括“我”）只要站在河桥细雨里，就自动成为新的“卿卿”。故事不死，兰因就不死；人间继续流传，她就能继续借他人的心头一点月光，与沈慕云并肩。 三、总结 “小院深静……”二十一字，是容娘亲手写给自己的“反向墓志铭”：\n——不写“我曾恨你”，写“愿你安好”；\n——不写“我等你”，写“休负兰因”；\n——不写“故事结束”，写“月笼明”留给下一位行人。\n她用最轻的语调，把最重的执念吹散在雨里：\n“只要世上还有人替我传诵这一句，你就从未真正离开我。”\nClaude Sonnet 4.5 这是一个凄美动人的志怪爱情故事，充满了中国古典文学的浪漫与哀愁。让我为你解读：\n故事解读 真相的反转 故事最精妙之处在于层层剥开的真相:\n表面上是沈慕云负心悔婚的俗套故事 实际上容娘早已溺水身亡，她自己编造了所有传言 她化身\u0026quot;谢娘\u0026quot;引导\u0026quot;我\u0026quot;，只为让世人记住他们的故事 深藏的深情 容娘的所作所为揭示了她至深的爱:\n编造负面传言：让沈慕云背负薄情之名，实则是她对这段感情念念不忘的证明 \u0026ldquo;三十年之约\u0026rdquo;：明知他不会来（因为她已是鬼魂），仍要给自己一个等待的理由 最后的谎言：当得知沈慕云27岁早逝，她选择相信\u0026quot;我\u0026quot;善意的谎言，带着他幸福的假象消散 悲剧的本质 两人都是命运的牺牲品——一个溺水早逝，一个27岁早卒。他们的爱情从未因背叛而破碎，而是被死亡生生拆散。容娘那句\u0026quot;因缘注定，捞一捞终不能得\u0026quot;正是这无奈的注脚。\n词句深意解读 \u0026ldquo;小院深静，欲问卿卿，何处月笼明\u0026rdquo;\n字面含义：深深的庭院静悄悄，想要问我的爱人，哪里的月光最明亮？ 故事中的含义： \u0026ldquo;小院深静\u0026quot;是她独自等待的孤寂处境 \u0026ldquo;欲问卿卿\u0026quot;是她想问沈慕云，却永远无法相见的遗憾 \u0026ldquo;何处月笼明\u0026quot;是在问：你在人间何处？那里的月色可好？我们还能否在同一轮明月下相望？ \u0026ldquo;千秋岁好，休负兰因\u0026rdquo;\n字面含义：愿你千秋万世安好，不要辜负我们美好的缘分 故事中的含义： 这是容娘最后的祝福与释怀 \u0026ldquo;千秋岁好\u0026rdquo;：既是祝福沈慕云（虽然他已逝），也是对这段感情的纪念 \u0026ldquo;休负兰因\u0026rdquo;：不是责怪他辜负，而是说\u0026quot;我们的缘分虽短暂如兰花，但请你记得它的芬芳，不要忘记我们曾经相爱\u0026rdquo; 最动人之处 容娘明知沈慕云已死，却仍要编织\u0026quot;他白头偕老\u0026quot;的幻象来安慰自己；她\u0026quot;任性使坏编排他一回\u0026rdquo;，实则是用全部的爱为他守护名声——宁可世人说她痴情被负，也不愿他在冥冥中孤独。\n那句\u0026quot;捞一捞终不能得，但宁可难平，也不愿放手\u0026rdquo;，是对所有求而不得之爱最诗意的诠释：即使知道不可能，也要在记忆里、在传说里，让这份爱永远鲜活。\n这正是中国古典爱情故事的极致浪漫——生死相隔，却以魂灵相守；真相残酷，却以谎言温柔。\nGemini 3 Flash 这是一个凄美而富有诗意的爱情故事，它通过“我”的视角，揭示了一个被时间、流言和自我幻想所包裹的悲剧真相。故事的魅力在于其层层剥开的悬念，以及对爱、遗憾、和记忆的深刻探讨。\n故事解读 1. 传说的建构与真相的揭示 故事首先提出了关于沈慕云悔婚的三个不同版本，其中城里老人讲述的“赌约”版本最有戏剧性，也吸引了“我”的探访。\n流言的本质： 无论是“另娶贵女”还是“不寿之症”，流言都在试图为沈慕云的悔婚提供一个合理的解释，以填补事实的空白。 “赌约”的虚构： “三十年故地重逢”的赌约是 容娘（化名谢娘） 为了让自己的故事能够被记住、被流传而编造的浪漫情节。它赋予了这段逝去的爱情一个等待和希望的维度，一个值得他人关注的理由。 真相的悲剧： 最终的真相是谢娘（容娘）在那年赴考后的雨天，跌下河桥溺亡，再也未能见到自己的少年郎。沈慕云的“悔婚”和“避而不见”并非是变心或绝情，而是因为容娘已经不在人世。她用谢娘的身份和编造的故事，让这段短暂的初恋以一种“被辜负”的、更具戏剧张力的方式存留于世人记忆中。 2. 人物与主题 人物/元素 象征意义 故事中的作用 容娘/谢娘 执念、永恒的初恋 故事的核心叙事者。她虽已逝去，却不甘被遗忘，通过虚构的故事维护了自己爱情的尊严和存在感。她的“任性使坏”是为了让他们的故事在人间留下印记。 沈慕云 逝去的理想、悲剧的命运 在故事的结局中，他的命运是 “年二十七早卒” 。这使得他无法真的“悔婚”，也使得容娘的悲剧更添一重宿命的哀伤。但他“很好”的结局是容娘最后的自我安慰。 河桥与雨 命运的转折点、阴阳相隔 河桥是两人定情与分离的象征，而 “滔天雨浪” 的幻境则是容娘逝世时的情景重现，明确了她的鬼魂身份。雨是故事基调，凄迷、绵延不绝。 “我” 倾听者、故事的传播者 “我”是故事进入现实的通道，作为记忆的载体，将容娘的心愿传递下去。 3. 爱与遗憾 容娘的内心充满难平的遗憾和执念。她深爱着沈慕云，宁愿被认为是“被悔婚”的弃妇，也要让这段爱情的故事流传，而不是被淹没在无声的消亡中。\n当“我”为了安慰她，编造沈慕云“后来又娶了新妇，白头偕老”的谎言时，她虽然“涩然”，却说“这样啊……那真是很好很好，再好不过的事了。”这显示了她至深的爱与善良：她宁愿相信爱人获得了幸福，也不愿他为她而终生抱憾。\n“小院深静,欲问卿卿,何处月笼明。千秋岁好,休负兰因”的含义 这句话是容娘临终或魂魄消散前喃喃念出的词句，是她对这段感情、对沈慕云最后的总结、疑问与祝愿。\n1. 拆解词句 小院深静，欲问卿卿： 描写了昔日两人相处的场景——静谧、美好的小院。这里的“卿卿”指代沈慕云。她在这个安静的回忆里，想要向他提问。 何处月笼明： 这是一个疑问句，也是一个哲学式的追问。“月笼明”指月光洒下，通常象征着光明、团圆或美好的结局。容娘想问的是： “我们的爱和美好（月光）最终在哪里得以安放和实现？” “我的少年郎，你现在是否幸福安康？” 这包含了她对爱人境况的牵挂，以及对逝去爱情终极归宿的迷惘。 千秋岁好： 意思是 “愿你长久地、永远地安好”。这是容娘对沈慕云发自内心的祝愿，也是她对“我”所编造的“白头偕老”结局的回应。 休负兰因： 核心是 “兰因”。 “兰因”源于《聊斋志异·莲香》中的“兰因絮果”，意指美好的开始，悲惨的结局（兰是香草，象征美好；絮是柳絮，随风飘散，象征离散）。 “休负” 是“不要辜负”的意思。 整体含义： 容娘以自己的悲剧为鉴，在消散的最后时刻，希望沈慕云（或祝愿世间所有有情人）不要辜负这美好的开始（即她与沈慕云曾拥有的纯粹初恋），要有一个好的结局。她既在对自己逝去的爱表示叹息，也在对爱人寄予了获得幸福的殷切期望。 2. 整体含义 这句话是容娘执念的温柔释放。它承载了她对过往美好时光的留恋、对爱人未来幸福的祝愿，以及对这段“兰因絮果”式悲剧爱情的坦然接受与超脱。她不再抱怨，而是带着对沈慕云深深的牵挂与祝福，消散于人世的细雨中。\nGPT5 这个故事本身就是一段借幻境和传说交织出的“人世与记忆、真实与虚构”的爱情传说。我们可以从三个层面来解读：\n一、故事的内核 表层叙事\n人们口口相传着沈慕云和容娘的故事，有多种版本：悔婚、病逝、守寡。 但实际上，这些都不是真的，是容娘自己虚构、编织出来的。她用不同的叙述“保存”了这段情感，使它不会被彻底遗忘。 真相：容娘年轻时便意外溺水而亡，和沈慕云的情缘戛然而止。 容娘的心意\n她不是想责怪谁，而是希望他们的故事能被记得。 她愿意编造悔婚、赌约的传说，只为在世间留下痕迹。哪怕人们误解她或沈慕云，也比“彻底消散”要好。 最终的温柔\n当她问“他在人间怎么样”时，叙述者选择撒了一个善意的谎，说他娶妻白首。 容娘听了，便真心觉得“那真是很好很好”。 她释然，带着笑意离开，只留下词句。 二、容娘留下的词句 “小院深静，欲问卿卿，何处月笼明。千秋岁好，休负兰因。”\n这首词可以这样理解：\n小院深静 ——环境空寂，暗示她的幽魂状态，也象征往昔爱情已成过往，唯有寂静陪伴。\n欲问卿卿，何处月笼明 ——她想问“卿卿”（她的少年郎，沈慕云），如今在何处？月光清明，却无法指引他们重逢。 ——“月”既是天上明月，也是寄托的情感象征：相隔阴阳，却共享一轮明月。\n千秋岁好 ——祝愿对方一生顺遂，千秋岁月都美好。\n休负兰因 ——“兰因”可指美好的情缘、纯洁的心意。她的愿望是：哪怕不能再相见，也不要辜负他们曾经的真挚。\n三、结合故事的整体解读 这首词就像是容娘最后的“寄语”：\n既是思念：她仍想追问“卿卿，你如今可好？” 也是祝福：哪怕自己已成往事，也愿对方在人间顺遂，不负青春年华。 更是执念的柔化：从怨与伤心，转为祝愿和守护。 于是，这句话的含义可以总结为： 👉 即便情缘如月，终究捞不着，但在心底，仍愿你岁岁安好，不负当年那份真心。\nDeepSeek R1 这是一个凄美而精巧的故事，它并非简单的负心汉传说，而是一则关于记忆、执念与深情告别的古典式志怪小说。故事的真相在结尾被彻底颠覆，而那句词，正是解开所有谜题的钥匙。\n故事解读：一场持续三十年的梦\n这个故事有多重反转，其核心结构如下：\n表层故事（传闻）：沈慕云高中悔婚，另娶贵女，留下一个三十年的赌约。这是一个符合世俗想象的、关于负心与等待的悲剧。\n中层故事（谢娘的讲述）：谢娘是容娘的婢女，她带领“我”经历幻象，并揭示自己才是悲剧的主角——她因洪水失去了自己的少年郎。这似乎将故事引向了另一个错位爱情的方向。\n深层故事（真相）：根本没有谢娘，也没有悔婚。眼前的魂魄就是容娘本人。沈慕云也并非负心，而是早已在二十七岁英年早逝。 整个“负心汉与三十年赌约”的故事，是容娘的鬼魂因为思念至深而编造的。\n容娘为何要编造故事？\n故事中点明了原因：“旁的人怨他也好，笑我也罢，我们的故事总有人记得才好。” 真实的悲剧是死亡带来的永诀，这过于绝对和寂静，会随着时间被世人遗忘。而一个带有“负心”、“赌约”等戏剧性元素的故事，反而更具传播力，更能让他们的爱情在人们的口耳相传中“活”下去。她守护的不是清白，而是记忆本身。\n“我”的角色与结局：“我”作为一个误入此地的听故事者，成为了容娘倾诉的对象。当容娘问起沈慕云在人间如何时，“我”那句善意的谎言——“他很好，后来又娶了新妇，白头偕老”——是故事的点睛之笔。这并非残忍，而是一种最深切的慈悲。它告诉执着等待的魂魄：你爱的那个人，在人间圆满终老，你无需再挂念了。这个谎言，给了容娘“放下”的理由。于是，她念出那句词，释然消散。\n环境象征：贯穿故事的“雨”，既是现实天气，也是哀伤的氛围烘托，更是三十年前那场生死洪水的象征。故事开头和结尾的“雨”与“柳色”形成闭环，暗示这一切都笼罩在容娘执念所化的、永恒凄迷的梦境里。\n“小院深静，欲问卿卿，何处月笼明。千秋岁好，休负兰因” 含义解读\n这句词是容娘的独白，也是她对沈慕云跨越生死的情话。结合故事真相，其含义层层递进：\n“小院深静，欲问卿卿，何处月笼明。”\n字面意境：庭院幽深寂静，我想问一问你，此刻哪里的月光正明亮地笼罩着（你）？ 故事深意：这描绘了容娘作为魂魄的孤独处境。“小院深静”是她三十年来徘徊之地的寂寥写照。“欲问卿卿”是极亲昵的呼唤，对象是早已不在人世的沈慕云。“何处月笼明”是一个跨越阴阳的发问：你的魂魄现在何处？是否安好？这句充满了无处寄托的牵挂与温柔探询。 “千秋岁好，休负兰因。”\n字面典故：“千秋岁好”是祝愿岁月长久美好；“兰因”典出《左传》，郑文公妾燕姞梦见天使赠兰，后生下公子兰，比喻像兰花一样美好的前因、命中注定的姻缘。“兰因絮果”则常指开端美好而结局凄凉。此处“休负兰因”即“不要辜负了我们美好的开端”。 故事深意：这是整首词的情感核心，也是容娘的释然之语。 在听到“我”的谎言之前，这或许是她固执的愿望：希望对方不要辜负当初的情缘。 但在听到“他很好”之后，这句话的含义彻底改变。 她将“我”的谎言信以为真：原来他在人间拥有了“千秋岁好”的圆满人生。于是，“休负兰因”从一句怨怼或期盼，变成了一句宽恕和祝福：既然你已有了美好的一生，那我便不再执着，不让你我当初美好的姻缘（兰因）成为束缚你的负累。我放过你，也放过我自己。 整体含义：这阙词是容娘对沈慕云的最终告别。她在一个人的“小院深静”中孤独思念了三十年，最终选择相信爱人已在人间获得“千秋岁好”，于是她决定“休负兰因”——放下执念，解脱这段因缘，让彼此都自由。\n这个故事的精妙之处在于，它用一个“谎言”（容娘编的故事）化解了另一个“谎言”（“我”说的善意的谎言），最终达成了最深层的真实：爱到极致，不是占有，而是希望对方幸福，哪怕这幸福与自己无关，甚至需要靠一个虚构的故事来成全。 那场三十年的雨，终于停了。\nQwen3-Max 这个故事是一则充满古典意蕴与幽微情感的志怪式短篇，融合了现实与幻梦、记忆与虚构、执念与释怀。它以“三十年之约”为引，层层剥开一段被时间掩埋的爱情往事，最终揭示出：所谓“故事”，不过是生者对逝者、对未竟之情的温柔重构。\n一、故事解读：一场由亡魂编织的梦 叙事的反转与真相的揭示\n故事开篇以“我”听闻关于沈慕云的多种传闻为引，最动人的是“容娘与赌约”的版本。老人指引“我”去找谢娘，看似是引路人，实则为幻境开启的契机。而当“我”见到谢娘，随她过桥、遇风雨、见幻象，最终才惊觉——谢娘即容娘，而“谢娘”只是她为讲述故事而虚构的身份。\n这一反转极具震撼力：容娘早已溺亡于三十年前的那场雨中，她的魂魄滞留人间，只为守候一个不可能兑现的约定。她编造“悔婚”“赌约”“婢女谢娘”等情节，实则是为了赋予这段无果之爱一个可被传颂的形态——哪怕是以怨恨、误解的方式，也胜过彻底被遗忘。\n“梦”的本质：执念与慈悲的交织\n容娘说：“左右是在梦里，容我任性使坏编排他一回。”\n这句话道出了她全部的温柔与心酸。她明知沈慕云早逝，却仍愿在梦中为他安排一个“白头偕老”的结局；她虚构自己被负心，实则是不愿世人知道他英年早逝、她殉情而亡的悲剧，更不愿他的名声因“负心”而受损。她的“编排”，是爱的另一种守护。\n“我”的角色：记忆的承接者\n“我”作为外来者，既是听众，也是见证者。当“我”选择隐瞒沈慕云早逝的真相，告诉她“他很好，白头偕老”，这并非欺骗，而是一种共谋式的慈悲——成全她最后的幻想，让她带着“他过得很好”的安心离去。这正呼应了容娘自己的善意：她宁愿被误解为被弃之人，也不愿世人知道他早夭。\n意象的象征\n河桥：连接现实与幻境、生与死的边界。 细雨/洪浪：情感的外化。细雨是绵长的思念，洪浪是记忆爆发的瞬间。 红妆花轿：未完成的婚礼，永远定格在幻象中。 柳色凄迷：古典诗词中常喻离别与哀愁，此处象征时光流转而情意不灭。 二、词句解读：“小院深静，欲问卿卿，何处月笼明。千秋岁好，休负兰因。” 这几句词虽为虚构，却深得宋词婉约之神髓，可视为容娘心声的凝练表达。\n“小院深静，欲问卿卿，何处月笼明”\n小院深静：回忆中两人初遇或定情之所，幽深宁静，充满私密温情。 欲问卿卿：“卿卿”为古时爱称，此处是容娘对沈慕云的深情呼唤。 何处月笼明：化用杜牧“烟笼寒水月笼沙”之意象。“月笼明”既指月光朦胧，亦喻情缘如月，看似明亮却不可触及。她在问：当年共赏明月之人，如今在何方？那轮见证誓言的月亮，是否还记得我们的约定？ 此句整体营造出一种追忆往昔、寻而不得的怅惘，是容娘三十余年来魂牵梦萦的写照。\n“千秋岁好，休负兰因”\n千秋岁：词牌名，亦指漫长岁月。此处双关，既指时间久远，也暗含祝福。 兰因：典出《周易·系辞上》“二人同心，其利断金；同心之言，其臭如兰。”后以“兰因”喻美好的姻缘或初心。“兰因絮果”则指初时美好、终成离散的姻缘。 休负兰因：意为“不要辜负当初那如兰般芬芳的誓约”。 然而，此处的“休负兰因”并非责备，而是临别前的温柔叮咛。她明知他已不在人世，却仍以梦中之语，嘱他“莫负初心”——实则是对自己执念的放下：纵使结局不如愿，我们曾有的“兰因”已是足够美好，不必怨，不必悔。\n三、整体主旨：爱的最高形式是成全与铭记 这个故事并非简单的“负心汉与痴情女”套路，而是一曲关于记忆、虚构与爱的尊严的挽歌。容娘以亡魂之身，编织一个“被辜负”的故事，只为让这段感情不被时间湮灭；而“我”以善意的谎言，成全她最后的体面。沈慕云虽早逝，却因她的守护，在传说中“白头偕老”——这何尝不是另一种永恒？\n那句词，既是她对往昔的回望，也是对未来的祝福。“千秋岁好，休负兰因”，不只是对沈慕云说，更是对所有听故事的人说：\n纵使缘浅，莫忘初心；纵使成空，爱已永恒。\n而那场三十年后的雨，依旧如初逢时般凄迷——因为有些爱，从未离开。\nLongCat 一、故事核心主题 记忆与执念的虚实交织\n故事通过\u0026quot;谢娘\u0026quot;的谎言（实为容娘的鬼魂）构建了多层叙事：表面是沈慕云负心的传说，实则是容娘对逝去的爱情与执念的投射。她借\u0026quot;赌约\u0026quot;之名，让故事流传千年，避免被世人遗忘。 \u0026ldquo;我们的故事总有人记得才好\u0026rdquo;——容娘的核心诉求，体现了人类对永恒记忆的追求，即使以谎言为代价。 生死与遗憾的象征\n暴雨中的幻象（红妆、花轿、洪浪）是容娘记忆的显影，暗示她的\u0026quot;婚姻\u0026quot;被洪水（命运）吞噬，少年郎（沈慕云）的离去是她无法释怀的痛。 \u0026ldquo;像天上的月亮，捞一捞终不能得\u0026rdquo;——以月亮隐喻理想化的爱情，虽不可得，但执念如月光笼罩人间，形成诗意化的遗憾。 真相与善意的谎言\n叙述者最后选择欺骗容娘（谎称沈慕云再婚），完成了对亡灵的救赎。这一细节揭示：人间对亡者的悲悯，有时在于编造圆满的结局。 沈慕云早卒、容娘化鬼的悲剧，被\u0026quot;坊间流传的故事\u0026quot;赋予不同版本，说明集体记忆对历史的再创造。 二、诗句逐层解析 \u0026ldquo;小院深静，欲问卿卿，何处月笼明\u0026rdquo;\n表层：寂静小院中，爱人（卿卿）的身影与月色交叠，却因薄雾难寻其踪迹。 深层：\u0026ldquo;月笼明\u0026quot;象征记忆的朦胧性——容娘对沈慕云的思念似月光明媚，却也如雾气般模糊难触。 **\u0026ldquo;欲问\u0026rdquo;**的未完成时态，强化了阴阳两隔的无奈。 \u0026ldquo;千秋岁好，休负兰因\u0026rdquo;\n典故：\u0026ldquo;兰因\u0026quot;出自《左传》\u0026ldquo;归妻茹姬，言兰之因\u0026rdquo;，喻美满姻缘。 直译：愿你们千年万代幸福，莫辜负天赐的缘分。 隐含矛盾： 容娘在诗句中作为\u0026quot;旁观者\u0026quot;祝福沈慕云，实为自我催眠式的安慰； \u0026ldquo;休负\u0026quot;二字暴露了她的脆弱：既然沈慕云早逝未娶，\u0026ldquo;兰因\u0026quot;早已成空，但鬼魂仍在固执地维护爱情的\u0026quot;尊严\u0026rdquo;。 超脱性：容娘最终接纳了悲剧，以诗意消解执念，身影消散的瞬间完成精神解脱。 三、诗句与故事的互文性 记忆的美化与重构\n诗句中的\u0026quot;小院深静\u0026quot;与\u0026quot;月笼明\u0026rdquo;，对应容娘虚构的\u0026quot;河桥赌约\u0026rdquo;，二者皆将痛苦记忆升华为唯美意象，体现情感对事实的改造。 对\u0026quot;时间\u0026quot;的超越\n\u0026ldquo;千秋岁好\u0026quot;既是对沈慕云的祝福，也是对自身存在的诘问：她以鬼魂之姿徘徊三十年，最终用诗句抹平时间刻度，与过去和解。 东方悲剧美学的典范\n全诗无激烈控诉，却以\u0026quot;雾中问月\u0026quot;\u0026ldquo;月下祝语\u0026quot;的含蓄方式，完成对命运无常的悲悯，契合传统文学中\u0026quot;哀而不伤\u0026quot;的美学标准。 四、结语：未完成的诗性正义 故事通过谎言、鬼魂、诗歌三重媒介，实现了另一种\u0026quot;正义\u0026rdquo;：容娘虽未能改写历史，却以美学方式完成了对残缺爱情的神圣化。而诗句\u0026quot;休负兰因\u0026quot;的矛盾性，正是东方文化中\u0026quot;执念与释怀\u0026quot;二元特质的精妙注脚。\n实验设定 作者：冉语优\nPrompt：\n我听过许多关于沈慕云的故事，只有这里的与众不同。有说他上京赴考，后来另聘了阁老家的贵女，也有说他早知得了不寿之症，不想教谁守寡罢了。只有这城里的老人告诉我，沈慕云初恋的少女叫做容娘，家就住在河桥对岸。两人已定了婚约，他赴考高中，到了那时却突然反悔，对容娘避之不见。“后来容娘伤心，从此再不见人。但此地人人都知道两人间的赌约：三十年后，故人故地，他敢不敢再来相见？”老人望了望我，接着说：“你来得巧。今日便是三十年整约定之日。城住着当年预备侍候她成亲的婢女，叫做谢娘，你既来了，可以求她领你去看。”_\n我谢过他，掉头走了。\n“无论多少年，都是一样的结果。”\n上桥的时候，我听他这样说。\n我见到了谢娘。此地的细雨绵绵无期，好似把每一个人的面目都笼在微湿的春雾里，看不真切，可我隐约感到已上了年纪的谢娘是美的。她当年侍候过的女主人——容娘一定更美吧？\n我向她道明来意。\n“啊，她和沈慕云的事儿呀……我不能告诉你”，她笑了笑，“但是我能带你去看。”\n她说完，不曾携伞，迎着屋外雨雾极快地走了出去。我跟了出去。不知怎么地，跟在她身边，我竟也能走得极快\n转眼间，我们走过了来时那座河桥，忽然，桥下河水巨涨，细雨变作滔天雨浪迎面拍来，一浪浪打两边栏杆。\n红妆、花轿、洪浪，幻幕般在我眼前一逝而过，我勉力闭眼，下意识逃避周遭的风浪，再睁眼时仍是小雨蒙濠，已然风平浪静。\n只有谢娘站在雨幕里，神情哀伤：“那一年，也是在这里，也是这样的天气，我在这里跌下了水，再没见到自己的少年郎。”\n我心头一震，这才发觉她身形虚浮，如临水上，宛然不似身在人世。“你是容娘？！”我问。\n她恢复了一点少女的笑容：“谢娘呀，悔婚呀，还有赌约，都是我编的。”\n“你为什么……”\n“旁的人怨他也好，笑我也罢，我们的故事总有人记得才好。就像天上的月亮，因缘注定，捞一捞终不能得，但宁可难平，也不愿放手”，她回过头来，露出那样天真的笑：“左右是在梦里，容我任性使坏编排他一回，他不会介意的吧。”\n我动容，一时无言。\n“他呢，他在人间怎么样？还好吗？”\n沈慕云，字薄君，天才绝人，年二十七早卒于世。\n“他很好”，想了想，我这样告诉她，“后来又娶了新妇，白头偕老。”\n她忽地莞尔，“这样啊……那真是很好很好，再好不过的事了。”\n我看她露出涩然的笑，喃喃念着什么，身影一点点地变淡消散。我听清了那一句词：“小院深静，欲问卿卿，何处月笼明。千秋岁好，休负兰因。”\n时雨霏霏，三十年后的此地笼罩着三十年前一样凄迷的柳色，仿佛他们的初逢，点滴片刻，却望尽整座人间\n解读这个故事，并结合故事解读\u0026quot;小院深静,欲问卿卿,何处月笼明。千秋岁好,休负兰因\u0026quot;的含义。\n","date":"13 January, 2025","id":17,"permalink":"/posts/story-chichi/","summary":"实验设定放在最后。","tags":"music","title":"AI怎么解读银临《迟迟》的背景故事？"},{"content":"Symars Rust代码生成库和 Raddy 自动求导库的来龙去脉\n故事的起因： 前段时间读了一些物理模拟的论文，想尝试复现一下。下手点先选了 stable neo hookean flesh simulation，但是选了什么并不重要。重要的是，所谓“现代”的物理模拟很多是隐式模拟，需要用牛顿法解一个优化问题。\n这之中就涉及到了：对能量的本构模型求导数（一阶梯度，二阶 hessian 矩阵）。这之中还涉及到从 小而稠密 的 hessian 子矩阵组装成 大而稀疏 的完整 hessian。这是一个精细活，一不小心就会出现极其难以排查的 bug。\n从 Dynamic Deformables 这篇文章中可以看出推导这个公式就要花不少功夫（就算是看懂论文里的 notation 也要好一会儿），于是我搜了搜更多东西，尝试寻找一些其他的解决方法：我不是很想在精细的 debug 上花很多时间。最终找到的解决方法有两种：\n求符号导数，然后进行代码生成； 自动求导。 找到的资料中，前者有 MATLAB 或者 SymPy，后者有 PyTorch 等深度学习库，和更适合的 TinyAD。\n为什么说更适合？因为深度学习库的求导是以tensor为单位的，但是我这里的求导需要以单个标量为单位，粒度不同，深度学习库可能会跑出完全没法看的帧率。\n但是一个致命的问题来了：上述工具都在 C++ 的工具链上，而我不会 C++（或者，我可能会一点点 C++，但是我不会 CMake，因此不会调包。）\n我曾经花了三天尝试在项目里用上 Eigen，然后失败告终，还是技术水平太菜了。\n我只好换一门我比较熟悉的语言：Rust。这是一切罪恶的开始\u0026hellip;\n一条看起来简单的路 目前 Rust 还没有一个可以求二阶 hessian 的自动求导库（至少我在 crates.io 没搜到）。\nSymPy 目前还不能生成 Rust 代码（可以，但是有 bug）。\n考虑实现难度我先选了后者：从 SymPy 表达式生成 Rust 代码。于是有了 Symars。\nSymPy 提供的访问符号表达式的数据结构是树的形式，节点类型是运算符类型（Add, Mul, Div, Sin, 等等）或者常数/符号，节点的孩子是 operand 操作数。实现代码生成的思路就是按深度优先遍历树，得到孩子的表达式，然后再根据节点类型得到当前节点的表达式。边界条件是当前节点是常数，或者符号。\n实现完了之后，我拿着生成的导数去先写一个简单的隐式弹簧质点系统；但是还是在 hessian 组装上消耗了很多时间在排查 index 打错这种 bug 上。\n再去走没走过的路 为了解决上述问题，我打算尝试原来放弃的那条路：自动求导。方案是在 Rust 里面使用 TinyAD。\n一条路的两种走法 一开始想了两个方法：毕竟我不是很懂 C++，可能相比于看懂整个 TinyAD 的 codebase，做一套 FFI 更现实一些。\n但是我发现，项目 clone 下来之后，我甚至不会拉依赖不会编译。（什么赛博残废）\n然后我重新观察了 TinyAD 的 codebase，发现核心逻辑大概在 ~1000 行代码，似乎不是不可能在完全不运行这个项目的前提下把代码复刻一遍。说干就干，于是有了Raddy：\n正确的走路姿势 找到了正确的走路姿势，开始着手实现。说一些实现细节：\n每个求导链路上的标量值都带一个相对变量的梯度和 hessian，所以肉眼可见的 memory overhead 比较严重；一个提醒用户的方法是不实现 Copy trait，在需要一个副本的时候 explicit clone。 有大量需要实现 (\u0026amp;)Type 和 (\u0026amp;)Type 之间的 operator trait，组合有 2 * 2 = 4 种，这意味着相同的代码要写 4 次。于是考虑引进某些元编程的方法： 用宏 macro 批量实现； 用 Python 脚本进行代码生成。 考虑到宏会让 rust-analyzer （局部）罢工，但是我离开 LSP 简直活不了，于是选择了后者。具体代码见 meta/ 目录，其实没啥技术含量，就是字符串拼接。\n测试：我要如何验证我求出来的导数是对的？第一个想法就是用我前面写过的 symars，对每个测试表达式生成其符号 grad 和 hessian 的代码，然后和求导结果交叉验证，然后让这些测试表达式尽可能覆盖所有实现过的方法。 symars 居然表现得很不错，稳定使用没有发现 bug。 稀疏之路 稠密的矩阵用一块连续的内存空间表示相邻的值；稀疏矩阵动辄上万的边长（上亿的总元素数 numel）不允许。于是针对稀疏矩阵单独实现了其 hessian 的组装过程：\n定义一个问题，即实现一个 Objective\u0026lt;N\u0026gt; trait，需要：\n确定 problem size N（这是编译器要求 const generics 必须是编译期常量） 实现计算逻辑 比如：弹簧质点系统的逻辑（其实就是高中学的胡克定律 $E =\\dfrac{1}{2}kx^2$ ）： 简单解释：在二维平面中模拟，每个点坐标 $(x,y)$ 有两个实数；每个弹簧涉及两个点，得到 $2 \\times 2 =4$ 这个自由度。 impl Objective\u0026lt;4\u0026gt; for SpringEnergy { type EvalArgs = f64; // restlength fn eval(\u0026amp;self, variables: \u0026amp;advec\u0026lt;4, 4\u0026gt;, restlen: \u0026amp;Self::EvalArgs) -\u0026gt; Ad\u0026lt;4\u0026gt; { // extract node positions from problem input: let p1 = advec::\u0026lt;4, 2\u0026gt;::new(variables[0].clone(), variables[1].clone()); let p2 = advec::\u0026lt;4, 2\u0026gt;::new(variables[2].clone(), variables[3].clone()); let len = (p2 - p1).norm(); let e = make::val(0.5 * self.k) * (len - make::val(*restlen)).powi(2); e } } 定义这个稀疏向量中的哪些分量，需要作为这个问题的输入（提供其 indices，\u0026amp;[[usize; N]]）。\nAD 自动组装 grad 和 hess（稀疏），涉及到 index map 的问题；\n最后用户手动将多个 grad 和 hess 加和。这一步就没有 index map 的问题了，就是简单的矩阵加法（triplet matrix 就更简单，直接把多个 triplet vector 接在一起就好了）。\n添加测试之前总共有2.2k行代码，添加测试之后项目总代码量膨胀到了18k行，再次证明数LOC是个没啥用的事情。\n最后，经过一大堆冗长的测试，写了一个 demo 来娱乐自己，顺便作为 example： 结语 收获：\n熟悉了自动求导 用 AI 写文档（他目前还读不懂我的代码，或者说还读不太懂 Rust，所以写的测试有许多语法问题） Happiness! ","date":"29 December, 2024","id":18,"permalink":"/posts/road-to-diff/","summary":"Symars  Rust代码生成库和 Raddy 自动求导库的来龙去脉","tags":"","title":"自动求导, 道阻且长"},{"content":"本文没有任何数学推导。我们从直观上理解这个算法，然后直接介绍算法的流程。希望了解数学推导的读者可以查看 CMU 的教案及其翻译。\n1. 问题 对于实对称矩阵 $A \\in \\mathbb{R}^{n \\times n}$ 和向量 $b \\in \\mathbb{R}^n$，求解\n$$Ax = b$$或者，等价的，\n$$\\text{argmin}_x f(x)$$其中\n$$f(x) = \\frac{1}{2}x^T A x - b^T x$$2. 预备知识 2.1. 从高中学的二级结论说起 高中的时候我们学过椭圆：\n$$a^{-2}x^2 + b^{-2}y^2 = 1$$如果你记性好的话，你应该记得这个二级结论：\n这是一个从圆里面推广而来的结论：如果 $a = b$，椭圆退化为圆，$k_{OM}k_l = -1$，即 $OM, l$ 两条直线垂直。\n2.2. 最速下降法 首先，你应该知道梯度下降法：\n$$x_{i+1} = x_i - \\alpha\\nabla f(x_i)$$最速下降法就是在梯度下降法的基础上，选择 $\\alpha$ 使得 $x_{i+1}$ 达到最小（在搜索方向上的最小值）：\n$$\\alpha^* = \\text{argmin}_\\alpha f(x_i - \\alpha\\nabla f(x_i))$$3. 共轭梯度法 3.1. 记号 $x_i$：第 $i$ 次循环之后的 $x$ 向量\n$r_i$：$b_i - Ax_i$，目标函数 $f(x)$ 在 $x_i$ 点的负梯度，或者线性方程组在 $x_i$ 点的残差。\n请记住：负梯度和残差是一个东西！ $d_i$：在 $x_i$ 点的搜索方向。最速下降算法里 $d_i = r_i$，共轭梯度里面需要一点修正。\n3.2. 最速下降 最速下降的新方向：$r_{i+1}$\n新方向与前一步下降方向 $r_i$ 垂直（画个等高线图直观理解，或者回想一下\u0026quot;等势面和电场线垂直\u0026quot;） 最速下降的 $\\alpha$ $$\\alpha_i = \\frac{r_i^T r_i}{d_i^T A d_i}$$3.3. 共轭梯度 我们直接逐项类比最速下降。\n新方向与前一步下降方向 $r_i$ 垂直 斜率之积为 $-a^{-2}b^2$ (Section 2.1)\n这个方向由最速下降的方向进行一些小改动得到，我们可以在后面的算法部分(Section 3.4)看到。把这个方向从和前一个搜索方向垂直改动到斜率之积为 $-a^{-2}b^2$ 就是 CG 和最速下降唯一不同的地方。 步长 $\\alpha$：由于是在一条直线上做优化，因此和最速下降的 $\\alpha$ 相同。 由于一次迭代只涉及到两个点、两个向量，只能构成一个平面，我们甚至不需要将二维向多维推广。\n若需推导，我们需要做的只是把点的 $n$ 维坐标映射到二维，然后对截面椭圆对应的二阶二次型进行 SVD 获得其长轴 $a$ 和短轴 $b$，进而根据其离及上述斜率积的二级结论计算两个方向的关系。这里不展开。 3.4. 算法 3.4.1. 初始化 算法输入：$A, b, x_0$\n$$\\vec{d}_{(0)} = \\vec{r}_{(0)} = \\vec{b}_{(0)} - \\mathbf{A}\\vec{x}_{(0)}$$3.4.2. 算法过程 $$\\alpha_{(i)} = \\frac{\\vec{r}_{(i)}^T \\vec{r}_{(i)}}{\\vec{d}_{(i)}^T \\mathbf{A}\\vec{d}_{(i)}}$$$$\\vec{x}_{(i+1)} = \\vec{x}_{(i)} + \\alpha_{(i)}\\vec{d}_{(i)}$$$$\\vec{r}_{(i+1)} = \\vec{r}_{(i)} - \\alpha_{(i)}\\mathbf{A}\\vec{d}_{(i)}$$$$\\beta_{(i+1)} = \\frac{\\vec{r}_{(i+1)}^T \\vec{r}_{(i+1)}}{\\vec{r}_{(i)}^T \\vec{r}_{(i)}}$$$$\\vec{d}_{(i+1)} = \\vec{r}_{(i+1)} + \\beta_{(i+1)}\\vec{d}_{(i)}$$其中的最后一步就是通过 $\\beta$ 将 $r_{i+1}$ 修正成 $d_{i+1}$ 的。\n3.4.3. 起讫 起：如果你对解 $x$ 有粗略的估计，就使用那个值作为起始点 $x_0$；否则，直接使用 $x_0 = 0$。\n讫：通常的做法是在残差向量的 2-norm 小于某个给定阈值的时候就停下来。通常这个阈值为初始残差的一小部分\n$$\\|r_i\\| \u003c \\varepsilon \\|r_0\\|$$其中 $\\varepsilon$ 是一个输入的参数。\n3.5. 杂项 由于 $Ad_i$ 在每个循环中都要被计算，且 $$r_{i+1} = r_i - \\alpha_i A d_i$$故可以用上式计算 $r_{i+1}$，而不必用 $b - Ax_{i+1}$。\n上述方法有浮点误差累计的危险，因此我们应该每过几个循环就重新用 $r_i = b - Ax_i$ 重新计算残差。 ","date":"7 December, 2024","id":19,"permalink":"/posts/conj-grad/","summary":"本文没有任何数学推导。我们从直观上理解这个算法，然后直接介绍算法的流程。希望了解数学推导的读者可以查看 CMU 的教案及其翻译。","tags":"math","title":"共轭梯度：一种高中解析几何的视角"},{"content":"个人信息 名称：黛西\nNickname: Da1sypetals\nEmail: da1sypetals.iota@gmail.com\n爱好 唱古风歌。\n比如, 我会唱这些：\n《人间不值得》《楚歌起》 黄诗扶\n《迟迟》《腐草为萤》 银临\n《故事外的人》 慕寒\n《惊鹊》《心上秋》 忘川风华录\n《泼墨漓江》 泠鸢yousa\n《敢归云间宿》 三无Marblue\n《忘川》《霁夜茶》 小曲儿\n《松烟入墨》《如是我闻》 Winky诗\n《悦神》 KBShinya\n《第三十八年夏至》《永定四十年》 河图\n《东风志》 Aki阿杰\n这里还有很多\u0026hellip;\n","date":"1 June, 2004","id":20,"permalink":"/about/","summary":"名称：黛西","tags":"","title":"关于我"}]