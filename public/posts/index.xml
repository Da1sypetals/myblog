<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Da1sypetals</title>
    <link>http://localhost:1313/posts/</link>
    <description>Recent content in Posts on Da1sypetals</description>
    <generator>Hugo</generator>
    <language>zh-CN</language>
    <lastBuildDate>Fri, 03 Oct 2025 01:02:21 +0800</lastBuildDate>
    <atom:link href="http://localhost:1313/posts/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>AI怎么解读银临《迟迟》的背景故事？</title>
      <link>http://localhost:1313/posts/chichi-story/</link>
      <pubDate>Fri, 03 Oct 2025 01:02:21 +0800</pubDate>
      <guid>http://localhost:1313/posts/chichi-story/</guid>
      <description>&lt;p&gt;实验设定放在最后。&lt;/p&gt;&#xA;&lt;h2 id=&#34;kimi-k2&#34;&gt;Kimi K2&lt;/h2&gt;&#xA;&lt;p&gt;这个故事是一个关于记忆、爱情与执念的幽怨传说，表面讲的是沈慕云与容娘的“负约”，实则讲的是 &lt;strong&gt;“如何不让一段真情被时间吞没”&lt;/strong&gt; ——哪怕要用谎言、用鬼魂、用一座城三十年不散的闲言碎语，也要把那个人留在人间。&lt;/p&gt;&#xA;&lt;p&gt;容娘（化作“谢娘”）自编自演了一出“赌约”，把负心、等待、重逢这些最戏剧化的扣子全缝进传闻里，让一代又一代外乡人替她“记得”。&lt;strong&gt;真正的负约者不是沈慕云，而是时间&lt;/strong&gt;；真正的守约者也不是容娘，而是“故事”本身——故事替他们完成了“三十年后故地重见”的誓言。&lt;/p&gt;&#xA;&lt;h3 id=&#34;一逐句解词&#34;&gt;一、逐句解词&lt;/h3&gt;&#xA;&lt;p&gt;&lt;strong&gt;小院深静，欲问卿卿，何处月笼明。&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;“小院深静”——当年二人初会的场景：河桥对岸的小院，春月微湿，一切尚未发生。&lt;/li&gt;&#xA;&lt;li&gt;“欲问卿卿”——想开口，却终究没问；一声“卿卿”把未出口的千言万语都压在舌尖。&lt;/li&gt;&#xA;&lt;li&gt;“何处月笼明”——月亮仍在，却照不到当年并肩看月的人；也暗指“容娘”自己已成幽魂，&lt;strong&gt;“月”是人间与冥界的唯一通道&lt;/strong&gt;，她再也回不去了。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;&lt;strong&gt;千秋岁好，休负兰因。&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;“千秋岁好”——字面是祝颂：愿你长享百岁千秋，岁岁安好。&lt;/li&gt;&#xA;&lt;li&gt;“休负兰因”——&lt;strong&gt;“兰因”出自《左传》“兰因絮果”&lt;/strong&gt;，兰因＝美好的开端，絮果＝离散的结局。&lt;br&gt;&#xA;容娘把典故截半，只留“兰因”，是&lt;strong&gt;把结局生生改写成“花开未谢”&lt;/strong&gt;——她不要“絮果”，只要“兰因”永存；换言之，&lt;strong&gt;“你若安好，便不算负我”&lt;/strong&gt;。&lt;/li&gt;&#xA;&lt;li&gt;合在一起，是&lt;strong&gt;鬼魂对活人最温柔的赦令&lt;/strong&gt;：你不必自责，不必回头，甚至不必记得我；只要你在人间岁岁平安，我们那一段“兰因”就从未被辜负。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h3 id=&#34;二整首小词在故事里的功能&#34;&gt;二、整首小词在故事里的功能&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;strong&gt;替沈慕云“平反”&lt;/strong&gt;&lt;br&gt;&#xA;城里传说他“高中负心”，而容娘最后一句“休负兰因”等于亲口否认了“负”字——&lt;strong&gt;“负”是世人附会，“兰因”才是她私藏的真相&lt;/strong&gt;。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;替自己“松绑”&lt;/strong&gt;&lt;br&gt;&#xA;她等了三十年，其实等的不是沈慕云，而是一个&lt;strong&gt;可以自我释怀的叙事版本&lt;/strong&gt;——“千秋岁好”四个字出口，执念才终于落地，鬼魂才能消散。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;把“故事”升华为“公共记忆”&lt;/strong&gt;&lt;br&gt;&#xA;词里“月笼明”是开放画面，任何后来者（包括“我”）只要站在河桥细雨里，就自动成为新的“卿卿”。&lt;strong&gt;故事不死，兰因就不死&lt;/strong&gt;；人间继续流传，她就能继续借他人的心头一点月光，与沈慕云并肩。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h3 id=&#34;三总结&#34;&gt;三、总结&lt;/h3&gt;&#xA;&lt;p&gt;“小院深静……”二十一字，是容娘亲手写给自己的“反向墓志铭”：&lt;br&gt;&#xA;——不写“我曾恨你”，写“愿你安好”；&lt;br&gt;&#xA;——不写“我等你”，写“休负兰因”；&lt;br&gt;&#xA;——不写“故事结束”，写“月笼明”留给下一位行人。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;她用最轻的语调，把最重的执念吹散在雨里：&lt;/strong&gt;&lt;br&gt;&#xA;&lt;strong&gt;“只要世上还有人替我传诵这一句，你就从未真正离开我。”&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;claude-sonnet-45&#34;&gt;Claude Sonnet 4.5&lt;/h2&gt;&#xA;&lt;p&gt;这是一个凄美动人的志怪爱情故事，充满了中国古典文学的浪漫与哀愁。让我为你解读：&lt;/p&gt;&#xA;&lt;h3 id=&#34;故事解读&#34;&gt;故事解读&lt;/h3&gt;&#xA;&lt;p&gt;&lt;strong&gt;真相的反转&lt;/strong&gt;&#xA;故事最精妙之处在于层层剥开的真相:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;表面上是沈慕云负心悔婚的俗套故事&lt;/li&gt;&#xA;&lt;li&gt;实际上容娘早已溺水身亡，她自己编造了所有传言&lt;/li&gt;&#xA;&lt;li&gt;她化身&amp;quot;谢娘&amp;quot;引导&amp;quot;我&amp;quot;，只为让世人记住他们的故事&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;strong&gt;深藏的深情&lt;/strong&gt;&#xA;容娘的所作所为揭示了她至深的爱:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;编造负面传言&lt;/strong&gt;：让沈慕云背负薄情之名，实则是她对这段感情念念不忘的证明&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;&amp;ldquo;三十年之约&amp;rdquo;&lt;/strong&gt;：明知他不会来（因为她已是鬼魂），仍要给自己一个等待的理由&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;最后的谎言&lt;/strong&gt;：当得知沈慕云27岁早逝，她选择相信&amp;quot;我&amp;quot;善意的谎言，带着他幸福的假象消散&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;strong&gt;悲剧的本质&lt;/strong&gt;&#xA;两人都是命运的牺牲品——一个溺水早逝，一个27岁早卒。他们的爱情从未因背叛而破碎，而是被死亡生生拆散。容娘那句&amp;quot;因缘注定，捞一捞终不能得&amp;quot;正是这无奈的注脚。&lt;/p&gt;&#xA;&lt;h3 id=&#34;词句深意解读&#34;&gt;词句深意解读&lt;/h3&gt;&#xA;&lt;p&gt;&lt;strong&gt;&amp;ldquo;小院深静，欲问卿卿，何处月笼明&amp;rdquo;&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;字面含义&lt;/strong&gt;：深深的庭院静悄悄，想要问我的爱人，哪里的月光最明亮？&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;故事中的含义&lt;/strong&gt;：&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&amp;ldquo;小院深静&amp;quot;是她独自等待的孤寂处境&lt;/li&gt;&#xA;&lt;li&gt;&amp;ldquo;欲问卿卿&amp;quot;是她想问沈慕云，却永远无法相见的遗憾&lt;/li&gt;&#xA;&lt;li&gt;&amp;ldquo;何处月笼明&amp;quot;是在问：你在人间何处？那里的月色可好？我们还能否在同一轮明月下相望？&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;strong&gt;&amp;ldquo;千秋岁好，休负兰因&amp;rdquo;&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;字面含义&lt;/strong&gt;：愿你千秋万世安好，不要辜负我们美好的缘分&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;故事中的含义&lt;/strong&gt;：&#xA;&lt;ul&gt;&#xA;&lt;li&gt;这是容娘最后的祝福与释怀&lt;/li&gt;&#xA;&lt;li&gt;&amp;ldquo;千秋岁好&amp;rdquo;：既是祝福沈慕云（虽然他已逝），也是对这段感情的纪念&lt;/li&gt;&#xA;&lt;li&gt;&amp;ldquo;休负兰因&amp;rdquo;：不是责怪他辜负，而是说&amp;quot;我们的缘分虽短暂如兰花，但请你记得它的芬芳，不要忘记我们曾经相爱&amp;rdquo;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;最动人之处&#34;&gt;最动人之处&lt;/h3&gt;&#xA;&lt;p&gt;容娘明知沈慕云已死，却仍要编织&amp;quot;他白头偕老&amp;quot;的幻象来安慰自己；她&amp;quot;任性使坏编排他一回&amp;rdquo;，实则是用全部的爱为他守护名声——宁可世人说她痴情被负，也不愿他在冥冥中孤独。&lt;/p&gt;&#xA;&lt;p&gt;那句&amp;quot;捞一捞终不能得，但宁可难平，也不愿放手&amp;rdquo;，是对所有求而不得之爱最诗意的诠释：&lt;strong&gt;即使知道不可能，也要在记忆里、在传说里，让这份爱永远鲜活&lt;/strong&gt;。&lt;/p&gt;&#xA;&lt;p&gt;这正是中国古典爱情故事的极致浪漫——生死相隔，却以魂灵相守；真相残酷，却以谎言温柔。&lt;/p&gt;&#xA;&lt;h2 id=&#34;gemini-3-flash&#34;&gt;Gemini 3 Flash&lt;/h2&gt;&#xA;&lt;p&gt;这是一个&lt;strong&gt;凄美而富有诗意的爱情故事&lt;/strong&gt;，它通过“我”的视角，揭示了一个被时间、流言和自我幻想所包裹的悲剧真相。故事的魅力在于其层层剥开的悬念，以及对&lt;strong&gt;爱、遗憾、和记忆&lt;/strong&gt;的深刻探讨。&lt;/p&gt;&#xA;&lt;h3 id=&#34;故事解读-1&#34;&gt;故事解读&lt;/h3&gt;&#xA;&lt;h4 id=&#34;1-传说的建构与真相的揭示&#34;&gt;1. 传说的建构与真相的揭示&lt;/h4&gt;&#xA;&lt;p&gt;故事首先提出了关于&lt;strong&gt;沈慕云&lt;/strong&gt;悔婚的三个不同版本，其中城里老人讲述的“赌约”版本最有戏剧性，也吸引了“我”的探访。&lt;/p&gt;</description>
    </item>
    <item>
      <title>近期GNN Attention算子优化工作速览</title>
      <link>http://localhost:1313/posts/gnn-optim/</link>
      <pubDate>Thu, 02 Oct 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/gnn-optim/</guid>
      <description>&lt;p&gt;注：本文用LLM辅助写作的地方主要在：&lt;em&gt;&lt;strong&gt;我认为LLM比我理解的更好的地方，会用LLM的表述代替。&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;问题设定&#34;&gt;问题设定&lt;/h2&gt;&#xA;&lt;p&gt;需要计算Graph Transformer中的Attention。在此我们忽略multihead-attention，考虑基本的single-head attention.&lt;/p&gt;&#xA;&lt;p&gt;此外，我们的attention mask(邻接矩阵A)是非结构化稀疏的。如果你的attention mask是结构化稀疏的，比如blockwise等可以被代码表示的稀疏pattern，你应该使用flash attention的varlen变体, 或者flex attention等attention编译器。&lt;/p&gt;&#xA;&lt;h3 id=&#34;notation&#34;&gt;Notation&lt;/h3&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;n: 图节点数，规模为 1k~1M&#xD;&#xA;nnz: 图边数（稀疏矩阵非零元素数，Num NonZero）&#xD;&#xA;&#x9;  规模为10n~1000n&#xD;&#xA;q, k, v: (n, d)&#xD;&#xA;A: (n, n), binary, 高度稀疏&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;计算公式&#34;&gt;计算公式&lt;/h3&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;softmax((q @ k.transpose()) * A) @ V&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;其中，&lt;code&gt;@&lt;/code&gt; 表示矩阵乘法，&lt;code&gt;*&lt;/code&gt;表示element-wise乘法。&lt;/p&gt;&#xA;&lt;h2 id=&#34;实现naive-version&#34;&gt;实现：naive version&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;最简单的就是把A给materialize出来，然后用作attention_mask。问题是A是$n^2$的，显存不够用。&lt;/li&gt;&#xA;&lt;li&gt;A用COO方式存储，大小(2,nnz)，然后先把每条边的qk-pair取出来得到(nnz,d)，然后再做reduce和scatter, 和V相乘。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;reformulate&#34;&gt;Reformulate&lt;/h2&gt;&#xA;&lt;p&gt;我们引入三个算子:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;SDDMM (Sampled Dense-Dense MatMul)&lt;/strong&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;A (m, k), B (k, n), 稠密&lt;/li&gt;&#xA;&lt;li&gt;M (n, n)， 稀疏&#xA;SDDMM(A, B, M) 定义为：&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;for i, j in product(range(n), range(n)):&#xD;&#xA;&#x9;if M[i, j] != 0:&#xD;&#xA;&#x9;&#x9;out[i, j] = dot(A[i,:], B[:,j])&#xD;&#xA;&#x9;else:&#xD;&#xA;&#x9;&#x9;out[i, j] = 0&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;&#xA;&lt;li&gt;Sparse Softmax: 在稀疏矩阵上按行softmax&lt;/li&gt;&#xA;&lt;li&gt;SpMM：sparse A @ dense B&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;此时我们的计算公式就可以重新写成:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Snapviewer Devlog #3: 性能优化</title>
      <link>http://localhost:1313/posts/snapviewer-3-zh/</link>
      <pubDate>Sat, 07 Jun 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/snapviewer-3-zh/</guid>
      <description>&lt;h1 id=&#34;内存与速度性能问题排查&#34;&gt;内存与速度性能问题排查&lt;/h1&gt;&#xA;&lt;p&gt;&lt;strong&gt;免责声明&lt;/strong&gt;：我主要在 Windows 上使用最新的稳定版 Rust 工具链和 CPython 3.13 进行开发和测试。&lt;/p&gt;&#xA;&lt;h2 id=&#34;1-背景与动机&#34;&gt;1. 背景与动机&lt;/h2&gt;&#xA;&lt;p&gt;SnapViewer 能够高效处理大型内存快照——例如，支持高达 500 MB 的压缩快照。然而，在处理 1.3 GB的snapshot的时，我发现了严重的内存和速度瓶颈：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;格式转换（pickle → 压缩 JSON）引发了约 30 GB 的内存峰值。&lt;/li&gt;&#xA;&lt;li&gt;将压缩 JSON 加载到 Rust 数据结构中又引发了另一次约 30 GB 的内存激增。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;频繁的 page fault 和强烈的磁盘 I/O（在任务管理器中观察到）导致应用程序响应迟缓，甚至频繁卡顿。为了解决这一问题，我们采用了 Profile-Guided Optimization（PGO，基于性能分析的优化）方法。&lt;/p&gt;&#xA;&lt;h2 id=&#34;2-profile-guided-optimizationpgo&#34;&gt;2. Profile-Guided Optimization（PGO）&lt;/h2&gt;&#xA;&lt;p&gt;PGO 需要通过实证分析来识别真正的热点。我首先使用 &lt;a href=&#34;https://crates.io/crates/memory-stats&#34;&gt;memory-stats&lt;/a&gt; crate 进行内存分析，在早期优化阶段进行轻量级检查。随后，我将数据加载流水线拆解为若干离散步骤：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;读取压缩文件（重度磁盘 I/O）&lt;/li&gt;&#xA;&lt;li&gt;从压缩流中提取 JSON 字符串&lt;/li&gt;&#xA;&lt;li&gt;将 JSON 反序列化为原生 Rust 数据结构&lt;/li&gt;&#xA;&lt;li&gt;填充内存中的 SQLite 数据库以支持即席 SQL 查询&lt;/li&gt;&#xA;&lt;li&gt;在 CPU 上构建三角网格（triangle mesh）&lt;/li&gt;&#xA;&lt;li&gt;初始化渲染窗口（CPU-GPU 数据传输）&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;性能分析揭示了两个主要的内存问题：过度使用 &lt;code&gt;clone&lt;/code&gt; 和多个中间数据结构。以下是我实施的优化措施。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Lsm Tree 实现备注</title>
      <link>http://localhost:1313/posts/lsm/</link>
      <pubDate>Sat, 01 Mar 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/lsm/</guid>
      <description>&lt;p&gt;Lsm Tree 是一种内存-磁盘的层级式数据结构，常用于实现写多读少的存储引擎。&lt;/p&gt;&#xA;&lt;p&gt;这是我实现 &lt;a href=&#34;https://github.com/Da1sypetals/Lsmkv&#34;&gt;Lsmkv&lt;/a&gt; 的时候记录的备注.&lt;/p&gt;&#xA;&lt;h2 id=&#34;组件&#34;&gt;组件&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;内存部分&lt;/li&gt;&#xA;&lt;li&gt;磁盘部分&lt;/li&gt;&#xA;&lt;li&gt;WAL&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;总体&#34;&gt;总体&lt;/h2&gt;&#xA;&lt;h2 id=&#34;初始化&#34;&gt;初始化&lt;/h2&gt;&#xA;&lt;p&gt;需要 init flush thread。flush thread 的工作流程:&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;等待 flush 信号量被 notify,获取一个 compact 信号量资源&lt;/li&gt;&#xA;&lt;li&gt;启动一个 sstwriter,写入这个 memtable&#xA;&lt;ul&gt;&#xA;&lt;li&gt;一个 memtable 对一个 sst&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;等到写入 sst 写完之后,才进行:&#xA;&lt;ul&gt;&#xA;&lt;li&gt;从 frozen memtables、frozen memtable sizes 里面删除这个 memtable&lt;/li&gt;&#xA;&lt;li&gt;从 wal 里面删除这个 memtable 对应的 wal&lt;/li&gt;&#xA;&lt;li&gt;update manifest&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;try-freeze&#34;&gt;Try Freeze&lt;/h2&gt;&#xA;&lt;p&gt;如果当前大小 &amp;gt; freeze size 那么就 freeze;进一步如果所有 frozen memtable 大小之和 &amp;gt; flush threshold,那么就 set flush signal。&lt;/p&gt;&#xA;&lt;h2 id=&#34;写操作&#34;&gt;写操作&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;写 memtable&lt;/li&gt;&#xA;&lt;li&gt;写 WAL&lt;/li&gt;&#xA;&lt;li&gt;try freeze&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;内存部分&#34;&gt;内存部分&lt;/h2&gt;&#xA;&lt;h3 id=&#34;put&#34;&gt;Put&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;添加到 memtable;&lt;/li&gt;&#xA;&lt;li&gt;更新 size。&#xA;&lt;ul&gt;&#xA;&lt;li&gt;size 不需要特别精确,只需要是一个大致的值即可。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h3 id=&#34;delete&#34;&gt;Delete&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;添加一个 tomb 标记到 memtable&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h3 id=&#34;get&#34;&gt;Get&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;从 active memtable 中获取&lt;/li&gt;&#xA;&lt;li&gt;从 new 到 old 遍历所有的 inactive memtable,获取。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;磁盘部分&#34;&gt;磁盘部分&lt;/h2&gt;&#xA;&lt;h3 id=&#34;compact-信号量&#34;&gt;compact 信号量&lt;/h3&gt;&#xA;&lt;p&gt;二元信号量。&lt;/p&gt;</description>
    </item>
    <item>
      <title>自动求导, 道阻且长</title>
      <link>http://localhost:1313/posts/road-to-diff/</link>
      <pubDate>Sun, 29 Dec 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/road-to-diff/</guid>
      <description>&lt;p&gt;TL;DR: &lt;a href=&#34;https://github.com/Da1sypetals/Symars&#34;&gt;Symars &lt;/a&gt; Rust代码生成库和 &lt;a href=&#34;https://github.com/Da1sypetals/Raddy&#34;&gt;Raddy&lt;/a&gt; 自动求导库的来龙去脉&lt;/p&gt;&#xA;&lt;h2 id=&#34;故事的起因&#34;&gt;故事的起因：&lt;/h2&gt;&#xA;&lt;p&gt;前段时间读了一些物理模拟的论文，想尝试复现一下。下手点先选了 &lt;a href=&#34;https://graphics.pixar.com/library/StableElasticity/paper.pdf&#34;&gt;stable neo hookean flesh simulation&lt;/a&gt;，但是选了什么并不重要。重要的是，所谓“现代”的物理模拟很多是隐式模拟，需要用牛顿法解一个优化问题。&lt;/p&gt;&#xA;&lt;p&gt;这之中就涉及到了：对能量的本构模型求导数（一阶梯度，二阶 hessian 矩阵）。这之中还涉及到从 &lt;em&gt;小而稠密&lt;/em&gt;  的 hessian 子矩阵组装成 &lt;em&gt;大而稀疏&lt;/em&gt; 的完整 hessian。这是一个精细活，一不小心就会出现极其难以排查的 bug。&lt;/p&gt;&#xA;&lt;p&gt;从 &lt;a href=&#34;https://www.tkim.graphics/DYNAMIC_DEFORMABLES/&#34;&gt;&lt;em&gt;Dynamic Deformables&lt;/em&gt;&lt;/a&gt; 这篇文章中可以看出推导这个公式就要花不少功夫（就算是看懂论文里的 notation 也要好一会儿），于是我搜了搜更多东西，尝试寻找一些其他的解决方法：我不是很想在精细的 debug 上花很多时间。最终找到的解决方法有两种：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;求符号导数，然后进行代码生成；&lt;/li&gt;&#xA;&lt;li&gt;自动求导。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;找到的资料中，前者有 MATLAB 或者 SymPy，后者有 PyTorch 等深度学习库，和更适合的 &lt;a href=&#34;https://github.com/patr-schm/TinyAD&#34;&gt;TinyAD&lt;/a&gt;。&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;为什么说更适合？因为深度学习库的求导是以tensor为单位的，但是我这里的求导需要以单个标量为单位，粒度不同，深度学习库可能会跑出完全没法看的帧率。&lt;/p&gt;&lt;/blockquote&gt;&#xA;&lt;p&gt;但是一个致命的问题来了：上述工具都在 C++ 的工具链上，而我不会 C++（或者，我可能会一点点 C++，但是我不会 CMake，因此不会调包。）&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;我曾经花了三天尝试在项目里用上 Eigen，然后失败告终，还是技术水平太菜了。&lt;/p&gt;&lt;/blockquote&gt;&#xA;&lt;p&gt;我只好换一门我比较熟悉的语言：Rust。这是一切罪恶的开始&amp;hellip;&lt;/p&gt;&#xA;&lt;h2 id=&#34;一条看起来简单的路&#34;&gt;一条看起来简单的路&lt;/h2&gt;&#xA;&lt;p&gt;目前 Rust 还没有一个可以求二阶 hessian 的自动求导库（至少我在 crates.io 没搜到）。&lt;br&gt;&#xA;SymPy 目前还不能生成 Rust 代码（可以，但是有 bug）。&lt;br&gt;&#xA;考虑实现难度我先选了后者：从 SymPy 表达式生成 Rust 代码。于是有了 &lt;a href=&#34;https://github.com/Da1sypetals/Symars&#34;&gt;Symars&lt;/a&gt;。&lt;/p&gt;&#xA;&lt;p&gt;SymPy 提供的访问符号表达式的数据结构是树的形式，节点类型是运算符类型（&lt;code&gt;Add&lt;/code&gt;, &lt;code&gt;Mul&lt;/code&gt;, &lt;code&gt;Div&lt;/code&gt;, &lt;code&gt;Sin&lt;/code&gt;, 等等）或者常数/符号，节点的孩子是 operand 操作数。实现代码生成的思路就是按深度优先遍历树，得到孩子的表达式，然后再根据节点类型得到当前节点的表达式。边界条件是当前节点是常数，或者符号。&lt;/p&gt;</description>
    </item>
    <item>
      <title>共轭梯度：一种高中解析几何的视角</title>
      <link>http://localhost:1313/posts/conj-grad/</link>
      <pubDate>Sat, 07 Dec 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/conj-grad/</guid>
      <description>&lt;p&gt;本文没有任何数学推导。我们从直观上理解这个算法，然后直接介绍算法的流程。希望了解数学推导的读者可以查看 &lt;a href=&#34;https://www.cs.cmu.edu/~quake-papers/painless-conjugate-gradient.pdf&#34;&gt;CMU 的教案&lt;/a&gt;及其&lt;a href=&#34;https://flat2010.github.io/2018/10/26/%E5%85%B1%E8%BD%AD%E6%A2%AF%E5%BA%A6%E6%B3%95%E9%80%9A%E4%BF%97%E8%AE%B2%E4%B9%89/#8-%E5%85%B1%E8%BD%AD%E6%A2%AF%E5%BA%A6%E6%B3%95&#34;&gt;翻译&lt;/a&gt;。&lt;/p&gt;&#xA;&lt;h2 id=&#34;1-问题&#34;&gt;1. 问题&lt;/h2&gt;&#xA;&lt;p&gt;对于实对称矩阵 $A \in \mathbb{R}^{n \times n}$ 和向量 $b \in \mathbb{R}^n$，求解&lt;/p&gt;&#xA;$$Ax = b$$&lt;p&gt;或者，等价的，&lt;/p&gt;&#xA;$$\text{argmin}_x f(x)$$&lt;p&gt;其中&lt;/p&gt;&#xA;$$f(x) = \frac{1}{2}x^T A x - b^T x$$&lt;h2 id=&#34;2-预备知识&#34;&gt;2. 预备知识&lt;/h2&gt;&#xA;&lt;h3 id=&#34;21-从高中学的二级结论说起&#34;&gt;2.1. 从高中学的二级结论说起&lt;/h3&gt;&#xA;&lt;p&gt;高中的时候我们学过椭圆：&lt;/p&gt;&#xA;$$a^{-2}x^2 + b^{-2}y^2 = 1$$&lt;p&gt;如果你记性好的话，你应该记得这个二级结论：&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;../images/2025-10-03-00-44-15.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;这是一个从圆里面推广而来的结论：如果 $a = b$，椭圆退化为圆，$k_{OM}k_l = -1$，即 $OM, l$ 两条直线垂直。&lt;/p&gt;&#xA;&lt;h3 id=&#34;22-最速下降法&#34;&gt;2.2. 最速下降法&lt;/h3&gt;&#xA;&lt;p&gt;首先，你应该知道梯度下降法：&lt;/p&gt;&#xA;$$x_{i+1} = x_i - \alpha\nabla f(x_i)$$&lt;p&gt;最速下降法就是在梯度下降法的基础上，选择 $\alpha$ 使得 $x_{i+1}$ 达到最小（在搜索方向上的最小值）：&lt;/p&gt;&#xA;$$\alpha^* = \text{argmin}_\alpha f(x_i - \alpha\nabla f(x_i))$$&lt;h2 id=&#34;3-共轭梯度法&#34;&gt;3. 共轭梯度法&lt;/h2&gt;&#xA;&lt;h3 id=&#34;31-记号&#34;&gt;3.1. 记号&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;$x_i$：第 $i$ 次循环之后的 $x$ 向量&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
