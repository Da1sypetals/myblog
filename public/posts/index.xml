<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Da1sypetals</title>
    <link>https://da1sy-petals.vercel.app/posts/</link>
    <description>Recent content in Posts on Da1sypetals</description>
    <generator>Hugo</generator>
    <language>zh-CN</language>
    <lastBuildDate>Mon, 05 Jan 2026 22:07:08 +0800</lastBuildDate>
    <atom:link href="https://da1sy-petals.vercel.app/posts/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>不通过反转正向传播的方式计算sinkhorn迭代的梯度</title>
      <link>https://da1sy-petals.vercel.app/posts/sinkhorn-bwd/</link>
      <pubDate>Mon, 05 Jan 2026 22:07:08 +0800</pubDate>
      <guid>https://da1sy-petals.vercel.app/posts/sinkhorn-bwd/</guid>
      <description>&lt;h2 id=&#34;变量定义与前向过程&#34;&gt;变量定义与前向过程&lt;/h2&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;注：$\odot$ 代表逐元素乘法。&lt;/p&gt;&lt;/blockquote&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;输入矩阵: $X \in \mathbb{R}^{n \times n}$。&lt;/li&gt;&#xA;&lt;li&gt;指数化: $P = \exp(X)$（逐元素指数）。&lt;/li&gt;&#xA;&lt;li&gt;Sinkhorn 结果: 得到bistochastic matrix $R = \text{diag}(u) P \text{diag}(v)$，其中 $u, v \in \mathbb{R}^n_{&gt;0}$ 是缩放因子，满足：&#xA;&lt;ul&gt;&#xA;&lt;li&gt;行和约束：$R \mathbf{1} = \mathbf{1} \implies u \odot (Pv) = \mathbf{1}$&lt;/li&gt;&#xA;&lt;li&gt;列和约束：$R^T \mathbf{1} = \mathbf{1} \implies v \odot (P^T u) = \mathbf{1}$&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;损失函数: $L = f(R)$，令 $G = \nabla_R L = \frac{\partial L}{\partial R}$ 为已知梯度。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;隐函数微分推导&#34;&gt;隐函数微分推导&lt;/h2&gt;&#xA;&lt;p&gt;我们的目标是求 $\frac{\partial L}{\partial X}$。根据链式法则：&lt;/p&gt;&#xA;$$\frac{\partial L}{\partial X} = \frac{\partial L}{\partial R} \cdot \frac{\partial R}{\partial P} \cdot \frac{\partial P}{\partial X}$$&lt;p&gt;由于 $P_{ij} = e^{X_{ij}} \implies \frac{\partial P_{ij}}{\partial X_{ij}} = P_{ij}$, 若能求出 $\frac{\partial L}{\partial P}$，最终结果就是 $\nabla_X L = \nabla_P L \odot P$。&lt;/p&gt;</description>
    </item>
    <item>
      <title>DeepSeek mHC的简单演示（可能有错误）</title>
      <link>https://da1sy-petals.vercel.app/posts/manifold-hc/</link>
      <pubDate>Sun, 04 Jan 2026 19:55:33 +0800</pubDate>
      <guid>https://da1sy-petals.vercel.app/posts/manifold-hc/</guid>
      <description>&lt;p&gt;DeepSeek发布了最新的魔改版Residual Connection：Manifold Constrained Hyper-Connection.&lt;/p&gt;&#xA;&lt;p&gt;其基本思路是把旁路residual限制在某个集合上&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;文中用更“几何”的manifold一词表述;&lt;/li&gt;&#xA;&lt;li&gt;退化的例子就是Kaiming的原版Residual Connection，约束是&lt;code&gt;residual = x&lt;/code&gt;&lt;/li&gt;&#xA;&lt;li&gt;本文则将residual projection matrix的谱范数限制在 $\leq 1$, 使其在正反向传播的时候不易爆炸/崩溃.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;类似的思路还可以在比如物理模拟中看到：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;通过将物体的transformation matrix约束在$SE(3)$，禁止物体形变，从而模拟刚体。&lt;/li&gt;&#xA;&lt;li&gt;进一步，在Affine body dynamics中，通过一个惩罚项惩罚transformation matrix偏离$SE(3)$的部分，将物体的transformation映射到尽可能近的$SE(3)$，从而在物体的行为尽可能接近刚体的同时，解决系统难以求解（有约束 $\rightarrow$无约束）的问题。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;HC的基本思路应该是：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;原本就有n个stream&lt;/li&gt;&#xA;&lt;li&gt;在主线forward的时候，把n个stream合并为一个（pre-proj），通过这一层网络（$f$），然后再打散回n个stream（post-proj）&#xA;&lt;ul&gt;&#xA;&lt;li&gt;即 $y=\text{post-proj} \circ f \circ \text{pre-proj}(x)$&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;支线复制输入x，通过一个res-proj进行信息混合之后，加回主线的输出&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;mHC对这个res-proj进行约束：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;要求其为bistochastic matrix.&#xA;&lt;ul&gt;&#xA;&lt;li&gt;具体做法就是通过sinkhorn迭代直接将其映射到最接近的doubly stochastic matrix上。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;个人想法: 这里是不是也可以参考muon中的正交化方法, 将奇异值全部设置为1?&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;可能需要考察的点包括:&#xA;&lt;ul&gt;&#xA;&lt;li&gt;muon中用的N-S迭代在较好的系数 $a,b,c$ 下是否能够收敛良好&lt;/li&gt;&#xA;&lt;li&gt;如果不希望保留中间结果, 反向怎么算 (可能也需要回溯正向传播的迭代过程)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;我自己写的，可能有错误的简单的代码实现&lt;a href=&#34;https://gist.github.com/Da1sypetals/0a7f70bf6b4ca7d46f0a1c5910e1a8b6&#34;&gt;在这里&lt;/a&gt;：&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Reference: https://www.arxiv.org/abs/2512.24880&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; torch&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; torch.nn &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; nn&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; torch.nn.functional &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; F&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; einops &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; ein&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; icecream &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; ic&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;N_ITER &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;20&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;sinkhorn_knopp&lt;/span&gt;(mat: torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Tensor) &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Tensor:&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#34;&amp;#34;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    mat: (..., n, n)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    Sidenote: IMO this technique should be subject to frequent change if mHC is proved to be effective&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    &amp;#34;&amp;#34;&amp;#34;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; _ &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(N_ITER):&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        mat &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; mat &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; mat&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sum(&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, keepdim&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;True&lt;/span&gt;)  &lt;span style=&#34;color:#75715e&#34;&gt;# column normalize&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        mat &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; mat &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; mat&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sum(&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, keepdim&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;True&lt;/span&gt;)  &lt;span style=&#34;color:#75715e&#34;&gt;# row normalize&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; mat&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;n &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;  &lt;span style=&#34;color:#75715e&#34;&gt;# stream width&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;C &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;256&lt;/span&gt;  &lt;span style=&#34;color:#75715e&#34;&gt;# embedding dim&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;norm &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; nn&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;RMSNorm((n &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; C,))&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;phi_pre &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; nn&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Parameter(torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;randn(n &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; C, n))&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;phi_post &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; nn&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Parameter(torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;randn(n &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; C, n))&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;phi_res &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; nn&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Parameter(torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;randn(n &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; C, n &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; n))&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;b_pre &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; nn&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Parameter(torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;randn(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, n))&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;b_post &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; nn&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Parameter(torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;randn(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, n))&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;b_res &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; nn&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Parameter(torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;randn(n, n))&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;alpha_pre &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; nn&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Parameter(torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tensor(&lt;span style=&#34;color:#ae81ff&#34;&gt;0.1&lt;/span&gt;))  &lt;span style=&#34;color:#75715e&#34;&gt;# for dimension illustration purposes&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;alpha_post &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; nn&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Parameter(torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tensor(&lt;span style=&#34;color:#ae81ff&#34;&gt;0.1&lt;/span&gt;))  &lt;span style=&#34;color:#75715e&#34;&gt;# for dimension illustration purposes&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;alpha_res &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; nn&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Parameter(torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tensor(&lt;span style=&#34;color:#ae81ff&#34;&gt;1.0&lt;/span&gt;))  &lt;span style=&#34;color:#75715e&#34;&gt;# for dimension illustration purposes&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;broadcast_to_n_stream&lt;/span&gt;(xl: torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Tensor) &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Tensor:&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; ein&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;repeat(xl, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;... C -&amp;gt; ... n C&amp;#34;&lt;/span&gt;, n&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;n)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;reduce_to_one_stream&lt;/span&gt;(xl: torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Tensor) &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Tensor:&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; ein&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reduce(xl, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;... n C -&amp;gt; ... C&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;mean&amp;#34;&lt;/span&gt;)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;manifold_constrained_hyperconnection&lt;/span&gt;(xl: torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Tensor, layer: nn&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Module) &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Tensor:&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;# x: (..., n, C)&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;# ===== residual =====&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    xl_vec &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; ein&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;rearrange(xl, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;... n C -&amp;gt; ... (n C)&amp;#34;&lt;/span&gt;)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    xl_vec_prime &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; norm(xl_vec)  &lt;span style=&#34;color:#75715e&#34;&gt;# (..., n*C)&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;# data dependent mapping construction&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    h_tilde_pre &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; alpha_pre &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; (xl_vec_prime &lt;span style=&#34;color:#f92672&#34;&gt;@&lt;/span&gt; phi_pre) &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; b_pre  &lt;span style=&#34;color:#75715e&#34;&gt;# (..., n)&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    h_tilde_post &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; alpha_post &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; (xl_vec_prime &lt;span style=&#34;color:#f92672&#34;&gt;@&lt;/span&gt; phi_post) &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; b_post  &lt;span style=&#34;color:#75715e&#34;&gt;# (..., n)&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    h_tilde_res &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; (&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        alpha_res&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; ein&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;rearrange(&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            (xl_vec_prime &lt;span style=&#34;color:#f92672&#34;&gt;@&lt;/span&gt; phi_res),&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;... (m n) -&amp;gt; ... m n&amp;#34;&lt;/span&gt;,&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            n&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;n,&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        )&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; b_res&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    )  &lt;span style=&#34;color:#75715e&#34;&gt;# (..., n, n)&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    h_pre &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; F&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sigmoid(h_tilde_pre)  &lt;span style=&#34;color:#75715e&#34;&gt;# (..., n)&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    h_post &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; F&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sigmoid(h_tilde_post)  &lt;span style=&#34;color:#75715e&#34;&gt;# (..., n)&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    h_res &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; sinkhorn_knopp(h_tilde_res&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;exp())  &lt;span style=&#34;color:#75715e&#34;&gt;# (..., n, n)&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    ic(h_pre&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    ic(h_post&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    ic(h_res&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;# data dependent mapping application&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    residual &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; ein&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;einsum(h_res, xl, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;... m n, ... n C -&amp;gt; ... m C&amp;#34;&lt;/span&gt;)  &lt;span style=&#34;color:#75715e&#34;&gt;# m=n&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    ic(residual&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;# ===== mainstream =====&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    x_pre &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; ein&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;einsum(h_pre, xl, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;... n, ... n C -&amp;gt; ... C&amp;#34;&lt;/span&gt;)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    ic(x_pre&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    layer_out &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; layer(x_pre)  &lt;span style=&#34;color:#75715e&#34;&gt;# (..., C)&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    ic(layer_out&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    x_post &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; ein&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;einsum(h_post, layer_out, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;... n, ... C -&amp;gt; ... n C&amp;#34;&lt;/span&gt;)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    ic(x_post&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    out &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; x_post &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; residual  &lt;span style=&#34;color:#75715e&#34;&gt;# (..., n, C)&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; out&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;batch_dims &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; (&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;100&lt;/span&gt;)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;layers &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [nn&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Identity() &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; _ &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;)]  &lt;span style=&#34;color:#75715e&#34;&gt;# for illustration purpose&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; __name__ &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;__main__&amp;#34;&lt;/span&gt;:&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;randn(&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;batch_dims, C)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    xl &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; broadcast_to_n_stream(x)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;# simulate 3 layers&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;===== layer 1 =====&amp;#34;&lt;/span&gt;)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    xl &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; manifold_constrained_hyperconnection(xl, layers[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;])&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;===== layer 2 =====&amp;#34;&lt;/span&gt;)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    xl &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; manifold_constrained_hyperconnection(xl, layers[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;])&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;===== layer 3 =====&amp;#34;&lt;/span&gt;)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    xl &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; manifold_constrained_hyperconnection(xl, layers[&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;])&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    out &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; reduce_to_one_stream(xl)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;===== output =====&amp;#34;&lt;/span&gt;)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    ic(out&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;</description>
    </item>
    <item>
      <title>cuTile 历险记，第2集：eDSL, DX &amp; LSP</title>
      <link>https://da1sy-petals.vercel.app/posts/cutile-2/</link>
      <pubDate>Thu, 11 Dec 2025 10:19:34 +0800</pubDate>
      <guid>https://da1sy-petals.vercel.app/posts/cutile-2/</guid>
      <description>&lt;h2 id=&#34;edsl开发难度以及dx&#34;&gt;eDSL，开发难度，以及DX&lt;/h2&gt;&#xA;&lt;p&gt;DSL（Domain-Specific Language，领域特定语言）是一种专为特定问题领域设计的编程语言。&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;GPT老师: &lt;br&gt;&#xA;DSL 可分为两类： &lt;br&gt; &lt;br&gt;&#xA;外部 DSL（External DSL）&#xA;&lt;br&gt;.  是一种独立的语言，通常需要专门的编译器或解释器。&#xA;&lt;br&gt;.  优点：语法可以完全为领域定制，表达力强。&#xA;&lt;br&gt;.  缺点：需要开发parser。&#xA;&lt;br&gt;.  示例：SQL（用于数据库查询）、正则表达式、Makefile、LaTeX。&#xA;&lt;br&gt;&lt;br&gt;&#xA;内嵌 DSL（embedded DSL，eDSL）&#xA;&lt;br&gt;.  并非独立语言，而是利用宿主通用语言的语法和特性，在其内部“模拟”出一种贴近领域的表达方式。&#xA;&lt;br&gt;.  依赖宿主语言的lexer/parser，无需额外实现。&#xA;&lt;br&gt;.  优点：开发便捷。&#xA;&lt;br&gt;.  缺点：受限于宿主语言的语法和表达能力；IDE往往无法提供针对DSL的insight（内部类型信息等）。&#xA;&lt;br&gt;.  示例：被&lt;code&gt;@torch.compile&lt;/code&gt;作用的torch代码，triton，以及我们的主角cuTile。&lt;/p&gt;&lt;/blockquote&gt;&#xA;&lt;p&gt;听某写了很多个triton kernel的大佬同事说，主要的debug triton代码的方式是：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;跑一遍看报错&lt;/li&gt;&#xA;&lt;li&gt;triton提供的print&lt;/li&gt;&#xA;&lt;li&gt;读IR&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;并没有能够提供良好的IDE功能的软件可以用，导致许多可以静态知道（并让IDE提供诊断）的类型信息需要靠运行时报错来修复，造成了（个人认为的）DX在这方面的欠缺。&lt;/p&gt;&#xA;&lt;h2 id=&#34;找回静态的信息&#34;&gt;找回静态的信息&lt;/h2&gt;&#xA;&lt;h3 id=&#34;编译器的一半的一半的一半&#34;&gt;编译器的一半的一半的一半&lt;/h3&gt;&#xA;&lt;p&gt;先把cuTile的整个编译流程切一切。&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;上半：开源部分&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;上半：python -&amp;gt; cutile-python-ir (python实现)&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;em&gt;上半（*）：参数检查，语法检查（不合法的python对象等），类型检查（tile shape/dtype mismatch）&lt;/em&gt;&lt;/li&gt;&#xA;&lt;li&gt;下半：基本优化，&lt;code&gt;eliminate_assign_ops&lt;/code&gt;, &lt;code&gt;hoist_loop_invariants&lt;/code&gt;, &lt;code&gt;dead_code_elimination_pass&lt;/code&gt; 等&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;下半：cutile-python-ir -&amp;gt; TileIR (C++实现)&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;下半：&lt;code&gt;tileiras&lt;/code&gt;&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;需求&#34;&gt;需求&lt;/h3&gt;&#xA;&lt;p&gt;尝试写一个软件，找回这些静态的信息，并显示到编辑器上。&#xA;我对这个软件的需求是：把（*）的检查所确定的尽可能多的信息显示在源代码上。&lt;/p&gt;&#xA;&lt;h2 id=&#34;实现&#34;&gt;实现&lt;/h2&gt;&#xA;&lt;p&gt;还好目前cuTile的编译器python侧代码还比较清晰, 趁还没有太多更新先研究个大概&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;也有一种可能, 机器相关的特性会完全放到&lt;code&gt;tileiras&lt;/code&gt;里面做, python侧永远都不会变得太复杂了&lt;/p&gt;&lt;/blockquote&gt;&#xA;&lt;h3 id=&#34;大致结构&#34;&gt;大致结构&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;查看infer type pass生成的IR（下面称为IR）可以发现：&lt;/p&gt;</description>
    </item>
    <item>
      <title>cuTile 历险记，第1集：编译</title>
      <link>https://da1sy-petals.vercel.app/posts/cutile-1/</link>
      <pubDate>Sat, 06 Dec 2025 16:30:12 +0800</pubDate>
      <guid>https://da1sy-petals.vercel.app/posts/cutile-1/</guid>
      <description>&lt;p&gt;原本第一集应该是语法和随便找个bmm，flash-attn2的kernel来实现一下并且进行benchmark的，因为所以gpu编程博客都是这样的。&lt;/p&gt;&#xA;&lt;p&gt;&lt;em&gt;Disclaimer: 我不了解编译器，以下所有内容基于自己的理解，和编译器术语出现偏差乃至出错之处敬请指出&lt;/em&gt;&lt;/p&gt;&#xA;&lt;p&gt;nv官网提示我们，需要cuda driver一个较高的版本，cuda toolkit 13.1（tileiras汇编器），以及blackwell以上的GPU（目前）才能使用cutile。但是我没有b200或者50系（cc12）的游戏卡，我手上能碰到的机器刚好截至hopper，所以我并没有办法编译执行cutile程序，失去了尝鲜的机会。&lt;/p&gt;&#xA;&lt;p&gt;但是有了cutile-python这个python端，下降到mlir之前的中间代码还是可以了解一下的。&lt;/p&gt;&#xA;&lt;h2 id=&#34;探索过程&#34;&gt;探索过程&lt;/h2&gt;&#xA;&lt;h3 id=&#34;屏蔽c库&#34;&gt;屏蔽C库&lt;/h3&gt;&#xA;&lt;p&gt;我们发现报错发生在&lt;code&gt;src/cuda/tile/_cext.pyi&lt;/code&gt;，提示驱动版本过低。vibe coding启动，我们让LLM把_cext这个cpp库用一个&lt;a href=&#34;https://github.com/Da1sypetals/cutile-python/blob/typecheck/src/cuda/tile/_cext.py&#34;&gt;mock&lt;/a&gt;进行替代，骗过编译器；然后包装了一个CutileIrDump类，通过&lt;code&gt;cuda.tile._compile._get_final_ir&lt;/code&gt;函数可以获取到cuTile IR （不是TileIR）。有两种格式，人类可读的和binary的。&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;../images/cutileir.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;了解编译流程，我们主要从&lt;code&gt;cuda.tile._compile._get_final_ir&lt;/code&gt;入手。&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;_get_final_ir&lt;/span&gt;(pyfunc, args, tile_context) &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; ir&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Function:&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    ir_ctx &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; ir&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;IRContext()&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    func_ir: ir&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Function &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; get_function_ir(pyfunc, ir_ctx, call_site&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;None&lt;/span&gt;)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    ir_args &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; func_ir&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;bind_arguments(args, get_constant_annotations(pyfunc))&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    func_ir &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; infer_types_pass(func_ir, ir_args, pyfunc, tile_context)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;# -------- 上方：语法、类型检查 ----------&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;# -------- 下方：（部分）机器无关优化 ----------&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    eliminate_assign_ops(func_ir) &lt;span style=&#34;color:#75715e&#34;&gt;# &amp;lt;-- breakpoint here&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    dead_code_elimination_pass(func_ir)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;not&lt;/span&gt; CUDA_TILE_TESTING_DISABLE_TOKEN_ORDER:&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        alias_result &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; alias_analysis_pass(func_ir)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        token_order_pass(func_ir, alias_result)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    rewrite_patterns(func_ir)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;# Loop invariant code motion needs to run after the token order pass.&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;# Otherwise, it may incorrectly hoist load operations out of the loop.&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    hoist_loop_invariants(func_ir)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    split_loops(func_ir&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;root_block)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    dead_code_elimination_pass(func_ir)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; func_ir&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;大概看一下代码：&lt;/p&gt;</description>
    </item>
    <item>
      <title>cuTile 历险记，第0集：心智模型</title>
      <link>https://da1sy-petals.vercel.app/posts/cutile-0/</link>
      <pubDate>Thu, 13 Nov 2025 19:38:26 +0800</pubDate>
      <guid>https://da1sy-petals.vercel.app/posts/cutile-0/</guid>
      <description>&lt;p&gt;首先，（在通常意义上来说）cuTile不是一个库，是一门语言，因为他&lt;del&gt;劫持&lt;/del&gt;捕获了Python的源码并且使用了自己的编译器对这段代码进行编译、Lower、执行等操作。这一点在宏观上可以对比triton。&lt;/p&gt;&#xA;&lt;p&gt;因此在使用cuTile的时候，要一直告诉自己 &amp;ldquo;This is not Python&amp;rdquo;.&lt;/p&gt;&#xA;&lt;h2 id=&#34;abstraction-level&#34;&gt;Abstraction Level&lt;/h2&gt;&#xA;&lt;p&gt;作为用户需要知道的：这门语言工作在哪个抽象层级。这里指的是这门语言提供的接口，&lt;strong&gt;并不&lt;/strong&gt;直接对应硬件。cuTile的compiler magic会把我们写的代码map到硬件上，但这并不是写cuTile的程序员需要关心的。&lt;/p&gt;&#xA;&lt;h3 id=&#34;内存&#34;&gt;内存&lt;/h3&gt;&#xA;&lt;p&gt;从逻辑上来说，cuTile暴露给用户的内存分为两种：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Global Memory (Gmem):&#xA;&lt;ul&gt;&#xA;&lt;li&gt;读写速度：慢&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;Cache:&#xA;&lt;ul&gt;&#xA;&lt;li&gt;读写速度：较快&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;编程模型&#34;&gt;编程模型&lt;/h3&gt;&#xA;&lt;h4 id=&#34;global-array&#34;&gt;Global Array&lt;/h4&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;存放在Gmem上&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;操作：只能进行Load(从Gmem读取到Cache)，以及Store(从Cache存入Gmem)。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;来源：PyTorch tensor 可以直接传入。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h4 id=&#34;tile-array&#34;&gt;Tile Array&lt;/h4&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;存放在Cache上&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;操作：可以在上面进行数学操作如&lt;code&gt;sin&lt;/code&gt;, &lt;code&gt;mma&lt;/code&gt;等。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;来源：tile kernel内创建(例如&lt;code&gt;cuda.tile.zeros&lt;/code&gt;)，或者Global Array load得到&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;Immutable&lt;/strong&gt;：&lt;strong&gt;在逻辑上&lt;/strong&gt;，任何对Tile Array的计算操作都会返回新的Tile Array (Returns copies, not views)；你也不能直接对Tile Array里面的内容进行修改。&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;cuTile的compiler magic肯定会在内部防止冗余内存的创建，毕竟速度&amp;gt;=SRAM的存储是如此昂贵；但是程序员是以immutable的形式编程的。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;metadata: dtype, shape&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;layout对用户是不可见的，交由编译器处理。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h4 id=&#34;示意图&#34;&gt;示意图：&lt;/h4&gt;&#xA;&lt;p&gt;&lt;img src=&#34;../images/2025-11-14-10-38-36.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;编程问题&#34;&gt;编程问题&lt;/h2&gt;&#xA;&lt;h3 id=&#34;问题输入&#34;&gt;问题输入&lt;/h3&gt;&#xA;&lt;p&gt;Tensor 级别的计算过程，比如：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Matmul+activation&lt;/li&gt;&#xA;&lt;li&gt;Attention Mechanism&lt;/li&gt;&#xA;&lt;li&gt;其他可以用NumPy/PyTorch这一级别的抽象所描述的算法。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;cutile是用来解决什么问题的&#34;&gt;cuTile是用来解决什么问题的&lt;/h3&gt;&#xA;&lt;p&gt;对于同一个算法，如何明智地加载数据、进行计算，可以减少Load/Store的数据量、增大计算密度，并且减少需要在Gmem上materialize的中间数据。&lt;/p&gt;&#xA;&lt;h2 id=&#34;奇怪的想法&#34;&gt;奇怪的想法&lt;/h2&gt;&#xA;&lt;p&gt;据nv的编译器工程师在各种talk里面所说，cuTile将会屏蔽所有&lt;strong&gt;硬件特异性&lt;/strong&gt;的功能，交由编译器处理。如果是这样的话，其他硬件厂商是不是更方便在这一层级往下做？比如，直接开发一套&lt;code&gt;rocm.tile&lt;/code&gt;，在接口上对标&lt;code&gt;cuda.tile&lt;/code&gt;，然后实现自己的编译器，Lower到自己的具有硬件特异性的IR代码上进行优化。这样似乎就避免了triton目前推出越来越多nvidia定制的功能，导致其他硬件厂商无法跟进的问题。&lt;/p&gt;&#xA;&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=uZTtViomW6w&#34;&gt;cuTile talk @ scipy&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=UEdGJGz8Eyg&#34;&gt;cuTile talk @ torch&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>Triton Tensor Descriptor: 茴字的第三种写法</title>
      <link>https://da1sy-petals.vercel.app/posts/triton-td/</link>
      <pubDate>Fri, 31 Oct 2025 21:49:36 +0800</pubDate>
      <guid>https://da1sy-petals.vercel.app/posts/triton-td/</guid>
      <description>&lt;p&gt;今天我们来介绍&lt;del&gt;茴字的第3种写法&lt;/del&gt;&lt;/p&gt;&#xA;&lt;p&gt;今天我们来介绍 Triton 中的第三种进行 tensor 指针运算的 API：Tensor Descriptor。内容来自&lt;a href=&#34;https://triton-lang.org/main/python-api/generated/triton.language.make_tensor_descriptor.html&#34;&gt;triton 文档&lt;/a&gt;。&lt;/p&gt;&#xA;&lt;h2 id=&#34;关于-triton-的基本概念&#34;&gt;关于 triton 的基本概念&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;triton 只是和 python 共用语言前端（我们写的代码），triton 会接管 python 的 AST，然后后续步骤就交由 triton 编译器一步步 lower 到 GPU 代码了。&lt;/li&gt;&#xA;&lt;li&gt;在第一次执行一个 kernel 之前发生的事情称为编译期，之后的执行称为运行时。&lt;/li&gt;&#xA;&lt;li&gt;triton的 kernel launch 的grid 参数是一个 ndrange，在 kernel 里面获取到的 &lt;code&gt;program_id(i)&lt;/code&gt; 就是第 i 维度的 index。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;tensor-descriptor的用法&#34;&gt;Tensor Descriptor的用法&lt;/h2&gt;&#xA;&lt;h3 id=&#34;创建&#34;&gt;创建&lt;/h3&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;desc &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tl&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;make_tensor_descriptor(&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    pointer,&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    shape&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[M, N],&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    strides&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[N, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;],&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    block_shape&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[M_BLOCK, N_BLOCK],&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;其中：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;code&gt;pointer&lt;/code&gt; 就是传入triton kernel的tensor&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;shape&lt;/code&gt; 是一个整数列表，&lt;strong&gt;可以编译期确定，也可以运行时动态传入，可以不是tilesize的倍数&lt;/strong&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;传入 &lt;code&gt;[tensor.shape(i) for i in range(tensor.dim())]&lt;/code&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;strides&lt;/code&gt; 是一个整数列表，&lt;strong&gt;可以编译期确定，也可以运行时动态传入，可以不是tilesize的倍数&lt;/strong&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;传入 &lt;code&gt;[tensor.stride(i) for i in range(tensor.dim())]&lt;/code&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;block_shape&lt;/code&gt; 是一个整数列表，&lt;strong&gt;必须是编译期常量&lt;/strong&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;对应概念是CUDA的blockDim&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;上述三者的长度必须相同，等于输入tensor的 &lt;code&gt;.dim()&lt;/code&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;读写&#34;&gt;读写&lt;/h3&gt;&#xA;&lt;h4 id=&#34;读&#34;&gt;读&lt;/h4&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;value &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; desc&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;load([moffset, noffset])&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;其中唯一的参数offsets是一个整数列表：&lt;/p&gt;</description>
    </item>
    <item>
      <title>我的 Mac Mini Setup</title>
      <link>https://da1sy-petals.vercel.app/posts/macmini-setup/</link>
      <pubDate>Fri, 24 Oct 2025 09:55:27 +0800</pubDate>
      <guid>https://da1sy-petals.vercel.app/posts/macmini-setup/</guid>
      <description>&lt;p&gt;花点时间配置一下我的Mac Mini.&lt;/p&gt;&#xA;&lt;h2 id=&#34;配件&#34;&gt;配件&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Mac Mini M4 最丐版，3349&lt;/li&gt;&#xA;&lt;li&gt;Samsung 990 evo plus, 996&lt;/li&gt;&#xA;&lt;li&gt;海备思硬盘盒+扩展坞，471&lt;/li&gt;&#xA;&lt;li&gt;Redmi 显示器 4K 60Hz，1449&lt;/li&gt;&#xA;&lt;li&gt;鼠标，65&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;setup&#34;&gt;Setup&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;把系统装到外接硬盘里：&lt;a href=&#34;https://www.bilibili.com/video/BV1m2rUYcEQA&#34;&gt;教程&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;鼠标滚轮反向&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;软件&#34;&gt;软件&lt;/h2&gt;&#xA;&lt;h3 id=&#34;浏览器&#34;&gt;浏览器&lt;/h3&gt;&#xA;&lt;p&gt;我的需求是：&lt;strong&gt;Vertical tab, 以及熟悉&lt;/strong&gt;。&lt;/p&gt;&#xA;&lt;p&gt;因为我之前在windows用的是edge，在mac上一搜居然也有，于是就直接用edge懒得换了。&lt;/p&gt;&#xA;&lt;h3 id=&#34;terminal&#34;&gt;Terminal&lt;/h3&gt;&#xA;&lt;h4 id=&#34;emulator-iterm2&#34;&gt;Emulator: iTerm2:&lt;/h4&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;主题：&lt;a href=&#34;https://github.com/phureewat29/fairyfloss&#34;&gt;FairyFloss&lt;/a&gt;，一个很girly的主题，背景颜色改深了一点&lt;/li&gt;&#xA;&lt;li&gt;字体：Jetbrains Mono&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h4 id=&#34;shell-fish&#34;&gt;Shell: fish&lt;/h4&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;注意去github装 fish 4，软件源上很有可能还是fish 3.7，fish 3 已经不维护了&lt;/li&gt;&#xA;&lt;li&gt;设置默认shell：有两个步骤，两个都要做：&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;code&gt;chsh&lt;/code&gt; 命令，具体格式请问AI&lt;/li&gt;&#xA;&lt;li&gt;按照下面指引&#xA;&lt;img src=&#34;../images/2025-10-24-10-12-50.png&#34; alt=&#34;&#34;&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;笔记&#34;&gt;笔记&lt;/h3&gt;&#xA;&lt;p&gt;ima.copilot，主要为了省心，我并没有折腾私有部署的兴趣，对信息安全也不甚关心。&lt;/p&gt;&#xA;&lt;h3 id=&#34;brew换源&#34;&gt;Brew换源&lt;/h3&gt;&#xA;&lt;p&gt;详见：&lt;a href=&#34;../brew-sources/&#34;&gt;这篇帖子&lt;/a&gt;&lt;/p&gt;&#xA;&lt;h3 id=&#34;实用软件&#34;&gt;实用软件&lt;/h3&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;typst&#xD;&#xA;fd (replacement of find)&#xD;&#xA;ripgrep&#xA;&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    <item>
      <title>Brew 换源</title>
      <link>https://da1sy-petals.vercel.app/posts/brew-sources/</link>
      <pubDate>Thu, 23 Oct 2025 00:00:00 +0000</pubDate>
      <guid>https://da1sy-petals.vercel.app/posts/brew-sources/</guid>
      <description>&lt;p&gt;原文：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://mirrors.ustc.edu.cn/help/brew.git.html&#34;&gt;https://mirrors.ustc.edu.cn/help/brew.git.html&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://mirrors.ustc.edu.cn/help/homebrew-bottles.html&#34;&gt;https://mirrors.ustc.edu.cn/help/homebrew-bottles.html&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://mirrors.ustc.edu.cn/help/homebrew-core.git.html&#34;&gt;https://mirrors.ustc.edu.cn/help/homebrew-core.git.html&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://mirrors.ustc.edu.cn/help/homebrew-cask.git.html&#34;&gt;https://mirrors.ustc.edu.cn/help/homebrew-cask.git.html&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;-一设置环境变量永久生效针对-fish&#34;&gt;✅ 一、设置环境变量（永久生效，针对 fish）&lt;/h2&gt;&#xA;&lt;p&gt;在 fish 中，永久设置环境变量应使用   set -Ux （全局、导出、持久化）：&#xA;（set文档： https://fishshell.com/docs/current/cmds/set.html ）&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Homebrew 主程序仓库&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;set -Ux HOMEBREW_BREW_GIT_REMOTE https://mirrors.ustc.edu.cn/brew.git&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Homebrew 核心公式仓库&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;set -Ux HOMEBREW_CORE_GIT_REMOTE https://mirrors.ustc.edu.cn/homebrew-core.git&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 预编译二进制包（bottles）域名&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;set -Ux HOMEBREW_BOTTLE_DOMAIN https://mirrors.ustc.edu.cn/homebrew-bottles&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 元数据 API 域名（Brew 4.0+ 必需）&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;set -Ux HOMEBREW_API_DOMAIN https://mirrors.ustc.edu.cn/homebrew-bottles/api&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;-二配置-homebrew-cask-使用镜像git-仓库方式&#34;&gt;✅ 二、配置 Homebrew Cask 使用镜像（Git 仓库方式）&lt;/h2&gt;&#xA;&lt;p&gt;由于Brew 4.0+ 默认使用 JSON API，大多数情况下不需要手动设置 cask 的 Git 镜像。但如果你仍希望显式使用 USTC 的 cask Git 仓库（例如离线环境或调试），请运行：&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;brew tap --custom-remote homebrew/cask https://mirrors.ustc.edu.cn/homebrew-cask.git&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;blockquote&gt;&#xA;&lt;p&gt;⚠️ 注意：如果你以后想恢复官方源，可运行：&#xA;&lt;code&gt;brew tap --custom-remote homebrew/cask https://github.com/Homebrew/homebrew-cask&lt;/code&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>一个关于GNN在Tensor Core上的实现的数学问题</title>
      <link>https://da1sy-petals.vercel.app/posts/interesting-math-gnn-tensor-core/</link>
      <pubDate>Sat, 04 Oct 2025 16:07:12 +0800</pubDate>
      <guid>https://da1sy-petals.vercel.app/posts/interesting-math-gnn-tensor-core/</guid>
      <description>&lt;h2 id=&#34;完整的问题&#34;&gt;完整的问题&lt;/h2&gt;&#xA;&lt;p&gt;可以看&lt;a href=&#34;https://g.co/gemini/share/ad1bd7ed4a63&#34;&gt;我和Gemini的对话&lt;/a&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;抽象出的问题&#34;&gt;抽象出的问题&lt;/h2&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;假设在mxn的矩阵中全为0，现在进行两个操作：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;以avgdeg/n的概率将矩阵中的值变为1；&lt;/li&gt;&#xA;&lt;li&gt;如果矩阵中有一列有一个1，那就把这一列都变成1。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;现在计算avgdeg&amp;rsquo;为矩阵中1的个数/(mn)，记avgdeg=d, avgdeg&amp;rsquo;=d&#39;&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;h2 id=&#34;kimi的回答&#34;&gt;Kimi的回答&lt;/h2&gt;&#xA;&lt;p&gt;我们来逐步分析这个问题，并给出数学推导。&lt;/p&gt;&#xA;&lt;h3 id=&#34;问题设定&#34;&gt;问题设定&lt;/h3&gt;&#xA;&lt;p&gt;我们有一个 $ m \times n $ 的矩阵，初始时所有元素为 0。&lt;/p&gt;&#xA;&lt;p&gt;进行两个操作：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;随机置 1&lt;/strong&gt;：以概率 $ \frac{\text{avgdeg}}{n} $ 将每个元素独立地变为 1（否则保持 0）。&lt;br&gt;&#xA;记 $ d = \text{avgdeg} $，所以每个元素变为 1 的概率是 $ p = \frac{d}{n} $。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;列传播&lt;/strong&gt;：如果某一列中&lt;strong&gt;至少有一个 1&lt;/strong&gt;，则将该列&lt;strong&gt;所有元素都变为 1&lt;/strong&gt;。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;最终，我们计算新的平均度：&lt;/p&gt;&#xA;\[&#xA;d&#39; = \frac{\text{矩阵中 1 的总数}}{mn}&#xA;\]&lt;p&gt;我们的目标是求 $ d&#39; $ 关于 $ d $ 的表达式，即 $ d&#39; = f(d) $。&lt;/p&gt;&#xA;&lt;h3 id=&#34;步骤-1计算某一列在操作-1-后至少有一个-1的概率&#34;&gt;步骤 1：计算某一列在操作 1 后&lt;strong&gt;至少有一个 1&lt;/strong&gt;的概率&lt;/h3&gt;&#xA;&lt;p&gt;在操作 1 后，每个元素独立地以概率 $ p = \frac{d}{n} $ 变为 1。&lt;/p&gt;</description>
    </item>
    <item>
      <title>近期GNN Attention算子优化工作速览</title>
      <link>https://da1sy-petals.vercel.app/posts/gnn-optim/</link>
      <pubDate>Thu, 02 Oct 2025 00:00:00 +0000</pubDate>
      <guid>https://da1sy-petals.vercel.app/posts/gnn-optim/</guid>
      <description>&lt;p&gt;注：本文用LLM辅助写作的地方主要在：&lt;em&gt;&lt;strong&gt;我认为LLM比我理解的更好的地方，会用LLM的表述代替。&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;问题设定&#34;&gt;问题设定&lt;/h2&gt;&#xA;&lt;p&gt;需要计算Graph Transformer中的Attention。在此我们忽略multihead-attention，考虑基本的single-head attention.&lt;/p&gt;&#xA;&lt;p&gt;此外，我们的attention mask(邻接矩阵A)是非结构化稀疏的。如果你的attention mask是结构化稀疏的，比如blockwise等可以被代码表示的稀疏pattern，你应该使用flash attention的varlen变体, 或者flex attention等attention编译器。&lt;/p&gt;&#xA;&lt;h3 id=&#34;notation&#34;&gt;Notation&lt;/h3&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;n: 图节点数，规模为 1k~1M&#xD;&#xA;nnz: 图边数（稀疏矩阵非零元素数，Num NonZero）&#xD;&#xA;&#x9;  规模为10n~1000n&#xD;&#xA;q, k, v: (n, d)&#xD;&#xA;A: (n, n), binary, 高度稀疏&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;计算公式&#34;&gt;计算公式&lt;/h3&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;softmax((q @ k.transpose()) * A) @ V&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;其中，&lt;code&gt;@&lt;/code&gt; 表示矩阵乘法，&lt;code&gt;*&lt;/code&gt;表示element-wise乘法。&lt;/p&gt;&#xA;&lt;h2 id=&#34;实现naive-version&#34;&gt;实现：naive version&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;最简单的就是把A给materialize出来，然后用作attention_mask。问题是A是$n^2$的，显存不够用。&lt;/li&gt;&#xA;&lt;li&gt;A用COO方式存储，大小(2,nnz)，然后先把每条边的qk-pair取出来得到(nnz,d)，然后再做reduce和scatter, 和V相乘。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;reformulate&#34;&gt;Reformulate&lt;/h2&gt;&#xA;&lt;p&gt;我们引入三个算子:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;SDDMM (Sampled Dense-Dense MatMul)&lt;/strong&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;A (m, k), B (k, n), 稠密&lt;/li&gt;&#xA;&lt;li&gt;M (n, n)， 稀疏&#xA;SDDMM(A, B, M) 定义为：&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;for i, j in product(range(n), range(n)):&#xD;&#xA;&#x9;if M[i, j] != 0:&#xD;&#xA;&#x9;&#x9;out[i, j] = dot(A[i,:], B[:,j])&#xD;&#xA;&#x9;else:&#xD;&#xA;&#x9;&#x9;out[i, j] = 0&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;&#xA;&lt;li&gt;Sparse Softmax: 在稀疏矩阵上按行softmax&lt;/li&gt;&#xA;&lt;li&gt;SpMM：sparse A @ dense B&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;此时我们的计算公式就可以重新写成:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Snapviewer Devlog #3: 性能优化</title>
      <link>https://da1sy-petals.vercel.app/posts/snapviewer-3-zh/</link>
      <pubDate>Sat, 07 Jun 2025 00:00:00 +0000</pubDate>
      <guid>https://da1sy-petals.vercel.app/posts/snapviewer-3-zh/</guid>
      <description>&lt;h1 id=&#34;内存与速度性能问题排查&#34;&gt;内存与速度性能问题排查&lt;/h1&gt;&#xA;&lt;p&gt;&lt;strong&gt;免责声明&lt;/strong&gt;：我主要在 Windows 上使用最新的稳定版 Rust 工具链和 CPython 3.13 进行开发和测试。&lt;/p&gt;&#xA;&lt;h2 id=&#34;1-背景与动机&#34;&gt;1. 背景与动机&lt;/h2&gt;&#xA;&lt;p&gt;SnapViewer 能够高效处理大型内存快照——例如，支持高达 500 MB 的压缩快照。然而，在处理 1.3 GB的snapshot的时，我发现了严重的内存和速度瓶颈：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;格式转换（pickle → 压缩 JSON）引发了约 30 GB 的内存峰值。&lt;/li&gt;&#xA;&lt;li&gt;将压缩 JSON 加载到 Rust 数据结构中又引发了另一次约 30 GB 的内存激增。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;频繁的 page fault 和强烈的磁盘 I/O（在任务管理器中观察到）导致应用程序响应迟缓，甚至频繁卡顿。为了解决这一问题，我们采用了 Profile-Guided Optimization（PGO，基于性能分析的优化）方法。&lt;/p&gt;&#xA;&lt;h2 id=&#34;2-profile-guided-optimizationpgo&#34;&gt;2. Profile-Guided Optimization（PGO）&lt;/h2&gt;&#xA;&lt;p&gt;PGO 需要通过实证分析来识别真正的热点。我首先使用 &lt;a href=&#34;https://crates.io/crates/memory-stats&#34;&gt;memory-stats&lt;/a&gt; crate 进行内存分析，在早期优化阶段进行轻量级检查。随后，我将数据加载流水线拆解为若干离散步骤：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;读取压缩文件（重度磁盘 I/O）&lt;/li&gt;&#xA;&lt;li&gt;从压缩流中提取 JSON 字符串&lt;/li&gt;&#xA;&lt;li&gt;将 JSON 反序列化为原生 Rust 数据结构&lt;/li&gt;&#xA;&lt;li&gt;填充内存中的 SQLite 数据库以支持即席 SQL 查询&lt;/li&gt;&#xA;&lt;li&gt;在 CPU 上构建三角网格（triangle mesh）&lt;/li&gt;&#xA;&lt;li&gt;初始化渲染窗口（CPU-GPU 数据传输）&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;性能分析揭示了两个主要的内存问题：过度使用 &lt;code&gt;clone&lt;/code&gt; 和多个中间数据结构。以下是我实施的优化措施。&lt;/p&gt;</description>
    </item>
    <item>
      <title>SnapViewer: 更快的PyTorch显存分配可视化</title>
      <link>https://da1sy-petals.vercel.app/posts/snapviewer-zh/</link>
      <pubDate>Fri, 06 Jun 2025 00:00:00 +0000</pubDate>
      <guid>https://da1sy-petals.vercel.app/posts/snapviewer-zh/</guid>
      <description>&lt;h2 id=&#34;背景&#34;&gt;背景&lt;/h2&gt;&#xA;&lt;p&gt;在使用 PyTorch 训练模型时，内存不足（OOM）错误是很常见的，因此需要对 GPU 内存进行优化。当简单的方法（如减少batch size）不再有效时，就需要分析模型本身的内存占用情况。&lt;/p&gt;&#xA;&lt;p&gt;此时，你可能会看到这份&lt;a href=&#34;https://docs.pytorch.org/docs/stable/torch_cuda_memory.html&#34;&gt;文档&lt;/a&gt;，它教你如何记录内存快照并在网站上进行可视化。&lt;/p&gt;&#xA;&lt;p&gt;但是这里存在一个严重的问题：这个网站性能比较差。&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;如果你的模型较小，快照只有几 MB，性能还可以接受。&lt;/li&gt;&#xA;&lt;li&gt;但是如果你的模型很大，快照达到几十甚至上百 MB，网站就会变得极慢，帧率可能低至每分钟 2-3 帧（非笔误）。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;我研究了网站的 JavaScript 代码，其主要功能是：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;手动加载 Python 的 pickle 文件；&lt;/li&gt;&#xA;&lt;li&gt;每次视口发生变化时重新解析原始数据为图形表示，然后将其渲染到屏幕上。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;这些解析逻辑用 JavaScript 编写，你可以想象一下每帧执行这些操作，处理上百 MB 数据要多久.&lt;/p&gt;&#xA;&lt;h2 id=&#34;灵感&#34;&gt;灵感&lt;/h2&gt;&#xA;&lt;p&gt;我当前的工作包括优化一个非LLM的深度学习模型。在处理数十亿参数的模型所导出的显存snapshot时，我遇到了这个问题。&lt;/p&gt;&#xA;&lt;p&gt;为什么不用现有的 LLM 基础设施而选择手动优化？简单地说，这个模型是研究人员自定义设计的，其中包含许多与标准 LLM 完全不同的模块。现在似乎每个人都认为深度学习就只是关于 LLM——以至于一些技术负责人也认为 LLM 的基础设施可以很容易地适配到其他模型上……不过我有点跑题了。&lt;/p&gt;&#xA;&lt;p&gt;最初，我写了一个简单的脚本来解析快照内容，希望能发现模型中的内存分配问题。但是在一个月的工作中，我发现我还是需要一个带有GUI的可视化器, 于是我开发了 SnapViewer.&lt;/p&gt;&#xA;&lt;p&gt;简而言之：内存快照的图形数据被解析并呈现为一个巨大的三角形mesh，利用现有的渲染库来高效处理网格渲染。&lt;/p&gt;&#xA;&lt;p&gt;下面是一个 100 MB 以上的快照在我的集成显卡上流畅运行的截图：&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;../images/snapviewer.gif&#34; alt=&#34;snapviewer&#34;&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;实现&#34;&gt;实现&lt;/h2&gt;&#xA;&lt;h3 id=&#34;参考实现&#34;&gt;参考实现&lt;/h3&gt;&#xA;&lt;p&gt;快照格式在 &lt;code&gt;record_memory_history&lt;/code&gt; 函数的&lt;a href=&#34;https://github.com/pytorch/pytorch/blob/main/torch/cuda/memory.py&#34;&gt;docstring&lt;/a&gt;中有部分记录。但这份文档并不完整, 可能是后续commit的人懒得更新docstring了.&lt;/p&gt;&#xA;&lt;p&gt;实际将快照解析为字典的过程发生在&lt;a href=&#34;https://github.com/pytorch/pytorch/blob/main/torch/cuda/_memory_viz.py&#34;&gt;这里&lt;/a&gt;：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;该脚本将分配器跟踪转换为内存时间线，然后传递给网页查看器的 JS 代码。&lt;/li&gt;&#xA;&lt;li&gt;JS 代码进一步将其转换为多边形（表示分配），用于可视化。每个多边形对应一个分配，存储大小和调用栈等细节。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h3 id=&#34;实现快照-反序列化&#34;&gt;实现：快照 (反)序列化&lt;/h3&gt;&#xA;&lt;h4 id=&#34;初始实现&#34;&gt;初始实现&lt;/h4&gt;&#xA;&lt;p&gt;我用 Python 实现这一部分，因为我需要处理 Python 原生数据结构。我只是简单地将字典转换为 JSON 文件。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Lsm Tree 实现备注</title>
      <link>https://da1sy-petals.vercel.app/posts/lsm/</link>
      <pubDate>Sat, 01 Mar 2025 00:00:00 +0000</pubDate>
      <guid>https://da1sy-petals.vercel.app/posts/lsm/</guid>
      <description>&lt;p&gt;Lsm Tree 是一种内存-磁盘的层级式数据结构，常用于实现写多读少的存储引擎。&lt;/p&gt;&#xA;&lt;p&gt;这是我实现 &lt;a href=&#34;https://github.com/Da1sypetals/Lsmkv&#34;&gt;Lsmkv&lt;/a&gt; 的时候记录的备注.&lt;/p&gt;&#xA;&lt;h2 id=&#34;组件&#34;&gt;组件&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;内存部分&lt;/li&gt;&#xA;&lt;li&gt;磁盘部分&lt;/li&gt;&#xA;&lt;li&gt;WAL&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;总体&#34;&gt;总体&lt;/h2&gt;&#xA;&lt;h2 id=&#34;初始化&#34;&gt;初始化&lt;/h2&gt;&#xA;&lt;p&gt;需要 init flush thread。flush thread 的工作流程:&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;等待 flush 信号量被 notify,获取一个 compact 信号量资源&lt;/li&gt;&#xA;&lt;li&gt;启动一个 sstwriter,写入这个 memtable&#xA;&lt;ul&gt;&#xA;&lt;li&gt;一个 memtable 对一个 sst&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;等到写入 sst 写完之后,才进行:&#xA;&lt;ul&gt;&#xA;&lt;li&gt;从 frozen memtables、frozen memtable sizes 里面删除这个 memtable&lt;/li&gt;&#xA;&lt;li&gt;从 wal 里面删除这个 memtable 对应的 wal&lt;/li&gt;&#xA;&lt;li&gt;update manifest&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;try-freeze&#34;&gt;Try Freeze&lt;/h2&gt;&#xA;&lt;p&gt;如果当前大小 &amp;gt; freeze size 那么就 freeze;进一步如果所有 frozen memtable 大小之和 &amp;gt; flush threshold,那么就 set flush signal。&lt;/p&gt;&#xA;&lt;h2 id=&#34;写操作&#34;&gt;写操作&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;写 memtable&lt;/li&gt;&#xA;&lt;li&gt;写 WAL&lt;/li&gt;&#xA;&lt;li&gt;try freeze&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;内存部分&#34;&gt;内存部分&lt;/h2&gt;&#xA;&lt;h3 id=&#34;put&#34;&gt;Put&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;添加到 memtable;&lt;/li&gt;&#xA;&lt;li&gt;更新 size。&#xA;&lt;ul&gt;&#xA;&lt;li&gt;size 不需要特别精确,只需要是一个大致的值即可。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h3 id=&#34;delete&#34;&gt;Delete&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;添加一个 tomb 标记到 memtable&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h3 id=&#34;get&#34;&gt;Get&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;从 active memtable 中获取&lt;/li&gt;&#xA;&lt;li&gt;从 new 到 old 遍历所有的 inactive memtable,获取。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;磁盘部分&#34;&gt;磁盘部分&lt;/h2&gt;&#xA;&lt;h3 id=&#34;compact-信号量&#34;&gt;compact 信号量&lt;/h3&gt;&#xA;&lt;p&gt;二元信号量。&lt;/p&gt;</description>
    </item>
    <item>
      <title>自动求导, 道阻且长</title>
      <link>https://da1sy-petals.vercel.app/posts/road-to-diff/</link>
      <pubDate>Sun, 29 Dec 2024 00:00:00 +0000</pubDate>
      <guid>https://da1sy-petals.vercel.app/posts/road-to-diff/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://github.com/Da1sypetals/Symars&#34;&gt;Symars &lt;/a&gt; Rust代码生成库和 &lt;a href=&#34;https://github.com/Da1sypetals/Raddy&#34;&gt;Raddy&lt;/a&gt; 自动求导库的来龙去脉&lt;/p&gt;&#xA;&lt;h2 id=&#34;故事的起因&#34;&gt;故事的起因：&lt;/h2&gt;&#xA;&lt;p&gt;前段时间读了一些物理模拟的论文，想尝试复现一下。下手点先选了 &lt;a href=&#34;https://graphics.pixar.com/library/StableElasticity/paper.pdf&#34;&gt;stable neo hookean flesh simulation&lt;/a&gt;，但是选了什么并不重要。重要的是，所谓“现代”的物理模拟很多是隐式模拟，需要用牛顿法解一个优化问题。&lt;/p&gt;&#xA;&lt;p&gt;这之中就涉及到了：对能量的本构模型求导数（一阶梯度，二阶 hessian 矩阵）。这之中还涉及到从 &lt;em&gt;小而稠密&lt;/em&gt;  的 hessian 子矩阵组装成 &lt;em&gt;大而稀疏&lt;/em&gt; 的完整 hessian。这是一个精细活，一不小心就会出现极其难以排查的 bug。&lt;/p&gt;&#xA;&lt;p&gt;从 &lt;a href=&#34;https://www.tkim.graphics/DYNAMIC_DEFORMABLES/&#34;&gt;&lt;em&gt;Dynamic Deformables&lt;/em&gt;&lt;/a&gt; 这篇文章中可以看出推导这个公式就要花不少功夫（就算是看懂论文里的 notation 也要好一会儿），于是我搜了搜更多东西，尝试寻找一些其他的解决方法：我不是很想在精细的 debug 上花很多时间。最终找到的解决方法有两种：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;求符号导数，然后进行代码生成；&lt;/li&gt;&#xA;&lt;li&gt;自动求导。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;找到的资料中，前者有 MATLAB 或者 SymPy，后者有 PyTorch 等深度学习库，和更适合的 &lt;a href=&#34;https://github.com/patr-schm/TinyAD&#34;&gt;TinyAD&lt;/a&gt;。&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;为什么说更适合？因为深度学习库的求导是以tensor为单位的，但是我这里的求导需要以单个标量为单位，粒度不同，深度学习库可能会跑出完全没法看的帧率。&lt;/p&gt;&lt;/blockquote&gt;&#xA;&lt;p&gt;但是一个致命的问题来了：上述工具都在 C++ 的工具链上，而我不会 C++（或者，我可能会一点点 C++，但是我不会 CMake，因此不会调包。）&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;我曾经花了三天尝试在项目里用上 Eigen，然后失败告终，还是技术水平太菜了。&lt;/p&gt;&lt;/blockquote&gt;&#xA;&lt;p&gt;我只好换一门我比较熟悉的语言：Rust。这是一切罪恶的开始&amp;hellip;&lt;/p&gt;&#xA;&lt;h2 id=&#34;一条看起来简单的路&#34;&gt;一条看起来简单的路&lt;/h2&gt;&#xA;&lt;p&gt;目前 Rust 还没有一个可以求二阶 hessian 的自动求导库（至少我在 crates.io 没搜到）。&lt;br&gt;&#xA;SymPy 目前还不能生成 Rust 代码（可以，但是有 bug）。&lt;br&gt;&#xA;考虑实现难度我先选了后者：从 SymPy 表达式生成 Rust 代码。于是有了 &lt;a href=&#34;https://github.com/Da1sypetals/Symars&#34;&gt;Symars&lt;/a&gt;。&lt;/p&gt;&#xA;&lt;p&gt;SymPy 提供的访问符号表达式的数据结构是树的形式，节点类型是运算符类型（&lt;code&gt;Add&lt;/code&gt;, &lt;code&gt;Mul&lt;/code&gt;, &lt;code&gt;Div&lt;/code&gt;, &lt;code&gt;Sin&lt;/code&gt;, 等等）或者常数/符号，节点的孩子是 operand 操作数。实现代码生成的思路就是按深度优先遍历树，得到孩子的表达式，然后再根据节点类型得到当前节点的表达式。边界条件是当前节点是常数，或者符号。&lt;/p&gt;</description>
    </item>
    <item>
      <title>共轭梯度：一种高中解析几何的视角</title>
      <link>https://da1sy-petals.vercel.app/posts/conj-grad/</link>
      <pubDate>Sat, 07 Dec 2024 00:00:00 +0000</pubDate>
      <guid>https://da1sy-petals.vercel.app/posts/conj-grad/</guid>
      <description>&lt;p&gt;本文没有任何数学推导。我们从直观上理解这个算法，然后直接介绍算法的流程。希望了解数学推导的读者可以查看 &lt;a href=&#34;https://www.cs.cmu.edu/~quake-papers/painless-conjugate-gradient.pdf&#34;&gt;CMU 的教案&lt;/a&gt;及其&lt;a href=&#34;https://flat2010.github.io/2018/10/26/%E5%85%B1%E8%BD%AD%E6%A2%AF%E5%BA%A6%E6%B3%95%E9%80%9A%E4%BF%97%E8%AE%B2%E4%B9%89/#8-%E5%85%B1%E8%BD%AD%E6%A2%AF%E5%BA%A6%E6%B3%95&#34;&gt;翻译&lt;/a&gt;。&lt;/p&gt;&#xA;&lt;h2 id=&#34;1-问题&#34;&gt;1. 问题&lt;/h2&gt;&#xA;&lt;p&gt;对于实对称矩阵 $A \in \mathbb{R}^{n \times n}$ 和向量 $b \in \mathbb{R}^n$，求解&lt;/p&gt;&#xA;$$Ax = b$$&lt;p&gt;或者，等价的，&lt;/p&gt;&#xA;$$\text{argmin}_x f(x)$$&lt;p&gt;其中&lt;/p&gt;&#xA;$$f(x) = \frac{1}{2}x^T A x - b^T x$$&lt;h2 id=&#34;2-预备知识&#34;&gt;2. 预备知识&lt;/h2&gt;&#xA;&lt;h3 id=&#34;21-从高中学的二级结论说起&#34;&gt;2.1. 从高中学的二级结论说起&lt;/h3&gt;&#xA;&lt;p&gt;高中的时候我们学过椭圆：&lt;/p&gt;&#xA;$$a^{-2}x^2 + b^{-2}y^2 = 1$$&lt;p&gt;如果你记性好的话，你应该记得这个二级结论：&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;../images/2025-10-03-00-44-15.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;这是一个从圆里面推广而来的结论：如果 $a = b$，椭圆退化为圆，$k_{OM}k_l = -1$，即 $OM, l$ 两条直线垂直。&lt;/p&gt;&#xA;&lt;h3 id=&#34;22-最速下降法&#34;&gt;2.2. 最速下降法&lt;/h3&gt;&#xA;&lt;p&gt;首先，你应该知道梯度下降法：&lt;/p&gt;&#xA;$$x_{i+1} = x_i - \alpha\nabla f(x_i)$$&lt;p&gt;最速下降法就是在梯度下降法的基础上，选择 $\alpha$ 使得 $x_{i+1}$ 达到最小（在搜索方向上的最小值）：&lt;/p&gt;&#xA;$$\alpha^* = \text{argmin}_\alpha f(x_i - \alpha\nabla f(x_i))$$&lt;h2 id=&#34;3-共轭梯度法&#34;&gt;3. 共轭梯度法&lt;/h2&gt;&#xA;&lt;h3 id=&#34;31-记号&#34;&gt;3.1. 记号&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;$x_i$：第 $i$ 次循环之后的 $x$ 向量&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
